{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d804ae66-9435-44be-8aad-beacbdeec0f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-18 19:05:34.741245: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-18 19:05:34.767682: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-18 19:05:35.180148: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9901"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['text', 'language', 'sentiment'], dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>language</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6359</th>\n",
       "      <td>اجي هاك الطاجين راك فزت به سربي ما حدو سخون. بالصحة والعافية.</td>\n",
       "      <td>mda</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6360</th>\n",
       "      <td>اخصنى انديروها ابنات ميدالت فالصيف فالمو صمورة متافقين ويشجعون ولداتنا تخيلوها هههههههه</td>\n",
       "      <td>mda</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6361</th>\n",
       "      <td>الفلاح هوا العمود الفقري ديال المغرب تبرك الله عليك الله يعونك</td>\n",
       "      <td>mda</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6362</th>\n",
       "      <td>كاين الخير والأرض خضارت والفلاح نشط مع هاد الأمطار غير كاين سمر والبرد مع الصباح حيت ليالي قريبة والحمد القوي العزيز</td>\n",
       "      <td>mda</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                      text   \n",
       "6359                                                         اجي هاك الطاجين راك فزت به سربي ما حدو سخون. بالصحة والعافية.  \\\n",
       "6360                               اخصنى انديروها ابنات ميدالت فالصيف فالمو صمورة متافقين ويشجعون ولداتنا تخيلوها هههههههه   \n",
       "6361                                                        الفلاح هوا العمود الفقري ديال المغرب تبرك الله عليك الله يعونك   \n",
       "6362  كاين الخير والأرض خضارت والفلاح نشط مع هاد الأمطار غير كاين سمر والبرد مع الصباح حيت ليالي قريبة والحمد القوي العزيز   \n",
       "\n",
       "     language sentiment  \n",
       "6359      mda  positive  \n",
       "6360      mda  positive  \n",
       "6361      mda  positive  \n",
       "6362      mda  positive  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "3542"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "negative    2858\n",
       "positive     684\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'negative', 'positive'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "3542"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', '__index_level_0__'],\n",
       "        num_rows: 2833\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', '__index_level_0__'],\n",
       "        num_rows: 709\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/EgyBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/EgyBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2833 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/709 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='675' max='675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [675/675 01:02, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.605200</td>\n",
       "      <td>0.538191</td>\n",
       "      <td>0.791255</td>\n",
       "      <td>0.441732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.471000</td>\n",
       "      <td>0.432331</td>\n",
       "      <td>0.791255</td>\n",
       "      <td>0.441732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.361800</td>\n",
       "      <td>0.325559</td>\n",
       "      <td>0.895628</td>\n",
       "      <td>0.833543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.281400</td>\n",
       "      <td>0.274424</td>\n",
       "      <td>0.913963</td>\n",
       "      <td>0.863161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.213200</td>\n",
       "      <td>0.282756</td>\n",
       "      <td>0.911142</td>\n",
       "      <td>0.857104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.167400</td>\n",
       "      <td>0.295621</td>\n",
       "      <td>0.888575</td>\n",
       "      <td>0.842322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.190600</td>\n",
       "      <td>0.280131</td>\n",
       "      <td>0.911142</td>\n",
       "      <td>0.863103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.148400</td>\n",
       "      <td>0.339056</td>\n",
       "      <td>0.870240</td>\n",
       "      <td>0.822034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.142100</td>\n",
       "      <td>0.306306</td>\n",
       "      <td>0.888575</td>\n",
       "      <td>0.842322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.104600</td>\n",
       "      <td>0.294955</td>\n",
       "      <td>0.908322</td>\n",
       "      <td>0.854979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.092300</td>\n",
       "      <td>0.310127</td>\n",
       "      <td>0.909732</td>\n",
       "      <td>0.857595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.081100</td>\n",
       "      <td>0.318630</td>\n",
       "      <td>0.912553</td>\n",
       "      <td>0.858979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.064500</td>\n",
       "      <td>0.347082</td>\n",
       "      <td>0.908322</td>\n",
       "      <td>0.855758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.067700</td>\n",
       "      <td>0.347566</td>\n",
       "      <td>0.905501</td>\n",
       "      <td>0.855888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.049200</td>\n",
       "      <td>0.371340</td>\n",
       "      <td>0.904090</td>\n",
       "      <td>0.851084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.058500</td>\n",
       "      <td>0.364028</td>\n",
       "      <td>0.911142</td>\n",
       "      <td>0.857104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.041300</td>\n",
       "      <td>0.379256</td>\n",
       "      <td>0.905501</td>\n",
       "      <td>0.852110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.064400</td>\n",
       "      <td>0.373331</td>\n",
       "      <td>0.899859</td>\n",
       "      <td>0.858290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.039900</td>\n",
       "      <td>0.379972</td>\n",
       "      <td>0.911142</td>\n",
       "      <td>0.854655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.044300</td>\n",
       "      <td>0.431251</td>\n",
       "      <td>0.891396</td>\n",
       "      <td>0.846974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.037600</td>\n",
       "      <td>0.389913</td>\n",
       "      <td>0.912553</td>\n",
       "      <td>0.863508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.037000</td>\n",
       "      <td>0.422894</td>\n",
       "      <td>0.899859</td>\n",
       "      <td>0.853783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.028900</td>\n",
       "      <td>0.407902</td>\n",
       "      <td>0.908322</td>\n",
       "      <td>0.859479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.027600</td>\n",
       "      <td>0.410288</td>\n",
       "      <td>0.904090</td>\n",
       "      <td>0.854105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>0.029900</td>\n",
       "      <td>0.431720</td>\n",
       "      <td>0.897038</td>\n",
       "      <td>0.850355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.032500</td>\n",
       "      <td>0.427332</td>\n",
       "      <td>0.898449</td>\n",
       "      <td>0.847800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>0.024100</td>\n",
       "      <td>0.432521</td>\n",
       "      <td>0.899859</td>\n",
       "      <td>0.851711</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/EgyBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/EgyBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2833 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/709 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='675' max='675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [675/675 01:03, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.607500</td>\n",
       "      <td>0.543277</td>\n",
       "      <td>0.791255</td>\n",
       "      <td>0.441732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.474400</td>\n",
       "      <td>0.419942</td>\n",
       "      <td>0.791255</td>\n",
       "      <td>0.441732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.367800</td>\n",
       "      <td>0.339897</td>\n",
       "      <td>0.857546</td>\n",
       "      <td>0.704804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.299100</td>\n",
       "      <td>0.322764</td>\n",
       "      <td>0.863188</td>\n",
       "      <td>0.816369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.219000</td>\n",
       "      <td>0.274453</td>\n",
       "      <td>0.901269</td>\n",
       "      <td>0.855508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.167100</td>\n",
       "      <td>0.288480</td>\n",
       "      <td>0.897038</td>\n",
       "      <td>0.848964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.189500</td>\n",
       "      <td>0.296384</td>\n",
       "      <td>0.899859</td>\n",
       "      <td>0.849546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.122900</td>\n",
       "      <td>0.340458</td>\n",
       "      <td>0.887165</td>\n",
       "      <td>0.839980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.123500</td>\n",
       "      <td>0.290119</td>\n",
       "      <td>0.912553</td>\n",
       "      <td>0.858979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.098000</td>\n",
       "      <td>0.313028</td>\n",
       "      <td>0.892807</td>\n",
       "      <td>0.847316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.083300</td>\n",
       "      <td>0.287279</td>\n",
       "      <td>0.913963</td>\n",
       "      <td>0.857623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.083700</td>\n",
       "      <td>0.295068</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.866918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.057000</td>\n",
       "      <td>0.332359</td>\n",
       "      <td>0.906911</td>\n",
       "      <td>0.861824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.066200</td>\n",
       "      <td>0.348536</td>\n",
       "      <td>0.905501</td>\n",
       "      <td>0.858022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.051700</td>\n",
       "      <td>0.347251</td>\n",
       "      <td>0.913963</td>\n",
       "      <td>0.863903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.048800</td>\n",
       "      <td>0.363329</td>\n",
       "      <td>0.904090</td>\n",
       "      <td>0.854832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.035500</td>\n",
       "      <td>0.393999</td>\n",
       "      <td>0.899859</td>\n",
       "      <td>0.848803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.067300</td>\n",
       "      <td>0.361788</td>\n",
       "      <td>0.911142</td>\n",
       "      <td>0.860939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.037800</td>\n",
       "      <td>0.377889</td>\n",
       "      <td>0.911142</td>\n",
       "      <td>0.859441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.039000</td>\n",
       "      <td>0.464976</td>\n",
       "      <td>0.881523</td>\n",
       "      <td>0.834124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.041500</td>\n",
       "      <td>0.408528</td>\n",
       "      <td>0.909732</td>\n",
       "      <td>0.859105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.036500</td>\n",
       "      <td>0.451789</td>\n",
       "      <td>0.892807</td>\n",
       "      <td>0.840889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.030100</td>\n",
       "      <td>0.439487</td>\n",
       "      <td>0.902680</td>\n",
       "      <td>0.851586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.027300</td>\n",
       "      <td>0.457749</td>\n",
       "      <td>0.891396</td>\n",
       "      <td>0.841427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>0.031900</td>\n",
       "      <td>0.443373</td>\n",
       "      <td>0.899859</td>\n",
       "      <td>0.848803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.030300</td>\n",
       "      <td>0.437060</td>\n",
       "      <td>0.902680</td>\n",
       "      <td>0.850831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>0.028100</td>\n",
       "      <td>0.445980</td>\n",
       "      <td>0.901269</td>\n",
       "      <td>0.849814</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/EgyBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/EgyBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2833 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/709 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='675' max='675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [675/675 01:03, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.607500</td>\n",
       "      <td>0.543277</td>\n",
       "      <td>0.791255</td>\n",
       "      <td>0.441732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.474400</td>\n",
       "      <td>0.419942</td>\n",
       "      <td>0.791255</td>\n",
       "      <td>0.441732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.367800</td>\n",
       "      <td>0.339897</td>\n",
       "      <td>0.857546</td>\n",
       "      <td>0.704804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.299100</td>\n",
       "      <td>0.322764</td>\n",
       "      <td>0.863188</td>\n",
       "      <td>0.816369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.219000</td>\n",
       "      <td>0.274453</td>\n",
       "      <td>0.901269</td>\n",
       "      <td>0.855508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.167100</td>\n",
       "      <td>0.288480</td>\n",
       "      <td>0.897038</td>\n",
       "      <td>0.848964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.189500</td>\n",
       "      <td>0.296384</td>\n",
       "      <td>0.899859</td>\n",
       "      <td>0.849546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.122900</td>\n",
       "      <td>0.340458</td>\n",
       "      <td>0.887165</td>\n",
       "      <td>0.839980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.123500</td>\n",
       "      <td>0.290119</td>\n",
       "      <td>0.912553</td>\n",
       "      <td>0.858979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.098000</td>\n",
       "      <td>0.313028</td>\n",
       "      <td>0.892807</td>\n",
       "      <td>0.847316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.083300</td>\n",
       "      <td>0.287279</td>\n",
       "      <td>0.913963</td>\n",
       "      <td>0.857623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.083700</td>\n",
       "      <td>0.295068</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.866918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.057000</td>\n",
       "      <td>0.332359</td>\n",
       "      <td>0.906911</td>\n",
       "      <td>0.861824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.066200</td>\n",
       "      <td>0.348536</td>\n",
       "      <td>0.905501</td>\n",
       "      <td>0.858022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.051700</td>\n",
       "      <td>0.347251</td>\n",
       "      <td>0.913963</td>\n",
       "      <td>0.863903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.048800</td>\n",
       "      <td>0.363329</td>\n",
       "      <td>0.904090</td>\n",
       "      <td>0.854832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.035500</td>\n",
       "      <td>0.393999</td>\n",
       "      <td>0.899859</td>\n",
       "      <td>0.848803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.067300</td>\n",
       "      <td>0.361788</td>\n",
       "      <td>0.911142</td>\n",
       "      <td>0.860939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.037800</td>\n",
       "      <td>0.377889</td>\n",
       "      <td>0.911142</td>\n",
       "      <td>0.859441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.039000</td>\n",
       "      <td>0.464976</td>\n",
       "      <td>0.881523</td>\n",
       "      <td>0.834124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.041500</td>\n",
       "      <td>0.408528</td>\n",
       "      <td>0.909732</td>\n",
       "      <td>0.859105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.036500</td>\n",
       "      <td>0.451789</td>\n",
       "      <td>0.892807</td>\n",
       "      <td>0.840889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.030100</td>\n",
       "      <td>0.439487</td>\n",
       "      <td>0.902680</td>\n",
       "      <td>0.851586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.027300</td>\n",
       "      <td>0.457749</td>\n",
       "      <td>0.891396</td>\n",
       "      <td>0.841427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>0.031900</td>\n",
       "      <td>0.443373</td>\n",
       "      <td>0.899859</td>\n",
       "      <td>0.848803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.030300</td>\n",
       "      <td>0.437060</td>\n",
       "      <td>0.902680</td>\n",
       "      <td>0.850831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>0.028100</td>\n",
       "      <td>0.445980</td>\n",
       "      <td>0.901269</td>\n",
       "      <td>0.849814</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/EgyBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/EgyBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2833 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/709 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='675' max='675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [675/675 01:02, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.616500</td>\n",
       "      <td>0.533799</td>\n",
       "      <td>0.803949</td>\n",
       "      <td>0.445661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.481300</td>\n",
       "      <td>0.469645</td>\n",
       "      <td>0.803949</td>\n",
       "      <td>0.445661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.464100</td>\n",
       "      <td>0.442207</td>\n",
       "      <td>0.803949</td>\n",
       "      <td>0.445661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.421800</td>\n",
       "      <td>0.388369</td>\n",
       "      <td>0.803949</td>\n",
       "      <td>0.445661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.379600</td>\n",
       "      <td>0.391619</td>\n",
       "      <td>0.803949</td>\n",
       "      <td>0.452668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.367400</td>\n",
       "      <td>0.352525</td>\n",
       "      <td>0.885755</td>\n",
       "      <td>0.777962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.302000</td>\n",
       "      <td>0.315889</td>\n",
       "      <td>0.904090</td>\n",
       "      <td>0.831695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.250600</td>\n",
       "      <td>0.318600</td>\n",
       "      <td>0.882934</td>\n",
       "      <td>0.813809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.253000</td>\n",
       "      <td>0.340805</td>\n",
       "      <td>0.870240</td>\n",
       "      <td>0.811837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.228700</td>\n",
       "      <td>0.364316</td>\n",
       "      <td>0.858956</td>\n",
       "      <td>0.804980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.187800</td>\n",
       "      <td>0.290158</td>\n",
       "      <td>0.902680</td>\n",
       "      <td>0.840813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.186100</td>\n",
       "      <td>0.281681</td>\n",
       "      <td>0.911142</td>\n",
       "      <td>0.846548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.197200</td>\n",
       "      <td>0.270690</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.857192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.155000</td>\n",
       "      <td>0.282321</td>\n",
       "      <td>0.913963</td>\n",
       "      <td>0.849508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.147600</td>\n",
       "      <td>0.305570</td>\n",
       "      <td>0.898449</td>\n",
       "      <td>0.841493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.182400</td>\n",
       "      <td>0.293288</td>\n",
       "      <td>0.906911</td>\n",
       "      <td>0.851538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.134500</td>\n",
       "      <td>0.312180</td>\n",
       "      <td>0.904090</td>\n",
       "      <td>0.850299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.109400</td>\n",
       "      <td>0.329306</td>\n",
       "      <td>0.899859</td>\n",
       "      <td>0.844918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.138800</td>\n",
       "      <td>0.326092</td>\n",
       "      <td>0.904090</td>\n",
       "      <td>0.843569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.153400</td>\n",
       "      <td>0.337435</td>\n",
       "      <td>0.901269</td>\n",
       "      <td>0.842540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.160800</td>\n",
       "      <td>0.338057</td>\n",
       "      <td>0.902680</td>\n",
       "      <td>0.835041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.173100</td>\n",
       "      <td>0.347793</td>\n",
       "      <td>0.894217</td>\n",
       "      <td>0.836181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.121100</td>\n",
       "      <td>0.352188</td>\n",
       "      <td>0.897038</td>\n",
       "      <td>0.843769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.106400</td>\n",
       "      <td>0.358424</td>\n",
       "      <td>0.897038</td>\n",
       "      <td>0.842982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>0.085700</td>\n",
       "      <td>0.375747</td>\n",
       "      <td>0.895628</td>\n",
       "      <td>0.842803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.097400</td>\n",
       "      <td>0.380568</td>\n",
       "      <td>0.895628</td>\n",
       "      <td>0.843572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>0.103700</td>\n",
       "      <td>0.371274</td>\n",
       "      <td>0.897038</td>\n",
       "      <td>0.842982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/EgyBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/EgyBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2833 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/709 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='675' max='675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [675/675 01:02, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.616500</td>\n",
       "      <td>0.533799</td>\n",
       "      <td>0.803949</td>\n",
       "      <td>0.445661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.481300</td>\n",
       "      <td>0.469645</td>\n",
       "      <td>0.803949</td>\n",
       "      <td>0.445661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.464100</td>\n",
       "      <td>0.442207</td>\n",
       "      <td>0.803949</td>\n",
       "      <td>0.445661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.421800</td>\n",
       "      <td>0.388369</td>\n",
       "      <td>0.803949</td>\n",
       "      <td>0.445661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.379600</td>\n",
       "      <td>0.391619</td>\n",
       "      <td>0.803949</td>\n",
       "      <td>0.452668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.367400</td>\n",
       "      <td>0.352525</td>\n",
       "      <td>0.885755</td>\n",
       "      <td>0.777962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.302000</td>\n",
       "      <td>0.315889</td>\n",
       "      <td>0.904090</td>\n",
       "      <td>0.831695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.250600</td>\n",
       "      <td>0.318600</td>\n",
       "      <td>0.882934</td>\n",
       "      <td>0.813809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.253000</td>\n",
       "      <td>0.340805</td>\n",
       "      <td>0.870240</td>\n",
       "      <td>0.811837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.228700</td>\n",
       "      <td>0.364316</td>\n",
       "      <td>0.858956</td>\n",
       "      <td>0.804980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.187800</td>\n",
       "      <td>0.290158</td>\n",
       "      <td>0.902680</td>\n",
       "      <td>0.840813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.186100</td>\n",
       "      <td>0.281681</td>\n",
       "      <td>0.911142</td>\n",
       "      <td>0.846548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.197200</td>\n",
       "      <td>0.270690</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.857192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.155000</td>\n",
       "      <td>0.282321</td>\n",
       "      <td>0.913963</td>\n",
       "      <td>0.849508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.147600</td>\n",
       "      <td>0.305570</td>\n",
       "      <td>0.898449</td>\n",
       "      <td>0.841493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.182400</td>\n",
       "      <td>0.293288</td>\n",
       "      <td>0.906911</td>\n",
       "      <td>0.851538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.134500</td>\n",
       "      <td>0.312180</td>\n",
       "      <td>0.904090</td>\n",
       "      <td>0.850299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.109400</td>\n",
       "      <td>0.329306</td>\n",
       "      <td>0.899859</td>\n",
       "      <td>0.844918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.138800</td>\n",
       "      <td>0.326092</td>\n",
       "      <td>0.904090</td>\n",
       "      <td>0.843569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.153400</td>\n",
       "      <td>0.337435</td>\n",
       "      <td>0.901269</td>\n",
       "      <td>0.842540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.160800</td>\n",
       "      <td>0.338057</td>\n",
       "      <td>0.902680</td>\n",
       "      <td>0.835041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.173100</td>\n",
       "      <td>0.347793</td>\n",
       "      <td>0.894217</td>\n",
       "      <td>0.836181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.121100</td>\n",
       "      <td>0.352188</td>\n",
       "      <td>0.897038</td>\n",
       "      <td>0.843769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.106400</td>\n",
       "      <td>0.358424</td>\n",
       "      <td>0.897038</td>\n",
       "      <td>0.842982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>0.085700</td>\n",
       "      <td>0.375747</td>\n",
       "      <td>0.895628</td>\n",
       "      <td>0.842803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.097400</td>\n",
       "      <td>0.380568</td>\n",
       "      <td>0.895628</td>\n",
       "      <td>0.843572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>0.103700</td>\n",
       "      <td>0.371274</td>\n",
       "      <td>0.897038</td>\n",
       "      <td>0.842982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/EgyBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/EgyBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2833 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/709 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='675' max='675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [675/675 01:03, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.616500</td>\n",
       "      <td>0.533799</td>\n",
       "      <td>0.803949</td>\n",
       "      <td>0.445661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.481300</td>\n",
       "      <td>0.469645</td>\n",
       "      <td>0.803949</td>\n",
       "      <td>0.445661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.464100</td>\n",
       "      <td>0.442207</td>\n",
       "      <td>0.803949</td>\n",
       "      <td>0.445661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.421800</td>\n",
       "      <td>0.388369</td>\n",
       "      <td>0.803949</td>\n",
       "      <td>0.445661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.379600</td>\n",
       "      <td>0.391619</td>\n",
       "      <td>0.803949</td>\n",
       "      <td>0.452668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.367400</td>\n",
       "      <td>0.352525</td>\n",
       "      <td>0.885755</td>\n",
       "      <td>0.777962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.302000</td>\n",
       "      <td>0.315889</td>\n",
       "      <td>0.904090</td>\n",
       "      <td>0.831695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.250600</td>\n",
       "      <td>0.318600</td>\n",
       "      <td>0.882934</td>\n",
       "      <td>0.813809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.253000</td>\n",
       "      <td>0.340805</td>\n",
       "      <td>0.870240</td>\n",
       "      <td>0.811837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.228700</td>\n",
       "      <td>0.364316</td>\n",
       "      <td>0.858956</td>\n",
       "      <td>0.804980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.187800</td>\n",
       "      <td>0.290158</td>\n",
       "      <td>0.902680</td>\n",
       "      <td>0.840813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.186100</td>\n",
       "      <td>0.281681</td>\n",
       "      <td>0.911142</td>\n",
       "      <td>0.846548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.197200</td>\n",
       "      <td>0.270690</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.857192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.155000</td>\n",
       "      <td>0.282321</td>\n",
       "      <td>0.913963</td>\n",
       "      <td>0.849508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.147600</td>\n",
       "      <td>0.305570</td>\n",
       "      <td>0.898449</td>\n",
       "      <td>0.841493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.182400</td>\n",
       "      <td>0.293288</td>\n",
       "      <td>0.906911</td>\n",
       "      <td>0.851538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.134500</td>\n",
       "      <td>0.312180</td>\n",
       "      <td>0.904090</td>\n",
       "      <td>0.850299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.109400</td>\n",
       "      <td>0.329306</td>\n",
       "      <td>0.899859</td>\n",
       "      <td>0.844918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.138800</td>\n",
       "      <td>0.326092</td>\n",
       "      <td>0.904090</td>\n",
       "      <td>0.843569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.153400</td>\n",
       "      <td>0.337435</td>\n",
       "      <td>0.901269</td>\n",
       "      <td>0.842540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.160800</td>\n",
       "      <td>0.338057</td>\n",
       "      <td>0.902680</td>\n",
       "      <td>0.835041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.173100</td>\n",
       "      <td>0.347793</td>\n",
       "      <td>0.894217</td>\n",
       "      <td>0.836181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.121100</td>\n",
       "      <td>0.352188</td>\n",
       "      <td>0.897038</td>\n",
       "      <td>0.843769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.106400</td>\n",
       "      <td>0.358424</td>\n",
       "      <td>0.897038</td>\n",
       "      <td>0.842982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>0.085700</td>\n",
       "      <td>0.375747</td>\n",
       "      <td>0.895628</td>\n",
       "      <td>0.842803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.097400</td>\n",
       "      <td>0.380568</td>\n",
       "      <td>0.895628</td>\n",
       "      <td>0.843572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>0.103700</td>\n",
       "      <td>0.371274</td>\n",
       "      <td>0.897038</td>\n",
       "      <td>0.842982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/EgyBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/EgyBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2833 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/709 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='675' max='675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [675/675 01:02, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.611800</td>\n",
       "      <td>0.527392</td>\n",
       "      <td>0.812412</td>\n",
       "      <td>0.448249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.474800</td>\n",
       "      <td>0.411294</td>\n",
       "      <td>0.812412</td>\n",
       "      <td>0.448249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.369500</td>\n",
       "      <td>0.328091</td>\n",
       "      <td>0.877292</td>\n",
       "      <td>0.734447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.287700</td>\n",
       "      <td>0.299763</td>\n",
       "      <td>0.913963</td>\n",
       "      <td>0.835293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.229200</td>\n",
       "      <td>0.278529</td>\n",
       "      <td>0.901269</td>\n",
       "      <td>0.838968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.195900</td>\n",
       "      <td>0.255109</td>\n",
       "      <td>0.923836</td>\n",
       "      <td>0.865471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.150300</td>\n",
       "      <td>0.249641</td>\n",
       "      <td>0.925247</td>\n",
       "      <td>0.874819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.128600</td>\n",
       "      <td>0.273066</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.849531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.109900</td>\n",
       "      <td>0.261265</td>\n",
       "      <td>0.923836</td>\n",
       "      <td>0.872073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.098200</td>\n",
       "      <td>0.284544</td>\n",
       "      <td>0.913963</td>\n",
       "      <td>0.860863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.093900</td>\n",
       "      <td>0.262832</td>\n",
       "      <td>0.921016</td>\n",
       "      <td>0.871906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.095700</td>\n",
       "      <td>0.275679</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.866918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.080500</td>\n",
       "      <td>0.270847</td>\n",
       "      <td>0.925247</td>\n",
       "      <td>0.874062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.059100</td>\n",
       "      <td>0.278170</td>\n",
       "      <td>0.925247</td>\n",
       "      <td>0.872510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.050300</td>\n",
       "      <td>0.298283</td>\n",
       "      <td>0.921016</td>\n",
       "      <td>0.868128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.067400</td>\n",
       "      <td>0.300634</td>\n",
       "      <td>0.921016</td>\n",
       "      <td>0.868128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.045500</td>\n",
       "      <td>0.320462</td>\n",
       "      <td>0.913963</td>\n",
       "      <td>0.859269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.047100</td>\n",
       "      <td>0.310491</td>\n",
       "      <td>0.923836</td>\n",
       "      <td>0.870505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.039900</td>\n",
       "      <td>0.338576</td>\n",
       "      <td>0.913963</td>\n",
       "      <td>0.861641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.040100</td>\n",
       "      <td>0.321763</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.861762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.026600</td>\n",
       "      <td>0.350833</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.861176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.026600</td>\n",
       "      <td>0.354762</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.861762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.026100</td>\n",
       "      <td>0.366368</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.861762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.018000</td>\n",
       "      <td>0.378360</td>\n",
       "      <td>0.909732</td>\n",
       "      <td>0.851058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>0.018700</td>\n",
       "      <td>0.382933</td>\n",
       "      <td>0.912553</td>\n",
       "      <td>0.858979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.019400</td>\n",
       "      <td>0.385602</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.860647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>0.028300</td>\n",
       "      <td>0.386809</td>\n",
       "      <td>0.912553</td>\n",
       "      <td>0.854863</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/EgyBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/EgyBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2833 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/709 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='675' max='675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [675/675 01:03, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.611800</td>\n",
       "      <td>0.527392</td>\n",
       "      <td>0.812412</td>\n",
       "      <td>0.448249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.474800</td>\n",
       "      <td>0.411294</td>\n",
       "      <td>0.812412</td>\n",
       "      <td>0.448249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.369500</td>\n",
       "      <td>0.328091</td>\n",
       "      <td>0.877292</td>\n",
       "      <td>0.734447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.287700</td>\n",
       "      <td>0.299763</td>\n",
       "      <td>0.913963</td>\n",
       "      <td>0.835293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.229200</td>\n",
       "      <td>0.278529</td>\n",
       "      <td>0.901269</td>\n",
       "      <td>0.838968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.195900</td>\n",
       "      <td>0.255109</td>\n",
       "      <td>0.923836</td>\n",
       "      <td>0.865471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.150300</td>\n",
       "      <td>0.249641</td>\n",
       "      <td>0.925247</td>\n",
       "      <td>0.874819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.128600</td>\n",
       "      <td>0.273066</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.849531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.109900</td>\n",
       "      <td>0.261265</td>\n",
       "      <td>0.923836</td>\n",
       "      <td>0.872073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.098200</td>\n",
       "      <td>0.284544</td>\n",
       "      <td>0.913963</td>\n",
       "      <td>0.860863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.093900</td>\n",
       "      <td>0.262832</td>\n",
       "      <td>0.921016</td>\n",
       "      <td>0.871906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.095700</td>\n",
       "      <td>0.275679</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.866918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.080500</td>\n",
       "      <td>0.270847</td>\n",
       "      <td>0.925247</td>\n",
       "      <td>0.874062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.059100</td>\n",
       "      <td>0.278170</td>\n",
       "      <td>0.925247</td>\n",
       "      <td>0.872510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.050300</td>\n",
       "      <td>0.298283</td>\n",
       "      <td>0.921016</td>\n",
       "      <td>0.868128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.067400</td>\n",
       "      <td>0.300634</td>\n",
       "      <td>0.921016</td>\n",
       "      <td>0.868128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.045500</td>\n",
       "      <td>0.320462</td>\n",
       "      <td>0.913963</td>\n",
       "      <td>0.859269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.047100</td>\n",
       "      <td>0.310491</td>\n",
       "      <td>0.923836</td>\n",
       "      <td>0.870505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.039900</td>\n",
       "      <td>0.338576</td>\n",
       "      <td>0.913963</td>\n",
       "      <td>0.861641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.040100</td>\n",
       "      <td>0.321763</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.861762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.026600</td>\n",
       "      <td>0.350833</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.861176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.026600</td>\n",
       "      <td>0.354762</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.861762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.026100</td>\n",
       "      <td>0.366368</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.861762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.018000</td>\n",
       "      <td>0.378360</td>\n",
       "      <td>0.909732</td>\n",
       "      <td>0.851058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>0.018700</td>\n",
       "      <td>0.382933</td>\n",
       "      <td>0.912553</td>\n",
       "      <td>0.858979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.019400</td>\n",
       "      <td>0.385602</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.860647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>0.028300</td>\n",
       "      <td>0.386809</td>\n",
       "      <td>0.912553</td>\n",
       "      <td>0.854863</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/EgyBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/EgyBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7229d3473fe54afca967c0a89a7517e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2833 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62f1ac7e77a34e47bae5ab33390b6dae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/709 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='675' max='675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [675/675 01:03, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.611800</td>\n",
       "      <td>0.527392</td>\n",
       "      <td>0.812412</td>\n",
       "      <td>0.448249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.474800</td>\n",
       "      <td>0.411294</td>\n",
       "      <td>0.812412</td>\n",
       "      <td>0.448249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.369500</td>\n",
       "      <td>0.328091</td>\n",
       "      <td>0.877292</td>\n",
       "      <td>0.734447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.287700</td>\n",
       "      <td>0.299763</td>\n",
       "      <td>0.913963</td>\n",
       "      <td>0.835293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.229200</td>\n",
       "      <td>0.278529</td>\n",
       "      <td>0.901269</td>\n",
       "      <td>0.838968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.195900</td>\n",
       "      <td>0.255109</td>\n",
       "      <td>0.923836</td>\n",
       "      <td>0.865471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.150300</td>\n",
       "      <td>0.249641</td>\n",
       "      <td>0.925247</td>\n",
       "      <td>0.874819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.128600</td>\n",
       "      <td>0.273066</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.849531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.109900</td>\n",
       "      <td>0.261265</td>\n",
       "      <td>0.923836</td>\n",
       "      <td>0.872073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.098200</td>\n",
       "      <td>0.284544</td>\n",
       "      <td>0.913963</td>\n",
       "      <td>0.860863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.093900</td>\n",
       "      <td>0.262832</td>\n",
       "      <td>0.921016</td>\n",
       "      <td>0.871906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.095700</td>\n",
       "      <td>0.275679</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.866918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.080500</td>\n",
       "      <td>0.270847</td>\n",
       "      <td>0.925247</td>\n",
       "      <td>0.874062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.059100</td>\n",
       "      <td>0.278170</td>\n",
       "      <td>0.925247</td>\n",
       "      <td>0.872510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.050300</td>\n",
       "      <td>0.298283</td>\n",
       "      <td>0.921016</td>\n",
       "      <td>0.868128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.067400</td>\n",
       "      <td>0.300634</td>\n",
       "      <td>0.921016</td>\n",
       "      <td>0.868128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.045500</td>\n",
       "      <td>0.320462</td>\n",
       "      <td>0.913963</td>\n",
       "      <td>0.859269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.047100</td>\n",
       "      <td>0.310491</td>\n",
       "      <td>0.923836</td>\n",
       "      <td>0.870505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.039900</td>\n",
       "      <td>0.338576</td>\n",
       "      <td>0.913963</td>\n",
       "      <td>0.861641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.040100</td>\n",
       "      <td>0.321763</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.861762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.026600</td>\n",
       "      <td>0.350833</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.861176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.026600</td>\n",
       "      <td>0.354762</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.861762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.026100</td>\n",
       "      <td>0.366368</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.861762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.018000</td>\n",
       "      <td>0.378360</td>\n",
       "      <td>0.909732</td>\n",
       "      <td>0.851058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>0.018700</td>\n",
       "      <td>0.382933</td>\n",
       "      <td>0.912553</td>\n",
       "      <td>0.858979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.019400</td>\n",
       "      <td>0.385602</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.860647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>0.028300</td>\n",
       "      <td>0.386809</td>\n",
       "      <td>0.912553</td>\n",
       "      <td>0.854863</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', '__index_level_0__'],\n",
       "        num_rows: 2833\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', '__index_level_0__'],\n",
       "        num_rows: 709\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7d7cf30e7a2438a811667e796b42771",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2833 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62e5c4cb2def42209f6fcd233c76d1a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/709 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='675' max='675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [675/675 01:03, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.324300</td>\n",
       "      <td>0.264752</td>\n",
       "      <td>0.891396</td>\n",
       "      <td>0.842873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.223900</td>\n",
       "      <td>0.268159</td>\n",
       "      <td>0.911142</td>\n",
       "      <td>0.857895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.132600</td>\n",
       "      <td>0.247118</td>\n",
       "      <td>0.905501</td>\n",
       "      <td>0.856610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.083200</td>\n",
       "      <td>0.419000</td>\n",
       "      <td>0.901269</td>\n",
       "      <td>0.824455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.061300</td>\n",
       "      <td>0.492869</td>\n",
       "      <td>0.868829</td>\n",
       "      <td>0.823941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.045400</td>\n",
       "      <td>0.389023</td>\n",
       "      <td>0.912553</td>\n",
       "      <td>0.861296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.026500</td>\n",
       "      <td>0.444023</td>\n",
       "      <td>0.912553</td>\n",
       "      <td>0.867641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.018600</td>\n",
       "      <td>0.426611</td>\n",
       "      <td>0.909732</td>\n",
       "      <td>0.865366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.008600</td>\n",
       "      <td>0.557660</td>\n",
       "      <td>0.895628</td>\n",
       "      <td>0.852620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>0.531647</td>\n",
       "      <td>0.912553</td>\n",
       "      <td>0.864223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>0.572419</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.869285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.628702</td>\n",
       "      <td>0.904090</td>\n",
       "      <td>0.856255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.619032</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.866495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.630629</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.866495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.638293</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.866177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.645012</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.866177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.650903</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.866177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.660173</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.866495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.666664</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.866495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.669563</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.866495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.671422</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.866495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.673506</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.868365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.677283</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.868365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.679218</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.868365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.680420</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.868365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.681508</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.868365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.684813</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.866495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "127c3d791f8248258aaf7327b5c614df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2833 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2aa6b0c2d0d94bc5b2814a17b52603f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/709 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='675' max='675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [675/675 01:03, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.324300</td>\n",
       "      <td>0.264752</td>\n",
       "      <td>0.891396</td>\n",
       "      <td>0.842873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.223900</td>\n",
       "      <td>0.268159</td>\n",
       "      <td>0.911142</td>\n",
       "      <td>0.857895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.132600</td>\n",
       "      <td>0.247118</td>\n",
       "      <td>0.905501</td>\n",
       "      <td>0.856610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.083200</td>\n",
       "      <td>0.419000</td>\n",
       "      <td>0.901269</td>\n",
       "      <td>0.824455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.061300</td>\n",
       "      <td>0.492869</td>\n",
       "      <td>0.868829</td>\n",
       "      <td>0.823941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.045400</td>\n",
       "      <td>0.389023</td>\n",
       "      <td>0.912553</td>\n",
       "      <td>0.861296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.026500</td>\n",
       "      <td>0.444023</td>\n",
       "      <td>0.912553</td>\n",
       "      <td>0.867641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.018600</td>\n",
       "      <td>0.426611</td>\n",
       "      <td>0.909732</td>\n",
       "      <td>0.865366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.008600</td>\n",
       "      <td>0.557660</td>\n",
       "      <td>0.895628</td>\n",
       "      <td>0.852620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>0.531647</td>\n",
       "      <td>0.912553</td>\n",
       "      <td>0.864223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>0.572419</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.869285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.628702</td>\n",
       "      <td>0.904090</td>\n",
       "      <td>0.856255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.619032</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.866495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.630629</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.866495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.638293</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.866177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.645012</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.866177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.650903</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.866177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.660173</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.866495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.666664</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.866495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.669563</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.866495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.671422</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.866495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.673506</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.868365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.677283</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.868365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.679218</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.868365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.680420</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.868365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.681508</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.868365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.684813</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.866495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc94b64f1c0246d29b3df555d3570c34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2833 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab8d3b3a890448b88c18014b8c259a19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/709 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='675' max='675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [675/675 01:03, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.324300</td>\n",
       "      <td>0.264752</td>\n",
       "      <td>0.891396</td>\n",
       "      <td>0.842873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.223900</td>\n",
       "      <td>0.268159</td>\n",
       "      <td>0.911142</td>\n",
       "      <td>0.857895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.132600</td>\n",
       "      <td>0.247118</td>\n",
       "      <td>0.905501</td>\n",
       "      <td>0.856610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.083200</td>\n",
       "      <td>0.419000</td>\n",
       "      <td>0.901269</td>\n",
       "      <td>0.824455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.061300</td>\n",
       "      <td>0.492869</td>\n",
       "      <td>0.868829</td>\n",
       "      <td>0.823941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.045400</td>\n",
       "      <td>0.389023</td>\n",
       "      <td>0.912553</td>\n",
       "      <td>0.861296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.026500</td>\n",
       "      <td>0.444023</td>\n",
       "      <td>0.912553</td>\n",
       "      <td>0.867641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.018600</td>\n",
       "      <td>0.426611</td>\n",
       "      <td>0.909732</td>\n",
       "      <td>0.865366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.008600</td>\n",
       "      <td>0.557660</td>\n",
       "      <td>0.895628</td>\n",
       "      <td>0.852620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>0.531647</td>\n",
       "      <td>0.912553</td>\n",
       "      <td>0.864223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>0.572419</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.869285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.628702</td>\n",
       "      <td>0.904090</td>\n",
       "      <td>0.856255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.619032</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.866495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.630629</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.866495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.638293</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.866177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.645012</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.866177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.650903</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.866177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.660173</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.866495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.666664</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.866495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.669563</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.866495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.671422</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.866495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.673506</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.868365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.677283</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.868365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.679218</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.868365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.680420</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.868365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.681508</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.868365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.684813</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.866495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa1a8d79801542dabb1db7c3a122cccc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2833 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d5b81ce963d4fadb55c0c45401011ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/709 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='675' max='675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [675/675 01:02, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.341200</td>\n",
       "      <td>0.289561</td>\n",
       "      <td>0.892807</td>\n",
       "      <td>0.839344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.249600</td>\n",
       "      <td>0.242334</td>\n",
       "      <td>0.925247</td>\n",
       "      <td>0.872510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.165900</td>\n",
       "      <td>0.244528</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.856291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.132700</td>\n",
       "      <td>0.268275</td>\n",
       "      <td>0.912553</td>\n",
       "      <td>0.861296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.050900</td>\n",
       "      <td>0.468764</td>\n",
       "      <td>0.913963</td>\n",
       "      <td>0.846516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.064500</td>\n",
       "      <td>0.366726</td>\n",
       "      <td>0.904090</td>\n",
       "      <td>0.854105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.033000</td>\n",
       "      <td>0.470076</td>\n",
       "      <td>0.909732</td>\n",
       "      <td>0.847461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.025400</td>\n",
       "      <td>0.451247</td>\n",
       "      <td>0.913963</td>\n",
       "      <td>0.863161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.008800</td>\n",
       "      <td>0.504997</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.856117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.009500</td>\n",
       "      <td>0.527810</td>\n",
       "      <td>0.909732</td>\n",
       "      <td>0.853607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.008200</td>\n",
       "      <td>0.545923</td>\n",
       "      <td>0.912553</td>\n",
       "      <td>0.851320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>0.543748</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.869769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.007300</td>\n",
       "      <td>0.592078</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.858709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.581061</td>\n",
       "      <td>0.912553</td>\n",
       "      <td>0.863508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.586272</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.868077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.613402</td>\n",
       "      <td>0.911142</td>\n",
       "      <td>0.853812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.609088</td>\n",
       "      <td>0.919605</td>\n",
       "      <td>0.869248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>0.684218</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.861762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.703157</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.860049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.624813</td>\n",
       "      <td>0.919605</td>\n",
       "      <td>0.872134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>0.626487</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.868811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.613026</td>\n",
       "      <td>0.921016</td>\n",
       "      <td>0.874032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.613793</td>\n",
       "      <td>0.921016</td>\n",
       "      <td>0.874032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.615436</td>\n",
       "      <td>0.921016</td>\n",
       "      <td>0.874032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.616782</td>\n",
       "      <td>0.921016</td>\n",
       "      <td>0.874032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.617845</td>\n",
       "      <td>0.921016</td>\n",
       "      <td>0.874032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.618425</td>\n",
       "      <td>0.921016</td>\n",
       "      <td>0.874032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6645e9c46414ec69e059863e9bd71ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2833 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f283bb4e194f4842ab18723ebe7eded5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/709 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='675' max='675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [675/675 01:02, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.341200</td>\n",
       "      <td>0.289561</td>\n",
       "      <td>0.892807</td>\n",
       "      <td>0.839344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.249600</td>\n",
       "      <td>0.242334</td>\n",
       "      <td>0.925247</td>\n",
       "      <td>0.872510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.165900</td>\n",
       "      <td>0.244528</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.856291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.132700</td>\n",
       "      <td>0.268275</td>\n",
       "      <td>0.912553</td>\n",
       "      <td>0.861296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.050900</td>\n",
       "      <td>0.468764</td>\n",
       "      <td>0.913963</td>\n",
       "      <td>0.846516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.064500</td>\n",
       "      <td>0.366726</td>\n",
       "      <td>0.904090</td>\n",
       "      <td>0.854105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.033000</td>\n",
       "      <td>0.470076</td>\n",
       "      <td>0.909732</td>\n",
       "      <td>0.847461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.025400</td>\n",
       "      <td>0.451247</td>\n",
       "      <td>0.913963</td>\n",
       "      <td>0.863161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.008800</td>\n",
       "      <td>0.504997</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.856117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.009500</td>\n",
       "      <td>0.527810</td>\n",
       "      <td>0.909732</td>\n",
       "      <td>0.853607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.008200</td>\n",
       "      <td>0.545923</td>\n",
       "      <td>0.912553</td>\n",
       "      <td>0.851320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>0.543748</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.869769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.007300</td>\n",
       "      <td>0.592078</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.858709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.581061</td>\n",
       "      <td>0.912553</td>\n",
       "      <td>0.863508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.586272</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.868077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.613402</td>\n",
       "      <td>0.911142</td>\n",
       "      <td>0.853812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.609088</td>\n",
       "      <td>0.919605</td>\n",
       "      <td>0.869248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>0.684218</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.861762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.703157</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.860049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.624813</td>\n",
       "      <td>0.919605</td>\n",
       "      <td>0.872134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>0.626487</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.868811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.613026</td>\n",
       "      <td>0.921016</td>\n",
       "      <td>0.874032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.613793</td>\n",
       "      <td>0.921016</td>\n",
       "      <td>0.874032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.615436</td>\n",
       "      <td>0.921016</td>\n",
       "      <td>0.874032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.616782</td>\n",
       "      <td>0.921016</td>\n",
       "      <td>0.874032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.617845</td>\n",
       "      <td>0.921016</td>\n",
       "      <td>0.874032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.618425</td>\n",
       "      <td>0.921016</td>\n",
       "      <td>0.874032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1639f81852ad4969a3fe35c4a7d132d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2833 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "549547a6491447ccbf8277601a1e8e12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/709 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='675' max='675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [675/675 01:02, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.341200</td>\n",
       "      <td>0.289561</td>\n",
       "      <td>0.892807</td>\n",
       "      <td>0.839344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.249600</td>\n",
       "      <td>0.242334</td>\n",
       "      <td>0.925247</td>\n",
       "      <td>0.872510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.165900</td>\n",
       "      <td>0.244528</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.856291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.132700</td>\n",
       "      <td>0.268275</td>\n",
       "      <td>0.912553</td>\n",
       "      <td>0.861296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.050900</td>\n",
       "      <td>0.468764</td>\n",
       "      <td>0.913963</td>\n",
       "      <td>0.846516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.064500</td>\n",
       "      <td>0.366726</td>\n",
       "      <td>0.904090</td>\n",
       "      <td>0.854105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.033000</td>\n",
       "      <td>0.470076</td>\n",
       "      <td>0.909732</td>\n",
       "      <td>0.847461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.025400</td>\n",
       "      <td>0.451247</td>\n",
       "      <td>0.913963</td>\n",
       "      <td>0.863161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.008800</td>\n",
       "      <td>0.504997</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.856117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.009500</td>\n",
       "      <td>0.527810</td>\n",
       "      <td>0.909732</td>\n",
       "      <td>0.853607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.008200</td>\n",
       "      <td>0.545923</td>\n",
       "      <td>0.912553</td>\n",
       "      <td>0.851320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>0.543748</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.869769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.007300</td>\n",
       "      <td>0.592078</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.858709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.581061</td>\n",
       "      <td>0.912553</td>\n",
       "      <td>0.863508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.586272</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.868077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.613402</td>\n",
       "      <td>0.911142</td>\n",
       "      <td>0.853812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.609088</td>\n",
       "      <td>0.919605</td>\n",
       "      <td>0.869248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>0.684218</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.861762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.703157</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.860049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.624813</td>\n",
       "      <td>0.919605</td>\n",
       "      <td>0.872134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>0.626487</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.868811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.613026</td>\n",
       "      <td>0.921016</td>\n",
       "      <td>0.874032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.613793</td>\n",
       "      <td>0.921016</td>\n",
       "      <td>0.874032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.615436</td>\n",
       "      <td>0.921016</td>\n",
       "      <td>0.874032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.616782</td>\n",
       "      <td>0.921016</td>\n",
       "      <td>0.874032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.617845</td>\n",
       "      <td>0.921016</td>\n",
       "      <td>0.874032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.618425</td>\n",
       "      <td>0.921016</td>\n",
       "      <td>0.874032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3afe954e6fd24d5abd31762914216883",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2833 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27c83ce154e64a2f9a25803075dcd2e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/709 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='675' max='675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [675/675 01:02, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.355400</td>\n",
       "      <td>0.235180</td>\n",
       "      <td>0.919605</td>\n",
       "      <td>0.853632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.216500</td>\n",
       "      <td>0.245835</td>\n",
       "      <td>0.913963</td>\n",
       "      <td>0.859269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.148600</td>\n",
       "      <td>0.240499</td>\n",
       "      <td>0.935120</td>\n",
       "      <td>0.889005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.113700</td>\n",
       "      <td>0.243021</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.867647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.052800</td>\n",
       "      <td>0.265302</td>\n",
       "      <td>0.937941</td>\n",
       "      <td>0.893164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.064200</td>\n",
       "      <td>0.348235</td>\n",
       "      <td>0.921016</td>\n",
       "      <td>0.865709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.387733</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.843975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.012200</td>\n",
       "      <td>0.390925</td>\n",
       "      <td>0.928068</td>\n",
       "      <td>0.884323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.014700</td>\n",
       "      <td>0.430976</td>\n",
       "      <td>0.922426</td>\n",
       "      <td>0.857785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>0.442077</td>\n",
       "      <td>0.925247</td>\n",
       "      <td>0.874819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.431350</td>\n",
       "      <td>0.929478</td>\n",
       "      <td>0.879353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.007800</td>\n",
       "      <td>0.460931</td>\n",
       "      <td>0.930889</td>\n",
       "      <td>0.881396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.476370</td>\n",
       "      <td>0.928068</td>\n",
       "      <td>0.881657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.483894</td>\n",
       "      <td>0.933709</td>\n",
       "      <td>0.884048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.513279</td>\n",
       "      <td>0.926657</td>\n",
       "      <td>0.876062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.515783</td>\n",
       "      <td>0.929478</td>\n",
       "      <td>0.880097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.519469</td>\n",
       "      <td>0.929478</td>\n",
       "      <td>0.879353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.524445</td>\n",
       "      <td>0.930889</td>\n",
       "      <td>0.882132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.529259</td>\n",
       "      <td>0.930889</td>\n",
       "      <td>0.882132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.532469</td>\n",
       "      <td>0.930889</td>\n",
       "      <td>0.882132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.535001</td>\n",
       "      <td>0.930889</td>\n",
       "      <td>0.882132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.537812</td>\n",
       "      <td>0.930889</td>\n",
       "      <td>0.882132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.540276</td>\n",
       "      <td>0.930889</td>\n",
       "      <td>0.882132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.541631</td>\n",
       "      <td>0.930889</td>\n",
       "      <td>0.882132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.542625</td>\n",
       "      <td>0.930889</td>\n",
       "      <td>0.882132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.543379</td>\n",
       "      <td>0.930889</td>\n",
       "      <td>0.882132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.543534</td>\n",
       "      <td>0.930889</td>\n",
       "      <td>0.882132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee42cad45fcb4ad09a13610721d42e3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2833 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "420e649e38e54fbab61328f2cd022a99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/709 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='675' max='675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [675/675 01:02, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.355400</td>\n",
       "      <td>0.235180</td>\n",
       "      <td>0.919605</td>\n",
       "      <td>0.853632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.216500</td>\n",
       "      <td>0.245835</td>\n",
       "      <td>0.913963</td>\n",
       "      <td>0.859269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.148600</td>\n",
       "      <td>0.240499</td>\n",
       "      <td>0.935120</td>\n",
       "      <td>0.889005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.113700</td>\n",
       "      <td>0.243021</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.867647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.052800</td>\n",
       "      <td>0.265302</td>\n",
       "      <td>0.937941</td>\n",
       "      <td>0.893164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.064200</td>\n",
       "      <td>0.348235</td>\n",
       "      <td>0.921016</td>\n",
       "      <td>0.865709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.387733</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.843975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.012200</td>\n",
       "      <td>0.390925</td>\n",
       "      <td>0.928068</td>\n",
       "      <td>0.884323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.014700</td>\n",
       "      <td>0.430976</td>\n",
       "      <td>0.922426</td>\n",
       "      <td>0.857785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>0.442077</td>\n",
       "      <td>0.925247</td>\n",
       "      <td>0.874819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.431350</td>\n",
       "      <td>0.929478</td>\n",
       "      <td>0.879353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.007800</td>\n",
       "      <td>0.460931</td>\n",
       "      <td>0.930889</td>\n",
       "      <td>0.881396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.476370</td>\n",
       "      <td>0.928068</td>\n",
       "      <td>0.881657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.483894</td>\n",
       "      <td>0.933709</td>\n",
       "      <td>0.884048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.513279</td>\n",
       "      <td>0.926657</td>\n",
       "      <td>0.876062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.515783</td>\n",
       "      <td>0.929478</td>\n",
       "      <td>0.880097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.519469</td>\n",
       "      <td>0.929478</td>\n",
       "      <td>0.879353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.524445</td>\n",
       "      <td>0.930889</td>\n",
       "      <td>0.882132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.529259</td>\n",
       "      <td>0.930889</td>\n",
       "      <td>0.882132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.532469</td>\n",
       "      <td>0.930889</td>\n",
       "      <td>0.882132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.535001</td>\n",
       "      <td>0.930889</td>\n",
       "      <td>0.882132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.537812</td>\n",
       "      <td>0.930889</td>\n",
       "      <td>0.882132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.540276</td>\n",
       "      <td>0.930889</td>\n",
       "      <td>0.882132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.541631</td>\n",
       "      <td>0.930889</td>\n",
       "      <td>0.882132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.542625</td>\n",
       "      <td>0.930889</td>\n",
       "      <td>0.882132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.543379</td>\n",
       "      <td>0.930889</td>\n",
       "      <td>0.882132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.543534</td>\n",
       "      <td>0.930889</td>\n",
       "      <td>0.882132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3859a0e074c49ac8879c2ad1a94bda5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2833 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd77b907a5b24a5bab8dbad3e498a451",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/709 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='675' max='675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [675/675 01:02, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.355400</td>\n",
       "      <td>0.235180</td>\n",
       "      <td>0.919605</td>\n",
       "      <td>0.853632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.216500</td>\n",
       "      <td>0.245835</td>\n",
       "      <td>0.913963</td>\n",
       "      <td>0.859269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.148600</td>\n",
       "      <td>0.240499</td>\n",
       "      <td>0.935120</td>\n",
       "      <td>0.889005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.113700</td>\n",
       "      <td>0.243021</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.867647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.052800</td>\n",
       "      <td>0.265302</td>\n",
       "      <td>0.937941</td>\n",
       "      <td>0.893164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.064200</td>\n",
       "      <td>0.348235</td>\n",
       "      <td>0.921016</td>\n",
       "      <td>0.865709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.387733</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.843975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.012200</td>\n",
       "      <td>0.390925</td>\n",
       "      <td>0.928068</td>\n",
       "      <td>0.884323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.014700</td>\n",
       "      <td>0.430976</td>\n",
       "      <td>0.922426</td>\n",
       "      <td>0.857785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>0.442077</td>\n",
       "      <td>0.925247</td>\n",
       "      <td>0.874819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.431350</td>\n",
       "      <td>0.929478</td>\n",
       "      <td>0.879353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.007800</td>\n",
       "      <td>0.460931</td>\n",
       "      <td>0.930889</td>\n",
       "      <td>0.881396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.476370</td>\n",
       "      <td>0.928068</td>\n",
       "      <td>0.881657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.483894</td>\n",
       "      <td>0.933709</td>\n",
       "      <td>0.884048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.513279</td>\n",
       "      <td>0.926657</td>\n",
       "      <td>0.876062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.515783</td>\n",
       "      <td>0.929478</td>\n",
       "      <td>0.880097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.519469</td>\n",
       "      <td>0.929478</td>\n",
       "      <td>0.879353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.524445</td>\n",
       "      <td>0.930889</td>\n",
       "      <td>0.882132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.529259</td>\n",
       "      <td>0.930889</td>\n",
       "      <td>0.882132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.532469</td>\n",
       "      <td>0.930889</td>\n",
       "      <td>0.882132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.535001</td>\n",
       "      <td>0.930889</td>\n",
       "      <td>0.882132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.537812</td>\n",
       "      <td>0.930889</td>\n",
       "      <td>0.882132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.540276</td>\n",
       "      <td>0.930889</td>\n",
       "      <td>0.882132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.541631</td>\n",
       "      <td>0.930889</td>\n",
       "      <td>0.882132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.542625</td>\n",
       "      <td>0.930889</td>\n",
       "      <td>0.882132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.543379</td>\n",
       "      <td>0.930889</td>\n",
       "      <td>0.882132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.543534</td>\n",
       "      <td>0.930889</td>\n",
       "      <td>0.882132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', '__index_level_0__'],\n",
       "        num_rows: 2833\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', '__index_level_0__'],\n",
       "        num_rows: 709\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunis-ai/TunBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tunis-ai/TunBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89bab8353471400d9082d9f0d8496628",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2833 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4790d52e41144e8bf4dd434a6cf8321",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/709 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='675' max='675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [675/675 00:59, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.526700</td>\n",
       "      <td>0.538749</td>\n",
       "      <td>0.791255</td>\n",
       "      <td>0.441732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.492500</td>\n",
       "      <td>0.512430</td>\n",
       "      <td>0.791255</td>\n",
       "      <td>0.441732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.491700</td>\n",
       "      <td>0.518177</td>\n",
       "      <td>0.791255</td>\n",
       "      <td>0.441732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.492900</td>\n",
       "      <td>0.516876</td>\n",
       "      <td>0.791255</td>\n",
       "      <td>0.441732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.492300</td>\n",
       "      <td>0.517181</td>\n",
       "      <td>0.791255</td>\n",
       "      <td>0.441732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.490400</td>\n",
       "      <td>0.515634</td>\n",
       "      <td>0.791255</td>\n",
       "      <td>0.441732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.517800</td>\n",
       "      <td>0.522408</td>\n",
       "      <td>0.791255</td>\n",
       "      <td>0.441732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.480200</td>\n",
       "      <td>0.510560</td>\n",
       "      <td>0.791255</td>\n",
       "      <td>0.441732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.475900</td>\n",
       "      <td>0.502940</td>\n",
       "      <td>0.791255</td>\n",
       "      <td>0.441732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.484700</td>\n",
       "      <td>0.591450</td>\n",
       "      <td>0.791255</td>\n",
       "      <td>0.441732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.496500</td>\n",
       "      <td>0.512815</td>\n",
       "      <td>0.791255</td>\n",
       "      <td>0.441732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.485800</td>\n",
       "      <td>0.515261</td>\n",
       "      <td>0.791255</td>\n",
       "      <td>0.441732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.499400</td>\n",
       "      <td>0.517121</td>\n",
       "      <td>0.791255</td>\n",
       "      <td>0.441732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.484900</td>\n",
       "      <td>0.512699</td>\n",
       "      <td>0.791255</td>\n",
       "      <td>0.441732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.448500</td>\n",
       "      <td>0.477483</td>\n",
       "      <td>0.788434</td>\n",
       "      <td>0.440852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.445900</td>\n",
       "      <td>0.470093</td>\n",
       "      <td>0.795487</td>\n",
       "      <td>0.622431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.426100</td>\n",
       "      <td>0.467646</td>\n",
       "      <td>0.798307</td>\n",
       "      <td>0.608007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.415800</td>\n",
       "      <td>0.467299</td>\n",
       "      <td>0.811001</td>\n",
       "      <td>0.573658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.402000</td>\n",
       "      <td>0.459528</td>\n",
       "      <td>0.805360</td>\n",
       "      <td>0.601672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.427300</td>\n",
       "      <td>0.461304</td>\n",
       "      <td>0.812412</td>\n",
       "      <td>0.570708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.387800</td>\n",
       "      <td>0.463209</td>\n",
       "      <td>0.806770</td>\n",
       "      <td>0.612517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.399500</td>\n",
       "      <td>0.470942</td>\n",
       "      <td>0.801128</td>\n",
       "      <td>0.622098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.393300</td>\n",
       "      <td>0.464721</td>\n",
       "      <td>0.798307</td>\n",
       "      <td>0.624988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.376100</td>\n",
       "      <td>0.466933</td>\n",
       "      <td>0.811001</td>\n",
       "      <td>0.589145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>0.379100</td>\n",
       "      <td>0.478444</td>\n",
       "      <td>0.789845</td>\n",
       "      <td>0.648076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.384700</td>\n",
       "      <td>0.472922</td>\n",
       "      <td>0.811001</td>\n",
       "      <td>0.619477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>0.365900</td>\n",
       "      <td>0.473190</td>\n",
       "      <td>0.805360</td>\n",
       "      <td>0.625986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunis-ai/TunBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tunis-ai/TunBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29bf8afea9794a0f826e5443cf8f7593",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2833 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "876f77930e594565a31b65bc07963b78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/709 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='675' max='675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [675/675 00:59, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.526700</td>\n",
       "      <td>0.538749</td>\n",
       "      <td>0.791255</td>\n",
       "      <td>0.441732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.492500</td>\n",
       "      <td>0.512430</td>\n",
       "      <td>0.791255</td>\n",
       "      <td>0.441732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.491700</td>\n",
       "      <td>0.518177</td>\n",
       "      <td>0.791255</td>\n",
       "      <td>0.441732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.492900</td>\n",
       "      <td>0.516876</td>\n",
       "      <td>0.791255</td>\n",
       "      <td>0.441732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.492300</td>\n",
       "      <td>0.517181</td>\n",
       "      <td>0.791255</td>\n",
       "      <td>0.441732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.490400</td>\n",
       "      <td>0.515634</td>\n",
       "      <td>0.791255</td>\n",
       "      <td>0.441732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.517800</td>\n",
       "      <td>0.522408</td>\n",
       "      <td>0.791255</td>\n",
       "      <td>0.441732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.480200</td>\n",
       "      <td>0.510560</td>\n",
       "      <td>0.791255</td>\n",
       "      <td>0.441732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.475900</td>\n",
       "      <td>0.502940</td>\n",
       "      <td>0.791255</td>\n",
       "      <td>0.441732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.484700</td>\n",
       "      <td>0.591450</td>\n",
       "      <td>0.791255</td>\n",
       "      <td>0.441732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.496500</td>\n",
       "      <td>0.512815</td>\n",
       "      <td>0.791255</td>\n",
       "      <td>0.441732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.485800</td>\n",
       "      <td>0.515261</td>\n",
       "      <td>0.791255</td>\n",
       "      <td>0.441732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.499400</td>\n",
       "      <td>0.517121</td>\n",
       "      <td>0.791255</td>\n",
       "      <td>0.441732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.484900</td>\n",
       "      <td>0.512699</td>\n",
       "      <td>0.791255</td>\n",
       "      <td>0.441732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.448500</td>\n",
       "      <td>0.477483</td>\n",
       "      <td>0.788434</td>\n",
       "      <td>0.440852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.445900</td>\n",
       "      <td>0.470093</td>\n",
       "      <td>0.795487</td>\n",
       "      <td>0.622431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.426100</td>\n",
       "      <td>0.467646</td>\n",
       "      <td>0.798307</td>\n",
       "      <td>0.608007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.415800</td>\n",
       "      <td>0.467299</td>\n",
       "      <td>0.811001</td>\n",
       "      <td>0.573658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.402000</td>\n",
       "      <td>0.459528</td>\n",
       "      <td>0.805360</td>\n",
       "      <td>0.601672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.427300</td>\n",
       "      <td>0.461304</td>\n",
       "      <td>0.812412</td>\n",
       "      <td>0.570708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.387800</td>\n",
       "      <td>0.463209</td>\n",
       "      <td>0.806770</td>\n",
       "      <td>0.612517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.399500</td>\n",
       "      <td>0.470942</td>\n",
       "      <td>0.801128</td>\n",
       "      <td>0.622098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.393300</td>\n",
       "      <td>0.464721</td>\n",
       "      <td>0.798307</td>\n",
       "      <td>0.624988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.376100</td>\n",
       "      <td>0.466933</td>\n",
       "      <td>0.811001</td>\n",
       "      <td>0.589145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>0.379100</td>\n",
       "      <td>0.478444</td>\n",
       "      <td>0.789845</td>\n",
       "      <td>0.648076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.384700</td>\n",
       "      <td>0.472922</td>\n",
       "      <td>0.811001</td>\n",
       "      <td>0.619477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>0.365900</td>\n",
       "      <td>0.473190</td>\n",
       "      <td>0.805360</td>\n",
       "      <td>0.625986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunis-ai/TunBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tunis-ai/TunBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b26b57c06484a809d126063cba94453",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2833 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e353edfa2b8842759e1fd7641514cff9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/709 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='675' max='675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [675/675 01:00, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.526700</td>\n",
       "      <td>0.538749</td>\n",
       "      <td>0.791255</td>\n",
       "      <td>0.441732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.492500</td>\n",
       "      <td>0.512430</td>\n",
       "      <td>0.791255</td>\n",
       "      <td>0.441732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.491700</td>\n",
       "      <td>0.518177</td>\n",
       "      <td>0.791255</td>\n",
       "      <td>0.441732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.492900</td>\n",
       "      <td>0.516876</td>\n",
       "      <td>0.791255</td>\n",
       "      <td>0.441732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.492300</td>\n",
       "      <td>0.517181</td>\n",
       "      <td>0.791255</td>\n",
       "      <td>0.441732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.490400</td>\n",
       "      <td>0.515634</td>\n",
       "      <td>0.791255</td>\n",
       "      <td>0.441732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.517800</td>\n",
       "      <td>0.522408</td>\n",
       "      <td>0.791255</td>\n",
       "      <td>0.441732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.480200</td>\n",
       "      <td>0.510560</td>\n",
       "      <td>0.791255</td>\n",
       "      <td>0.441732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.475900</td>\n",
       "      <td>0.502940</td>\n",
       "      <td>0.791255</td>\n",
       "      <td>0.441732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.484700</td>\n",
       "      <td>0.591450</td>\n",
       "      <td>0.791255</td>\n",
       "      <td>0.441732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.496500</td>\n",
       "      <td>0.512815</td>\n",
       "      <td>0.791255</td>\n",
       "      <td>0.441732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.485800</td>\n",
       "      <td>0.515261</td>\n",
       "      <td>0.791255</td>\n",
       "      <td>0.441732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.499400</td>\n",
       "      <td>0.517121</td>\n",
       "      <td>0.791255</td>\n",
       "      <td>0.441732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.484900</td>\n",
       "      <td>0.512699</td>\n",
       "      <td>0.791255</td>\n",
       "      <td>0.441732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.448500</td>\n",
       "      <td>0.477483</td>\n",
       "      <td>0.788434</td>\n",
       "      <td>0.440852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.445900</td>\n",
       "      <td>0.470093</td>\n",
       "      <td>0.795487</td>\n",
       "      <td>0.622431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.426100</td>\n",
       "      <td>0.467646</td>\n",
       "      <td>0.798307</td>\n",
       "      <td>0.608007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.415800</td>\n",
       "      <td>0.467299</td>\n",
       "      <td>0.811001</td>\n",
       "      <td>0.573658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.402000</td>\n",
       "      <td>0.459528</td>\n",
       "      <td>0.805360</td>\n",
       "      <td>0.601672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.427300</td>\n",
       "      <td>0.461304</td>\n",
       "      <td>0.812412</td>\n",
       "      <td>0.570708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.387800</td>\n",
       "      <td>0.463209</td>\n",
       "      <td>0.806770</td>\n",
       "      <td>0.612517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.399500</td>\n",
       "      <td>0.470942</td>\n",
       "      <td>0.801128</td>\n",
       "      <td>0.622098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.393300</td>\n",
       "      <td>0.464721</td>\n",
       "      <td>0.798307</td>\n",
       "      <td>0.624988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.376100</td>\n",
       "      <td>0.466933</td>\n",
       "      <td>0.811001</td>\n",
       "      <td>0.589145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>0.379100</td>\n",
       "      <td>0.478444</td>\n",
       "      <td>0.789845</td>\n",
       "      <td>0.648076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.384700</td>\n",
       "      <td>0.472922</td>\n",
       "      <td>0.811001</td>\n",
       "      <td>0.619477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>0.365900</td>\n",
       "      <td>0.473190</td>\n",
       "      <td>0.805360</td>\n",
       "      <td>0.625986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunis-ai/TunBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tunis-ai/TunBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6960299f791419eaa3af46eecdd806a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2833 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05bd2f75bf5d4f75837f8f58ee3080aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/709 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='675' max='675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [675/675 01:00, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.561300</td>\n",
       "      <td>0.502402</td>\n",
       "      <td>0.803949</td>\n",
       "      <td>0.445661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.489700</td>\n",
       "      <td>0.506331</td>\n",
       "      <td>0.803949</td>\n",
       "      <td>0.445661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.485300</td>\n",
       "      <td>0.500205</td>\n",
       "      <td>0.803949</td>\n",
       "      <td>0.445661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.516800</td>\n",
       "      <td>0.495936</td>\n",
       "      <td>0.803949</td>\n",
       "      <td>0.445661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.500600</td>\n",
       "      <td>0.499233</td>\n",
       "      <td>0.803949</td>\n",
       "      <td>0.445661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.506100</td>\n",
       "      <td>0.497444</td>\n",
       "      <td>0.803949</td>\n",
       "      <td>0.445661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.496900</td>\n",
       "      <td>0.503894</td>\n",
       "      <td>0.803949</td>\n",
       "      <td>0.445661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.504000</td>\n",
       "      <td>0.502282</td>\n",
       "      <td>0.803949</td>\n",
       "      <td>0.445661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.483900</td>\n",
       "      <td>0.500248</td>\n",
       "      <td>0.803949</td>\n",
       "      <td>0.445661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.500800</td>\n",
       "      <td>0.505779</td>\n",
       "      <td>0.803949</td>\n",
       "      <td>0.445661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.448300</td>\n",
       "      <td>0.496869</td>\n",
       "      <td>0.803949</td>\n",
       "      <td>0.445661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.457900</td>\n",
       "      <td>0.450439</td>\n",
       "      <td>0.820874</td>\n",
       "      <td>0.581944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.490200</td>\n",
       "      <td>0.477978</td>\n",
       "      <td>0.805360</td>\n",
       "      <td>0.453152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.452400</td>\n",
       "      <td>0.473742</td>\n",
       "      <td>0.816643</td>\n",
       "      <td>0.515405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.437100</td>\n",
       "      <td>0.440794</td>\n",
       "      <td>0.820874</td>\n",
       "      <td>0.612353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.437900</td>\n",
       "      <td>0.471089</td>\n",
       "      <td>0.815233</td>\n",
       "      <td>0.646284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.424300</td>\n",
       "      <td>0.441278</td>\n",
       "      <td>0.826516</td>\n",
       "      <td>0.599094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.407700</td>\n",
       "      <td>0.451779</td>\n",
       "      <td>0.809591</td>\n",
       "      <td>0.664775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.393100</td>\n",
       "      <td>0.452274</td>\n",
       "      <td>0.830748</td>\n",
       "      <td>0.614534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.404100</td>\n",
       "      <td>0.448630</td>\n",
       "      <td>0.809591</td>\n",
       "      <td>0.671174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.371600</td>\n",
       "      <td>0.434537</td>\n",
       "      <td>0.826516</td>\n",
       "      <td>0.670341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.396800</td>\n",
       "      <td>0.426747</td>\n",
       "      <td>0.834979</td>\n",
       "      <td>0.669084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.376400</td>\n",
       "      <td>0.439570</td>\n",
       "      <td>0.823695</td>\n",
       "      <td>0.669833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.396600</td>\n",
       "      <td>0.435108</td>\n",
       "      <td>0.819464</td>\n",
       "      <td>0.665517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>0.347700</td>\n",
       "      <td>0.443547</td>\n",
       "      <td>0.829337</td>\n",
       "      <td>0.673286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.368000</td>\n",
       "      <td>0.435516</td>\n",
       "      <td>0.832158</td>\n",
       "      <td>0.673796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>0.378500</td>\n",
       "      <td>0.436940</td>\n",
       "      <td>0.829337</td>\n",
       "      <td>0.673286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunis-ai/TunBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tunis-ai/TunBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a400b3c635c24be6a1d9a27cd1e7afbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2833 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c750510682314b0c8c230e3d704110e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/709 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='675' max='675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [675/675 01:00, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.561300</td>\n",
       "      <td>0.502402</td>\n",
       "      <td>0.803949</td>\n",
       "      <td>0.445661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.489700</td>\n",
       "      <td>0.506331</td>\n",
       "      <td>0.803949</td>\n",
       "      <td>0.445661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.485300</td>\n",
       "      <td>0.500205</td>\n",
       "      <td>0.803949</td>\n",
       "      <td>0.445661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.516800</td>\n",
       "      <td>0.495936</td>\n",
       "      <td>0.803949</td>\n",
       "      <td>0.445661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.500600</td>\n",
       "      <td>0.499233</td>\n",
       "      <td>0.803949</td>\n",
       "      <td>0.445661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.506100</td>\n",
       "      <td>0.497444</td>\n",
       "      <td>0.803949</td>\n",
       "      <td>0.445661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.496900</td>\n",
       "      <td>0.503894</td>\n",
       "      <td>0.803949</td>\n",
       "      <td>0.445661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.504000</td>\n",
       "      <td>0.502282</td>\n",
       "      <td>0.803949</td>\n",
       "      <td>0.445661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.483900</td>\n",
       "      <td>0.500248</td>\n",
       "      <td>0.803949</td>\n",
       "      <td>0.445661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.500800</td>\n",
       "      <td>0.505779</td>\n",
       "      <td>0.803949</td>\n",
       "      <td>0.445661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.448300</td>\n",
       "      <td>0.496869</td>\n",
       "      <td>0.803949</td>\n",
       "      <td>0.445661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.457900</td>\n",
       "      <td>0.450439</td>\n",
       "      <td>0.820874</td>\n",
       "      <td>0.581944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.490200</td>\n",
       "      <td>0.477978</td>\n",
       "      <td>0.805360</td>\n",
       "      <td>0.453152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.452400</td>\n",
       "      <td>0.473742</td>\n",
       "      <td>0.816643</td>\n",
       "      <td>0.515405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.437100</td>\n",
       "      <td>0.440794</td>\n",
       "      <td>0.820874</td>\n",
       "      <td>0.612353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.437900</td>\n",
       "      <td>0.471089</td>\n",
       "      <td>0.815233</td>\n",
       "      <td>0.646284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.424300</td>\n",
       "      <td>0.441278</td>\n",
       "      <td>0.826516</td>\n",
       "      <td>0.599094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.407700</td>\n",
       "      <td>0.451779</td>\n",
       "      <td>0.809591</td>\n",
       "      <td>0.664775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.393100</td>\n",
       "      <td>0.452274</td>\n",
       "      <td>0.830748</td>\n",
       "      <td>0.614534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.404100</td>\n",
       "      <td>0.448630</td>\n",
       "      <td>0.809591</td>\n",
       "      <td>0.671174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.371600</td>\n",
       "      <td>0.434537</td>\n",
       "      <td>0.826516</td>\n",
       "      <td>0.670341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.396800</td>\n",
       "      <td>0.426747</td>\n",
       "      <td>0.834979</td>\n",
       "      <td>0.669084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.376400</td>\n",
       "      <td>0.439570</td>\n",
       "      <td>0.823695</td>\n",
       "      <td>0.669833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.396600</td>\n",
       "      <td>0.435108</td>\n",
       "      <td>0.819464</td>\n",
       "      <td>0.665517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>0.347700</td>\n",
       "      <td>0.443547</td>\n",
       "      <td>0.829337</td>\n",
       "      <td>0.673286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.368000</td>\n",
       "      <td>0.435516</td>\n",
       "      <td>0.832158</td>\n",
       "      <td>0.673796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>0.378500</td>\n",
       "      <td>0.436940</td>\n",
       "      <td>0.829337</td>\n",
       "      <td>0.673286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunis-ai/TunBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tunis-ai/TunBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61d21b7928cd4c5290b98fcc7c192380",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2833 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3c2e04a5278403ab3e37908b0e42f74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/709 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='675' max='675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [675/675 01:00, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.561300</td>\n",
       "      <td>0.502402</td>\n",
       "      <td>0.803949</td>\n",
       "      <td>0.445661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.489700</td>\n",
       "      <td>0.506331</td>\n",
       "      <td>0.803949</td>\n",
       "      <td>0.445661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.485300</td>\n",
       "      <td>0.500205</td>\n",
       "      <td>0.803949</td>\n",
       "      <td>0.445661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.516800</td>\n",
       "      <td>0.495936</td>\n",
       "      <td>0.803949</td>\n",
       "      <td>0.445661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.500600</td>\n",
       "      <td>0.499233</td>\n",
       "      <td>0.803949</td>\n",
       "      <td>0.445661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.506100</td>\n",
       "      <td>0.497444</td>\n",
       "      <td>0.803949</td>\n",
       "      <td>0.445661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.496900</td>\n",
       "      <td>0.503894</td>\n",
       "      <td>0.803949</td>\n",
       "      <td>0.445661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.504000</td>\n",
       "      <td>0.502282</td>\n",
       "      <td>0.803949</td>\n",
       "      <td>0.445661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.483900</td>\n",
       "      <td>0.500248</td>\n",
       "      <td>0.803949</td>\n",
       "      <td>0.445661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.500800</td>\n",
       "      <td>0.505779</td>\n",
       "      <td>0.803949</td>\n",
       "      <td>0.445661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.448300</td>\n",
       "      <td>0.496869</td>\n",
       "      <td>0.803949</td>\n",
       "      <td>0.445661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.457900</td>\n",
       "      <td>0.450439</td>\n",
       "      <td>0.820874</td>\n",
       "      <td>0.581944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.490200</td>\n",
       "      <td>0.477978</td>\n",
       "      <td>0.805360</td>\n",
       "      <td>0.453152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.452400</td>\n",
       "      <td>0.473742</td>\n",
       "      <td>0.816643</td>\n",
       "      <td>0.515405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.437100</td>\n",
       "      <td>0.440794</td>\n",
       "      <td>0.820874</td>\n",
       "      <td>0.612353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.437900</td>\n",
       "      <td>0.471089</td>\n",
       "      <td>0.815233</td>\n",
       "      <td>0.646284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.424300</td>\n",
       "      <td>0.441278</td>\n",
       "      <td>0.826516</td>\n",
       "      <td>0.599094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.407700</td>\n",
       "      <td>0.451779</td>\n",
       "      <td>0.809591</td>\n",
       "      <td>0.664775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.393100</td>\n",
       "      <td>0.452274</td>\n",
       "      <td>0.830748</td>\n",
       "      <td>0.614534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.404100</td>\n",
       "      <td>0.448630</td>\n",
       "      <td>0.809591</td>\n",
       "      <td>0.671174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.371600</td>\n",
       "      <td>0.434537</td>\n",
       "      <td>0.826516</td>\n",
       "      <td>0.670341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.396800</td>\n",
       "      <td>0.426747</td>\n",
       "      <td>0.834979</td>\n",
       "      <td>0.669084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.376400</td>\n",
       "      <td>0.439570</td>\n",
       "      <td>0.823695</td>\n",
       "      <td>0.669833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.396600</td>\n",
       "      <td>0.435108</td>\n",
       "      <td>0.819464</td>\n",
       "      <td>0.665517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>0.347700</td>\n",
       "      <td>0.443547</td>\n",
       "      <td>0.829337</td>\n",
       "      <td>0.673286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.368000</td>\n",
       "      <td>0.435516</td>\n",
       "      <td>0.832158</td>\n",
       "      <td>0.673796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>0.378500</td>\n",
       "      <td>0.436940</td>\n",
       "      <td>0.829337</td>\n",
       "      <td>0.673286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunis-ai/TunBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tunis-ai/TunBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67a24a5adf544cf5a31882c14367ffca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2833 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7226a277df9940cab1877b46e5d56a7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/709 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='675' max='675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [675/675 01:00, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.557200</td>\n",
       "      <td>0.491146</td>\n",
       "      <td>0.812412</td>\n",
       "      <td>0.448249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.504200</td>\n",
       "      <td>0.494648</td>\n",
       "      <td>0.812412</td>\n",
       "      <td>0.448249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.500300</td>\n",
       "      <td>0.484169</td>\n",
       "      <td>0.812412</td>\n",
       "      <td>0.448249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.488800</td>\n",
       "      <td>0.482617</td>\n",
       "      <td>0.812412</td>\n",
       "      <td>0.448249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.506300</td>\n",
       "      <td>0.495196</td>\n",
       "      <td>0.812412</td>\n",
       "      <td>0.448249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.512000</td>\n",
       "      <td>0.499273</td>\n",
       "      <td>0.812412</td>\n",
       "      <td>0.448249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.478257</td>\n",
       "      <td>0.812412</td>\n",
       "      <td>0.448249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.473900</td>\n",
       "      <td>0.459260</td>\n",
       "      <td>0.815233</td>\n",
       "      <td>0.568777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.459400</td>\n",
       "      <td>0.455531</td>\n",
       "      <td>0.816643</td>\n",
       "      <td>0.590268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.465000</td>\n",
       "      <td>0.443573</td>\n",
       "      <td>0.826516</td>\n",
       "      <td>0.595111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.434200</td>\n",
       "      <td>0.443114</td>\n",
       "      <td>0.822285</td>\n",
       "      <td>0.541067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.439100</td>\n",
       "      <td>0.440597</td>\n",
       "      <td>0.825106</td>\n",
       "      <td>0.563215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.429100</td>\n",
       "      <td>0.442273</td>\n",
       "      <td>0.815233</td>\n",
       "      <td>0.603686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.414100</td>\n",
       "      <td>0.428056</td>\n",
       "      <td>0.829337</td>\n",
       "      <td>0.571443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.385400</td>\n",
       "      <td>0.450964</td>\n",
       "      <td>0.825106</td>\n",
       "      <td>0.636049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.398700</td>\n",
       "      <td>0.436910</td>\n",
       "      <td>0.826516</td>\n",
       "      <td>0.627888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.390600</td>\n",
       "      <td>0.441519</td>\n",
       "      <td>0.822285</td>\n",
       "      <td>0.613674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.371300</td>\n",
       "      <td>0.464470</td>\n",
       "      <td>0.822285</td>\n",
       "      <td>0.560952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.377400</td>\n",
       "      <td>0.438590</td>\n",
       "      <td>0.823695</td>\n",
       "      <td>0.637699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.354600</td>\n",
       "      <td>0.454317</td>\n",
       "      <td>0.827927</td>\n",
       "      <td>0.615482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.352500</td>\n",
       "      <td>0.472725</td>\n",
       "      <td>0.812412</td>\n",
       "      <td>0.658474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.343600</td>\n",
       "      <td>0.489329</td>\n",
       "      <td>0.806770</td>\n",
       "      <td>0.659809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.347400</td>\n",
       "      <td>0.460533</td>\n",
       "      <td>0.832158</td>\n",
       "      <td>0.626685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.347500</td>\n",
       "      <td>0.454991</td>\n",
       "      <td>0.822285</td>\n",
       "      <td>0.617118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>0.310600</td>\n",
       "      <td>0.461186</td>\n",
       "      <td>0.822285</td>\n",
       "      <td>0.617118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.320500</td>\n",
       "      <td>0.470939</td>\n",
       "      <td>0.825106</td>\n",
       "      <td>0.661382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>0.344000</td>\n",
       "      <td>0.465978</td>\n",
       "      <td>0.820874</td>\n",
       "      <td>0.619148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunis-ai/TunBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tunis-ai/TunBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab9b723d24694f1299f70967ee2d6de1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2833 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "784c5b9b52144fc3873d692065e0e8f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/709 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='675' max='675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [675/675 01:00, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.557200</td>\n",
       "      <td>0.491146</td>\n",
       "      <td>0.812412</td>\n",
       "      <td>0.448249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.504200</td>\n",
       "      <td>0.494648</td>\n",
       "      <td>0.812412</td>\n",
       "      <td>0.448249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.500300</td>\n",
       "      <td>0.484169</td>\n",
       "      <td>0.812412</td>\n",
       "      <td>0.448249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.488800</td>\n",
       "      <td>0.482617</td>\n",
       "      <td>0.812412</td>\n",
       "      <td>0.448249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.506300</td>\n",
       "      <td>0.495196</td>\n",
       "      <td>0.812412</td>\n",
       "      <td>0.448249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.512000</td>\n",
       "      <td>0.499273</td>\n",
       "      <td>0.812412</td>\n",
       "      <td>0.448249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.478257</td>\n",
       "      <td>0.812412</td>\n",
       "      <td>0.448249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.473900</td>\n",
       "      <td>0.459260</td>\n",
       "      <td>0.815233</td>\n",
       "      <td>0.568777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.459400</td>\n",
       "      <td>0.455531</td>\n",
       "      <td>0.816643</td>\n",
       "      <td>0.590268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.465000</td>\n",
       "      <td>0.443573</td>\n",
       "      <td>0.826516</td>\n",
       "      <td>0.595111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.434200</td>\n",
       "      <td>0.443114</td>\n",
       "      <td>0.822285</td>\n",
       "      <td>0.541067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.439100</td>\n",
       "      <td>0.440597</td>\n",
       "      <td>0.825106</td>\n",
       "      <td>0.563215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.429100</td>\n",
       "      <td>0.442273</td>\n",
       "      <td>0.815233</td>\n",
       "      <td>0.603686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.414100</td>\n",
       "      <td>0.428056</td>\n",
       "      <td>0.829337</td>\n",
       "      <td>0.571443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.385400</td>\n",
       "      <td>0.450964</td>\n",
       "      <td>0.825106</td>\n",
       "      <td>0.636049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.398700</td>\n",
       "      <td>0.436910</td>\n",
       "      <td>0.826516</td>\n",
       "      <td>0.627888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.390600</td>\n",
       "      <td>0.441519</td>\n",
       "      <td>0.822285</td>\n",
       "      <td>0.613674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.371300</td>\n",
       "      <td>0.464470</td>\n",
       "      <td>0.822285</td>\n",
       "      <td>0.560952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.377400</td>\n",
       "      <td>0.438590</td>\n",
       "      <td>0.823695</td>\n",
       "      <td>0.637699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.354600</td>\n",
       "      <td>0.454317</td>\n",
       "      <td>0.827927</td>\n",
       "      <td>0.615482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.352500</td>\n",
       "      <td>0.472725</td>\n",
       "      <td>0.812412</td>\n",
       "      <td>0.658474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.343600</td>\n",
       "      <td>0.489329</td>\n",
       "      <td>0.806770</td>\n",
       "      <td>0.659809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.347400</td>\n",
       "      <td>0.460533</td>\n",
       "      <td>0.832158</td>\n",
       "      <td>0.626685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.347500</td>\n",
       "      <td>0.454991</td>\n",
       "      <td>0.822285</td>\n",
       "      <td>0.617118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>0.310600</td>\n",
       "      <td>0.461186</td>\n",
       "      <td>0.822285</td>\n",
       "      <td>0.617118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.320500</td>\n",
       "      <td>0.470939</td>\n",
       "      <td>0.825106</td>\n",
       "      <td>0.661382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>0.344000</td>\n",
       "      <td>0.465978</td>\n",
       "      <td>0.820874</td>\n",
       "      <td>0.619148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunis-ai/TunBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tunis-ai/TunBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f115f52b246b42bcbeb70cf9d06a7c99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2833 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "294297de8bf04dfd829f195882938481",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/709 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='675' max='675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [675/675 01:00, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.557200</td>\n",
       "      <td>0.491146</td>\n",
       "      <td>0.812412</td>\n",
       "      <td>0.448249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.504200</td>\n",
       "      <td>0.494648</td>\n",
       "      <td>0.812412</td>\n",
       "      <td>0.448249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.500300</td>\n",
       "      <td>0.484169</td>\n",
       "      <td>0.812412</td>\n",
       "      <td>0.448249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.488800</td>\n",
       "      <td>0.482617</td>\n",
       "      <td>0.812412</td>\n",
       "      <td>0.448249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.506300</td>\n",
       "      <td>0.495196</td>\n",
       "      <td>0.812412</td>\n",
       "      <td>0.448249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.512000</td>\n",
       "      <td>0.499273</td>\n",
       "      <td>0.812412</td>\n",
       "      <td>0.448249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.478257</td>\n",
       "      <td>0.812412</td>\n",
       "      <td>0.448249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.473900</td>\n",
       "      <td>0.459260</td>\n",
       "      <td>0.815233</td>\n",
       "      <td>0.568777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.459400</td>\n",
       "      <td>0.455531</td>\n",
       "      <td>0.816643</td>\n",
       "      <td>0.590268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.465000</td>\n",
       "      <td>0.443573</td>\n",
       "      <td>0.826516</td>\n",
       "      <td>0.595111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.434200</td>\n",
       "      <td>0.443114</td>\n",
       "      <td>0.822285</td>\n",
       "      <td>0.541067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.439100</td>\n",
       "      <td>0.440597</td>\n",
       "      <td>0.825106</td>\n",
       "      <td>0.563215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.429100</td>\n",
       "      <td>0.442273</td>\n",
       "      <td>0.815233</td>\n",
       "      <td>0.603686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.414100</td>\n",
       "      <td>0.428056</td>\n",
       "      <td>0.829337</td>\n",
       "      <td>0.571443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.385400</td>\n",
       "      <td>0.450964</td>\n",
       "      <td>0.825106</td>\n",
       "      <td>0.636049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.398700</td>\n",
       "      <td>0.436910</td>\n",
       "      <td>0.826516</td>\n",
       "      <td>0.627888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.390600</td>\n",
       "      <td>0.441519</td>\n",
       "      <td>0.822285</td>\n",
       "      <td>0.613674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.371300</td>\n",
       "      <td>0.464470</td>\n",
       "      <td>0.822285</td>\n",
       "      <td>0.560952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.377400</td>\n",
       "      <td>0.438590</td>\n",
       "      <td>0.823695</td>\n",
       "      <td>0.637699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.354600</td>\n",
       "      <td>0.454317</td>\n",
       "      <td>0.827927</td>\n",
       "      <td>0.615482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.352500</td>\n",
       "      <td>0.472725</td>\n",
       "      <td>0.812412</td>\n",
       "      <td>0.658474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.343600</td>\n",
       "      <td>0.489329</td>\n",
       "      <td>0.806770</td>\n",
       "      <td>0.659809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.347400</td>\n",
       "      <td>0.460533</td>\n",
       "      <td>0.832158</td>\n",
       "      <td>0.626685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.347500</td>\n",
       "      <td>0.454991</td>\n",
       "      <td>0.822285</td>\n",
       "      <td>0.617118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>0.310600</td>\n",
       "      <td>0.461186</td>\n",
       "      <td>0.822285</td>\n",
       "      <td>0.617118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.320500</td>\n",
       "      <td>0.470939</td>\n",
       "      <td>0.825106</td>\n",
       "      <td>0.661382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>0.344000</td>\n",
       "      <td>0.465978</td>\n",
       "      <td>0.820874</td>\n",
       "      <td>0.619148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', '__index_level_0__'],\n",
       "        num_rows: 2833\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', '__index_level_0__'],\n",
       "        num_rows: 709\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alger-ia/dziribert, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd7b7846ea5f483ebf808143541e9167",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2833 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3aea76870f04efa9fbc6d434a813700",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/709 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='675' max='675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [675/675 01:02, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.314300</td>\n",
       "      <td>0.225533</td>\n",
       "      <td>0.921016</td>\n",
       "      <td>0.868128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.223300</td>\n",
       "      <td>0.252547</td>\n",
       "      <td>0.912553</td>\n",
       "      <td>0.849459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.105000</td>\n",
       "      <td>0.279978</td>\n",
       "      <td>0.904090</td>\n",
       "      <td>0.860284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.058600</td>\n",
       "      <td>0.402025</td>\n",
       "      <td>0.911142</td>\n",
       "      <td>0.845570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.049100</td>\n",
       "      <td>0.447342</td>\n",
       "      <td>0.894217</td>\n",
       "      <td>0.848323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.028700</td>\n",
       "      <td>0.431107</td>\n",
       "      <td>0.909732</td>\n",
       "      <td>0.848383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.025700</td>\n",
       "      <td>0.380339</td>\n",
       "      <td>0.923836</td>\n",
       "      <td>0.878531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.479716</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.870617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.007800</td>\n",
       "      <td>0.492151</td>\n",
       "      <td>0.923836</td>\n",
       "      <td>0.880488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>0.522617</td>\n",
       "      <td>0.909732</td>\n",
       "      <td>0.862687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.560048</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.865804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.623502</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.861762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.615040</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.861476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.575356</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.870945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.629668</td>\n",
       "      <td>0.919605</td>\n",
       "      <td>0.866172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.682980</td>\n",
       "      <td>0.921016</td>\n",
       "      <td>0.865709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.591847</td>\n",
       "      <td>0.911142</td>\n",
       "      <td>0.859441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.620983</td>\n",
       "      <td>0.921016</td>\n",
       "      <td>0.870431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.648620</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.864226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.651557</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.864226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.652514</td>\n",
       "      <td>0.919605</td>\n",
       "      <td>0.866960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.653278</td>\n",
       "      <td>0.919605</td>\n",
       "      <td>0.866960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.652717</td>\n",
       "      <td>0.919605</td>\n",
       "      <td>0.866960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.653480</td>\n",
       "      <td>0.919605</td>\n",
       "      <td>0.866960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.654534</td>\n",
       "      <td>0.919605</td>\n",
       "      <td>0.866960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.655140</td>\n",
       "      <td>0.919605</td>\n",
       "      <td>0.866960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.655433</td>\n",
       "      <td>0.919605</td>\n",
       "      <td>0.866960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alger-ia/dziribert, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4e745f195964fc49535387081522df2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2833 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "258ccc65daf64717ac317c11eae47fb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/709 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='675' max='675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [675/675 01:01, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.314300</td>\n",
       "      <td>0.225533</td>\n",
       "      <td>0.921016</td>\n",
       "      <td>0.868128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.223300</td>\n",
       "      <td>0.252547</td>\n",
       "      <td>0.912553</td>\n",
       "      <td>0.849459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.105000</td>\n",
       "      <td>0.279978</td>\n",
       "      <td>0.904090</td>\n",
       "      <td>0.860284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.058600</td>\n",
       "      <td>0.402025</td>\n",
       "      <td>0.911142</td>\n",
       "      <td>0.845570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.049100</td>\n",
       "      <td>0.447342</td>\n",
       "      <td>0.894217</td>\n",
       "      <td>0.848323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.028700</td>\n",
       "      <td>0.431107</td>\n",
       "      <td>0.909732</td>\n",
       "      <td>0.848383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.025700</td>\n",
       "      <td>0.380339</td>\n",
       "      <td>0.923836</td>\n",
       "      <td>0.878531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.479716</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.870617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.007800</td>\n",
       "      <td>0.492151</td>\n",
       "      <td>0.923836</td>\n",
       "      <td>0.880488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>0.522617</td>\n",
       "      <td>0.909732</td>\n",
       "      <td>0.862687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.560048</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.865804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.623502</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.861762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.615040</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.861476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.575356</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.870945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.629668</td>\n",
       "      <td>0.919605</td>\n",
       "      <td>0.866172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.682980</td>\n",
       "      <td>0.921016</td>\n",
       "      <td>0.865709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.591847</td>\n",
       "      <td>0.911142</td>\n",
       "      <td>0.859441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.620983</td>\n",
       "      <td>0.921016</td>\n",
       "      <td>0.870431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.648620</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.864226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.651557</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.864226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.652514</td>\n",
       "      <td>0.919605</td>\n",
       "      <td>0.866960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.653278</td>\n",
       "      <td>0.919605</td>\n",
       "      <td>0.866960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.652717</td>\n",
       "      <td>0.919605</td>\n",
       "      <td>0.866960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.653480</td>\n",
       "      <td>0.919605</td>\n",
       "      <td>0.866960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.654534</td>\n",
       "      <td>0.919605</td>\n",
       "      <td>0.866960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.655140</td>\n",
       "      <td>0.919605</td>\n",
       "      <td>0.866960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.655433</td>\n",
       "      <td>0.919605</td>\n",
       "      <td>0.866960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alger-ia/dziribert, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "579a137e59e345be8683d0001e484da1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2833 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f55143ab49e4581843e3efc4feaa366",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/709 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='675' max='675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [675/675 01:01, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.314300</td>\n",
       "      <td>0.225533</td>\n",
       "      <td>0.921016</td>\n",
       "      <td>0.868128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.223300</td>\n",
       "      <td>0.252547</td>\n",
       "      <td>0.912553</td>\n",
       "      <td>0.849459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.105000</td>\n",
       "      <td>0.279978</td>\n",
       "      <td>0.904090</td>\n",
       "      <td>0.860284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.058600</td>\n",
       "      <td>0.402025</td>\n",
       "      <td>0.911142</td>\n",
       "      <td>0.845570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.049100</td>\n",
       "      <td>0.447342</td>\n",
       "      <td>0.894217</td>\n",
       "      <td>0.848323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.028700</td>\n",
       "      <td>0.431107</td>\n",
       "      <td>0.909732</td>\n",
       "      <td>0.848383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.025700</td>\n",
       "      <td>0.380339</td>\n",
       "      <td>0.923836</td>\n",
       "      <td>0.878531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.479716</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.870617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.007800</td>\n",
       "      <td>0.492151</td>\n",
       "      <td>0.923836</td>\n",
       "      <td>0.880488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>0.522617</td>\n",
       "      <td>0.909732</td>\n",
       "      <td>0.862687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.560048</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.865804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.623502</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.861762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.615040</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.861476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.575356</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.870945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.629668</td>\n",
       "      <td>0.919605</td>\n",
       "      <td>0.866172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.682980</td>\n",
       "      <td>0.921016</td>\n",
       "      <td>0.865709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.591847</td>\n",
       "      <td>0.911142</td>\n",
       "      <td>0.859441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.620983</td>\n",
       "      <td>0.921016</td>\n",
       "      <td>0.870431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.648620</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.864226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.651557</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.864226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.652514</td>\n",
       "      <td>0.919605</td>\n",
       "      <td>0.866960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.653278</td>\n",
       "      <td>0.919605</td>\n",
       "      <td>0.866960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.652717</td>\n",
       "      <td>0.919605</td>\n",
       "      <td>0.866960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.653480</td>\n",
       "      <td>0.919605</td>\n",
       "      <td>0.866960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.654534</td>\n",
       "      <td>0.919605</td>\n",
       "      <td>0.866960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.655140</td>\n",
       "      <td>0.919605</td>\n",
       "      <td>0.866960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.655433</td>\n",
       "      <td>0.919605</td>\n",
       "      <td>0.866960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alger-ia/dziribert, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ec4189535104aa7a94699c9a77b0729",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2833 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6803ad4db8c1445bb158427e9564104c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/709 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='675' max='675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [675/675 01:01, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.341600</td>\n",
       "      <td>0.262525</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.845275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.202700</td>\n",
       "      <td>0.234019</td>\n",
       "      <td>0.921016</td>\n",
       "      <td>0.868128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.112400</td>\n",
       "      <td>0.270122</td>\n",
       "      <td>0.929478</td>\n",
       "      <td>0.877826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.083300</td>\n",
       "      <td>0.288234</td>\n",
       "      <td>0.922426</td>\n",
       "      <td>0.874548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.029400</td>\n",
       "      <td>0.368011</td>\n",
       "      <td>0.919605</td>\n",
       "      <td>0.872134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.013900</td>\n",
       "      <td>0.432166</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.867647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>0.476278</td>\n",
       "      <td>0.922426</td>\n",
       "      <td>0.873111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.005900</td>\n",
       "      <td>0.522012</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.868811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.012900</td>\n",
       "      <td>0.534893</td>\n",
       "      <td>0.909732</td>\n",
       "      <td>0.856822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>0.611537</td>\n",
       "      <td>0.912553</td>\n",
       "      <td>0.842417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.556350</td>\n",
       "      <td>0.919605</td>\n",
       "      <td>0.866172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.614512</td>\n",
       "      <td>0.913963</td>\n",
       "      <td>0.864634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.864521</td>\n",
       "      <td>0.878702</td>\n",
       "      <td>0.828721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>0.673743</td>\n",
       "      <td>0.908322</td>\n",
       "      <td>0.860890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.584264</td>\n",
       "      <td>0.921016</td>\n",
       "      <td>0.871175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.589096</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.865804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.604650</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.864287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.611301</td>\n",
       "      <td>0.913963</td>\n",
       "      <td>0.861641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.617816</td>\n",
       "      <td>0.913963</td>\n",
       "      <td>0.861641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.617090</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.863528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.619469</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.863528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>0.632483</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.864287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.684402</td>\n",
       "      <td>0.912553</td>\n",
       "      <td>0.865621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.684638</td>\n",
       "      <td>0.911142</td>\n",
       "      <td>0.863103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.644767</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.865035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.643629</td>\n",
       "      <td>0.913963</td>\n",
       "      <td>0.862407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.643739</td>\n",
       "      <td>0.913963</td>\n",
       "      <td>0.862407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alger-ia/dziribert, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2ec1554927245cfb7f764eb357f8165",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2833 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01abb64360ce4a39b84cc59e2e388559",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/709 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='675' max='675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [675/675 01:01, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.341600</td>\n",
       "      <td>0.262525</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.845275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.202700</td>\n",
       "      <td>0.234019</td>\n",
       "      <td>0.921016</td>\n",
       "      <td>0.868128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.112400</td>\n",
       "      <td>0.270122</td>\n",
       "      <td>0.929478</td>\n",
       "      <td>0.877826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.083300</td>\n",
       "      <td>0.288234</td>\n",
       "      <td>0.922426</td>\n",
       "      <td>0.874548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.029400</td>\n",
       "      <td>0.368011</td>\n",
       "      <td>0.919605</td>\n",
       "      <td>0.872134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.013900</td>\n",
       "      <td>0.432166</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.867647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>0.476278</td>\n",
       "      <td>0.922426</td>\n",
       "      <td>0.873111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.005900</td>\n",
       "      <td>0.522012</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.868811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.012900</td>\n",
       "      <td>0.534893</td>\n",
       "      <td>0.909732</td>\n",
       "      <td>0.856822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>0.611537</td>\n",
       "      <td>0.912553</td>\n",
       "      <td>0.842417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.556350</td>\n",
       "      <td>0.919605</td>\n",
       "      <td>0.866172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.614512</td>\n",
       "      <td>0.913963</td>\n",
       "      <td>0.864634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.864521</td>\n",
       "      <td>0.878702</td>\n",
       "      <td>0.828721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>0.673743</td>\n",
       "      <td>0.908322</td>\n",
       "      <td>0.860890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.584264</td>\n",
       "      <td>0.921016</td>\n",
       "      <td>0.871175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.589096</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.865804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.604650</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.864287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.611301</td>\n",
       "      <td>0.913963</td>\n",
       "      <td>0.861641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.617816</td>\n",
       "      <td>0.913963</td>\n",
       "      <td>0.861641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.617090</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.863528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.619469</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.863528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>0.632483</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.864287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.684402</td>\n",
       "      <td>0.912553</td>\n",
       "      <td>0.865621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.684638</td>\n",
       "      <td>0.911142</td>\n",
       "      <td>0.863103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.644767</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.865035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.643629</td>\n",
       "      <td>0.913963</td>\n",
       "      <td>0.862407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.643739</td>\n",
       "      <td>0.913963</td>\n",
       "      <td>0.862407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alger-ia/dziribert, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26c9e307931b4e6f8242b08652bf33ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2833 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c77d3cda569d46e0bd7f1bd9c877ac16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/709 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='675' max='675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [675/675 01:01, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.341600</td>\n",
       "      <td>0.262525</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.845275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.202700</td>\n",
       "      <td>0.234019</td>\n",
       "      <td>0.921016</td>\n",
       "      <td>0.868128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.112400</td>\n",
       "      <td>0.270122</td>\n",
       "      <td>0.929478</td>\n",
       "      <td>0.877826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.083300</td>\n",
       "      <td>0.288234</td>\n",
       "      <td>0.922426</td>\n",
       "      <td>0.874548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.029400</td>\n",
       "      <td>0.368011</td>\n",
       "      <td>0.919605</td>\n",
       "      <td>0.872134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.013900</td>\n",
       "      <td>0.432166</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.867647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>0.476278</td>\n",
       "      <td>0.922426</td>\n",
       "      <td>0.873111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.005900</td>\n",
       "      <td>0.522012</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.868811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.012900</td>\n",
       "      <td>0.534893</td>\n",
       "      <td>0.909732</td>\n",
       "      <td>0.856822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>0.611537</td>\n",
       "      <td>0.912553</td>\n",
       "      <td>0.842417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.556350</td>\n",
       "      <td>0.919605</td>\n",
       "      <td>0.866172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.614512</td>\n",
       "      <td>0.913963</td>\n",
       "      <td>0.864634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.864521</td>\n",
       "      <td>0.878702</td>\n",
       "      <td>0.828721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>0.673743</td>\n",
       "      <td>0.908322</td>\n",
       "      <td>0.860890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.584264</td>\n",
       "      <td>0.921016</td>\n",
       "      <td>0.871175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.589096</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.865804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.604650</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.864287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.611301</td>\n",
       "      <td>0.913963</td>\n",
       "      <td>0.861641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.617816</td>\n",
       "      <td>0.913963</td>\n",
       "      <td>0.861641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.617090</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.863528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.619469</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.863528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>0.632483</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.864287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.684402</td>\n",
       "      <td>0.912553</td>\n",
       "      <td>0.865621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.684638</td>\n",
       "      <td>0.911142</td>\n",
       "      <td>0.863103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.644767</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.865035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.643629</td>\n",
       "      <td>0.913963</td>\n",
       "      <td>0.862407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.643739</td>\n",
       "      <td>0.913963</td>\n",
       "      <td>0.862407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alger-ia/dziribert, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce31db80d327476e92bcd0907066d6c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2833 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a9687c6070d4b16a14f57c3a59f9481",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/709 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='675' max='675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [675/675 01:01, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.305800</td>\n",
       "      <td>0.255761</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.840946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.224400</td>\n",
       "      <td>0.244889</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.848437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.096500</td>\n",
       "      <td>0.371658</td>\n",
       "      <td>0.912553</td>\n",
       "      <td>0.833214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.256416</td>\n",
       "      <td>0.928068</td>\n",
       "      <td>0.871677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.038900</td>\n",
       "      <td>0.309382</td>\n",
       "      <td>0.922426</td>\n",
       "      <td>0.865180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.019300</td>\n",
       "      <td>0.404030</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.861176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.018600</td>\n",
       "      <td>0.456736</td>\n",
       "      <td>0.912553</td>\n",
       "      <td>0.850398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.007100</td>\n",
       "      <td>0.452028</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.864226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>0.475223</td>\n",
       "      <td>0.922426</td>\n",
       "      <td>0.873836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.011500</td>\n",
       "      <td>0.552890</td>\n",
       "      <td>0.894217</td>\n",
       "      <td>0.837860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.531740</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.858077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>0.535406</td>\n",
       "      <td>0.921016</td>\n",
       "      <td>0.863165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.580612</td>\n",
       "      <td>0.919605</td>\n",
       "      <td>0.853632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.576649</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.852452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.581193</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.856291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.604862</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.852530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.619669</td>\n",
       "      <td>0.921016</td>\n",
       "      <td>0.858624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.621168</td>\n",
       "      <td>0.921016</td>\n",
       "      <td>0.858624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.607705</td>\n",
       "      <td>0.912553</td>\n",
       "      <td>0.854863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.616011</td>\n",
       "      <td>0.911142</td>\n",
       "      <td>0.854655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.614042</td>\n",
       "      <td>0.913963</td>\n",
       "      <td>0.856780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.611125</td>\n",
       "      <td>0.913963</td>\n",
       "      <td>0.856780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.612674</td>\n",
       "      <td>0.912553</td>\n",
       "      <td>0.853121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.613748</td>\n",
       "      <td>0.912553</td>\n",
       "      <td>0.851320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.614983</td>\n",
       "      <td>0.913963</td>\n",
       "      <td>0.853266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.615639</td>\n",
       "      <td>0.913963</td>\n",
       "      <td>0.853266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.615866</td>\n",
       "      <td>0.913963</td>\n",
       "      <td>0.853266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alger-ia/dziribert, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "368d1f159c9349b0a6100a334ed361ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2833 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "698c0273b3ff48dd9f1849eb752f11ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/709 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='675' max='675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [675/675 01:00, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.305800</td>\n",
       "      <td>0.255761</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.840946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.224400</td>\n",
       "      <td>0.244889</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.848437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.096500</td>\n",
       "      <td>0.371658</td>\n",
       "      <td>0.912553</td>\n",
       "      <td>0.833214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.256416</td>\n",
       "      <td>0.928068</td>\n",
       "      <td>0.871677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.038900</td>\n",
       "      <td>0.309382</td>\n",
       "      <td>0.922426</td>\n",
       "      <td>0.865180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.019300</td>\n",
       "      <td>0.404030</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.861176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.018600</td>\n",
       "      <td>0.456736</td>\n",
       "      <td>0.912553</td>\n",
       "      <td>0.850398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.007100</td>\n",
       "      <td>0.452028</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.864226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>0.475223</td>\n",
       "      <td>0.922426</td>\n",
       "      <td>0.873836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.011500</td>\n",
       "      <td>0.552890</td>\n",
       "      <td>0.894217</td>\n",
       "      <td>0.837860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.531740</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.858077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>0.535406</td>\n",
       "      <td>0.921016</td>\n",
       "      <td>0.863165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.580612</td>\n",
       "      <td>0.919605</td>\n",
       "      <td>0.853632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.576649</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.852452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.581193</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.856291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.604862</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.852530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.619669</td>\n",
       "      <td>0.921016</td>\n",
       "      <td>0.858624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.621168</td>\n",
       "      <td>0.921016</td>\n",
       "      <td>0.858624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.607705</td>\n",
       "      <td>0.912553</td>\n",
       "      <td>0.854863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.616011</td>\n",
       "      <td>0.911142</td>\n",
       "      <td>0.854655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.614042</td>\n",
       "      <td>0.913963</td>\n",
       "      <td>0.856780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.611125</td>\n",
       "      <td>0.913963</td>\n",
       "      <td>0.856780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.612674</td>\n",
       "      <td>0.912553</td>\n",
       "      <td>0.853121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.613748</td>\n",
       "      <td>0.912553</td>\n",
       "      <td>0.851320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.614983</td>\n",
       "      <td>0.913963</td>\n",
       "      <td>0.853266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.615639</td>\n",
       "      <td>0.913963</td>\n",
       "      <td>0.853266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.615866</td>\n",
       "      <td>0.913963</td>\n",
       "      <td>0.853266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alger-ia/dziribert, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "140a62e5b45b4a4bb19fdc88611e7a81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2833 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bda79488f124c1db79fe480d279f5e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/709 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='675' max='675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [675/675 01:00, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.305800</td>\n",
       "      <td>0.255761</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.840946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.224400</td>\n",
       "      <td>0.244889</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.848437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.096500</td>\n",
       "      <td>0.371658</td>\n",
       "      <td>0.912553</td>\n",
       "      <td>0.833214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.256416</td>\n",
       "      <td>0.928068</td>\n",
       "      <td>0.871677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.038900</td>\n",
       "      <td>0.309382</td>\n",
       "      <td>0.922426</td>\n",
       "      <td>0.865180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.019300</td>\n",
       "      <td>0.404030</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.861176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.018600</td>\n",
       "      <td>0.456736</td>\n",
       "      <td>0.912553</td>\n",
       "      <td>0.850398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.007100</td>\n",
       "      <td>0.452028</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.864226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>0.475223</td>\n",
       "      <td>0.922426</td>\n",
       "      <td>0.873836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.011500</td>\n",
       "      <td>0.552890</td>\n",
       "      <td>0.894217</td>\n",
       "      <td>0.837860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.531740</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.858077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>0.535406</td>\n",
       "      <td>0.921016</td>\n",
       "      <td>0.863165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.580612</td>\n",
       "      <td>0.919605</td>\n",
       "      <td>0.853632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.576649</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.852452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.581193</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.856291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.604862</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.852530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.619669</td>\n",
       "      <td>0.921016</td>\n",
       "      <td>0.858624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.621168</td>\n",
       "      <td>0.921016</td>\n",
       "      <td>0.858624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.607705</td>\n",
       "      <td>0.912553</td>\n",
       "      <td>0.854863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.616011</td>\n",
       "      <td>0.911142</td>\n",
       "      <td>0.854655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.614042</td>\n",
       "      <td>0.913963</td>\n",
       "      <td>0.856780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.611125</td>\n",
       "      <td>0.913963</td>\n",
       "      <td>0.856780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.612674</td>\n",
       "      <td>0.912553</td>\n",
       "      <td>0.853121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.613748</td>\n",
       "      <td>0.912553</td>\n",
       "      <td>0.851320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.614983</td>\n",
       "      <td>0.913963</td>\n",
       "      <td>0.853266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.615639</td>\n",
       "      <td>0.913963</td>\n",
       "      <td>0.853266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.615866</td>\n",
       "      <td>0.913963</td>\n",
       "      <td>0.853266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', '__index_level_0__'],\n",
       "        num_rows: 2833\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', '__index_level_0__'],\n",
       "        num_rows: 709\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SI2M-Lab/DarijaBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SI2M-Lab/DarijaBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e9bf2c1b2074c349c66810ca8a9637c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2833 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "061e813e3cef4982b637c3c674ed9e62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/709 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='675' max='675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [675/675 01:02, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.322400</td>\n",
       "      <td>0.352323</td>\n",
       "      <td>0.892807</td>\n",
       "      <td>0.799979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.228200</td>\n",
       "      <td>0.298733</td>\n",
       "      <td>0.912553</td>\n",
       "      <td>0.845540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.142100</td>\n",
       "      <td>0.224632</td>\n",
       "      <td>0.923836</td>\n",
       "      <td>0.878531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.085500</td>\n",
       "      <td>0.431966</td>\n",
       "      <td>0.904090</td>\n",
       "      <td>0.830593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.062900</td>\n",
       "      <td>0.306177</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.861973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.037700</td>\n",
       "      <td>0.366399</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.862292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.025400</td>\n",
       "      <td>0.392768</td>\n",
       "      <td>0.922426</td>\n",
       "      <td>0.873111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.021800</td>\n",
       "      <td>0.407141</td>\n",
       "      <td>0.911142</td>\n",
       "      <td>0.870854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.010700</td>\n",
       "      <td>0.422975</td>\n",
       "      <td>0.912553</td>\n",
       "      <td>0.852228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>0.439628</td>\n",
       "      <td>0.922426</td>\n",
       "      <td>0.874548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>0.553539</td>\n",
       "      <td>0.912553</td>\n",
       "      <td>0.850398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.444678</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.869769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.496311</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.868077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.471306</td>\n",
       "      <td>0.922426</td>\n",
       "      <td>0.878598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.478136</td>\n",
       "      <td>0.928068</td>\n",
       "      <td>0.888603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.486371</td>\n",
       "      <td>0.926657</td>\n",
       "      <td>0.886123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.492380</td>\n",
       "      <td>0.928068</td>\n",
       "      <td>0.888603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.497011</td>\n",
       "      <td>0.928068</td>\n",
       "      <td>0.888603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.501015</td>\n",
       "      <td>0.926657</td>\n",
       "      <td>0.886123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.514887</td>\n",
       "      <td>0.926657</td>\n",
       "      <td>0.883030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.539773</td>\n",
       "      <td>0.928068</td>\n",
       "      <td>0.883672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.543907</td>\n",
       "      <td>0.928068</td>\n",
       "      <td>0.883672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.546572</td>\n",
       "      <td>0.928068</td>\n",
       "      <td>0.883672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.549568</td>\n",
       "      <td>0.928068</td>\n",
       "      <td>0.883672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.550593</td>\n",
       "      <td>0.928068</td>\n",
       "      <td>0.883672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.559414</td>\n",
       "      <td>0.928068</td>\n",
       "      <td>0.883672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.561406</td>\n",
       "      <td>0.926657</td>\n",
       "      <td>0.881056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SI2M-Lab/DarijaBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SI2M-Lab/DarijaBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da8a53fe653d4810a5f9d5bf17e9d492",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2833 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eea85e914ebf4df7be88ffbd09301804",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/709 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='675' max='675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [675/675 01:02, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.322400</td>\n",
       "      <td>0.352323</td>\n",
       "      <td>0.892807</td>\n",
       "      <td>0.799979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.228200</td>\n",
       "      <td>0.298733</td>\n",
       "      <td>0.912553</td>\n",
       "      <td>0.845540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.142100</td>\n",
       "      <td>0.224632</td>\n",
       "      <td>0.923836</td>\n",
       "      <td>0.878531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.085500</td>\n",
       "      <td>0.431966</td>\n",
       "      <td>0.904090</td>\n",
       "      <td>0.830593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.062900</td>\n",
       "      <td>0.306177</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.861973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.037700</td>\n",
       "      <td>0.366399</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.862292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.025400</td>\n",
       "      <td>0.392768</td>\n",
       "      <td>0.922426</td>\n",
       "      <td>0.873111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.021800</td>\n",
       "      <td>0.407141</td>\n",
       "      <td>0.911142</td>\n",
       "      <td>0.870854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.010700</td>\n",
       "      <td>0.422975</td>\n",
       "      <td>0.912553</td>\n",
       "      <td>0.852228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>0.439628</td>\n",
       "      <td>0.922426</td>\n",
       "      <td>0.874548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>0.553539</td>\n",
       "      <td>0.912553</td>\n",
       "      <td>0.850398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.444678</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.869769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.496311</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.868077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.471306</td>\n",
       "      <td>0.922426</td>\n",
       "      <td>0.878598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.478136</td>\n",
       "      <td>0.928068</td>\n",
       "      <td>0.888603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.486371</td>\n",
       "      <td>0.926657</td>\n",
       "      <td>0.886123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.492380</td>\n",
       "      <td>0.928068</td>\n",
       "      <td>0.888603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.497011</td>\n",
       "      <td>0.928068</td>\n",
       "      <td>0.888603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.501015</td>\n",
       "      <td>0.926657</td>\n",
       "      <td>0.886123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.514887</td>\n",
       "      <td>0.926657</td>\n",
       "      <td>0.883030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.539773</td>\n",
       "      <td>0.928068</td>\n",
       "      <td>0.883672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.543907</td>\n",
       "      <td>0.928068</td>\n",
       "      <td>0.883672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.546572</td>\n",
       "      <td>0.928068</td>\n",
       "      <td>0.883672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.549568</td>\n",
       "      <td>0.928068</td>\n",
       "      <td>0.883672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.550593</td>\n",
       "      <td>0.928068</td>\n",
       "      <td>0.883672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.559414</td>\n",
       "      <td>0.928068</td>\n",
       "      <td>0.883672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.561406</td>\n",
       "      <td>0.926657</td>\n",
       "      <td>0.881056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SI2M-Lab/DarijaBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SI2M-Lab/DarijaBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f34353598c054bd590bad7d8f0c70131",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2833 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efab430000204f64a231b2ee4110e5ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/709 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='675' max='675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [675/675 01:02, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.322400</td>\n",
       "      <td>0.352323</td>\n",
       "      <td>0.892807</td>\n",
       "      <td>0.799979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.228200</td>\n",
       "      <td>0.298733</td>\n",
       "      <td>0.912553</td>\n",
       "      <td>0.845540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.142100</td>\n",
       "      <td>0.224632</td>\n",
       "      <td>0.923836</td>\n",
       "      <td>0.878531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.085500</td>\n",
       "      <td>0.431966</td>\n",
       "      <td>0.904090</td>\n",
       "      <td>0.830593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.062900</td>\n",
       "      <td>0.306177</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.861973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.037700</td>\n",
       "      <td>0.366399</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.862292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.025400</td>\n",
       "      <td>0.392768</td>\n",
       "      <td>0.922426</td>\n",
       "      <td>0.873111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.021800</td>\n",
       "      <td>0.407141</td>\n",
       "      <td>0.911142</td>\n",
       "      <td>0.870854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.010700</td>\n",
       "      <td>0.422975</td>\n",
       "      <td>0.912553</td>\n",
       "      <td>0.852228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>0.439628</td>\n",
       "      <td>0.922426</td>\n",
       "      <td>0.874548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>0.553539</td>\n",
       "      <td>0.912553</td>\n",
       "      <td>0.850398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.444678</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.869769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.496311</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.868077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.471306</td>\n",
       "      <td>0.922426</td>\n",
       "      <td>0.878598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.478136</td>\n",
       "      <td>0.928068</td>\n",
       "      <td>0.888603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.486371</td>\n",
       "      <td>0.926657</td>\n",
       "      <td>0.886123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.492380</td>\n",
       "      <td>0.928068</td>\n",
       "      <td>0.888603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.497011</td>\n",
       "      <td>0.928068</td>\n",
       "      <td>0.888603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.501015</td>\n",
       "      <td>0.926657</td>\n",
       "      <td>0.886123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.514887</td>\n",
       "      <td>0.926657</td>\n",
       "      <td>0.883030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.539773</td>\n",
       "      <td>0.928068</td>\n",
       "      <td>0.883672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.543907</td>\n",
       "      <td>0.928068</td>\n",
       "      <td>0.883672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.546572</td>\n",
       "      <td>0.928068</td>\n",
       "      <td>0.883672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.549568</td>\n",
       "      <td>0.928068</td>\n",
       "      <td>0.883672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.550593</td>\n",
       "      <td>0.928068</td>\n",
       "      <td>0.883672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.559414</td>\n",
       "      <td>0.928068</td>\n",
       "      <td>0.883672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.561406</td>\n",
       "      <td>0.926657</td>\n",
       "      <td>0.881056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SI2M-Lab/DarijaBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SI2M-Lab/DarijaBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4f40cf329c44b01a750796a60e722c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2833 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3c460c1f67a45389ac6c507cabf5c83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/709 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='675' max='675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [675/675 01:02, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.333200</td>\n",
       "      <td>0.254649</td>\n",
       "      <td>0.901269</td>\n",
       "      <td>0.839883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.243800</td>\n",
       "      <td>0.243322</td>\n",
       "      <td>0.921016</td>\n",
       "      <td>0.857667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.138300</td>\n",
       "      <td>0.236606</td>\n",
       "      <td>0.928068</td>\n",
       "      <td>0.873360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.097800</td>\n",
       "      <td>0.322583</td>\n",
       "      <td>0.911142</td>\n",
       "      <td>0.861671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.045100</td>\n",
       "      <td>0.368465</td>\n",
       "      <td>0.922426</td>\n",
       "      <td>0.873836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.042400</td>\n",
       "      <td>0.333888</td>\n",
       "      <td>0.929478</td>\n",
       "      <td>0.881549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.026400</td>\n",
       "      <td>0.403322</td>\n",
       "      <td>0.929478</td>\n",
       "      <td>0.881549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.011800</td>\n",
       "      <td>0.391610</td>\n",
       "      <td>0.926657</td>\n",
       "      <td>0.872939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.441458</td>\n",
       "      <td>0.926657</td>\n",
       "      <td>0.880376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>0.477920</td>\n",
       "      <td>0.932299</td>\n",
       "      <td>0.884893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.487904</td>\n",
       "      <td>0.929478</td>\n",
       "      <td>0.884977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>0.520516</td>\n",
       "      <td>0.926657</td>\n",
       "      <td>0.883668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>0.475779</td>\n",
       "      <td>0.930889</td>\n",
       "      <td>0.882132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>0.487950</td>\n",
       "      <td>0.932299</td>\n",
       "      <td>0.889578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.492792</td>\n",
       "      <td>0.932299</td>\n",
       "      <td>0.886287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.528505</td>\n",
       "      <td>0.932299</td>\n",
       "      <td>0.881961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.503512</td>\n",
       "      <td>0.936530</td>\n",
       "      <td>0.892418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.533432</td>\n",
       "      <td>0.929478</td>\n",
       "      <td>0.887529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>0.529987</td>\n",
       "      <td>0.932299</td>\n",
       "      <td>0.885596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.533894</td>\n",
       "      <td>0.932299</td>\n",
       "      <td>0.885596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.533686</td>\n",
       "      <td>0.933709</td>\n",
       "      <td>0.888319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.538018</td>\n",
       "      <td>0.932299</td>\n",
       "      <td>0.885596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.541049</td>\n",
       "      <td>0.932299</td>\n",
       "      <td>0.885596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.530517</td>\n",
       "      <td>0.930889</td>\n",
       "      <td>0.884955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.531446</td>\n",
       "      <td>0.930889</td>\n",
       "      <td>0.885632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.532085</td>\n",
       "      <td>0.930889</td>\n",
       "      <td>0.885632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.532345</td>\n",
       "      <td>0.930889</td>\n",
       "      <td>0.885632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SI2M-Lab/DarijaBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SI2M-Lab/DarijaBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3530c863b40d4da0ba544d0d89641594",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2833 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ec297564f224d1e8d9c71bf8b0bf38c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/709 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='675' max='675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [675/675 01:02, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.333200</td>\n",
       "      <td>0.254649</td>\n",
       "      <td>0.901269</td>\n",
       "      <td>0.839883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.243800</td>\n",
       "      <td>0.243322</td>\n",
       "      <td>0.921016</td>\n",
       "      <td>0.857667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.138300</td>\n",
       "      <td>0.236606</td>\n",
       "      <td>0.928068</td>\n",
       "      <td>0.873360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.097800</td>\n",
       "      <td>0.322583</td>\n",
       "      <td>0.911142</td>\n",
       "      <td>0.861671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.045100</td>\n",
       "      <td>0.368465</td>\n",
       "      <td>0.922426</td>\n",
       "      <td>0.873836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.042400</td>\n",
       "      <td>0.333888</td>\n",
       "      <td>0.929478</td>\n",
       "      <td>0.881549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.026400</td>\n",
       "      <td>0.403322</td>\n",
       "      <td>0.929478</td>\n",
       "      <td>0.881549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.011800</td>\n",
       "      <td>0.391610</td>\n",
       "      <td>0.926657</td>\n",
       "      <td>0.872939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.441458</td>\n",
       "      <td>0.926657</td>\n",
       "      <td>0.880376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>0.477920</td>\n",
       "      <td>0.932299</td>\n",
       "      <td>0.884893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.487904</td>\n",
       "      <td>0.929478</td>\n",
       "      <td>0.884977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>0.520516</td>\n",
       "      <td>0.926657</td>\n",
       "      <td>0.883668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>0.475779</td>\n",
       "      <td>0.930889</td>\n",
       "      <td>0.882132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>0.487950</td>\n",
       "      <td>0.932299</td>\n",
       "      <td>0.889578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.492792</td>\n",
       "      <td>0.932299</td>\n",
       "      <td>0.886287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.528505</td>\n",
       "      <td>0.932299</td>\n",
       "      <td>0.881961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.503512</td>\n",
       "      <td>0.936530</td>\n",
       "      <td>0.892418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.533432</td>\n",
       "      <td>0.929478</td>\n",
       "      <td>0.887529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>0.529987</td>\n",
       "      <td>0.932299</td>\n",
       "      <td>0.885596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.533894</td>\n",
       "      <td>0.932299</td>\n",
       "      <td>0.885596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.533686</td>\n",
       "      <td>0.933709</td>\n",
       "      <td>0.888319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.538018</td>\n",
       "      <td>0.932299</td>\n",
       "      <td>0.885596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.541049</td>\n",
       "      <td>0.932299</td>\n",
       "      <td>0.885596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.530517</td>\n",
       "      <td>0.930889</td>\n",
       "      <td>0.884955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.531446</td>\n",
       "      <td>0.930889</td>\n",
       "      <td>0.885632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.532085</td>\n",
       "      <td>0.930889</td>\n",
       "      <td>0.885632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.532345</td>\n",
       "      <td>0.930889</td>\n",
       "      <td>0.885632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SI2M-Lab/DarijaBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SI2M-Lab/DarijaBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03d1760c985c4a5399fd44138dd71bb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2833 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffd6222f17064224aca0a1d31acdbaef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/709 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='675' max='675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [675/675 01:02, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.333200</td>\n",
       "      <td>0.254649</td>\n",
       "      <td>0.901269</td>\n",
       "      <td>0.839883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.243800</td>\n",
       "      <td>0.243322</td>\n",
       "      <td>0.921016</td>\n",
       "      <td>0.857667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.138300</td>\n",
       "      <td>0.236606</td>\n",
       "      <td>0.928068</td>\n",
       "      <td>0.873360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.097800</td>\n",
       "      <td>0.322583</td>\n",
       "      <td>0.911142</td>\n",
       "      <td>0.861671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.045100</td>\n",
       "      <td>0.368465</td>\n",
       "      <td>0.922426</td>\n",
       "      <td>0.873836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.042400</td>\n",
       "      <td>0.333888</td>\n",
       "      <td>0.929478</td>\n",
       "      <td>0.881549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.026400</td>\n",
       "      <td>0.403322</td>\n",
       "      <td>0.929478</td>\n",
       "      <td>0.881549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.011800</td>\n",
       "      <td>0.391610</td>\n",
       "      <td>0.926657</td>\n",
       "      <td>0.872939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.441458</td>\n",
       "      <td>0.926657</td>\n",
       "      <td>0.880376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>0.477920</td>\n",
       "      <td>0.932299</td>\n",
       "      <td>0.884893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.487904</td>\n",
       "      <td>0.929478</td>\n",
       "      <td>0.884977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>0.520516</td>\n",
       "      <td>0.926657</td>\n",
       "      <td>0.883668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>0.475779</td>\n",
       "      <td>0.930889</td>\n",
       "      <td>0.882132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>0.487950</td>\n",
       "      <td>0.932299</td>\n",
       "      <td>0.889578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.492792</td>\n",
       "      <td>0.932299</td>\n",
       "      <td>0.886287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.528505</td>\n",
       "      <td>0.932299</td>\n",
       "      <td>0.881961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.503512</td>\n",
       "      <td>0.936530</td>\n",
       "      <td>0.892418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.533432</td>\n",
       "      <td>0.929478</td>\n",
       "      <td>0.887529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>0.529987</td>\n",
       "      <td>0.932299</td>\n",
       "      <td>0.885596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.533894</td>\n",
       "      <td>0.932299</td>\n",
       "      <td>0.885596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.533686</td>\n",
       "      <td>0.933709</td>\n",
       "      <td>0.888319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.538018</td>\n",
       "      <td>0.932299</td>\n",
       "      <td>0.885596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.541049</td>\n",
       "      <td>0.932299</td>\n",
       "      <td>0.885596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.530517</td>\n",
       "      <td>0.930889</td>\n",
       "      <td>0.884955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.531446</td>\n",
       "      <td>0.930889</td>\n",
       "      <td>0.885632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.532085</td>\n",
       "      <td>0.930889</td>\n",
       "      <td>0.885632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.532345</td>\n",
       "      <td>0.930889</td>\n",
       "      <td>0.885632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SI2M-Lab/DarijaBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SI2M-Lab/DarijaBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dfe53014de34cd0a456e196c62829fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2833 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcefe38d13634ebc9fb1f4f38e403633",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/709 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='675' max='675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [675/675 01:02, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.343500</td>\n",
       "      <td>0.242282</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.849502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.217200</td>\n",
       "      <td>0.213972</td>\n",
       "      <td>0.909732</td>\n",
       "      <td>0.845572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.142200</td>\n",
       "      <td>0.282806</td>\n",
       "      <td>0.925247</td>\n",
       "      <td>0.861992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.100500</td>\n",
       "      <td>0.307963</td>\n",
       "      <td>0.906911</td>\n",
       "      <td>0.858396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.065400</td>\n",
       "      <td>0.332393</td>\n",
       "      <td>0.926657</td>\n",
       "      <td>0.866929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.039000</td>\n",
       "      <td>0.369561</td>\n",
       "      <td>0.926657</td>\n",
       "      <td>0.875301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.029500</td>\n",
       "      <td>0.409730</td>\n",
       "      <td>0.922426</td>\n",
       "      <td>0.861612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>0.452196</td>\n",
       "      <td>0.926657</td>\n",
       "      <td>0.867834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.008300</td>\n",
       "      <td>0.446810</td>\n",
       "      <td>0.926657</td>\n",
       "      <td>0.878985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.474647</td>\n",
       "      <td>0.925247</td>\n",
       "      <td>0.873293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.523402</td>\n",
       "      <td>0.925247</td>\n",
       "      <td>0.861010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>0.504250</td>\n",
       "      <td>0.925247</td>\n",
       "      <td>0.877726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.504868</td>\n",
       "      <td>0.922426</td>\n",
       "      <td>0.871628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.544212</td>\n",
       "      <td>0.933709</td>\n",
       "      <td>0.879310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.503592</td>\n",
       "      <td>0.928068</td>\n",
       "      <td>0.880259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.515554</td>\n",
       "      <td>0.929478</td>\n",
       "      <td>0.877826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.540865</td>\n",
       "      <td>0.926657</td>\n",
       "      <td>0.869595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.550525</td>\n",
       "      <td>0.926657</td>\n",
       "      <td>0.869595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.529779</td>\n",
       "      <td>0.925247</td>\n",
       "      <td>0.874819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.538771</td>\n",
       "      <td>0.926657</td>\n",
       "      <td>0.875301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.007600</td>\n",
       "      <td>0.581807</td>\n",
       "      <td>0.930889</td>\n",
       "      <td>0.875879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.571832</td>\n",
       "      <td>0.928068</td>\n",
       "      <td>0.871677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.541695</td>\n",
       "      <td>0.925247</td>\n",
       "      <td>0.872510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.559208</td>\n",
       "      <td>0.929478</td>\n",
       "      <td>0.878596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.564640</td>\n",
       "      <td>0.929478</td>\n",
       "      <td>0.877826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.564282</td>\n",
       "      <td>0.929478</td>\n",
       "      <td>0.878596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.563955</td>\n",
       "      <td>0.929478</td>\n",
       "      <td>0.878596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SI2M-Lab/DarijaBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SI2M-Lab/DarijaBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b511ea844134f278b180dbed5b1581c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2833 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0c4b8e52893474dbac4e5bf6b3dba82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/709 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='675' max='675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [675/675 01:02, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.343500</td>\n",
       "      <td>0.242282</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.849502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.217200</td>\n",
       "      <td>0.213972</td>\n",
       "      <td>0.909732</td>\n",
       "      <td>0.845572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.142200</td>\n",
       "      <td>0.282806</td>\n",
       "      <td>0.925247</td>\n",
       "      <td>0.861992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.100500</td>\n",
       "      <td>0.307963</td>\n",
       "      <td>0.906911</td>\n",
       "      <td>0.858396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.065400</td>\n",
       "      <td>0.332393</td>\n",
       "      <td>0.926657</td>\n",
       "      <td>0.866929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.039000</td>\n",
       "      <td>0.369561</td>\n",
       "      <td>0.926657</td>\n",
       "      <td>0.875301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.029500</td>\n",
       "      <td>0.409730</td>\n",
       "      <td>0.922426</td>\n",
       "      <td>0.861612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>0.452196</td>\n",
       "      <td>0.926657</td>\n",
       "      <td>0.867834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.008300</td>\n",
       "      <td>0.446810</td>\n",
       "      <td>0.926657</td>\n",
       "      <td>0.878985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.474647</td>\n",
       "      <td>0.925247</td>\n",
       "      <td>0.873293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.523402</td>\n",
       "      <td>0.925247</td>\n",
       "      <td>0.861010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>0.504250</td>\n",
       "      <td>0.925247</td>\n",
       "      <td>0.877726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.504868</td>\n",
       "      <td>0.922426</td>\n",
       "      <td>0.871628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.544212</td>\n",
       "      <td>0.933709</td>\n",
       "      <td>0.879310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.503592</td>\n",
       "      <td>0.928068</td>\n",
       "      <td>0.880259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.515554</td>\n",
       "      <td>0.929478</td>\n",
       "      <td>0.877826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.540865</td>\n",
       "      <td>0.926657</td>\n",
       "      <td>0.869595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.550525</td>\n",
       "      <td>0.926657</td>\n",
       "      <td>0.869595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.529779</td>\n",
       "      <td>0.925247</td>\n",
       "      <td>0.874819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.538771</td>\n",
       "      <td>0.926657</td>\n",
       "      <td>0.875301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.007600</td>\n",
       "      <td>0.581807</td>\n",
       "      <td>0.930889</td>\n",
       "      <td>0.875879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.571832</td>\n",
       "      <td>0.928068</td>\n",
       "      <td>0.871677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.541695</td>\n",
       "      <td>0.925247</td>\n",
       "      <td>0.872510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.559208</td>\n",
       "      <td>0.929478</td>\n",
       "      <td>0.878596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.564640</td>\n",
       "      <td>0.929478</td>\n",
       "      <td>0.877826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.564282</td>\n",
       "      <td>0.929478</td>\n",
       "      <td>0.878596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.563955</td>\n",
       "      <td>0.929478</td>\n",
       "      <td>0.878596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SI2M-Lab/DarijaBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SI2M-Lab/DarijaBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53fc729c60494ad68a7681d8965915af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2833 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90947db9615c463dbba8e32039b76a3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/709 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='675' max='675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [675/675 01:02, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.343500</td>\n",
       "      <td>0.242282</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.849502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.217200</td>\n",
       "      <td>0.213972</td>\n",
       "      <td>0.909732</td>\n",
       "      <td>0.845572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.142200</td>\n",
       "      <td>0.282806</td>\n",
       "      <td>0.925247</td>\n",
       "      <td>0.861992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.100500</td>\n",
       "      <td>0.307963</td>\n",
       "      <td>0.906911</td>\n",
       "      <td>0.858396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.065400</td>\n",
       "      <td>0.332393</td>\n",
       "      <td>0.926657</td>\n",
       "      <td>0.866929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.039000</td>\n",
       "      <td>0.369561</td>\n",
       "      <td>0.926657</td>\n",
       "      <td>0.875301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.029500</td>\n",
       "      <td>0.409730</td>\n",
       "      <td>0.922426</td>\n",
       "      <td>0.861612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>0.452196</td>\n",
       "      <td>0.926657</td>\n",
       "      <td>0.867834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.008300</td>\n",
       "      <td>0.446810</td>\n",
       "      <td>0.926657</td>\n",
       "      <td>0.878985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.474647</td>\n",
       "      <td>0.925247</td>\n",
       "      <td>0.873293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.523402</td>\n",
       "      <td>0.925247</td>\n",
       "      <td>0.861010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>0.504250</td>\n",
       "      <td>0.925247</td>\n",
       "      <td>0.877726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.504868</td>\n",
       "      <td>0.922426</td>\n",
       "      <td>0.871628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.544212</td>\n",
       "      <td>0.933709</td>\n",
       "      <td>0.879310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.503592</td>\n",
       "      <td>0.928068</td>\n",
       "      <td>0.880259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.515554</td>\n",
       "      <td>0.929478</td>\n",
       "      <td>0.877826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.540865</td>\n",
       "      <td>0.926657</td>\n",
       "      <td>0.869595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.550525</td>\n",
       "      <td>0.926657</td>\n",
       "      <td>0.869595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.529779</td>\n",
       "      <td>0.925247</td>\n",
       "      <td>0.874819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.538771</td>\n",
       "      <td>0.926657</td>\n",
       "      <td>0.875301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.007600</td>\n",
       "      <td>0.581807</td>\n",
       "      <td>0.930889</td>\n",
       "      <td>0.875879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.571832</td>\n",
       "      <td>0.928068</td>\n",
       "      <td>0.871677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.541695</td>\n",
       "      <td>0.925247</td>\n",
       "      <td>0.872510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.559208</td>\n",
       "      <td>0.929478</td>\n",
       "      <td>0.878596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.564640</td>\n",
       "      <td>0.929478</td>\n",
       "      <td>0.877826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.564282</td>\n",
       "      <td>0.929478</td>\n",
       "      <td>0.878596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.563955</td>\n",
       "      <td>0.929478</td>\n",
       "      <td>0.878596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', '__index_level_0__'],\n",
       "        num_rows: 2833\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', '__index_level_0__'],\n",
       "        num_rows: 709\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorRoBERTa, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at otmangi/MorRoBERTa and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f13bb12181c1437aaeb00a5e6577b5fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2833 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "029881f27ca94959b92411a41b9fd5c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/709 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='675' max='675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [675/675 00:33, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.338200</td>\n",
       "      <td>0.272599</td>\n",
       "      <td>0.906911</td>\n",
       "      <td>0.839747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.236100</td>\n",
       "      <td>0.271816</td>\n",
       "      <td>0.894217</td>\n",
       "      <td>0.813764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.162000</td>\n",
       "      <td>0.268304</td>\n",
       "      <td>0.911142</td>\n",
       "      <td>0.865839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.087700</td>\n",
       "      <td>0.287356</td>\n",
       "      <td>0.911142</td>\n",
       "      <td>0.856301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.070500</td>\n",
       "      <td>0.318711</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.876183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.030400</td>\n",
       "      <td>0.347178</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.873642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.019300</td>\n",
       "      <td>0.553010</td>\n",
       "      <td>0.901269</td>\n",
       "      <td>0.830034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>0.519865</td>\n",
       "      <td>0.898449</td>\n",
       "      <td>0.846293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.006500</td>\n",
       "      <td>0.566631</td>\n",
       "      <td>0.911142</td>\n",
       "      <td>0.858674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.569869</td>\n",
       "      <td>0.912553</td>\n",
       "      <td>0.868939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.601670</td>\n",
       "      <td>0.909732</td>\n",
       "      <td>0.859105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.631858</td>\n",
       "      <td>0.909732</td>\n",
       "      <td>0.861286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.627385</td>\n",
       "      <td>0.908322</td>\n",
       "      <td>0.861580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.663086</td>\n",
       "      <td>0.909732</td>\n",
       "      <td>0.855240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.646932</td>\n",
       "      <td>0.913963</td>\n",
       "      <td>0.871366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.646460</td>\n",
       "      <td>0.913963</td>\n",
       "      <td>0.866761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.656831</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.867911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.663212</td>\n",
       "      <td>0.911142</td>\n",
       "      <td>0.860196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666495</td>\n",
       "      <td>0.911142</td>\n",
       "      <td>0.860196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.668969</td>\n",
       "      <td>0.911142</td>\n",
       "      <td>0.860196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.672582</td>\n",
       "      <td>0.911142</td>\n",
       "      <td>0.860196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.675757</td>\n",
       "      <td>0.911142</td>\n",
       "      <td>0.860196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.676505</td>\n",
       "      <td>0.911142</td>\n",
       "      <td>0.860196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.673303</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.867911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.692024</td>\n",
       "      <td>0.908322</td>\n",
       "      <td>0.854188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.694935</td>\n",
       "      <td>0.908322</td>\n",
       "      <td>0.854188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.695076</td>\n",
       "      <td>0.908322</td>\n",
       "      <td>0.854188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorRoBERTa, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at otmangi/MorRoBERTa and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79a7004c64b349908193062e64e4ac5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2833 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99ef5e7c27fb4ece9650591283bdefd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/709 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='675' max='675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [675/675 00:33, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.338200</td>\n",
       "      <td>0.272599</td>\n",
       "      <td>0.906911</td>\n",
       "      <td>0.839747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.236100</td>\n",
       "      <td>0.271816</td>\n",
       "      <td>0.894217</td>\n",
       "      <td>0.813764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.162000</td>\n",
       "      <td>0.268304</td>\n",
       "      <td>0.911142</td>\n",
       "      <td>0.865839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.087700</td>\n",
       "      <td>0.287356</td>\n",
       "      <td>0.911142</td>\n",
       "      <td>0.856301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.070500</td>\n",
       "      <td>0.318711</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.876183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.030400</td>\n",
       "      <td>0.347178</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.873642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.019300</td>\n",
       "      <td>0.553010</td>\n",
       "      <td>0.901269</td>\n",
       "      <td>0.830034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>0.519865</td>\n",
       "      <td>0.898449</td>\n",
       "      <td>0.846293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.006500</td>\n",
       "      <td>0.566631</td>\n",
       "      <td>0.911142</td>\n",
       "      <td>0.858674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.569869</td>\n",
       "      <td>0.912553</td>\n",
       "      <td>0.868939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.601670</td>\n",
       "      <td>0.909732</td>\n",
       "      <td>0.859105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.631858</td>\n",
       "      <td>0.909732</td>\n",
       "      <td>0.861286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.627385</td>\n",
       "      <td>0.908322</td>\n",
       "      <td>0.861580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.663086</td>\n",
       "      <td>0.909732</td>\n",
       "      <td>0.855240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.646932</td>\n",
       "      <td>0.913963</td>\n",
       "      <td>0.871366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.646460</td>\n",
       "      <td>0.913963</td>\n",
       "      <td>0.866761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.656831</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.867911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.663212</td>\n",
       "      <td>0.911142</td>\n",
       "      <td>0.860196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666495</td>\n",
       "      <td>0.911142</td>\n",
       "      <td>0.860196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.668969</td>\n",
       "      <td>0.911142</td>\n",
       "      <td>0.860196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.672582</td>\n",
       "      <td>0.911142</td>\n",
       "      <td>0.860196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.675757</td>\n",
       "      <td>0.911142</td>\n",
       "      <td>0.860196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.676505</td>\n",
       "      <td>0.911142</td>\n",
       "      <td>0.860196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.673303</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.867911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.692024</td>\n",
       "      <td>0.908322</td>\n",
       "      <td>0.854188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.694935</td>\n",
       "      <td>0.908322</td>\n",
       "      <td>0.854188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.695076</td>\n",
       "      <td>0.908322</td>\n",
       "      <td>0.854188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorRoBERTa, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at otmangi/MorRoBERTa and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de2204cf427f411ea7937ce51103d073",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2833 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20bfce980f8b4d798364d159b8619202",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/709 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='675' max='675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [675/675 00:33, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.338200</td>\n",
       "      <td>0.272599</td>\n",
       "      <td>0.906911</td>\n",
       "      <td>0.839747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.236100</td>\n",
       "      <td>0.271816</td>\n",
       "      <td>0.894217</td>\n",
       "      <td>0.813764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.162000</td>\n",
       "      <td>0.268304</td>\n",
       "      <td>0.911142</td>\n",
       "      <td>0.865839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.087700</td>\n",
       "      <td>0.287356</td>\n",
       "      <td>0.911142</td>\n",
       "      <td>0.856301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.070500</td>\n",
       "      <td>0.318711</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.876183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.030400</td>\n",
       "      <td>0.347178</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.873642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.019300</td>\n",
       "      <td>0.553010</td>\n",
       "      <td>0.901269</td>\n",
       "      <td>0.830034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>0.519865</td>\n",
       "      <td>0.898449</td>\n",
       "      <td>0.846293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.006500</td>\n",
       "      <td>0.566631</td>\n",
       "      <td>0.911142</td>\n",
       "      <td>0.858674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.569869</td>\n",
       "      <td>0.912553</td>\n",
       "      <td>0.868939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.601670</td>\n",
       "      <td>0.909732</td>\n",
       "      <td>0.859105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.631858</td>\n",
       "      <td>0.909732</td>\n",
       "      <td>0.861286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.627385</td>\n",
       "      <td>0.908322</td>\n",
       "      <td>0.861580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.663086</td>\n",
       "      <td>0.909732</td>\n",
       "      <td>0.855240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.646932</td>\n",
       "      <td>0.913963</td>\n",
       "      <td>0.871366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.646460</td>\n",
       "      <td>0.913963</td>\n",
       "      <td>0.866761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.656831</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.867911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.663212</td>\n",
       "      <td>0.911142</td>\n",
       "      <td>0.860196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666495</td>\n",
       "      <td>0.911142</td>\n",
       "      <td>0.860196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.668969</td>\n",
       "      <td>0.911142</td>\n",
       "      <td>0.860196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.672582</td>\n",
       "      <td>0.911142</td>\n",
       "      <td>0.860196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.675757</td>\n",
       "      <td>0.911142</td>\n",
       "      <td>0.860196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.676505</td>\n",
       "      <td>0.911142</td>\n",
       "      <td>0.860196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.673303</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.867911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.692024</td>\n",
       "      <td>0.908322</td>\n",
       "      <td>0.854188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.694935</td>\n",
       "      <td>0.908322</td>\n",
       "      <td>0.854188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.695076</td>\n",
       "      <td>0.908322</td>\n",
       "      <td>0.854188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorRoBERTa, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at otmangi/MorRoBERTa and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f0756f60a85429a9e0906bfbf1d0c9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2833 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08f978254df84543bc88585a7a1549be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/709 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='675' max='675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [675/675 00:33, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.357400</td>\n",
       "      <td>0.297391</td>\n",
       "      <td>0.902680</td>\n",
       "      <td>0.816421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.264718</td>\n",
       "      <td>0.897038</td>\n",
       "      <td>0.835339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.131400</td>\n",
       "      <td>0.301111</td>\n",
       "      <td>0.905501</td>\n",
       "      <td>0.842693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.325663</td>\n",
       "      <td>0.906911</td>\n",
       "      <td>0.853145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.041400</td>\n",
       "      <td>0.494806</td>\n",
       "      <td>0.902680</td>\n",
       "      <td>0.841721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.028900</td>\n",
       "      <td>0.509112</td>\n",
       "      <td>0.899859</td>\n",
       "      <td>0.837133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.009100</td>\n",
       "      <td>0.582205</td>\n",
       "      <td>0.897038</td>\n",
       "      <td>0.832546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.014000</td>\n",
       "      <td>0.576925</td>\n",
       "      <td>0.905501</td>\n",
       "      <td>0.833629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>0.597435</td>\n",
       "      <td>0.904090</td>\n",
       "      <td>0.836932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.675435</td>\n",
       "      <td>0.902680</td>\n",
       "      <td>0.843495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>0.675847</td>\n",
       "      <td>0.904090</td>\n",
       "      <td>0.838907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.727250</td>\n",
       "      <td>0.895628</td>\n",
       "      <td>0.835344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.721910</td>\n",
       "      <td>0.894217</td>\n",
       "      <td>0.830828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.784597</td>\n",
       "      <td>0.889986</td>\n",
       "      <td>0.831802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.753989</td>\n",
       "      <td>0.901269</td>\n",
       "      <td>0.827860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.736075</td>\n",
       "      <td>0.905501</td>\n",
       "      <td>0.845427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.796606</td>\n",
       "      <td>0.894217</td>\n",
       "      <td>0.835323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.753678</td>\n",
       "      <td>0.911142</td>\n",
       "      <td>0.848455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.758442</td>\n",
       "      <td>0.902680</td>\n",
       "      <td>0.839889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.830679</td>\n",
       "      <td>0.891396</td>\n",
       "      <td>0.832681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.779958</td>\n",
       "      <td>0.899859</td>\n",
       "      <td>0.838959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.765043</td>\n",
       "      <td>0.909732</td>\n",
       "      <td>0.845572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.757462</td>\n",
       "      <td>0.904090</td>\n",
       "      <td>0.844457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>0.769370</td>\n",
       "      <td>0.899859</td>\n",
       "      <td>0.839850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.800201</td>\n",
       "      <td>0.895628</td>\n",
       "      <td>0.837090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.804707</td>\n",
       "      <td>0.894217</td>\n",
       "      <td>0.835323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.804615</td>\n",
       "      <td>0.894217</td>\n",
       "      <td>0.835323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorRoBERTa, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at otmangi/MorRoBERTa and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5f65ae2d9094f56a7d52edafc57c9b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2833 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "605edfd74518409fad9b9af3bcb94d84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/709 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='675' max='675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [675/675 00:33, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.357400</td>\n",
       "      <td>0.297391</td>\n",
       "      <td>0.902680</td>\n",
       "      <td>0.816421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.264718</td>\n",
       "      <td>0.897038</td>\n",
       "      <td>0.835339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.131400</td>\n",
       "      <td>0.301111</td>\n",
       "      <td>0.905501</td>\n",
       "      <td>0.842693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.325663</td>\n",
       "      <td>0.906911</td>\n",
       "      <td>0.853145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.041400</td>\n",
       "      <td>0.494806</td>\n",
       "      <td>0.902680</td>\n",
       "      <td>0.841721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.028900</td>\n",
       "      <td>0.509112</td>\n",
       "      <td>0.899859</td>\n",
       "      <td>0.837133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.009100</td>\n",
       "      <td>0.582205</td>\n",
       "      <td>0.897038</td>\n",
       "      <td>0.832546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.014000</td>\n",
       "      <td>0.576925</td>\n",
       "      <td>0.905501</td>\n",
       "      <td>0.833629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>0.597435</td>\n",
       "      <td>0.904090</td>\n",
       "      <td>0.836932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.675435</td>\n",
       "      <td>0.902680</td>\n",
       "      <td>0.843495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>0.675847</td>\n",
       "      <td>0.904090</td>\n",
       "      <td>0.838907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.727250</td>\n",
       "      <td>0.895628</td>\n",
       "      <td>0.835344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.721910</td>\n",
       "      <td>0.894217</td>\n",
       "      <td>0.830828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.784597</td>\n",
       "      <td>0.889986</td>\n",
       "      <td>0.831802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.753989</td>\n",
       "      <td>0.901269</td>\n",
       "      <td>0.827860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.736075</td>\n",
       "      <td>0.905501</td>\n",
       "      <td>0.845427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.796606</td>\n",
       "      <td>0.894217</td>\n",
       "      <td>0.835323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.753678</td>\n",
       "      <td>0.911142</td>\n",
       "      <td>0.848455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.758442</td>\n",
       "      <td>0.902680</td>\n",
       "      <td>0.839889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.830679</td>\n",
       "      <td>0.891396</td>\n",
       "      <td>0.832681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.779958</td>\n",
       "      <td>0.899859</td>\n",
       "      <td>0.838959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.765043</td>\n",
       "      <td>0.909732</td>\n",
       "      <td>0.845572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.757462</td>\n",
       "      <td>0.904090</td>\n",
       "      <td>0.844457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>0.769370</td>\n",
       "      <td>0.899859</td>\n",
       "      <td>0.839850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.800201</td>\n",
       "      <td>0.895628</td>\n",
       "      <td>0.837090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.804707</td>\n",
       "      <td>0.894217</td>\n",
       "      <td>0.835323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.804615</td>\n",
       "      <td>0.894217</td>\n",
       "      <td>0.835323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorRoBERTa, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at otmangi/MorRoBERTa and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1f7a2a771064428b07c0531d95143f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2833 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05e36762be4b45ada46ac65c12122e6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/709 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='675' max='675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [675/675 00:34, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.357400</td>\n",
       "      <td>0.297391</td>\n",
       "      <td>0.902680</td>\n",
       "      <td>0.816421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.264718</td>\n",
       "      <td>0.897038</td>\n",
       "      <td>0.835339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.131400</td>\n",
       "      <td>0.301111</td>\n",
       "      <td>0.905501</td>\n",
       "      <td>0.842693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.325663</td>\n",
       "      <td>0.906911</td>\n",
       "      <td>0.853145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.041400</td>\n",
       "      <td>0.494806</td>\n",
       "      <td>0.902680</td>\n",
       "      <td>0.841721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.028900</td>\n",
       "      <td>0.509112</td>\n",
       "      <td>0.899859</td>\n",
       "      <td>0.837133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.009100</td>\n",
       "      <td>0.582205</td>\n",
       "      <td>0.897038</td>\n",
       "      <td>0.832546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.014000</td>\n",
       "      <td>0.576925</td>\n",
       "      <td>0.905501</td>\n",
       "      <td>0.833629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>0.597435</td>\n",
       "      <td>0.904090</td>\n",
       "      <td>0.836932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.675435</td>\n",
       "      <td>0.902680</td>\n",
       "      <td>0.843495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>0.675847</td>\n",
       "      <td>0.904090</td>\n",
       "      <td>0.838907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.727250</td>\n",
       "      <td>0.895628</td>\n",
       "      <td>0.835344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.721910</td>\n",
       "      <td>0.894217</td>\n",
       "      <td>0.830828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.784597</td>\n",
       "      <td>0.889986</td>\n",
       "      <td>0.831802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.753989</td>\n",
       "      <td>0.901269</td>\n",
       "      <td>0.827860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.736075</td>\n",
       "      <td>0.905501</td>\n",
       "      <td>0.845427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.796606</td>\n",
       "      <td>0.894217</td>\n",
       "      <td>0.835323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.753678</td>\n",
       "      <td>0.911142</td>\n",
       "      <td>0.848455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.758442</td>\n",
       "      <td>0.902680</td>\n",
       "      <td>0.839889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.830679</td>\n",
       "      <td>0.891396</td>\n",
       "      <td>0.832681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.779958</td>\n",
       "      <td>0.899859</td>\n",
       "      <td>0.838959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.765043</td>\n",
       "      <td>0.909732</td>\n",
       "      <td>0.845572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.757462</td>\n",
       "      <td>0.904090</td>\n",
       "      <td>0.844457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>0.769370</td>\n",
       "      <td>0.899859</td>\n",
       "      <td>0.839850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.800201</td>\n",
       "      <td>0.895628</td>\n",
       "      <td>0.837090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.804707</td>\n",
       "      <td>0.894217</td>\n",
       "      <td>0.835323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.804615</td>\n",
       "      <td>0.894217</td>\n",
       "      <td>0.835323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorRoBERTa, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at otmangi/MorRoBERTa and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d77eb5481694d648df3a1916b574c5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2833 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "103c61e8397045638f232d1facccb19c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/709 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='675' max='675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [675/675 00:33, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.327500</td>\n",
       "      <td>0.230063</td>\n",
       "      <td>0.913963</td>\n",
       "      <td>0.846516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.249400</td>\n",
       "      <td>0.278708</td>\n",
       "      <td>0.906911</td>\n",
       "      <td>0.816976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.135800</td>\n",
       "      <td>0.257639</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.852530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.141800</td>\n",
       "      <td>0.368633</td>\n",
       "      <td>0.905501</td>\n",
       "      <td>0.812004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.068600</td>\n",
       "      <td>0.332804</td>\n",
       "      <td>0.913963</td>\n",
       "      <td>0.848528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.039600</td>\n",
       "      <td>0.390139</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.854549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.024900</td>\n",
       "      <td>0.450862</td>\n",
       "      <td>0.908322</td>\n",
       "      <td>0.839640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>0.502043</td>\n",
       "      <td>0.906911</td>\n",
       "      <td>0.835575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>0.528319</td>\n",
       "      <td>0.908322</td>\n",
       "      <td>0.841676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>0.553349</td>\n",
       "      <td>0.912553</td>\n",
       "      <td>0.845540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>0.583296</td>\n",
       "      <td>0.912553</td>\n",
       "      <td>0.843477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.912553</td>\n",
       "      <td>0.844518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.579237</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.850523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.647970</td>\n",
       "      <td>0.919605</td>\n",
       "      <td>0.848348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.585081</td>\n",
       "      <td>0.913963</td>\n",
       "      <td>0.848528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.615693</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.850549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.658740</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.846368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.652002</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.847442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.643809</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.848496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.636320</td>\n",
       "      <td>0.913963</td>\n",
       "      <td>0.845482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.642476</td>\n",
       "      <td>0.913963</td>\n",
       "      <td>0.845482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.639606</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.848526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.639401</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.851548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.646069</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.848526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>0.654296</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.847501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.662159</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.850548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.661022</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.850548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorRoBERTa, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at otmangi/MorRoBERTa and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af2f4929c6ec438798f0e462cdd97c97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2833 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75acc9ff3bdf4662b5f10f708ac1c548",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/709 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='675' max='675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [675/675 00:34, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.327500</td>\n",
       "      <td>0.230063</td>\n",
       "      <td>0.913963</td>\n",
       "      <td>0.846516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.249400</td>\n",
       "      <td>0.278708</td>\n",
       "      <td>0.906911</td>\n",
       "      <td>0.816976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.135800</td>\n",
       "      <td>0.257639</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.852530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.141800</td>\n",
       "      <td>0.368633</td>\n",
       "      <td>0.905501</td>\n",
       "      <td>0.812004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.068600</td>\n",
       "      <td>0.332804</td>\n",
       "      <td>0.913963</td>\n",
       "      <td>0.848528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.039600</td>\n",
       "      <td>0.390139</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.854549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.024900</td>\n",
       "      <td>0.450862</td>\n",
       "      <td>0.908322</td>\n",
       "      <td>0.839640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>0.502043</td>\n",
       "      <td>0.906911</td>\n",
       "      <td>0.835575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>0.528319</td>\n",
       "      <td>0.908322</td>\n",
       "      <td>0.841676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>0.553349</td>\n",
       "      <td>0.912553</td>\n",
       "      <td>0.845540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>0.583296</td>\n",
       "      <td>0.912553</td>\n",
       "      <td>0.843477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.912553</td>\n",
       "      <td>0.844518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.579237</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.850523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.647970</td>\n",
       "      <td>0.919605</td>\n",
       "      <td>0.848348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.585081</td>\n",
       "      <td>0.913963</td>\n",
       "      <td>0.848528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.615693</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.850549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.658740</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.846368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.652002</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.847442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.643809</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.848496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.636320</td>\n",
       "      <td>0.913963</td>\n",
       "      <td>0.845482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.642476</td>\n",
       "      <td>0.913963</td>\n",
       "      <td>0.845482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.639606</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.848526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.639401</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.851548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.646069</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.848526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>0.654296</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.847501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.662159</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.850548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.661022</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.850548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorRoBERTa, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at otmangi/MorRoBERTa and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "829020c04dbf42b6bcbb06813f571294",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2833 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53ec63ec2f964a4caa4aa147d55fac7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/709 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='675' max='675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [675/675 00:34, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.327500</td>\n",
       "      <td>0.230063</td>\n",
       "      <td>0.913963</td>\n",
       "      <td>0.846516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.249400</td>\n",
       "      <td>0.278708</td>\n",
       "      <td>0.906911</td>\n",
       "      <td>0.816976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.135800</td>\n",
       "      <td>0.257639</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.852530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.141800</td>\n",
       "      <td>0.368633</td>\n",
       "      <td>0.905501</td>\n",
       "      <td>0.812004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.068600</td>\n",
       "      <td>0.332804</td>\n",
       "      <td>0.913963</td>\n",
       "      <td>0.848528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.039600</td>\n",
       "      <td>0.390139</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.854549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.024900</td>\n",
       "      <td>0.450862</td>\n",
       "      <td>0.908322</td>\n",
       "      <td>0.839640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>0.502043</td>\n",
       "      <td>0.906911</td>\n",
       "      <td>0.835575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>0.528319</td>\n",
       "      <td>0.908322</td>\n",
       "      <td>0.841676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>0.553349</td>\n",
       "      <td>0.912553</td>\n",
       "      <td>0.845540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>0.583296</td>\n",
       "      <td>0.912553</td>\n",
       "      <td>0.843477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.912553</td>\n",
       "      <td>0.844518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.579237</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.850523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.647970</td>\n",
       "      <td>0.919605</td>\n",
       "      <td>0.848348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.585081</td>\n",
       "      <td>0.913963</td>\n",
       "      <td>0.848528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.615693</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.850549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.658740</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.846368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.652002</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.847442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.643809</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.848496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.636320</td>\n",
       "      <td>0.913963</td>\n",
       "      <td>0.845482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.642476</td>\n",
       "      <td>0.913963</td>\n",
       "      <td>0.845482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.639606</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.848526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.639401</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.851548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.646069</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.848526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>0.654296</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.847501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.662159</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.850548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.661022</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.850548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', '__index_level_0__'],\n",
       "        num_rows: 2833\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', '__index_level_0__'],\n",
       "        num_rows: 709\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorrBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at otmangi/MorrBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cfc2e9be5904f95b3d6b161c2f41efe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2833 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ecf3d3d886149258fec88b24b46942e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/709 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='675' max='675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [675/675 01:01, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.296900</td>\n",
       "      <td>0.238469</td>\n",
       "      <td>0.905501</td>\n",
       "      <td>0.841752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.213000</td>\n",
       "      <td>0.235473</td>\n",
       "      <td>0.911142</td>\n",
       "      <td>0.858674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.144100</td>\n",
       "      <td>0.285909</td>\n",
       "      <td>0.901269</td>\n",
       "      <td>0.831094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.080700</td>\n",
       "      <td>0.302846</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.861176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.066900</td>\n",
       "      <td>0.485734</td>\n",
       "      <td>0.908322</td>\n",
       "      <td>0.844604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.028100</td>\n",
       "      <td>0.408612</td>\n",
       "      <td>0.906911</td>\n",
       "      <td>0.852348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.019600</td>\n",
       "      <td>0.463080</td>\n",
       "      <td>0.906911</td>\n",
       "      <td>0.846404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.012900</td>\n",
       "      <td>0.492354</td>\n",
       "      <td>0.908322</td>\n",
       "      <td>0.858024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>0.521806</td>\n",
       "      <td>0.905501</td>\n",
       "      <td>0.848873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>0.591161</td>\n",
       "      <td>0.901269</td>\n",
       "      <td>0.845077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.625748</td>\n",
       "      <td>0.906911</td>\n",
       "      <td>0.852348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.652375</td>\n",
       "      <td>0.909732</td>\n",
       "      <td>0.856822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.707861</td>\n",
       "      <td>0.898449</td>\n",
       "      <td>0.831454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.680096</td>\n",
       "      <td>0.911142</td>\n",
       "      <td>0.860196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.724039</td>\n",
       "      <td>0.902680</td>\n",
       "      <td>0.840813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.710640</td>\n",
       "      <td>0.905501</td>\n",
       "      <td>0.852110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.735077</td>\n",
       "      <td>0.901269</td>\n",
       "      <td>0.840783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.715720</td>\n",
       "      <td>0.906911</td>\n",
       "      <td>0.854702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.728150</td>\n",
       "      <td>0.906911</td>\n",
       "      <td>0.852348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.740828</td>\n",
       "      <td>0.904090</td>\n",
       "      <td>0.847039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.745242</td>\n",
       "      <td>0.902680</td>\n",
       "      <td>0.844362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.748498</td>\n",
       "      <td>0.902680</td>\n",
       "      <td>0.844362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.751151</td>\n",
       "      <td>0.902680</td>\n",
       "      <td>0.844362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.753639</td>\n",
       "      <td>0.901269</td>\n",
       "      <td>0.841668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.755193</td>\n",
       "      <td>0.901269</td>\n",
       "      <td>0.841668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.756630</td>\n",
       "      <td>0.901269</td>\n",
       "      <td>0.841668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.756801</td>\n",
       "      <td>0.901269</td>\n",
       "      <td>0.841668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorrBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at otmangi/MorrBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64dcd7ff97ee489ca823cab85dc5690c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2833 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d0c183bdadf495f83643abc2a83d956",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/709 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='675' max='675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [675/675 01:01, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.296900</td>\n",
       "      <td>0.238469</td>\n",
       "      <td>0.905501</td>\n",
       "      <td>0.841752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.213000</td>\n",
       "      <td>0.235473</td>\n",
       "      <td>0.911142</td>\n",
       "      <td>0.858674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.144100</td>\n",
       "      <td>0.285909</td>\n",
       "      <td>0.901269</td>\n",
       "      <td>0.831094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.080700</td>\n",
       "      <td>0.302846</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.861176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.066900</td>\n",
       "      <td>0.485734</td>\n",
       "      <td>0.908322</td>\n",
       "      <td>0.844604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.028100</td>\n",
       "      <td>0.408612</td>\n",
       "      <td>0.906911</td>\n",
       "      <td>0.852348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.019600</td>\n",
       "      <td>0.463080</td>\n",
       "      <td>0.906911</td>\n",
       "      <td>0.846404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.012900</td>\n",
       "      <td>0.492354</td>\n",
       "      <td>0.908322</td>\n",
       "      <td>0.858024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>0.521806</td>\n",
       "      <td>0.905501</td>\n",
       "      <td>0.848873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>0.591161</td>\n",
       "      <td>0.901269</td>\n",
       "      <td>0.845077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.625748</td>\n",
       "      <td>0.906911</td>\n",
       "      <td>0.852348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.652375</td>\n",
       "      <td>0.909732</td>\n",
       "      <td>0.856822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.707861</td>\n",
       "      <td>0.898449</td>\n",
       "      <td>0.831454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.680096</td>\n",
       "      <td>0.911142</td>\n",
       "      <td>0.860196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.724039</td>\n",
       "      <td>0.902680</td>\n",
       "      <td>0.840813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.710640</td>\n",
       "      <td>0.905501</td>\n",
       "      <td>0.852110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.735077</td>\n",
       "      <td>0.901269</td>\n",
       "      <td>0.840783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.715720</td>\n",
       "      <td>0.906911</td>\n",
       "      <td>0.854702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.728150</td>\n",
       "      <td>0.906911</td>\n",
       "      <td>0.852348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.740828</td>\n",
       "      <td>0.904090</td>\n",
       "      <td>0.847039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.745242</td>\n",
       "      <td>0.902680</td>\n",
       "      <td>0.844362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.748498</td>\n",
       "      <td>0.902680</td>\n",
       "      <td>0.844362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.751151</td>\n",
       "      <td>0.902680</td>\n",
       "      <td>0.844362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.753639</td>\n",
       "      <td>0.901269</td>\n",
       "      <td>0.841668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.755193</td>\n",
       "      <td>0.901269</td>\n",
       "      <td>0.841668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.756630</td>\n",
       "      <td>0.901269</td>\n",
       "      <td>0.841668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.756801</td>\n",
       "      <td>0.901269</td>\n",
       "      <td>0.841668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorrBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at otmangi/MorrBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3aebcd74e94c4c9885afaba9b2092615",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2833 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb4a9146f1304c9e885de36d7e4147e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/709 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='675' max='675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [675/675 01:02, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.296900</td>\n",
       "      <td>0.238469</td>\n",
       "      <td>0.905501</td>\n",
       "      <td>0.841752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.213000</td>\n",
       "      <td>0.235473</td>\n",
       "      <td>0.911142</td>\n",
       "      <td>0.858674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.144100</td>\n",
       "      <td>0.285909</td>\n",
       "      <td>0.901269</td>\n",
       "      <td>0.831094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.080700</td>\n",
       "      <td>0.302846</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.861176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.066900</td>\n",
       "      <td>0.485734</td>\n",
       "      <td>0.908322</td>\n",
       "      <td>0.844604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.028100</td>\n",
       "      <td>0.408612</td>\n",
       "      <td>0.906911</td>\n",
       "      <td>0.852348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.019600</td>\n",
       "      <td>0.463080</td>\n",
       "      <td>0.906911</td>\n",
       "      <td>0.846404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.012900</td>\n",
       "      <td>0.492354</td>\n",
       "      <td>0.908322</td>\n",
       "      <td>0.858024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>0.521806</td>\n",
       "      <td>0.905501</td>\n",
       "      <td>0.848873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>0.591161</td>\n",
       "      <td>0.901269</td>\n",
       "      <td>0.845077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.625748</td>\n",
       "      <td>0.906911</td>\n",
       "      <td>0.852348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.652375</td>\n",
       "      <td>0.909732</td>\n",
       "      <td>0.856822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.707861</td>\n",
       "      <td>0.898449</td>\n",
       "      <td>0.831454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.680096</td>\n",
       "      <td>0.911142</td>\n",
       "      <td>0.860196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.724039</td>\n",
       "      <td>0.902680</td>\n",
       "      <td>0.840813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.710640</td>\n",
       "      <td>0.905501</td>\n",
       "      <td>0.852110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.735077</td>\n",
       "      <td>0.901269</td>\n",
       "      <td>0.840783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.715720</td>\n",
       "      <td>0.906911</td>\n",
       "      <td>0.854702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.728150</td>\n",
       "      <td>0.906911</td>\n",
       "      <td>0.852348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.740828</td>\n",
       "      <td>0.904090</td>\n",
       "      <td>0.847039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.745242</td>\n",
       "      <td>0.902680</td>\n",
       "      <td>0.844362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.748498</td>\n",
       "      <td>0.902680</td>\n",
       "      <td>0.844362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.751151</td>\n",
       "      <td>0.902680</td>\n",
       "      <td>0.844362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.753639</td>\n",
       "      <td>0.901269</td>\n",
       "      <td>0.841668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.755193</td>\n",
       "      <td>0.901269</td>\n",
       "      <td>0.841668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.756630</td>\n",
       "      <td>0.901269</td>\n",
       "      <td>0.841668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.756801</td>\n",
       "      <td>0.901269</td>\n",
       "      <td>0.841668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorrBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at otmangi/MorrBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "150675e35daa4f1aa0d84d57a63595ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2833 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b409a5f5cfe4bee9a33c12af764f5ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/709 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='675' max='675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [675/675 01:01, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.302100</td>\n",
       "      <td>0.250796</td>\n",
       "      <td>0.899859</td>\n",
       "      <td>0.837133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.230600</td>\n",
       "      <td>0.234003</td>\n",
       "      <td>0.919605</td>\n",
       "      <td>0.867735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.116700</td>\n",
       "      <td>0.344002</td>\n",
       "      <td>0.885755</td>\n",
       "      <td>0.831625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.086800</td>\n",
       "      <td>0.336537</td>\n",
       "      <td>0.898449</td>\n",
       "      <td>0.838042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.027500</td>\n",
       "      <td>0.561520</td>\n",
       "      <td>0.884344</td>\n",
       "      <td>0.829946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.029800</td>\n",
       "      <td>0.572230</td>\n",
       "      <td>0.895628</td>\n",
       "      <td>0.835344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.011600</td>\n",
       "      <td>0.567202</td>\n",
       "      <td>0.905501</td>\n",
       "      <td>0.842693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.550184</td>\n",
       "      <td>0.912553</td>\n",
       "      <td>0.856549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.665844</td>\n",
       "      <td>0.897038</td>\n",
       "      <td>0.840550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>0.628467</td>\n",
       "      <td>0.911142</td>\n",
       "      <td>0.850300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>0.736963</td>\n",
       "      <td>0.895628</td>\n",
       "      <td>0.840428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.706291</td>\n",
       "      <td>0.905501</td>\n",
       "      <td>0.851319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.689847</td>\n",
       "      <td>0.908322</td>\n",
       "      <td>0.847389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.874985</td>\n",
       "      <td>0.873061</td>\n",
       "      <td>0.815082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.729981</td>\n",
       "      <td>0.908322</td>\n",
       "      <td>0.850897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.729976</td>\n",
       "      <td>0.898449</td>\n",
       "      <td>0.828394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.749772</td>\n",
       "      <td>0.899859</td>\n",
       "      <td>0.833302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.787397</td>\n",
       "      <td>0.898449</td>\n",
       "      <td>0.839794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.793850</td>\n",
       "      <td>0.899859</td>\n",
       "      <td>0.841592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.789085</td>\n",
       "      <td>0.904090</td>\n",
       "      <td>0.847039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>0.747179</td>\n",
       "      <td>0.904090</td>\n",
       "      <td>0.838907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.783842</td>\n",
       "      <td>0.902680</td>\n",
       "      <td>0.843495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.783686</td>\n",
       "      <td>0.902680</td>\n",
       "      <td>0.842615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.777842</td>\n",
       "      <td>0.904090</td>\n",
       "      <td>0.835920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.776355</td>\n",
       "      <td>0.904090</td>\n",
       "      <td>0.838907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.778486</td>\n",
       "      <td>0.902680</td>\n",
       "      <td>0.838951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.778864</td>\n",
       "      <td>0.901269</td>\n",
       "      <td>0.837095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorrBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at otmangi/MorrBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f279b929ecd740639acb573286763122",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2833 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c75a3ba5c2342d6bd9d859d076c6ace",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/709 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='675' max='675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [675/675 01:02, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.302100</td>\n",
       "      <td>0.250796</td>\n",
       "      <td>0.899859</td>\n",
       "      <td>0.837133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.230600</td>\n",
       "      <td>0.234003</td>\n",
       "      <td>0.919605</td>\n",
       "      <td>0.867735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.116700</td>\n",
       "      <td>0.344002</td>\n",
       "      <td>0.885755</td>\n",
       "      <td>0.831625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.086800</td>\n",
       "      <td>0.336537</td>\n",
       "      <td>0.898449</td>\n",
       "      <td>0.838042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.027500</td>\n",
       "      <td>0.561520</td>\n",
       "      <td>0.884344</td>\n",
       "      <td>0.829946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.029800</td>\n",
       "      <td>0.572230</td>\n",
       "      <td>0.895628</td>\n",
       "      <td>0.835344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.011600</td>\n",
       "      <td>0.567202</td>\n",
       "      <td>0.905501</td>\n",
       "      <td>0.842693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.550184</td>\n",
       "      <td>0.912553</td>\n",
       "      <td>0.856549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.665844</td>\n",
       "      <td>0.897038</td>\n",
       "      <td>0.840550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>0.628467</td>\n",
       "      <td>0.911142</td>\n",
       "      <td>0.850300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>0.736963</td>\n",
       "      <td>0.895628</td>\n",
       "      <td>0.840428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.706291</td>\n",
       "      <td>0.905501</td>\n",
       "      <td>0.851319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.689847</td>\n",
       "      <td>0.908322</td>\n",
       "      <td>0.847389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.874985</td>\n",
       "      <td>0.873061</td>\n",
       "      <td>0.815082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.729981</td>\n",
       "      <td>0.908322</td>\n",
       "      <td>0.850897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.729976</td>\n",
       "      <td>0.898449</td>\n",
       "      <td>0.828394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.749772</td>\n",
       "      <td>0.899859</td>\n",
       "      <td>0.833302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.787397</td>\n",
       "      <td>0.898449</td>\n",
       "      <td>0.839794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.793850</td>\n",
       "      <td>0.899859</td>\n",
       "      <td>0.841592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.789085</td>\n",
       "      <td>0.904090</td>\n",
       "      <td>0.847039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>0.747179</td>\n",
       "      <td>0.904090</td>\n",
       "      <td>0.838907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.783842</td>\n",
       "      <td>0.902680</td>\n",
       "      <td>0.843495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.783686</td>\n",
       "      <td>0.902680</td>\n",
       "      <td>0.842615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.777842</td>\n",
       "      <td>0.904090</td>\n",
       "      <td>0.835920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.776355</td>\n",
       "      <td>0.904090</td>\n",
       "      <td>0.838907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.778486</td>\n",
       "      <td>0.902680</td>\n",
       "      <td>0.838951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.778864</td>\n",
       "      <td>0.901269</td>\n",
       "      <td>0.837095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorrBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at otmangi/MorrBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d790f9134fa4b3aa69b41290aff245f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2833 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b7bc0a7e5624bc8bd81fccadcc0a1a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/709 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='675' max='675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [675/675 01:02, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.302100</td>\n",
       "      <td>0.250796</td>\n",
       "      <td>0.899859</td>\n",
       "      <td>0.837133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.230600</td>\n",
       "      <td>0.234003</td>\n",
       "      <td>0.919605</td>\n",
       "      <td>0.867735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.116700</td>\n",
       "      <td>0.344002</td>\n",
       "      <td>0.885755</td>\n",
       "      <td>0.831625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.086800</td>\n",
       "      <td>0.336537</td>\n",
       "      <td>0.898449</td>\n",
       "      <td>0.838042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.027500</td>\n",
       "      <td>0.561520</td>\n",
       "      <td>0.884344</td>\n",
       "      <td>0.829946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.029800</td>\n",
       "      <td>0.572230</td>\n",
       "      <td>0.895628</td>\n",
       "      <td>0.835344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.011600</td>\n",
       "      <td>0.567202</td>\n",
       "      <td>0.905501</td>\n",
       "      <td>0.842693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.550184</td>\n",
       "      <td>0.912553</td>\n",
       "      <td>0.856549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.665844</td>\n",
       "      <td>0.897038</td>\n",
       "      <td>0.840550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>0.628467</td>\n",
       "      <td>0.911142</td>\n",
       "      <td>0.850300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>0.736963</td>\n",
       "      <td>0.895628</td>\n",
       "      <td>0.840428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.706291</td>\n",
       "      <td>0.905501</td>\n",
       "      <td>0.851319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.689847</td>\n",
       "      <td>0.908322</td>\n",
       "      <td>0.847389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.874985</td>\n",
       "      <td>0.873061</td>\n",
       "      <td>0.815082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.729981</td>\n",
       "      <td>0.908322</td>\n",
       "      <td>0.850897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.729976</td>\n",
       "      <td>0.898449</td>\n",
       "      <td>0.828394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.749772</td>\n",
       "      <td>0.899859</td>\n",
       "      <td>0.833302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.787397</td>\n",
       "      <td>0.898449</td>\n",
       "      <td>0.839794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.793850</td>\n",
       "      <td>0.899859</td>\n",
       "      <td>0.841592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.789085</td>\n",
       "      <td>0.904090</td>\n",
       "      <td>0.847039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>0.747179</td>\n",
       "      <td>0.904090</td>\n",
       "      <td>0.838907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.783842</td>\n",
       "      <td>0.902680</td>\n",
       "      <td>0.843495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.783686</td>\n",
       "      <td>0.902680</td>\n",
       "      <td>0.842615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.777842</td>\n",
       "      <td>0.904090</td>\n",
       "      <td>0.835920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.776355</td>\n",
       "      <td>0.904090</td>\n",
       "      <td>0.838907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.778486</td>\n",
       "      <td>0.902680</td>\n",
       "      <td>0.838951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.778864</td>\n",
       "      <td>0.901269</td>\n",
       "      <td>0.837095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorrBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at otmangi/MorrBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d2886d15edd48fb8ae48d12c77f2d67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2833 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71ad710256774a9f94ee7357f9de4da3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/709 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='675' max='675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [675/675 01:02, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.300500</td>\n",
       "      <td>0.236199</td>\n",
       "      <td>0.908322</td>\n",
       "      <td>0.849171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.219000</td>\n",
       "      <td>0.224871</td>\n",
       "      <td>0.922426</td>\n",
       "      <td>0.866874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.125400</td>\n",
       "      <td>0.274929</td>\n",
       "      <td>0.921016</td>\n",
       "      <td>0.856693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.102900</td>\n",
       "      <td>0.283533</td>\n",
       "      <td>0.908322</td>\n",
       "      <td>0.844604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.061600</td>\n",
       "      <td>0.336511</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.854315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.041900</td>\n",
       "      <td>0.349805</td>\n",
       "      <td>0.909732</td>\n",
       "      <td>0.853607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.021300</td>\n",
       "      <td>0.371555</td>\n",
       "      <td>0.919605</td>\n",
       "      <td>0.857529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.008300</td>\n",
       "      <td>0.539153</td>\n",
       "      <td>0.921016</td>\n",
       "      <td>0.855702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>0.590436</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.848437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.562921</td>\n",
       "      <td>0.906911</td>\n",
       "      <td>0.845499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>0.595011</td>\n",
       "      <td>0.921016</td>\n",
       "      <td>0.853664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>0.657318</td>\n",
       "      <td>0.906911</td>\n",
       "      <td>0.850716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.585020</td>\n",
       "      <td>0.922426</td>\n",
       "      <td>0.866034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>0.595356</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.860913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.614392</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.863418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.605316</td>\n",
       "      <td>0.919605</td>\n",
       "      <td>0.858461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.611163</td>\n",
       "      <td>0.921016</td>\n",
       "      <td>0.860488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.616099</td>\n",
       "      <td>0.919605</td>\n",
       "      <td>0.859377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.621623</td>\n",
       "      <td>0.919605</td>\n",
       "      <td>0.860277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.627717</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.856291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.631878</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.859171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.643170</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.860049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.655956</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.860049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.658968</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.860049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.660008</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.860049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.660798</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.860049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.661115</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.860049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorrBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at otmangi/MorrBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2bd3824aa114ed7bfdc3a632dd28b34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2833 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d0870bab4d845b2922b89fb266f0ba6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/709 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='675' max='675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [675/675 01:01, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.300500</td>\n",
       "      <td>0.236199</td>\n",
       "      <td>0.908322</td>\n",
       "      <td>0.849171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.219000</td>\n",
       "      <td>0.224871</td>\n",
       "      <td>0.922426</td>\n",
       "      <td>0.866874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.125400</td>\n",
       "      <td>0.274929</td>\n",
       "      <td>0.921016</td>\n",
       "      <td>0.856693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.102900</td>\n",
       "      <td>0.283533</td>\n",
       "      <td>0.908322</td>\n",
       "      <td>0.844604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.061600</td>\n",
       "      <td>0.336511</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.854315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.041900</td>\n",
       "      <td>0.349805</td>\n",
       "      <td>0.909732</td>\n",
       "      <td>0.853607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.021300</td>\n",
       "      <td>0.371555</td>\n",
       "      <td>0.919605</td>\n",
       "      <td>0.857529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.008300</td>\n",
       "      <td>0.539153</td>\n",
       "      <td>0.921016</td>\n",
       "      <td>0.855702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>0.590436</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.848437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.562921</td>\n",
       "      <td>0.906911</td>\n",
       "      <td>0.845499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>0.595011</td>\n",
       "      <td>0.921016</td>\n",
       "      <td>0.853664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>0.657318</td>\n",
       "      <td>0.906911</td>\n",
       "      <td>0.850716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.585020</td>\n",
       "      <td>0.922426</td>\n",
       "      <td>0.866034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>0.595356</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.860913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.614392</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.863418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.605316</td>\n",
       "      <td>0.919605</td>\n",
       "      <td>0.858461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.611163</td>\n",
       "      <td>0.921016</td>\n",
       "      <td>0.860488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.616099</td>\n",
       "      <td>0.919605</td>\n",
       "      <td>0.859377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.621623</td>\n",
       "      <td>0.919605</td>\n",
       "      <td>0.860277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.627717</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.856291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.631878</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.859171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.643170</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.860049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.655956</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.860049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.658968</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.860049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.660008</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.860049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.660798</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.860049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.661115</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.860049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorrBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at otmangi/MorrBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4969004e43e4b6aaf2bb15f3d77e47f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2833 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37cc8b6a497c49259c4ddb568eb03ef3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/709 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='675' max='675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [675/675 01:02, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.300500</td>\n",
       "      <td>0.236199</td>\n",
       "      <td>0.908322</td>\n",
       "      <td>0.849171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.219000</td>\n",
       "      <td>0.224871</td>\n",
       "      <td>0.922426</td>\n",
       "      <td>0.866874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.125400</td>\n",
       "      <td>0.274929</td>\n",
       "      <td>0.921016</td>\n",
       "      <td>0.856693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.102900</td>\n",
       "      <td>0.283533</td>\n",
       "      <td>0.908322</td>\n",
       "      <td>0.844604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.061600</td>\n",
       "      <td>0.336511</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>0.854315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.041900</td>\n",
       "      <td>0.349805</td>\n",
       "      <td>0.909732</td>\n",
       "      <td>0.853607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.021300</td>\n",
       "      <td>0.371555</td>\n",
       "      <td>0.919605</td>\n",
       "      <td>0.857529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.008300</td>\n",
       "      <td>0.539153</td>\n",
       "      <td>0.921016</td>\n",
       "      <td>0.855702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>0.590436</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.848437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.562921</td>\n",
       "      <td>0.906911</td>\n",
       "      <td>0.845499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>0.595011</td>\n",
       "      <td>0.921016</td>\n",
       "      <td>0.853664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>0.657318</td>\n",
       "      <td>0.906911</td>\n",
       "      <td>0.850716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.585020</td>\n",
       "      <td>0.922426</td>\n",
       "      <td>0.866034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>0.595356</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.860913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.614392</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.863418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.605316</td>\n",
       "      <td>0.919605</td>\n",
       "      <td>0.858461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.611163</td>\n",
       "      <td>0.921016</td>\n",
       "      <td>0.860488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.616099</td>\n",
       "      <td>0.919605</td>\n",
       "      <td>0.859377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.621623</td>\n",
       "      <td>0.919605</td>\n",
       "      <td>0.860277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.627717</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.856291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.631878</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.859171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.643170</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.860049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.655956</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.860049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.658968</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.860049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.660008</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.860049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.660798</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.860049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.661115</td>\n",
       "      <td>0.918195</td>\n",
       "      <td>0.860049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SI2M-Lab/DarijaBERT</td>\n",
       "      <td>0.936530</td>\n",
       "      <td>0.892418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alger-ia/dziribert</td>\n",
       "      <td>0.923836</td>\n",
       "      <td>0.880488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>faisalq/EgyBERT</td>\n",
       "      <td>0.925247</td>\n",
       "      <td>0.874819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>faisalq/SaudiBERT</td>\n",
       "      <td>0.937941</td>\n",
       "      <td>0.893164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>otmangi/MorRoBERTa</td>\n",
       "      <td>0.916784</td>\n",
       "      <td>0.876183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>otmangi/MorrBERT</td>\n",
       "      <td>0.919605</td>\n",
       "      <td>0.867735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>tunis-ai/TunBERT</td>\n",
       "      <td>0.832158</td>\n",
       "      <td>0.673796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model  Accuracy        F1\n",
       "0   SI2M-Lab/DarijaBERT  0.936530  0.892418\n",
       "3    alger-ia/dziribert  0.923836  0.880488\n",
       "6       faisalq/EgyBERT  0.925247  0.874819\n",
       "9     faisalq/SaudiBERT  0.937941  0.893164\n",
       "12   otmangi/MorRoBERTa  0.916784  0.876183\n",
       "15     otmangi/MorrBERT  0.919605  0.867735\n",
       "18     tunis-ai/TunBERT  0.832158  0.673796"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" \n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import pyarabic.araby as araby\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.initializers import TruncatedNormal\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from datasets import load_dataset, Dataset, concatenate_datasets\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', 1000)\n",
    "\n",
    "\n",
    "fname = 'MSA_MDA_2'\n",
    "log_file = fname + '.txt'\n",
    "\n",
    "with open(log_file, 'w') as f:\n",
    "    f.write('Model,Accuracy,F1\\n')\n",
    "\n",
    "\n",
    "df = pd.read_csv('datasets/MSA_MDA_comments.csv', encoding='utf-8', engine='python', sep='\\t') #, quotechar=\"'\"  , quoting=3\n",
    "\n",
    "display(len(df))\n",
    "df = df[df['language'] == 'mda']\n",
    "      \n",
    "display(df.columns)\n",
    "display(df[:4])\n",
    "\n",
    "\n",
    "display(len(df))\n",
    "\n",
    "c = df['sentiment'].value_counts()\n",
    "display(c)\n",
    "\n",
    "classes = set(df['sentiment'].values)\n",
    "display(classes)\n",
    "\n",
    "df['sentiment'] = df['sentiment'].astype('category')\n",
    "df['label'] = df['sentiment'].cat.codes\n",
    "\n",
    "df = df[['text', 'label']]\n",
    "classes_num = len(classes)\n",
    "display(classes_num)\n",
    "display(len(df))\n",
    "\n",
    "\n",
    "max_sequence_length = 128\n",
    "\n",
    "\n",
    "\n",
    "models = [ \n",
    "        'faisalq/EgyBERT',            \n",
    "    'faisalq/SaudiBERT',            \n",
    "    'tunis-ai/TunBERT',\n",
    "    'alger-ia/dziribert',\n",
    "    'SI2M-Lab/DarijaBERT',\n",
    "    'otmangi/MorRoBERTa',\n",
    "    'otmangi/MorrBERT'\n",
    "            \n",
    "]\n",
    "\n",
    "\n",
    "seeds = [0, 1, 42]\n",
    "\n",
    "for model_name in models:\n",
    "    for seed in seeds:\n",
    "        ds = Dataset.from_pandas(df)\n",
    "        ds = ds.train_test_split(test_size=0.2, seed = seed)\n",
    "        if seed==0:\n",
    "            display(ds)\n",
    "            \n",
    "        for i in range(3):\n",
    "            print(f'{model_name}, try:{i}')\n",
    "                  \n",
    "            tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "            model = AutoModelForSequenceClassification.from_pretrained(model_name,\n",
    "                                                                  num_labels=classes_num).to('cuda')                                                 \n",
    "            dataset_train = ds['train']\n",
    "            dataset_validation = ds['test']                                                    \n",
    "            \n",
    "          \n",
    "    \n",
    "            def preprocess_function(examples):\n",
    "                return tokenizer(examples['text'], truncation=True, padding=\"max_length\",\n",
    "                                max_length=max_sequence_length)\n",
    "            \n",
    "            \n",
    "            dataset_train = dataset_train.map(preprocess_function, batched=True)\n",
    "            dataset_validation = dataset_validation.map(preprocess_function, batched=True)\n",
    "            \n",
    "           \n",
    "            \n",
    "            def compute_metrics(eval_pred):\n",
    "                logits, labels = eval_pred\n",
    "                predictions = np.argmax(logits, axis=-1)    \n",
    "                acc = accuracy_score(labels, predictions)        \n",
    "                f1 = f1_score(labels, predictions, average='macro')   \n",
    "                with open(log_file, 'a') as f:\n",
    "                    f.write(f'{model_name},{acc},{f1}\\n')\n",
    "                return {'accuracy': acc, 'f1_score': f1}\n",
    "    \n",
    "    \n",
    "            \n",
    "            \n",
    "            epochs = 15\n",
    "            save_steps = 10000 #save checkpoint every 10000 steps\n",
    "            batch_size = 64\n",
    "            \n",
    "            training_args = TrainingArguments(\n",
    "                output_dir = 'bert/',\n",
    "                overwrite_output_dir=True,\n",
    "                num_train_epochs = epochs,\n",
    "                per_device_train_batch_size = batch_size,\n",
    "                per_device_eval_batch_size = batch_size,\n",
    "                save_steps = save_steps,\n",
    "                save_total_limit = 1, #only save the last 5 checkpoints\n",
    "                fp16=True,\n",
    "                learning_rate = 5e-5,  # 5e-5 is the default\n",
    "                logging_steps = 25, #50_000\n",
    "                evaluation_strategy = 'steps',\n",
    "                # evaluate_during_training = True,\n",
    "                eval_steps = 25\n",
    "                \n",
    "            )\n",
    "            \n",
    "            trainer = Trainer(\n",
    "                model = model,\n",
    "                args = training_args,\n",
    "                # data_collator=data_collator,\n",
    "                train_dataset=dataset_train,\n",
    "                eval_dataset=dataset_validation,\n",
    "                compute_metrics = compute_metrics\n",
    "            )\n",
    "            \n",
    "            \n",
    "            trainer.train()\n",
    "\n",
    "\n",
    "results = pd.read_csv(log_file)\n",
    "\n",
    "best_results = results.groupby('Model', as_index=False)['F1'].max()\n",
    "\n",
    "best_results = pd.merge(best_results, results, on=['Model', 'F1'])\n",
    "best_results = best_results[['Model', 'Accuracy', 'F1']]\n",
    "best_results = best_results.drop_duplicates()\n",
    "best_results.to_csv(f'{fname}.csv')\n",
    "display(best_results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a213ac86-934f-4e82-a949-0bcdcae2188d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220784d6-b06d-4429-adb8-0026654f9d49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8647cf08-3aa6-44eb-846f-4bed97554042",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e203fa6b-c9d7-44a4-b501-a67bfd3e4ce4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8794b705-31a1-45d7-8e88-4017a9c282aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
