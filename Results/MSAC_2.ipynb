{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d804ae66-9435-44be-8aad-beacbdeec0f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-17 04:53:32.046391: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-17 04:53:32.072230: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-17 04:53:32.485516: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Found cached dataset parquet (/home/ffq/.cache/huggingface/datasets/AbderrahmanSkiredj1___parquet/AbderrahmanSkiredj1--MSAC_darija_sentiment_analysis-78ec287cfc3da3ad/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b5a98cec54a4a1d8123e606b03459ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['text', 'label'], dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'طوال حياتي لم المس اي تغير حتى قدمت هذه الحكومة فل نقف بجانها بصوتنا'</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'منتوج رائع  وثمن مناسب ....جميل'</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'كلنا ابن كيران لمتافق معايا يدير جيم'</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'وفقك الله لولاية اخرى حقاش مكينش محسن منك'</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                     text   \n",
       "0  'طوال حياتي لم المس اي تغير حتى قدمت هذه الحكومة فل نقف بجانها بصوتنا'  \\\n",
       "1                                       'منتوج رائع  وثمن مناسب ....جميل'   \n",
       "2                                  'كلنا ابن كيران لمتافق معايا يدير جيم'   \n",
       "3                             'وفقك الله لولاية اخرى حقاش مكينش محسن منك'   \n",
       "\n",
       "  label  \n",
       "0   pos  \n",
       "1   pos  \n",
       "2   pos  \n",
       "3   pos  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'neg', 'pos'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "label\n",
       "pos    1000\n",
       "neg    1000\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 1600\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 400\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/EgyBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/EgyBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 01:06, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.671100</td>\n",
       "      <td>0.623361</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.887189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.515100</td>\n",
       "      <td>0.425650</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.898001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.352600</td>\n",
       "      <td>0.320460</td>\n",
       "      <td>0.917500</td>\n",
       "      <td>0.916345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.248400</td>\n",
       "      <td>0.285425</td>\n",
       "      <td>0.917500</td>\n",
       "      <td>0.916026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.199800</td>\n",
       "      <td>0.260188</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.913651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.144900</td>\n",
       "      <td>0.276651</td>\n",
       "      <td>0.905000</td>\n",
       "      <td>0.904762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.112000</td>\n",
       "      <td>0.257271</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.924517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.078800</td>\n",
       "      <td>0.271034</td>\n",
       "      <td>0.917500</td>\n",
       "      <td>0.916788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.074300</td>\n",
       "      <td>0.408380</td>\n",
       "      <td>0.877500</td>\n",
       "      <td>0.877438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.068400</td>\n",
       "      <td>0.283268</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.911275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.041400</td>\n",
       "      <td>0.323748</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.912157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.028900</td>\n",
       "      <td>0.374191</td>\n",
       "      <td>0.907500</td>\n",
       "      <td>0.907137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.032800</td>\n",
       "      <td>0.352014</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.912038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.020400</td>\n",
       "      <td>0.338710</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.918928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.029600</td>\n",
       "      <td>0.348563</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.919418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.014700</td>\n",
       "      <td>0.399607</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.912157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.024900</td>\n",
       "      <td>0.383348</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.911971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.025100</td>\n",
       "      <td>0.384216</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.911971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.017100</td>\n",
       "      <td>0.387205</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.914452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.024200</td>\n",
       "      <td>0.435592</td>\n",
       "      <td>0.907500</td>\n",
       "      <td>0.907137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.018900</td>\n",
       "      <td>0.422378</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.909557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.016600</td>\n",
       "      <td>0.443023</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.909618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.016000</td>\n",
       "      <td>0.402878</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.919418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.478775</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.899639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>0.483314</td>\n",
       "      <td>0.907500</td>\n",
       "      <td>0.907291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.016200</td>\n",
       "      <td>0.494333</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.899840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>0.458945</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.899639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.012100</td>\n",
       "      <td>0.450200</td>\n",
       "      <td>0.907500</td>\n",
       "      <td>0.907011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.463874</td>\n",
       "      <td>0.902500</td>\n",
       "      <td>0.902118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.007800</td>\n",
       "      <td>0.461689</td>\n",
       "      <td>0.902500</td>\n",
       "      <td>0.902118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.007700</td>\n",
       "      <td>0.461378</td>\n",
       "      <td>0.905000</td>\n",
       "      <td>0.904597</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/EgyBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/EgyBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 01:50, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.673400</td>\n",
       "      <td>0.629427</td>\n",
       "      <td>0.882500</td>\n",
       "      <td>0.882287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.527600</td>\n",
       "      <td>0.446657</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.889203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.365800</td>\n",
       "      <td>0.335914</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.911054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.238400</td>\n",
       "      <td>0.261721</td>\n",
       "      <td>0.927500</td>\n",
       "      <td>0.927003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.180600</td>\n",
       "      <td>0.258179</td>\n",
       "      <td>0.922500</td>\n",
       "      <td>0.921594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.140500</td>\n",
       "      <td>0.257090</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.924081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.111400</td>\n",
       "      <td>0.279988</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.912100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.082200</td>\n",
       "      <td>0.287968</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.919547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.067200</td>\n",
       "      <td>0.301588</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.919547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>0.354486</td>\n",
       "      <td>0.905000</td>\n",
       "      <td>0.904712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.046000</td>\n",
       "      <td>0.307340</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.924388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.028000</td>\n",
       "      <td>0.350981</td>\n",
       "      <td>0.917500</td>\n",
       "      <td>0.917176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.034700</td>\n",
       "      <td>0.353619</td>\n",
       "      <td>0.922500</td>\n",
       "      <td>0.922145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.025800</td>\n",
       "      <td>0.366759</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.914581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.019200</td>\n",
       "      <td>0.370792</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.914452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.011200</td>\n",
       "      <td>0.386444</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.909265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.018000</td>\n",
       "      <td>0.430153</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.912157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.017700</td>\n",
       "      <td>0.429576</td>\n",
       "      <td>0.907500</td>\n",
       "      <td>0.907011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.013700</td>\n",
       "      <td>0.425285</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.912157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.014000</td>\n",
       "      <td>0.428872</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.909420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>0.441774</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.911900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.012600</td>\n",
       "      <td>0.457417</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.914381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.008300</td>\n",
       "      <td>0.462533</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.914381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.016700</td>\n",
       "      <td>0.465145</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.911900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.007800</td>\n",
       "      <td>0.468638</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.911900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.012300</td>\n",
       "      <td>0.447937</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.912100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.007600</td>\n",
       "      <td>0.456234</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.912157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>0.456775</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.914639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.007600</td>\n",
       "      <td>0.457613</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.914639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.011900</td>\n",
       "      <td>0.458023</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.912100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.011900</td>\n",
       "      <td>0.457882</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.912100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/EgyBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/EgyBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 01:50, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.673400</td>\n",
       "      <td>0.629427</td>\n",
       "      <td>0.882500</td>\n",
       "      <td>0.882287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.527600</td>\n",
       "      <td>0.446657</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.889203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.365800</td>\n",
       "      <td>0.335914</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.911054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.238400</td>\n",
       "      <td>0.261721</td>\n",
       "      <td>0.927500</td>\n",
       "      <td>0.927003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.180600</td>\n",
       "      <td>0.258179</td>\n",
       "      <td>0.922500</td>\n",
       "      <td>0.921594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.140500</td>\n",
       "      <td>0.257090</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.924081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.111400</td>\n",
       "      <td>0.279988</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.912100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.082200</td>\n",
       "      <td>0.287968</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.919547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.067200</td>\n",
       "      <td>0.301588</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.919547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>0.354486</td>\n",
       "      <td>0.905000</td>\n",
       "      <td>0.904712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.046000</td>\n",
       "      <td>0.307340</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.924388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.028000</td>\n",
       "      <td>0.350981</td>\n",
       "      <td>0.917500</td>\n",
       "      <td>0.917176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.034700</td>\n",
       "      <td>0.353619</td>\n",
       "      <td>0.922500</td>\n",
       "      <td>0.922145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.025800</td>\n",
       "      <td>0.366759</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.914581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.019200</td>\n",
       "      <td>0.370792</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.914452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.011200</td>\n",
       "      <td>0.386444</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.909265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.018000</td>\n",
       "      <td>0.430153</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.912157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.017700</td>\n",
       "      <td>0.429576</td>\n",
       "      <td>0.907500</td>\n",
       "      <td>0.907011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.013700</td>\n",
       "      <td>0.425285</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.912157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.014000</td>\n",
       "      <td>0.428872</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.909420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>0.441774</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.911900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.012600</td>\n",
       "      <td>0.457417</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.914381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.008300</td>\n",
       "      <td>0.462533</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.914381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.016700</td>\n",
       "      <td>0.465145</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.911900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.007800</td>\n",
       "      <td>0.468638</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.911900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.012300</td>\n",
       "      <td>0.447937</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.912100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.007600</td>\n",
       "      <td>0.456234</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.912157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>0.456775</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.914639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.007600</td>\n",
       "      <td>0.457613</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.914639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.011900</td>\n",
       "      <td>0.458023</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.912100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.011900</td>\n",
       "      <td>0.457882</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.912100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/EgyBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/EgyBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 01:50, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.671800</td>\n",
       "      <td>0.618632</td>\n",
       "      <td>0.867500</td>\n",
       "      <td>0.867260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.521600</td>\n",
       "      <td>0.419557</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.912038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.355600</td>\n",
       "      <td>0.341722</td>\n",
       "      <td>0.905000</td>\n",
       "      <td>0.903941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.260300</td>\n",
       "      <td>0.284746</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.919547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.192700</td>\n",
       "      <td>0.263112</td>\n",
       "      <td>0.922500</td>\n",
       "      <td>0.922196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.132800</td>\n",
       "      <td>0.321021</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.899910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.130500</td>\n",
       "      <td>0.282505</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.914519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.095800</td>\n",
       "      <td>0.300322</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.912100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.080900</td>\n",
       "      <td>0.322264</td>\n",
       "      <td>0.907500</td>\n",
       "      <td>0.907291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.055500</td>\n",
       "      <td>0.384721</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.897392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.051500</td>\n",
       "      <td>0.348516</td>\n",
       "      <td>0.907500</td>\n",
       "      <td>0.907193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.029800</td>\n",
       "      <td>0.387394</td>\n",
       "      <td>0.907500</td>\n",
       "      <td>0.907453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.030400</td>\n",
       "      <td>0.417353</td>\n",
       "      <td>0.907500</td>\n",
       "      <td>0.907370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.020900</td>\n",
       "      <td>0.408698</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.909774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.027000</td>\n",
       "      <td>0.416371</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.912038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.022900</td>\n",
       "      <td>0.435053</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.909890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.024500</td>\n",
       "      <td>0.474657</td>\n",
       "      <td>0.905000</td>\n",
       "      <td>0.904962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.016300</td>\n",
       "      <td>0.431323</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.912302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.022000</td>\n",
       "      <td>0.460632</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.909890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.017600</td>\n",
       "      <td>0.463959</td>\n",
       "      <td>0.907500</td>\n",
       "      <td>0.907402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.025700</td>\n",
       "      <td>0.455916</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.912258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.009100</td>\n",
       "      <td>0.465096</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.912100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.025600</td>\n",
       "      <td>0.470717</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.911971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.018000</td>\n",
       "      <td>0.470328</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.914639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.021000</td>\n",
       "      <td>0.477512</td>\n",
       "      <td>0.907500</td>\n",
       "      <td>0.907193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.021300</td>\n",
       "      <td>0.479552</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.909727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.016900</td>\n",
       "      <td>0.482031</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.909727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.012700</td>\n",
       "      <td>0.484298</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.909727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.021100</td>\n",
       "      <td>0.485751</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.909727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.021100</td>\n",
       "      <td>0.493568</td>\n",
       "      <td>0.907500</td>\n",
       "      <td>0.907244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.016900</td>\n",
       "      <td>0.495935</td>\n",
       "      <td>0.907500</td>\n",
       "      <td>0.907244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/EgyBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/EgyBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 01:50, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.671800</td>\n",
       "      <td>0.618632</td>\n",
       "      <td>0.867500</td>\n",
       "      <td>0.867260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.521600</td>\n",
       "      <td>0.419557</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.912038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.355600</td>\n",
       "      <td>0.341722</td>\n",
       "      <td>0.905000</td>\n",
       "      <td>0.903941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.260300</td>\n",
       "      <td>0.284746</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.919547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.192700</td>\n",
       "      <td>0.263112</td>\n",
       "      <td>0.922500</td>\n",
       "      <td>0.922196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.132800</td>\n",
       "      <td>0.321021</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.899910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.130500</td>\n",
       "      <td>0.282505</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.914519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.095800</td>\n",
       "      <td>0.300322</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.912100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.080900</td>\n",
       "      <td>0.322264</td>\n",
       "      <td>0.907500</td>\n",
       "      <td>0.907291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.055500</td>\n",
       "      <td>0.384721</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.897392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.051500</td>\n",
       "      <td>0.348516</td>\n",
       "      <td>0.907500</td>\n",
       "      <td>0.907193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.029800</td>\n",
       "      <td>0.387394</td>\n",
       "      <td>0.907500</td>\n",
       "      <td>0.907453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.030400</td>\n",
       "      <td>0.417353</td>\n",
       "      <td>0.907500</td>\n",
       "      <td>0.907370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.020900</td>\n",
       "      <td>0.408698</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.909774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.027000</td>\n",
       "      <td>0.416371</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.912038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.022900</td>\n",
       "      <td>0.435053</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.909890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.024500</td>\n",
       "      <td>0.474657</td>\n",
       "      <td>0.905000</td>\n",
       "      <td>0.904962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.016300</td>\n",
       "      <td>0.431323</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.912302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.022000</td>\n",
       "      <td>0.460632</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.909890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.017600</td>\n",
       "      <td>0.463959</td>\n",
       "      <td>0.907500</td>\n",
       "      <td>0.907402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.025700</td>\n",
       "      <td>0.455916</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.912258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.009100</td>\n",
       "      <td>0.465096</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.912100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.025600</td>\n",
       "      <td>0.470717</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.911971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.018000</td>\n",
       "      <td>0.470328</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.914639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.021000</td>\n",
       "      <td>0.477512</td>\n",
       "      <td>0.907500</td>\n",
       "      <td>0.907193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.021300</td>\n",
       "      <td>0.479552</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.909727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.016900</td>\n",
       "      <td>0.482031</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.909727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.012700</td>\n",
       "      <td>0.484298</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.909727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.021100</td>\n",
       "      <td>0.485751</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.909727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.021100</td>\n",
       "      <td>0.493568</td>\n",
       "      <td>0.907500</td>\n",
       "      <td>0.907244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.016900</td>\n",
       "      <td>0.495935</td>\n",
       "      <td>0.907500</td>\n",
       "      <td>0.907244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/EgyBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/EgyBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 01:50, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.671800</td>\n",
       "      <td>0.618632</td>\n",
       "      <td>0.867500</td>\n",
       "      <td>0.867260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.521600</td>\n",
       "      <td>0.419557</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.912038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.355600</td>\n",
       "      <td>0.341722</td>\n",
       "      <td>0.905000</td>\n",
       "      <td>0.903941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.260300</td>\n",
       "      <td>0.284746</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.919547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.192700</td>\n",
       "      <td>0.263112</td>\n",
       "      <td>0.922500</td>\n",
       "      <td>0.922196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.132800</td>\n",
       "      <td>0.321021</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.899910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.130500</td>\n",
       "      <td>0.282505</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.914519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.095800</td>\n",
       "      <td>0.300322</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.912100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.080900</td>\n",
       "      <td>0.322264</td>\n",
       "      <td>0.907500</td>\n",
       "      <td>0.907291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.055500</td>\n",
       "      <td>0.384721</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.897392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.051500</td>\n",
       "      <td>0.348516</td>\n",
       "      <td>0.907500</td>\n",
       "      <td>0.907193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.029800</td>\n",
       "      <td>0.387394</td>\n",
       "      <td>0.907500</td>\n",
       "      <td>0.907453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.030400</td>\n",
       "      <td>0.417353</td>\n",
       "      <td>0.907500</td>\n",
       "      <td>0.907370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.020900</td>\n",
       "      <td>0.408698</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.909774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.027000</td>\n",
       "      <td>0.416371</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.912038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.022900</td>\n",
       "      <td>0.435053</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.909890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.024500</td>\n",
       "      <td>0.474657</td>\n",
       "      <td>0.905000</td>\n",
       "      <td>0.904962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.016300</td>\n",
       "      <td>0.431323</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.912302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.022000</td>\n",
       "      <td>0.460632</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.909890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.017600</td>\n",
       "      <td>0.463959</td>\n",
       "      <td>0.907500</td>\n",
       "      <td>0.907402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.025700</td>\n",
       "      <td>0.455916</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.912258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.009100</td>\n",
       "      <td>0.465096</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.912100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.025600</td>\n",
       "      <td>0.470717</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.911971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.018000</td>\n",
       "      <td>0.470328</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.914639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.021000</td>\n",
       "      <td>0.477512</td>\n",
       "      <td>0.907500</td>\n",
       "      <td>0.907193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.021300</td>\n",
       "      <td>0.479552</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.909727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.016900</td>\n",
       "      <td>0.482031</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.909727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.012700</td>\n",
       "      <td>0.484298</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.909727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.021100</td>\n",
       "      <td>0.485751</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.909727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.021100</td>\n",
       "      <td>0.493568</td>\n",
       "      <td>0.907500</td>\n",
       "      <td>0.907244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.016900</td>\n",
       "      <td>0.495935</td>\n",
       "      <td>0.907500</td>\n",
       "      <td>0.907244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/EgyBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/EgyBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 01:50, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.675900</td>\n",
       "      <td>0.626273</td>\n",
       "      <td>0.877500</td>\n",
       "      <td>0.876853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.535900</td>\n",
       "      <td>0.420074</td>\n",
       "      <td>0.922500</td>\n",
       "      <td>0.922196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.364300</td>\n",
       "      <td>0.311947</td>\n",
       "      <td>0.927500</td>\n",
       "      <td>0.927062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.264800</td>\n",
       "      <td>0.260896</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.929788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.179900</td>\n",
       "      <td>0.272641</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.919950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.130500</td>\n",
       "      <td>0.247837</td>\n",
       "      <td>0.927500</td>\n",
       "      <td>0.927300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.122500</td>\n",
       "      <td>0.291791</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.909998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.101200</td>\n",
       "      <td>0.300080</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.914991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.089000</td>\n",
       "      <td>0.278332</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.919757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.076300</td>\n",
       "      <td>0.286613</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.919711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.070100</td>\n",
       "      <td>0.327810</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.914947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.060300</td>\n",
       "      <td>0.302337</td>\n",
       "      <td>0.922500</td>\n",
       "      <td>0.922360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.059900</td>\n",
       "      <td>0.293526</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.919711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.042000</td>\n",
       "      <td>0.338219</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.914966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.042800</td>\n",
       "      <td>0.349598</td>\n",
       "      <td>0.917500</td>\n",
       "      <td>0.917487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.024900</td>\n",
       "      <td>0.365970</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.914966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.024600</td>\n",
       "      <td>0.379657</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.909919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.015700</td>\n",
       "      <td>0.399300</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.912473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.022600</td>\n",
       "      <td>0.390978</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.912456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.010500</td>\n",
       "      <td>0.405368</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.912434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>0.421633</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.914923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.012400</td>\n",
       "      <td>0.430177</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.912434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.014700</td>\n",
       "      <td>0.420079</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.914864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>0.415185</td>\n",
       "      <td>0.917500</td>\n",
       "      <td>0.917313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.004800</td>\n",
       "      <td>0.423371</td>\n",
       "      <td>0.917500</td>\n",
       "      <td>0.917313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.431138</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.914828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>0.437216</td>\n",
       "      <td>0.917500</td>\n",
       "      <td>0.917351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>0.451829</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.914896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.466899</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.912407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>0.473518</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.912407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.474580</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.912407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/EgyBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/EgyBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 01:50, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.675900</td>\n",
       "      <td>0.626273</td>\n",
       "      <td>0.877500</td>\n",
       "      <td>0.876853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.535900</td>\n",
       "      <td>0.420074</td>\n",
       "      <td>0.922500</td>\n",
       "      <td>0.922196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.364300</td>\n",
       "      <td>0.311947</td>\n",
       "      <td>0.927500</td>\n",
       "      <td>0.927062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.264800</td>\n",
       "      <td>0.260896</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.929788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.179900</td>\n",
       "      <td>0.272641</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.919950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.130500</td>\n",
       "      <td>0.247837</td>\n",
       "      <td>0.927500</td>\n",
       "      <td>0.927300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.122500</td>\n",
       "      <td>0.291791</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.909998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.101200</td>\n",
       "      <td>0.300080</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.914991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.089000</td>\n",
       "      <td>0.278332</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.919757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.076300</td>\n",
       "      <td>0.286613</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.919711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.070100</td>\n",
       "      <td>0.327810</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.914947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.060300</td>\n",
       "      <td>0.302337</td>\n",
       "      <td>0.922500</td>\n",
       "      <td>0.922360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.059900</td>\n",
       "      <td>0.293526</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.919711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.042000</td>\n",
       "      <td>0.338219</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.914966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.042800</td>\n",
       "      <td>0.349598</td>\n",
       "      <td>0.917500</td>\n",
       "      <td>0.917487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.024900</td>\n",
       "      <td>0.365970</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.914966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.024600</td>\n",
       "      <td>0.379657</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.909919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.015700</td>\n",
       "      <td>0.399300</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.912473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.022600</td>\n",
       "      <td>0.390978</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.912456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.010500</td>\n",
       "      <td>0.405368</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.912434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>0.421633</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.914923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.012400</td>\n",
       "      <td>0.430177</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.912434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.014700</td>\n",
       "      <td>0.420079</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.914864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>0.415185</td>\n",
       "      <td>0.917500</td>\n",
       "      <td>0.917313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.004800</td>\n",
       "      <td>0.423371</td>\n",
       "      <td>0.917500</td>\n",
       "      <td>0.917313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.431138</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.914828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>0.437216</td>\n",
       "      <td>0.917500</td>\n",
       "      <td>0.917351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>0.451829</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.914896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.466899</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.912407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>0.473518</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.912407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.474580</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.912407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/EgyBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/EgyBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 01:50, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.675900</td>\n",
       "      <td>0.626273</td>\n",
       "      <td>0.877500</td>\n",
       "      <td>0.876853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.535900</td>\n",
       "      <td>0.420074</td>\n",
       "      <td>0.922500</td>\n",
       "      <td>0.922196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.364300</td>\n",
       "      <td>0.311947</td>\n",
       "      <td>0.927500</td>\n",
       "      <td>0.927062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.264800</td>\n",
       "      <td>0.260896</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.929788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.179900</td>\n",
       "      <td>0.272641</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.919950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.130500</td>\n",
       "      <td>0.247837</td>\n",
       "      <td>0.927500</td>\n",
       "      <td>0.927300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.122500</td>\n",
       "      <td>0.291791</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.909998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.101200</td>\n",
       "      <td>0.300080</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.914991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.089000</td>\n",
       "      <td>0.278332</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.919757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.076300</td>\n",
       "      <td>0.286613</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.919711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.070100</td>\n",
       "      <td>0.327810</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.914947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.060300</td>\n",
       "      <td>0.302337</td>\n",
       "      <td>0.922500</td>\n",
       "      <td>0.922360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.059900</td>\n",
       "      <td>0.293526</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.919711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.042000</td>\n",
       "      <td>0.338219</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.914966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.042800</td>\n",
       "      <td>0.349598</td>\n",
       "      <td>0.917500</td>\n",
       "      <td>0.917487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.024900</td>\n",
       "      <td>0.365970</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.914966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.024600</td>\n",
       "      <td>0.379657</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.909919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.015700</td>\n",
       "      <td>0.399300</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.912473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.022600</td>\n",
       "      <td>0.390978</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.912456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.010500</td>\n",
       "      <td>0.405368</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.912434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>0.421633</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.914923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.012400</td>\n",
       "      <td>0.430177</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.912434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.014700</td>\n",
       "      <td>0.420079</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.914864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>0.415185</td>\n",
       "      <td>0.917500</td>\n",
       "      <td>0.917313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.004800</td>\n",
       "      <td>0.423371</td>\n",
       "      <td>0.917500</td>\n",
       "      <td>0.917313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.431138</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.914828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>0.437216</td>\n",
       "      <td>0.917500</td>\n",
       "      <td>0.917351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>0.451829</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.914896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.466899</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.912407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>0.473518</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.912407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.474580</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.912407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 1600\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 400\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 01:49, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>0.282074</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.909345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.150200</td>\n",
       "      <td>0.292630</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.911825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.072200</td>\n",
       "      <td>0.353163</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.911971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.045800</td>\n",
       "      <td>0.374537</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.911275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.017900</td>\n",
       "      <td>0.439981</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.909919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.009500</td>\n",
       "      <td>0.492295</td>\n",
       "      <td>0.917500</td>\n",
       "      <td>0.917001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.034200</td>\n",
       "      <td>0.619916</td>\n",
       "      <td>0.907500</td>\n",
       "      <td>0.905971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.013500</td>\n",
       "      <td>0.519317</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.911825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.533843</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.909420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.580735</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.912038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.575923</td>\n",
       "      <td>0.917500</td>\n",
       "      <td>0.916442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.636797</td>\n",
       "      <td>0.905000</td>\n",
       "      <td>0.904657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>0.577493</td>\n",
       "      <td>0.917500</td>\n",
       "      <td>0.916788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.608103</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.909420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.616254</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.911825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.620479</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.911745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.626429</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.911745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.631939</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.911745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.636841</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.911745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.641101</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.914306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.645007</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.914306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.648689</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.914306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.652048</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.914306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.654949</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.914306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.657482</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.914306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.659433</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.914306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.660993</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.914306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.661437</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.914306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.659076</td>\n",
       "      <td>0.917500</td>\n",
       "      <td>0.916863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.659541</td>\n",
       "      <td>0.917500</td>\n",
       "      <td>0.916863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.659739</td>\n",
       "      <td>0.917500</td>\n",
       "      <td>0.916863</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 01:48, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>0.282074</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.909345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.150200</td>\n",
       "      <td>0.292630</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.911825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.072200</td>\n",
       "      <td>0.353163</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.911971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.045800</td>\n",
       "      <td>0.374537</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.911275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.017900</td>\n",
       "      <td>0.439981</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.909919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.009500</td>\n",
       "      <td>0.492295</td>\n",
       "      <td>0.917500</td>\n",
       "      <td>0.917001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.034200</td>\n",
       "      <td>0.619916</td>\n",
       "      <td>0.907500</td>\n",
       "      <td>0.905971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.013500</td>\n",
       "      <td>0.519317</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.911825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.533843</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.909420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.580735</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.912038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.575923</td>\n",
       "      <td>0.917500</td>\n",
       "      <td>0.916442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.636797</td>\n",
       "      <td>0.905000</td>\n",
       "      <td>0.904657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>0.577493</td>\n",
       "      <td>0.917500</td>\n",
       "      <td>0.916788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.608103</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.909420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.616254</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.911825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.620479</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.911745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.626429</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.911745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.631939</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.911745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.636841</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.911745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.641101</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.914306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.645007</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.914306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.648689</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.914306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.652048</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.914306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.654949</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.914306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.657482</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.914306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.659433</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.914306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.660993</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.914306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.661437</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.914306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.659076</td>\n",
       "      <td>0.917500</td>\n",
       "      <td>0.916863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.659541</td>\n",
       "      <td>0.917500</td>\n",
       "      <td>0.916863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.659739</td>\n",
       "      <td>0.917500</td>\n",
       "      <td>0.916863</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 01:48, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>0.282074</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.909345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.150200</td>\n",
       "      <td>0.292630</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.911825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.072200</td>\n",
       "      <td>0.353163</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.911971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.045800</td>\n",
       "      <td>0.374537</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.911275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.017900</td>\n",
       "      <td>0.439981</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.909919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.009500</td>\n",
       "      <td>0.492295</td>\n",
       "      <td>0.917500</td>\n",
       "      <td>0.917001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.034200</td>\n",
       "      <td>0.619916</td>\n",
       "      <td>0.907500</td>\n",
       "      <td>0.905971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.013500</td>\n",
       "      <td>0.519317</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.911825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.533843</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.909420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.580735</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.912038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.575923</td>\n",
       "      <td>0.917500</td>\n",
       "      <td>0.916442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.636797</td>\n",
       "      <td>0.905000</td>\n",
       "      <td>0.904657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>0.577493</td>\n",
       "      <td>0.917500</td>\n",
       "      <td>0.916788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.608103</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.909420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.616254</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.911825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.620479</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.911745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.626429</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.911745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.631939</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.911745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.636841</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.911745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.641101</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.914306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.645007</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.914306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.648689</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.914306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.652048</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.914306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.654949</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.914306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.657482</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.914306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.659433</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.914306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.660993</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.914306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.661437</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.914306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.659076</td>\n",
       "      <td>0.917500</td>\n",
       "      <td>0.916863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.659541</td>\n",
       "      <td>0.917500</td>\n",
       "      <td>0.916863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.659739</td>\n",
       "      <td>0.917500</td>\n",
       "      <td>0.916863</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 01:47, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.375900</td>\n",
       "      <td>0.280129</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.895806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.166800</td>\n",
       "      <td>0.360078</td>\n",
       "      <td>0.877500</td>\n",
       "      <td>0.877481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.095100</td>\n",
       "      <td>0.276195</td>\n",
       "      <td>0.927500</td>\n",
       "      <td>0.927168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.048100</td>\n",
       "      <td>0.254283</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.929604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.016600</td>\n",
       "      <td>0.390551</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.909890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>0.430523</td>\n",
       "      <td>0.917500</td>\n",
       "      <td>0.917226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.007900</td>\n",
       "      <td>0.434293</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.919711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.482077</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.909919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>0.424801</td>\n",
       "      <td>0.927500</td>\n",
       "      <td>0.927003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.480772</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.919547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.545409</td>\n",
       "      <td>0.922500</td>\n",
       "      <td>0.922243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>0.537296</td>\n",
       "      <td>0.927500</td>\n",
       "      <td>0.927260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.550992</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.924388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.549598</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.929788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.575193</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.924848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.516636</td>\n",
       "      <td>0.932500</td>\n",
       "      <td>0.932191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.528807</td>\n",
       "      <td>0.927500</td>\n",
       "      <td>0.927062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.524935</td>\n",
       "      <td>0.927500</td>\n",
       "      <td>0.927062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.526589</td>\n",
       "      <td>0.932500</td>\n",
       "      <td>0.932191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.531141</td>\n",
       "      <td>0.932500</td>\n",
       "      <td>0.932191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.580366</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.919838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.605803</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.914864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.606466</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.914864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.596668</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.919838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.548868</td>\n",
       "      <td>0.935000</td>\n",
       "      <td>0.934765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.547724</td>\n",
       "      <td>0.935000</td>\n",
       "      <td>0.934765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.548993</td>\n",
       "      <td>0.935000</td>\n",
       "      <td>0.934765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>0.550052</td>\n",
       "      <td>0.935000</td>\n",
       "      <td>0.934765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.550669</td>\n",
       "      <td>0.935000</td>\n",
       "      <td>0.934765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.573954</td>\n",
       "      <td>0.932500</td>\n",
       "      <td>0.932276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.575580</td>\n",
       "      <td>0.932500</td>\n",
       "      <td>0.932276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 01:47, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.375900</td>\n",
       "      <td>0.280129</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.895806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.166800</td>\n",
       "      <td>0.360078</td>\n",
       "      <td>0.877500</td>\n",
       "      <td>0.877481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.095100</td>\n",
       "      <td>0.276195</td>\n",
       "      <td>0.927500</td>\n",
       "      <td>0.927168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.048100</td>\n",
       "      <td>0.254283</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.929604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.016600</td>\n",
       "      <td>0.390551</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.909890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>0.430523</td>\n",
       "      <td>0.917500</td>\n",
       "      <td>0.917226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.007900</td>\n",
       "      <td>0.434293</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.919711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.482077</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.909919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>0.424801</td>\n",
       "      <td>0.927500</td>\n",
       "      <td>0.927003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.480772</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.919547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.545409</td>\n",
       "      <td>0.922500</td>\n",
       "      <td>0.922243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>0.537296</td>\n",
       "      <td>0.927500</td>\n",
       "      <td>0.927260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.550992</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.924388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.549598</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.929788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.575193</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.924848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.516636</td>\n",
       "      <td>0.932500</td>\n",
       "      <td>0.932191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.528807</td>\n",
       "      <td>0.927500</td>\n",
       "      <td>0.927062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.524935</td>\n",
       "      <td>0.927500</td>\n",
       "      <td>0.927062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.526589</td>\n",
       "      <td>0.932500</td>\n",
       "      <td>0.932191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.531141</td>\n",
       "      <td>0.932500</td>\n",
       "      <td>0.932191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.580366</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.919838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.605803</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.914864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.606466</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.914864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.596668</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.919838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.548868</td>\n",
       "      <td>0.935000</td>\n",
       "      <td>0.934765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.547724</td>\n",
       "      <td>0.935000</td>\n",
       "      <td>0.934765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.548993</td>\n",
       "      <td>0.935000</td>\n",
       "      <td>0.934765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>0.550052</td>\n",
       "      <td>0.935000</td>\n",
       "      <td>0.934765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.550669</td>\n",
       "      <td>0.935000</td>\n",
       "      <td>0.934765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.573954</td>\n",
       "      <td>0.932500</td>\n",
       "      <td>0.932276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.575580</td>\n",
       "      <td>0.932500</td>\n",
       "      <td>0.932276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 01:47, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.375900</td>\n",
       "      <td>0.280129</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.895806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.166800</td>\n",
       "      <td>0.360078</td>\n",
       "      <td>0.877500</td>\n",
       "      <td>0.877481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.095100</td>\n",
       "      <td>0.276195</td>\n",
       "      <td>0.927500</td>\n",
       "      <td>0.927168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.048100</td>\n",
       "      <td>0.254283</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.929604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.016600</td>\n",
       "      <td>0.390551</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.909890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>0.430523</td>\n",
       "      <td>0.917500</td>\n",
       "      <td>0.917226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.007900</td>\n",
       "      <td>0.434293</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.919711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.482077</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.909919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>0.424801</td>\n",
       "      <td>0.927500</td>\n",
       "      <td>0.927003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.480772</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.919547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.545409</td>\n",
       "      <td>0.922500</td>\n",
       "      <td>0.922243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>0.537296</td>\n",
       "      <td>0.927500</td>\n",
       "      <td>0.927260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.550992</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.924388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.549598</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.929788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.575193</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.924848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.516636</td>\n",
       "      <td>0.932500</td>\n",
       "      <td>0.932191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.528807</td>\n",
       "      <td>0.927500</td>\n",
       "      <td>0.927062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.524935</td>\n",
       "      <td>0.927500</td>\n",
       "      <td>0.927062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.526589</td>\n",
       "      <td>0.932500</td>\n",
       "      <td>0.932191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.531141</td>\n",
       "      <td>0.932500</td>\n",
       "      <td>0.932191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.580366</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.919838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.605803</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.914864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.606466</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.914864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.596668</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.919838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.548868</td>\n",
       "      <td>0.935000</td>\n",
       "      <td>0.934765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.547724</td>\n",
       "      <td>0.935000</td>\n",
       "      <td>0.934765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.548993</td>\n",
       "      <td>0.935000</td>\n",
       "      <td>0.934765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>0.550052</td>\n",
       "      <td>0.935000</td>\n",
       "      <td>0.934765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.550669</td>\n",
       "      <td>0.935000</td>\n",
       "      <td>0.934765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.573954</td>\n",
       "      <td>0.932500</td>\n",
       "      <td>0.932276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.575580</td>\n",
       "      <td>0.932500</td>\n",
       "      <td>0.932276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 01:47, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.377700</td>\n",
       "      <td>0.172619</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.944646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.162300</td>\n",
       "      <td>0.207973</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.929549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.080100</td>\n",
       "      <td>0.219208</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.939946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.073500</td>\n",
       "      <td>0.408020</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.914947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.034100</td>\n",
       "      <td>0.236104</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.944767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.015600</td>\n",
       "      <td>0.336589</td>\n",
       "      <td>0.932500</td>\n",
       "      <td>0.932449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.383747</td>\n",
       "      <td>0.932500</td>\n",
       "      <td>0.932479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.009800</td>\n",
       "      <td>0.326952</td>\n",
       "      <td>0.935000</td>\n",
       "      <td>0.934959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>0.326683</td>\n",
       "      <td>0.947500</td>\n",
       "      <td>0.947426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.346037</td>\n",
       "      <td>0.942500</td>\n",
       "      <td>0.942439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.332638</td>\n",
       "      <td>0.947500</td>\n",
       "      <td>0.947426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.353640</td>\n",
       "      <td>0.947500</td>\n",
       "      <td>0.947355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>0.401413</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.937434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.386359</td>\n",
       "      <td>0.942500</td>\n",
       "      <td>0.942370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.395079</td>\n",
       "      <td>0.942500</td>\n",
       "      <td>0.942370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.403738</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.944888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.410707</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.944888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.417210</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.944888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.422132</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.944888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.426479</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.944888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.430133</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.944888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.433478</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.944888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.436421</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.944888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.438940</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.944888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.441068</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.944888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.443246</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.944888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.444842</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.944888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.447163</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.944888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.448256</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.944888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.448839</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.944888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.449133</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.944888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 01:47, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.377700</td>\n",
       "      <td>0.172619</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.944646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.162300</td>\n",
       "      <td>0.207973</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.929549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.080100</td>\n",
       "      <td>0.219208</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.939946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.073500</td>\n",
       "      <td>0.408020</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.914947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.034100</td>\n",
       "      <td>0.236104</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.944767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.015600</td>\n",
       "      <td>0.336589</td>\n",
       "      <td>0.932500</td>\n",
       "      <td>0.932449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.383747</td>\n",
       "      <td>0.932500</td>\n",
       "      <td>0.932479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.009800</td>\n",
       "      <td>0.326952</td>\n",
       "      <td>0.935000</td>\n",
       "      <td>0.934959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>0.326683</td>\n",
       "      <td>0.947500</td>\n",
       "      <td>0.947426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.346037</td>\n",
       "      <td>0.942500</td>\n",
       "      <td>0.942439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.332638</td>\n",
       "      <td>0.947500</td>\n",
       "      <td>0.947426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.353640</td>\n",
       "      <td>0.947500</td>\n",
       "      <td>0.947355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>0.401413</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.937434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.386359</td>\n",
       "      <td>0.942500</td>\n",
       "      <td>0.942370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.395079</td>\n",
       "      <td>0.942500</td>\n",
       "      <td>0.942370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.403738</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.944888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.410707</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.944888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.417210</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.944888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.422132</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.944888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.426479</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.944888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.430133</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.944888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.433478</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.944888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.436421</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.944888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.438940</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.944888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.441068</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.944888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.443246</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.944888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.444842</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.944888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.447163</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.944888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.448256</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.944888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.448839</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.944888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.449133</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.944888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 01:48, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.377700</td>\n",
       "      <td>0.172619</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.944646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.162300</td>\n",
       "      <td>0.207973</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.929549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.080100</td>\n",
       "      <td>0.219208</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.939946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.073500</td>\n",
       "      <td>0.408020</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.914947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.034100</td>\n",
       "      <td>0.236104</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.944767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.015600</td>\n",
       "      <td>0.336589</td>\n",
       "      <td>0.932500</td>\n",
       "      <td>0.932449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.383747</td>\n",
       "      <td>0.932500</td>\n",
       "      <td>0.932479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.009800</td>\n",
       "      <td>0.326952</td>\n",
       "      <td>0.935000</td>\n",
       "      <td>0.934959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>0.326683</td>\n",
       "      <td>0.947500</td>\n",
       "      <td>0.947426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.346037</td>\n",
       "      <td>0.942500</td>\n",
       "      <td>0.942439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.332638</td>\n",
       "      <td>0.947500</td>\n",
       "      <td>0.947426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.353640</td>\n",
       "      <td>0.947500</td>\n",
       "      <td>0.947355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>0.401413</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.937434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.386359</td>\n",
       "      <td>0.942500</td>\n",
       "      <td>0.942370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.395079</td>\n",
       "      <td>0.942500</td>\n",
       "      <td>0.942370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.403738</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.944888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.410707</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.944888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.417210</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.944888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.422132</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.944888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.426479</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.944888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.430133</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.944888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.433478</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.944888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.436421</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.944888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.438940</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.944888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.441068</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.944888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.443246</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.944888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.444842</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.944888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.447163</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.944888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.448256</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.944888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.448839</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.944888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.449133</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.944888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 1600\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 400\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunis-ai/TunBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tunis-ai/TunBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 01:45, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.812700</td>\n",
       "      <td>0.846562</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.315068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.715600</td>\n",
       "      <td>0.689436</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.350649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.701100</td>\n",
       "      <td>0.705453</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.315068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.699500</td>\n",
       "      <td>0.721399</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.554367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.650600</td>\n",
       "      <td>0.711500</td>\n",
       "      <td>0.570000</td>\n",
       "      <td>0.548129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.629200</td>\n",
       "      <td>0.702778</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.612946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.612800</td>\n",
       "      <td>0.651643</td>\n",
       "      <td>0.655000</td>\n",
       "      <td>0.653536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.593800</td>\n",
       "      <td>0.667141</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>0.620279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.556700</td>\n",
       "      <td>0.653534</td>\n",
       "      <td>0.662500</td>\n",
       "      <td>0.661380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.532800</td>\n",
       "      <td>0.703871</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>0.540230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.544500</td>\n",
       "      <td>0.705890</td>\n",
       "      <td>0.662500</td>\n",
       "      <td>0.658916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.495100</td>\n",
       "      <td>0.666869</td>\n",
       "      <td>0.707500</td>\n",
       "      <td>0.707352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.461500</td>\n",
       "      <td>0.618558</td>\n",
       "      <td>0.722500</td>\n",
       "      <td>0.721998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.454300</td>\n",
       "      <td>0.606122</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.703772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.433600</td>\n",
       "      <td>0.655495</td>\n",
       "      <td>0.695000</td>\n",
       "      <td>0.681620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.455100</td>\n",
       "      <td>0.643801</td>\n",
       "      <td>0.702500</td>\n",
       "      <td>0.702275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.423000</td>\n",
       "      <td>0.698118</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.689369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.466900</td>\n",
       "      <td>0.643399</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.699248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.393800</td>\n",
       "      <td>0.639868</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.693557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.377100</td>\n",
       "      <td>0.742584</td>\n",
       "      <td>0.682500</td>\n",
       "      <td>0.682498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.356500</td>\n",
       "      <td>0.721713</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.687342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.322300</td>\n",
       "      <td>0.831908</td>\n",
       "      <td>0.662500</td>\n",
       "      <td>0.662143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.345600</td>\n",
       "      <td>0.734169</td>\n",
       "      <td>0.702500</td>\n",
       "      <td>0.701333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.301700</td>\n",
       "      <td>0.824581</td>\n",
       "      <td>0.682500</td>\n",
       "      <td>0.682403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.268700</td>\n",
       "      <td>0.864982</td>\n",
       "      <td>0.647500</td>\n",
       "      <td>0.646703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.257900</td>\n",
       "      <td>0.943747</td>\n",
       "      <td>0.657500</td>\n",
       "      <td>0.657327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.277900</td>\n",
       "      <td>0.878623</td>\n",
       "      <td>0.645000</td>\n",
       "      <td>0.644110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.234800</td>\n",
       "      <td>0.948427</td>\n",
       "      <td>0.657500</td>\n",
       "      <td>0.657395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.235100</td>\n",
       "      <td>0.978237</td>\n",
       "      <td>0.632500</td>\n",
       "      <td>0.631281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.214500</td>\n",
       "      <td>0.949659</td>\n",
       "      <td>0.652500</td>\n",
       "      <td>0.652133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.218200</td>\n",
       "      <td>0.945331</td>\n",
       "      <td>0.672500</td>\n",
       "      <td>0.672482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunis-ai/TunBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tunis-ai/TunBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 01:46, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.812700</td>\n",
       "      <td>0.846562</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.315068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.715600</td>\n",
       "      <td>0.689436</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.350649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.701100</td>\n",
       "      <td>0.705453</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.315068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.699500</td>\n",
       "      <td>0.721399</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.554367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.650600</td>\n",
       "      <td>0.711500</td>\n",
       "      <td>0.570000</td>\n",
       "      <td>0.548129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.629200</td>\n",
       "      <td>0.702778</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.612946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.612800</td>\n",
       "      <td>0.651643</td>\n",
       "      <td>0.655000</td>\n",
       "      <td>0.653536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.593800</td>\n",
       "      <td>0.667141</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>0.620279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.556700</td>\n",
       "      <td>0.653534</td>\n",
       "      <td>0.662500</td>\n",
       "      <td>0.661380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.532800</td>\n",
       "      <td>0.703871</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>0.540230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.544500</td>\n",
       "      <td>0.705890</td>\n",
       "      <td>0.662500</td>\n",
       "      <td>0.658916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.495100</td>\n",
       "      <td>0.666869</td>\n",
       "      <td>0.707500</td>\n",
       "      <td>0.707352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.461500</td>\n",
       "      <td>0.618558</td>\n",
       "      <td>0.722500</td>\n",
       "      <td>0.721998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.454300</td>\n",
       "      <td>0.606122</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.703772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.433600</td>\n",
       "      <td>0.655495</td>\n",
       "      <td>0.695000</td>\n",
       "      <td>0.681620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.455100</td>\n",
       "      <td>0.643801</td>\n",
       "      <td>0.702500</td>\n",
       "      <td>0.702275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.423000</td>\n",
       "      <td>0.698118</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.689369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.466900</td>\n",
       "      <td>0.643399</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.699248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.393800</td>\n",
       "      <td>0.639868</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.693557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.377100</td>\n",
       "      <td>0.742584</td>\n",
       "      <td>0.682500</td>\n",
       "      <td>0.682498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.356500</td>\n",
       "      <td>0.721713</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.687342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.322300</td>\n",
       "      <td>0.831908</td>\n",
       "      <td>0.662500</td>\n",
       "      <td>0.662143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.345600</td>\n",
       "      <td>0.734169</td>\n",
       "      <td>0.702500</td>\n",
       "      <td>0.701333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.301700</td>\n",
       "      <td>0.824581</td>\n",
       "      <td>0.682500</td>\n",
       "      <td>0.682403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.268700</td>\n",
       "      <td>0.864982</td>\n",
       "      <td>0.647500</td>\n",
       "      <td>0.646703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.257900</td>\n",
       "      <td>0.943747</td>\n",
       "      <td>0.657500</td>\n",
       "      <td>0.657327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.277900</td>\n",
       "      <td>0.878623</td>\n",
       "      <td>0.645000</td>\n",
       "      <td>0.644110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.234800</td>\n",
       "      <td>0.948427</td>\n",
       "      <td>0.657500</td>\n",
       "      <td>0.657395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.235100</td>\n",
       "      <td>0.978237</td>\n",
       "      <td>0.632500</td>\n",
       "      <td>0.631281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.214500</td>\n",
       "      <td>0.949659</td>\n",
       "      <td>0.652500</td>\n",
       "      <td>0.652133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.218200</td>\n",
       "      <td>0.945331</td>\n",
       "      <td>0.672500</td>\n",
       "      <td>0.672482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunis-ai/TunBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tunis-ai/TunBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 01:46, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.812700</td>\n",
       "      <td>0.846562</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.315068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.715600</td>\n",
       "      <td>0.689436</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.350649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.701100</td>\n",
       "      <td>0.705453</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.315068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.699500</td>\n",
       "      <td>0.721399</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.554367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.650600</td>\n",
       "      <td>0.711500</td>\n",
       "      <td>0.570000</td>\n",
       "      <td>0.548129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.629200</td>\n",
       "      <td>0.702778</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.612946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.612800</td>\n",
       "      <td>0.651643</td>\n",
       "      <td>0.655000</td>\n",
       "      <td>0.653536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.593800</td>\n",
       "      <td>0.667141</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>0.620279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.556700</td>\n",
       "      <td>0.653534</td>\n",
       "      <td>0.662500</td>\n",
       "      <td>0.661380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.532800</td>\n",
       "      <td>0.703871</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>0.540230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.544500</td>\n",
       "      <td>0.705890</td>\n",
       "      <td>0.662500</td>\n",
       "      <td>0.658916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.495100</td>\n",
       "      <td>0.666869</td>\n",
       "      <td>0.707500</td>\n",
       "      <td>0.707352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.461500</td>\n",
       "      <td>0.618558</td>\n",
       "      <td>0.722500</td>\n",
       "      <td>0.721998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.454300</td>\n",
       "      <td>0.606122</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.703772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.433600</td>\n",
       "      <td>0.655495</td>\n",
       "      <td>0.695000</td>\n",
       "      <td>0.681620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.455100</td>\n",
       "      <td>0.643801</td>\n",
       "      <td>0.702500</td>\n",
       "      <td>0.702275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.423000</td>\n",
       "      <td>0.698118</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.689369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.466900</td>\n",
       "      <td>0.643399</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.699248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.393800</td>\n",
       "      <td>0.639868</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.693557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.377100</td>\n",
       "      <td>0.742584</td>\n",
       "      <td>0.682500</td>\n",
       "      <td>0.682498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.356500</td>\n",
       "      <td>0.721713</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.687342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.322300</td>\n",
       "      <td>0.831908</td>\n",
       "      <td>0.662500</td>\n",
       "      <td>0.662143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.345600</td>\n",
       "      <td>0.734169</td>\n",
       "      <td>0.702500</td>\n",
       "      <td>0.701333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.301700</td>\n",
       "      <td>0.824581</td>\n",
       "      <td>0.682500</td>\n",
       "      <td>0.682403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.268700</td>\n",
       "      <td>0.864982</td>\n",
       "      <td>0.647500</td>\n",
       "      <td>0.646703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.257900</td>\n",
       "      <td>0.943747</td>\n",
       "      <td>0.657500</td>\n",
       "      <td>0.657327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.277900</td>\n",
       "      <td>0.878623</td>\n",
       "      <td>0.645000</td>\n",
       "      <td>0.644110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.234800</td>\n",
       "      <td>0.948427</td>\n",
       "      <td>0.657500</td>\n",
       "      <td>0.657395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.235100</td>\n",
       "      <td>0.978237</td>\n",
       "      <td>0.632500</td>\n",
       "      <td>0.631281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.214500</td>\n",
       "      <td>0.949659</td>\n",
       "      <td>0.652500</td>\n",
       "      <td>0.652133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.218200</td>\n",
       "      <td>0.945331</td>\n",
       "      <td>0.672500</td>\n",
       "      <td>0.672482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunis-ai/TunBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tunis-ai/TunBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 01:46, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.817900</td>\n",
       "      <td>0.691453</td>\n",
       "      <td>0.617500</td>\n",
       "      <td>0.566667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.699100</td>\n",
       "      <td>0.725612</td>\n",
       "      <td>0.467500</td>\n",
       "      <td>0.318569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.706900</td>\n",
       "      <td>0.627602</td>\n",
       "      <td>0.652500</td>\n",
       "      <td>0.646758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.661700</td>\n",
       "      <td>0.616834</td>\n",
       "      <td>0.672500</td>\n",
       "      <td>0.672252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.660500</td>\n",
       "      <td>0.637210</td>\n",
       "      <td>0.657500</td>\n",
       "      <td>0.648211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.656400</td>\n",
       "      <td>0.585336</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.693095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.666800</td>\n",
       "      <td>0.603579</td>\n",
       "      <td>0.697500</td>\n",
       "      <td>0.692501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.571200</td>\n",
       "      <td>0.588413</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.724828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.599500</td>\n",
       "      <td>0.585744</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.721632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.621300</td>\n",
       "      <td>0.572735</td>\n",
       "      <td>0.715000</td>\n",
       "      <td>0.710836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.563800</td>\n",
       "      <td>0.631687</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.653688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.525500</td>\n",
       "      <td>0.587794</td>\n",
       "      <td>0.705000</td>\n",
       "      <td>0.704882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.497900</td>\n",
       "      <td>0.685410</td>\n",
       "      <td>0.682500</td>\n",
       "      <td>0.678055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.523700</td>\n",
       "      <td>0.578717</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.700838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.465100</td>\n",
       "      <td>0.606821</td>\n",
       "      <td>0.717500</td>\n",
       "      <td>0.717286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.499600</td>\n",
       "      <td>0.599780</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.707717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.435700</td>\n",
       "      <td>0.618096</td>\n",
       "      <td>0.717500</td>\n",
       "      <td>0.715564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.405400</td>\n",
       "      <td>0.619101</td>\n",
       "      <td>0.707500</td>\n",
       "      <td>0.705496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.406200</td>\n",
       "      <td>0.608111</td>\n",
       "      <td>0.707500</td>\n",
       "      <td>0.707454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.373100</td>\n",
       "      <td>0.718923</td>\n",
       "      <td>0.705000</td>\n",
       "      <td>0.704970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.376000</td>\n",
       "      <td>0.664048</td>\n",
       "      <td>0.685000</td>\n",
       "      <td>0.684211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.343800</td>\n",
       "      <td>0.706956</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.699932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.340700</td>\n",
       "      <td>0.682017</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.695979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.309300</td>\n",
       "      <td>0.751348</td>\n",
       "      <td>0.697500</td>\n",
       "      <td>0.697453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.299500</td>\n",
       "      <td>0.758823</td>\n",
       "      <td>0.702500</td>\n",
       "      <td>0.700461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.288700</td>\n",
       "      <td>0.771849</td>\n",
       "      <td>0.697500</td>\n",
       "      <td>0.697271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.283400</td>\n",
       "      <td>0.792866</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.686463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.262500</td>\n",
       "      <td>0.818560</td>\n",
       "      <td>0.695000</td>\n",
       "      <td>0.692780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.244800</td>\n",
       "      <td>0.862000</td>\n",
       "      <td>0.707500</td>\n",
       "      <td>0.707352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.260600</td>\n",
       "      <td>0.829467</td>\n",
       "      <td>0.692500</td>\n",
       "      <td>0.691805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.256800</td>\n",
       "      <td>0.844604</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.699880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunis-ai/TunBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tunis-ai/TunBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 01:46, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.817900</td>\n",
       "      <td>0.691453</td>\n",
       "      <td>0.617500</td>\n",
       "      <td>0.566667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.699100</td>\n",
       "      <td>0.725612</td>\n",
       "      <td>0.467500</td>\n",
       "      <td>0.318569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.706900</td>\n",
       "      <td>0.627602</td>\n",
       "      <td>0.652500</td>\n",
       "      <td>0.646758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.661700</td>\n",
       "      <td>0.616834</td>\n",
       "      <td>0.672500</td>\n",
       "      <td>0.672252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.660500</td>\n",
       "      <td>0.637210</td>\n",
       "      <td>0.657500</td>\n",
       "      <td>0.648211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.656400</td>\n",
       "      <td>0.585336</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.693095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.666800</td>\n",
       "      <td>0.603579</td>\n",
       "      <td>0.697500</td>\n",
       "      <td>0.692501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.571200</td>\n",
       "      <td>0.588413</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.724828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.599500</td>\n",
       "      <td>0.585744</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.721632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.621300</td>\n",
       "      <td>0.572735</td>\n",
       "      <td>0.715000</td>\n",
       "      <td>0.710836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.563800</td>\n",
       "      <td>0.631687</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.653688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.525500</td>\n",
       "      <td>0.587794</td>\n",
       "      <td>0.705000</td>\n",
       "      <td>0.704882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.497900</td>\n",
       "      <td>0.685410</td>\n",
       "      <td>0.682500</td>\n",
       "      <td>0.678055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.523700</td>\n",
       "      <td>0.578717</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.700838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.465100</td>\n",
       "      <td>0.606821</td>\n",
       "      <td>0.717500</td>\n",
       "      <td>0.717286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.499600</td>\n",
       "      <td>0.599780</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.707717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.435700</td>\n",
       "      <td>0.618096</td>\n",
       "      <td>0.717500</td>\n",
       "      <td>0.715564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.405400</td>\n",
       "      <td>0.619101</td>\n",
       "      <td>0.707500</td>\n",
       "      <td>0.705496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.406200</td>\n",
       "      <td>0.608111</td>\n",
       "      <td>0.707500</td>\n",
       "      <td>0.707454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.373100</td>\n",
       "      <td>0.718923</td>\n",
       "      <td>0.705000</td>\n",
       "      <td>0.704970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.376000</td>\n",
       "      <td>0.664048</td>\n",
       "      <td>0.685000</td>\n",
       "      <td>0.684211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.343800</td>\n",
       "      <td>0.706956</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.699932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.340700</td>\n",
       "      <td>0.682017</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.695979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.309300</td>\n",
       "      <td>0.751348</td>\n",
       "      <td>0.697500</td>\n",
       "      <td>0.697453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.299500</td>\n",
       "      <td>0.758823</td>\n",
       "      <td>0.702500</td>\n",
       "      <td>0.700461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.288700</td>\n",
       "      <td>0.771849</td>\n",
       "      <td>0.697500</td>\n",
       "      <td>0.697271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.283400</td>\n",
       "      <td>0.792866</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.686463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.262500</td>\n",
       "      <td>0.818560</td>\n",
       "      <td>0.695000</td>\n",
       "      <td>0.692780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.244800</td>\n",
       "      <td>0.862000</td>\n",
       "      <td>0.707500</td>\n",
       "      <td>0.707352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.260600</td>\n",
       "      <td>0.829467</td>\n",
       "      <td>0.692500</td>\n",
       "      <td>0.691805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.256800</td>\n",
       "      <td>0.844604</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.699880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunis-ai/TunBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tunis-ai/TunBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 01:46, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.817900</td>\n",
       "      <td>0.691453</td>\n",
       "      <td>0.617500</td>\n",
       "      <td>0.566667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.699100</td>\n",
       "      <td>0.725612</td>\n",
       "      <td>0.467500</td>\n",
       "      <td>0.318569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.706900</td>\n",
       "      <td>0.627602</td>\n",
       "      <td>0.652500</td>\n",
       "      <td>0.646758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.661700</td>\n",
       "      <td>0.616834</td>\n",
       "      <td>0.672500</td>\n",
       "      <td>0.672252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.660500</td>\n",
       "      <td>0.637210</td>\n",
       "      <td>0.657500</td>\n",
       "      <td>0.648211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.656400</td>\n",
       "      <td>0.585336</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.693095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.666800</td>\n",
       "      <td>0.603579</td>\n",
       "      <td>0.697500</td>\n",
       "      <td>0.692501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.571200</td>\n",
       "      <td>0.588413</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.724828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.599500</td>\n",
       "      <td>0.585744</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.721632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.621300</td>\n",
       "      <td>0.572735</td>\n",
       "      <td>0.715000</td>\n",
       "      <td>0.710836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.563800</td>\n",
       "      <td>0.631687</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.653688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.525500</td>\n",
       "      <td>0.587794</td>\n",
       "      <td>0.705000</td>\n",
       "      <td>0.704882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.497900</td>\n",
       "      <td>0.685410</td>\n",
       "      <td>0.682500</td>\n",
       "      <td>0.678055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.523700</td>\n",
       "      <td>0.578717</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.700838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.465100</td>\n",
       "      <td>0.606821</td>\n",
       "      <td>0.717500</td>\n",
       "      <td>0.717286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.499600</td>\n",
       "      <td>0.599780</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.707717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.435700</td>\n",
       "      <td>0.618096</td>\n",
       "      <td>0.717500</td>\n",
       "      <td>0.715564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.405400</td>\n",
       "      <td>0.619101</td>\n",
       "      <td>0.707500</td>\n",
       "      <td>0.705496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.406200</td>\n",
       "      <td>0.608111</td>\n",
       "      <td>0.707500</td>\n",
       "      <td>0.707454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.373100</td>\n",
       "      <td>0.718923</td>\n",
       "      <td>0.705000</td>\n",
       "      <td>0.704970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.376000</td>\n",
       "      <td>0.664048</td>\n",
       "      <td>0.685000</td>\n",
       "      <td>0.684211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.343800</td>\n",
       "      <td>0.706956</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.699932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.340700</td>\n",
       "      <td>0.682017</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.695979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.309300</td>\n",
       "      <td>0.751348</td>\n",
       "      <td>0.697500</td>\n",
       "      <td>0.697453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.299500</td>\n",
       "      <td>0.758823</td>\n",
       "      <td>0.702500</td>\n",
       "      <td>0.700461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.288700</td>\n",
       "      <td>0.771849</td>\n",
       "      <td>0.697500</td>\n",
       "      <td>0.697271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.283400</td>\n",
       "      <td>0.792866</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.686463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.262500</td>\n",
       "      <td>0.818560</td>\n",
       "      <td>0.695000</td>\n",
       "      <td>0.692780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.244800</td>\n",
       "      <td>0.862000</td>\n",
       "      <td>0.707500</td>\n",
       "      <td>0.707352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.260600</td>\n",
       "      <td>0.829467</td>\n",
       "      <td>0.692500</td>\n",
       "      <td>0.691805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.256800</td>\n",
       "      <td>0.844604</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.699880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunis-ai/TunBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tunis-ai/TunBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 01:46, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.937700</td>\n",
       "      <td>0.697587</td>\n",
       "      <td>0.522500</td>\n",
       "      <td>0.343186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.709500</td>\n",
       "      <td>0.706040</td>\n",
       "      <td>0.477500</td>\n",
       "      <td>0.323181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.698400</td>\n",
       "      <td>0.708550</td>\n",
       "      <td>0.522500</td>\n",
       "      <td>0.343186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.706500</td>\n",
       "      <td>0.695698</td>\n",
       "      <td>0.477500</td>\n",
       "      <td>0.323181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.695700</td>\n",
       "      <td>0.692885</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>0.360348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.696100</td>\n",
       "      <td>0.692822</td>\n",
       "      <td>0.612500</td>\n",
       "      <td>0.589336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.695300</td>\n",
       "      <td>0.691337</td>\n",
       "      <td>0.522500</td>\n",
       "      <td>0.343186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.701900</td>\n",
       "      <td>0.708181</td>\n",
       "      <td>0.477500</td>\n",
       "      <td>0.323181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.674100</td>\n",
       "      <td>0.657917</td>\n",
       "      <td>0.615000</td>\n",
       "      <td>0.579648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.668500</td>\n",
       "      <td>0.660195</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.687404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.661000</td>\n",
       "      <td>0.624506</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.667305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.623400</td>\n",
       "      <td>0.622326</td>\n",
       "      <td>0.685000</td>\n",
       "      <td>0.679153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.648600</td>\n",
       "      <td>0.646032</td>\n",
       "      <td>0.642500</td>\n",
       "      <td>0.633406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.598200</td>\n",
       "      <td>0.606008</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.674797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.590700</td>\n",
       "      <td>0.605638</td>\n",
       "      <td>0.682500</td>\n",
       "      <td>0.681925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.559900</td>\n",
       "      <td>0.599359</td>\n",
       "      <td>0.677500</td>\n",
       "      <td>0.676771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.548300</td>\n",
       "      <td>0.586433</td>\n",
       "      <td>0.695000</td>\n",
       "      <td>0.694381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.509300</td>\n",
       "      <td>0.593281</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.718230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.524400</td>\n",
       "      <td>0.566475</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.699248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.507700</td>\n",
       "      <td>0.567844</td>\n",
       "      <td>0.717500</td>\n",
       "      <td>0.715320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.466300</td>\n",
       "      <td>0.596385</td>\n",
       "      <td>0.735000</td>\n",
       "      <td>0.734196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.447900</td>\n",
       "      <td>0.597524</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.718416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.413700</td>\n",
       "      <td>0.620002</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.718416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.430000</td>\n",
       "      <td>0.632617</td>\n",
       "      <td>0.715000</td>\n",
       "      <td>0.702497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.405800</td>\n",
       "      <td>0.613808</td>\n",
       "      <td>0.732500</td>\n",
       "      <td>0.730436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.385500</td>\n",
       "      <td>0.661685</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.699880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>0.621910</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.722496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.363900</td>\n",
       "      <td>0.643655</td>\n",
       "      <td>0.727500</td>\n",
       "      <td>0.723685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.387100</td>\n",
       "      <td>0.650433</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.708360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.358100</td>\n",
       "      <td>0.637518</td>\n",
       "      <td>0.717500</td>\n",
       "      <td>0.709838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.360800</td>\n",
       "      <td>0.635942</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.714402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunis-ai/TunBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tunis-ai/TunBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 01:46, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.937700</td>\n",
       "      <td>0.697587</td>\n",
       "      <td>0.522500</td>\n",
       "      <td>0.343186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.709500</td>\n",
       "      <td>0.706040</td>\n",
       "      <td>0.477500</td>\n",
       "      <td>0.323181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.698400</td>\n",
       "      <td>0.708550</td>\n",
       "      <td>0.522500</td>\n",
       "      <td>0.343186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.706500</td>\n",
       "      <td>0.695698</td>\n",
       "      <td>0.477500</td>\n",
       "      <td>0.323181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.695700</td>\n",
       "      <td>0.692885</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>0.360348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.696100</td>\n",
       "      <td>0.692822</td>\n",
       "      <td>0.612500</td>\n",
       "      <td>0.589336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.695300</td>\n",
       "      <td>0.691337</td>\n",
       "      <td>0.522500</td>\n",
       "      <td>0.343186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.701900</td>\n",
       "      <td>0.708181</td>\n",
       "      <td>0.477500</td>\n",
       "      <td>0.323181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.674100</td>\n",
       "      <td>0.657917</td>\n",
       "      <td>0.615000</td>\n",
       "      <td>0.579648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.668500</td>\n",
       "      <td>0.660195</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.687404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.661000</td>\n",
       "      <td>0.624506</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.667305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.623400</td>\n",
       "      <td>0.622326</td>\n",
       "      <td>0.685000</td>\n",
       "      <td>0.679153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.648600</td>\n",
       "      <td>0.646032</td>\n",
       "      <td>0.642500</td>\n",
       "      <td>0.633406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.598200</td>\n",
       "      <td>0.606008</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.674797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.590700</td>\n",
       "      <td>0.605638</td>\n",
       "      <td>0.682500</td>\n",
       "      <td>0.681925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.559900</td>\n",
       "      <td>0.599359</td>\n",
       "      <td>0.677500</td>\n",
       "      <td>0.676771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.548300</td>\n",
       "      <td>0.586433</td>\n",
       "      <td>0.695000</td>\n",
       "      <td>0.694381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.509300</td>\n",
       "      <td>0.593281</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.718230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.524400</td>\n",
       "      <td>0.566475</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.699248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.507700</td>\n",
       "      <td>0.567844</td>\n",
       "      <td>0.717500</td>\n",
       "      <td>0.715320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.466300</td>\n",
       "      <td>0.596385</td>\n",
       "      <td>0.735000</td>\n",
       "      <td>0.734196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.447900</td>\n",
       "      <td>0.597524</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.718416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.413700</td>\n",
       "      <td>0.620002</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.718416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.430000</td>\n",
       "      <td>0.632617</td>\n",
       "      <td>0.715000</td>\n",
       "      <td>0.702497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.405800</td>\n",
       "      <td>0.613808</td>\n",
       "      <td>0.732500</td>\n",
       "      <td>0.730436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.385500</td>\n",
       "      <td>0.661685</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.699880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>0.621910</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.722496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.363900</td>\n",
       "      <td>0.643655</td>\n",
       "      <td>0.727500</td>\n",
       "      <td>0.723685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.387100</td>\n",
       "      <td>0.650433</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.708360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.358100</td>\n",
       "      <td>0.637518</td>\n",
       "      <td>0.717500</td>\n",
       "      <td>0.709838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.360800</td>\n",
       "      <td>0.635942</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.714402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunis-ai/TunBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tunis-ai/TunBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 01:46, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.937700</td>\n",
       "      <td>0.697587</td>\n",
       "      <td>0.522500</td>\n",
       "      <td>0.343186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.709500</td>\n",
       "      <td>0.706040</td>\n",
       "      <td>0.477500</td>\n",
       "      <td>0.323181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.698400</td>\n",
       "      <td>0.708550</td>\n",
       "      <td>0.522500</td>\n",
       "      <td>0.343186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.706500</td>\n",
       "      <td>0.695698</td>\n",
       "      <td>0.477500</td>\n",
       "      <td>0.323181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.695700</td>\n",
       "      <td>0.692885</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>0.360348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.696100</td>\n",
       "      <td>0.692822</td>\n",
       "      <td>0.612500</td>\n",
       "      <td>0.589336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.695300</td>\n",
       "      <td>0.691337</td>\n",
       "      <td>0.522500</td>\n",
       "      <td>0.343186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.701900</td>\n",
       "      <td>0.708181</td>\n",
       "      <td>0.477500</td>\n",
       "      <td>0.323181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.674100</td>\n",
       "      <td>0.657917</td>\n",
       "      <td>0.615000</td>\n",
       "      <td>0.579648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.668500</td>\n",
       "      <td>0.660195</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.687404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.661000</td>\n",
       "      <td>0.624506</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.667305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.623400</td>\n",
       "      <td>0.622326</td>\n",
       "      <td>0.685000</td>\n",
       "      <td>0.679153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.648600</td>\n",
       "      <td>0.646032</td>\n",
       "      <td>0.642500</td>\n",
       "      <td>0.633406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.598200</td>\n",
       "      <td>0.606008</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.674797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.590700</td>\n",
       "      <td>0.605638</td>\n",
       "      <td>0.682500</td>\n",
       "      <td>0.681925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.559900</td>\n",
       "      <td>0.599359</td>\n",
       "      <td>0.677500</td>\n",
       "      <td>0.676771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.548300</td>\n",
       "      <td>0.586433</td>\n",
       "      <td>0.695000</td>\n",
       "      <td>0.694381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.509300</td>\n",
       "      <td>0.593281</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.718230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.524400</td>\n",
       "      <td>0.566475</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.699248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.507700</td>\n",
       "      <td>0.567844</td>\n",
       "      <td>0.717500</td>\n",
       "      <td>0.715320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.466300</td>\n",
       "      <td>0.596385</td>\n",
       "      <td>0.735000</td>\n",
       "      <td>0.734196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.447900</td>\n",
       "      <td>0.597524</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.718416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.413700</td>\n",
       "      <td>0.620002</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.718416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.430000</td>\n",
       "      <td>0.632617</td>\n",
       "      <td>0.715000</td>\n",
       "      <td>0.702497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.405800</td>\n",
       "      <td>0.613808</td>\n",
       "      <td>0.732500</td>\n",
       "      <td>0.730436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.385500</td>\n",
       "      <td>0.661685</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.699880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>0.621910</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.722496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.363900</td>\n",
       "      <td>0.643655</td>\n",
       "      <td>0.727500</td>\n",
       "      <td>0.723685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.387100</td>\n",
       "      <td>0.650433</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.708360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.358100</td>\n",
       "      <td>0.637518</td>\n",
       "      <td>0.717500</td>\n",
       "      <td>0.709838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.360800</td>\n",
       "      <td>0.635942</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.714402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 1600\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 400\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alger-ia/dziribert, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 01:47, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.351400</td>\n",
       "      <td>0.310417</td>\n",
       "      <td>0.885000</td>\n",
       "      <td>0.882353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.153700</td>\n",
       "      <td>0.277965</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.896302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.072900</td>\n",
       "      <td>0.344863</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.029900</td>\n",
       "      <td>0.462860</td>\n",
       "      <td>0.905000</td>\n",
       "      <td>0.904657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.009700</td>\n",
       "      <td>0.559397</td>\n",
       "      <td>0.885000</td>\n",
       "      <td>0.884712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.010800</td>\n",
       "      <td>0.608482</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.888653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>0.639634</td>\n",
       "      <td>0.882500</td>\n",
       "      <td>0.881695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.680051</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.879127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.717290</td>\n",
       "      <td>0.882500</td>\n",
       "      <td>0.881372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>0.693762</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.887059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.717633</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.888998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.756655</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.879491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>0.799992</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.885490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.776814</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.885641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.784970</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.889458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.794625</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.889458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.785512</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.891850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.786881</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.891850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.790034</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.835215</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.890724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.820717</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.886529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.821719</td>\n",
       "      <td>0.885000</td>\n",
       "      <td>0.884061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.825851</td>\n",
       "      <td>0.885000</td>\n",
       "      <td>0.884061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.829686</td>\n",
       "      <td>0.885000</td>\n",
       "      <td>0.884061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.832879</td>\n",
       "      <td>0.885000</td>\n",
       "      <td>0.884061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.834714</td>\n",
       "      <td>0.885000</td>\n",
       "      <td>0.884061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.836832</td>\n",
       "      <td>0.885000</td>\n",
       "      <td>0.884061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.838525</td>\n",
       "      <td>0.885000</td>\n",
       "      <td>0.884061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.841043</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.886529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.842099</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.886529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.842458</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.886529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alger-ia/dziribert, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 01:49, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.351400</td>\n",
       "      <td>0.310417</td>\n",
       "      <td>0.885000</td>\n",
       "      <td>0.882353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.153700</td>\n",
       "      <td>0.277965</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.896302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.072900</td>\n",
       "      <td>0.344863</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.029900</td>\n",
       "      <td>0.462860</td>\n",
       "      <td>0.905000</td>\n",
       "      <td>0.904657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.009700</td>\n",
       "      <td>0.559397</td>\n",
       "      <td>0.885000</td>\n",
       "      <td>0.884712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.010800</td>\n",
       "      <td>0.608482</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.888653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>0.639634</td>\n",
       "      <td>0.882500</td>\n",
       "      <td>0.881695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.680051</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.879127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.717290</td>\n",
       "      <td>0.882500</td>\n",
       "      <td>0.881372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>0.693762</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.887059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.717633</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.888998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.756655</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.879491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>0.799992</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.885490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.776814</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.885641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.784970</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.889458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.794625</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.889458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.785512</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.891850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.786881</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.891850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.790034</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.835215</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.890724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.820717</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.886529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.821719</td>\n",
       "      <td>0.885000</td>\n",
       "      <td>0.884061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.825851</td>\n",
       "      <td>0.885000</td>\n",
       "      <td>0.884061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.829686</td>\n",
       "      <td>0.885000</td>\n",
       "      <td>0.884061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.832879</td>\n",
       "      <td>0.885000</td>\n",
       "      <td>0.884061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.834714</td>\n",
       "      <td>0.885000</td>\n",
       "      <td>0.884061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.836832</td>\n",
       "      <td>0.885000</td>\n",
       "      <td>0.884061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.838525</td>\n",
       "      <td>0.885000</td>\n",
       "      <td>0.884061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.841043</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.886529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.842099</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.886529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.842458</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.886529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alger-ia/dziribert, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 01:49, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.351400</td>\n",
       "      <td>0.310417</td>\n",
       "      <td>0.885000</td>\n",
       "      <td>0.882353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.153700</td>\n",
       "      <td>0.277965</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.896302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.072900</td>\n",
       "      <td>0.344863</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.029900</td>\n",
       "      <td>0.462860</td>\n",
       "      <td>0.905000</td>\n",
       "      <td>0.904657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.009700</td>\n",
       "      <td>0.559397</td>\n",
       "      <td>0.885000</td>\n",
       "      <td>0.884712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.010800</td>\n",
       "      <td>0.608482</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.888653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>0.639634</td>\n",
       "      <td>0.882500</td>\n",
       "      <td>0.881695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.680051</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.879127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.717290</td>\n",
       "      <td>0.882500</td>\n",
       "      <td>0.881372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>0.693762</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.887059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.717633</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.888998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.756655</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.879491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>0.799992</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.885490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.776814</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.885641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.784970</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.889458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.794625</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.889458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.785512</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.891850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.786881</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.891850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.790034</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.835215</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.890724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.820717</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.886529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.821719</td>\n",
       "      <td>0.885000</td>\n",
       "      <td>0.884061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.825851</td>\n",
       "      <td>0.885000</td>\n",
       "      <td>0.884061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.829686</td>\n",
       "      <td>0.885000</td>\n",
       "      <td>0.884061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.832879</td>\n",
       "      <td>0.885000</td>\n",
       "      <td>0.884061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.834714</td>\n",
       "      <td>0.885000</td>\n",
       "      <td>0.884061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.836832</td>\n",
       "      <td>0.885000</td>\n",
       "      <td>0.884061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.838525</td>\n",
       "      <td>0.885000</td>\n",
       "      <td>0.884061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.841043</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.886529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.842099</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.886529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.842458</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.886529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alger-ia/dziribert, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 01:48, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.385800</td>\n",
       "      <td>0.308780</td>\n",
       "      <td>0.885000</td>\n",
       "      <td>0.883953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.146200</td>\n",
       "      <td>0.366244</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.878907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.096000</td>\n",
       "      <td>0.396300</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.886185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.036100</td>\n",
       "      <td>0.507910</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.879566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.016200</td>\n",
       "      <td>0.499842</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.006500</td>\n",
       "      <td>0.605711</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.892143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>0.650772</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.891932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.665048</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.896958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.683940</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.896958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.700376</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.896958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.714497</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.896958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.725946</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.896958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.737238</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.896958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.746056</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.899508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.753463</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.899508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.760171</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.899508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.766863</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.899508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.772802</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.899508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.777897</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.899508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.782469</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.899508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.786749</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.899508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.786701</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.896958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.789529</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.896958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.792399</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.896958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.795187</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.896958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.797559</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.896958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.799784</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.896958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.801344</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.896958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.802489</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.896958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.803166</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.896958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.803405</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.896958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alger-ia/dziribert, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 01:49, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.385800</td>\n",
       "      <td>0.308780</td>\n",
       "      <td>0.885000</td>\n",
       "      <td>0.883953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.146200</td>\n",
       "      <td>0.366244</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.878907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.096000</td>\n",
       "      <td>0.396300</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.886185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.036100</td>\n",
       "      <td>0.507910</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.879566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.016200</td>\n",
       "      <td>0.499842</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.006500</td>\n",
       "      <td>0.605711</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.892143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>0.650772</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.891932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.665048</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.896958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.683940</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.896958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.700376</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.896958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.714497</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.896958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.725946</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.896958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.737238</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.896958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.746056</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.899508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.753463</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.899508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.760171</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.899508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.766863</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.899508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.772802</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.899508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.777897</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.899508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.782469</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.899508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.786749</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.899508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.786701</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.896958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.789529</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.896958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.792399</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.896958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.795187</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.896958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.797559</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.896958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.799784</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.896958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.801344</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.896958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.802489</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.896958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.803166</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.896958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.803405</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.896958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alger-ia/dziribert, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 01:48, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.385800</td>\n",
       "      <td>0.308780</td>\n",
       "      <td>0.885000</td>\n",
       "      <td>0.883953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.146200</td>\n",
       "      <td>0.366244</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.878907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.096000</td>\n",
       "      <td>0.396300</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.886185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.036100</td>\n",
       "      <td>0.507910</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.879566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.016200</td>\n",
       "      <td>0.499842</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.006500</td>\n",
       "      <td>0.605711</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.892143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>0.650772</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.891932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.665048</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.896958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.683940</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.896958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.700376</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.896958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.714497</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.896958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.725946</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.896958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.737238</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.896958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.746056</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.899508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.753463</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.899508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.760171</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.899508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.766863</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.899508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.772802</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.899508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.777897</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.899508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.782469</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.899508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.786749</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.899508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.786701</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.896958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.789529</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.896958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.792399</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.896958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.795187</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.896958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.797559</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.896958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.799784</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.896958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.801344</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.896958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.802489</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.896958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.803166</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.896958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.803405</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.896958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alger-ia/dziribert, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 01:50, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.368500</td>\n",
       "      <td>0.231529</td>\n",
       "      <td>0.917500</td>\n",
       "      <td>0.917122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.167300</td>\n",
       "      <td>0.310858</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.899997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.055400</td>\n",
       "      <td>0.303344</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.912499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.055300</td>\n",
       "      <td>0.365260</td>\n",
       "      <td>0.902500</td>\n",
       "      <td>0.902324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.014700</td>\n",
       "      <td>0.394112</td>\n",
       "      <td>0.907500</td>\n",
       "      <td>0.906941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.494054</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.897217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.560415</td>\n",
       "      <td>0.902500</td>\n",
       "      <td>0.902363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.708867</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.555697</td>\n",
       "      <td>0.907500</td>\n",
       "      <td>0.906786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.701258</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.897484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.639103</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.671418</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.892257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.719810</td>\n",
       "      <td>0.907500</td>\n",
       "      <td>0.907453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.667875</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.909557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.744710</td>\n",
       "      <td>0.905000</td>\n",
       "      <td>0.904979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.705686</td>\n",
       "      <td>0.907500</td>\n",
       "      <td>0.907370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.643219</td>\n",
       "      <td>0.905000</td>\n",
       "      <td>0.904463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.683427</td>\n",
       "      <td>0.902500</td>\n",
       "      <td>0.902280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.711118</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.909856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.762721</td>\n",
       "      <td>0.902500</td>\n",
       "      <td>0.902485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.772951</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.899990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.769777</td>\n",
       "      <td>0.902500</td>\n",
       "      <td>0.902485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.767254</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.899977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.766830</td>\n",
       "      <td>0.905000</td>\n",
       "      <td>0.904962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.767911</td>\n",
       "      <td>0.905000</td>\n",
       "      <td>0.904962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.768619</td>\n",
       "      <td>0.905000</td>\n",
       "      <td>0.904962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.769018</td>\n",
       "      <td>0.907500</td>\n",
       "      <td>0.907453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.769157</td>\n",
       "      <td>0.907500</td>\n",
       "      <td>0.907453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.769366</td>\n",
       "      <td>0.907500</td>\n",
       "      <td>0.907453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.769543</td>\n",
       "      <td>0.907500</td>\n",
       "      <td>0.907453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.769509</td>\n",
       "      <td>0.907500</td>\n",
       "      <td>0.907453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alger-ia/dziribert, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 01:48, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.368500</td>\n",
       "      <td>0.231529</td>\n",
       "      <td>0.917500</td>\n",
       "      <td>0.917122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.167300</td>\n",
       "      <td>0.310858</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.899997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.055400</td>\n",
       "      <td>0.303344</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.912499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.055300</td>\n",
       "      <td>0.365260</td>\n",
       "      <td>0.902500</td>\n",
       "      <td>0.902324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.014700</td>\n",
       "      <td>0.394112</td>\n",
       "      <td>0.907500</td>\n",
       "      <td>0.906941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.494054</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.897217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.560415</td>\n",
       "      <td>0.902500</td>\n",
       "      <td>0.902363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.708867</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.555697</td>\n",
       "      <td>0.907500</td>\n",
       "      <td>0.906786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.701258</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.897484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.639103</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.671418</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.892257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.719810</td>\n",
       "      <td>0.907500</td>\n",
       "      <td>0.907453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.667875</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.909557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.744710</td>\n",
       "      <td>0.905000</td>\n",
       "      <td>0.904979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.705686</td>\n",
       "      <td>0.907500</td>\n",
       "      <td>0.907370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.643219</td>\n",
       "      <td>0.905000</td>\n",
       "      <td>0.904463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.683427</td>\n",
       "      <td>0.902500</td>\n",
       "      <td>0.902280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.711118</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.909856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.762721</td>\n",
       "      <td>0.902500</td>\n",
       "      <td>0.902485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.772951</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.899990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.769777</td>\n",
       "      <td>0.902500</td>\n",
       "      <td>0.902485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.767254</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.899977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.766830</td>\n",
       "      <td>0.905000</td>\n",
       "      <td>0.904962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.767911</td>\n",
       "      <td>0.905000</td>\n",
       "      <td>0.904962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.768619</td>\n",
       "      <td>0.905000</td>\n",
       "      <td>0.904962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.769018</td>\n",
       "      <td>0.907500</td>\n",
       "      <td>0.907453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.769157</td>\n",
       "      <td>0.907500</td>\n",
       "      <td>0.907453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.769366</td>\n",
       "      <td>0.907500</td>\n",
       "      <td>0.907453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.769543</td>\n",
       "      <td>0.907500</td>\n",
       "      <td>0.907453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.769509</td>\n",
       "      <td>0.907500</td>\n",
       "      <td>0.907453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alger-ia/dziribert, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 01:48, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.368500</td>\n",
       "      <td>0.231529</td>\n",
       "      <td>0.917500</td>\n",
       "      <td>0.917122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.167300</td>\n",
       "      <td>0.310858</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.899997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.055400</td>\n",
       "      <td>0.303344</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.912499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.055300</td>\n",
       "      <td>0.365260</td>\n",
       "      <td>0.902500</td>\n",
       "      <td>0.902324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.014700</td>\n",
       "      <td>0.394112</td>\n",
       "      <td>0.907500</td>\n",
       "      <td>0.906941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.494054</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.897217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.560415</td>\n",
       "      <td>0.902500</td>\n",
       "      <td>0.902363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.708867</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.555697</td>\n",
       "      <td>0.907500</td>\n",
       "      <td>0.906786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.701258</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.897484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.639103</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.671418</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.892257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.719810</td>\n",
       "      <td>0.907500</td>\n",
       "      <td>0.907453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.667875</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.909557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.744710</td>\n",
       "      <td>0.905000</td>\n",
       "      <td>0.904979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.705686</td>\n",
       "      <td>0.907500</td>\n",
       "      <td>0.907370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.643219</td>\n",
       "      <td>0.905000</td>\n",
       "      <td>0.904463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.683427</td>\n",
       "      <td>0.902500</td>\n",
       "      <td>0.902280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.711118</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.909856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.762721</td>\n",
       "      <td>0.902500</td>\n",
       "      <td>0.902485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.772951</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.899990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.769777</td>\n",
       "      <td>0.902500</td>\n",
       "      <td>0.902485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.767254</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.899977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.766830</td>\n",
       "      <td>0.905000</td>\n",
       "      <td>0.904962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.767911</td>\n",
       "      <td>0.905000</td>\n",
       "      <td>0.904962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.768619</td>\n",
       "      <td>0.905000</td>\n",
       "      <td>0.904962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.769018</td>\n",
       "      <td>0.907500</td>\n",
       "      <td>0.907453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.769157</td>\n",
       "      <td>0.907500</td>\n",
       "      <td>0.907453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.769366</td>\n",
       "      <td>0.907500</td>\n",
       "      <td>0.907453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.769543</td>\n",
       "      <td>0.907500</td>\n",
       "      <td>0.907453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.769509</td>\n",
       "      <td>0.907500</td>\n",
       "      <td>0.907453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 1600\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 400\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SI2M-Lab/DarijaBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SI2M-Lab/DarijaBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 01:53, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.414400</td>\n",
       "      <td>0.351708</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.879491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.204400</td>\n",
       "      <td>0.392982</td>\n",
       "      <td>0.877500</td>\n",
       "      <td>0.876199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.139300</td>\n",
       "      <td>0.365320</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.886305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.047000</td>\n",
       "      <td>0.549021</td>\n",
       "      <td>0.877500</td>\n",
       "      <td>0.876443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.031600</td>\n",
       "      <td>0.572549</td>\n",
       "      <td>0.877500</td>\n",
       "      <td>0.875311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.027500</td>\n",
       "      <td>0.530476</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.873016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.017300</td>\n",
       "      <td>0.679643</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>0.667890</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.878247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.733595</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.886058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>0.764960</td>\n",
       "      <td>0.882500</td>\n",
       "      <td>0.880710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.784129</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.878530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.824066</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.879127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.947346</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.871716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.903927</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.879491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>0.970656</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.874621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.896534</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.886185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.896567</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.886185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.915617</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.886185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.924858</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.886185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.931625</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.886185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.936313</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.886185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.941664</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.886185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.945893</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.886185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.949657</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.888774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.944518</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.886185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.947669</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.886185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.949936</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.886185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.951498</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.886185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.952448</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.886185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.953776</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.886185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.954162</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.886185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SI2M-Lab/DarijaBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SI2M-Lab/DarijaBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 01:52, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.414400</td>\n",
       "      <td>0.351708</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.879491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.204400</td>\n",
       "      <td>0.392982</td>\n",
       "      <td>0.877500</td>\n",
       "      <td>0.876199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.139300</td>\n",
       "      <td>0.365320</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.886305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.047000</td>\n",
       "      <td>0.549021</td>\n",
       "      <td>0.877500</td>\n",
       "      <td>0.876443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.031600</td>\n",
       "      <td>0.572549</td>\n",
       "      <td>0.877500</td>\n",
       "      <td>0.875311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.027500</td>\n",
       "      <td>0.530476</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.873016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.017300</td>\n",
       "      <td>0.679643</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>0.667890</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.878247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.733595</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.886058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>0.764960</td>\n",
       "      <td>0.882500</td>\n",
       "      <td>0.880710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.784129</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.878530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.824066</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.879127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.947346</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.871716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.903927</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.879491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>0.970656</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.874621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.896534</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.886185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.896567</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.886185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.915617</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.886185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.924858</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.886185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.931625</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.886185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.936313</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.886185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.941664</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.886185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.945893</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.886185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.949657</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.888774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.944518</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.886185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.947669</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.886185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.949936</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.886185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.951498</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.886185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.952448</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.886185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.953776</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.886185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.954162</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.886185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SI2M-Lab/DarijaBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SI2M-Lab/DarijaBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 01:52, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.414400</td>\n",
       "      <td>0.351708</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.879491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.204400</td>\n",
       "      <td>0.392982</td>\n",
       "      <td>0.877500</td>\n",
       "      <td>0.876199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.139300</td>\n",
       "      <td>0.365320</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.886305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.047000</td>\n",
       "      <td>0.549021</td>\n",
       "      <td>0.877500</td>\n",
       "      <td>0.876443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.031600</td>\n",
       "      <td>0.572549</td>\n",
       "      <td>0.877500</td>\n",
       "      <td>0.875311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.027500</td>\n",
       "      <td>0.530476</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.873016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.017300</td>\n",
       "      <td>0.679643</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>0.667890</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.878247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.733595</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.886058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>0.764960</td>\n",
       "      <td>0.882500</td>\n",
       "      <td>0.880710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.784129</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.878530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.824066</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.879127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.947346</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.871716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.903927</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.879491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>0.970656</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.874621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.896534</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.886185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.896567</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.886185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.915617</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.886185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.924858</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.886185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.931625</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.886185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.936313</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.886185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.941664</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.886185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.945893</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.886185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.949657</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.888774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.944518</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.886185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.947669</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.886185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.949936</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.886185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.951498</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.886185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.952448</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.886185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.953776</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.886185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.954162</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.886185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SI2M-Lab/DarijaBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SI2M-Lab/DarijaBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 01:52, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.518600</td>\n",
       "      <td>0.573056</td>\n",
       "      <td>0.790000</td>\n",
       "      <td>0.775395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.269800</td>\n",
       "      <td>0.359069</td>\n",
       "      <td>0.877500</td>\n",
       "      <td>0.877370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.341114</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.889901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.100300</td>\n",
       "      <td>0.423064</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.889102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.056400</td>\n",
       "      <td>0.580996</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.859996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.035500</td>\n",
       "      <td>0.519589</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.892078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.011400</td>\n",
       "      <td>0.634894</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.887189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.026400</td>\n",
       "      <td>0.517325</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.887296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>0.742547</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.873469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.007600</td>\n",
       "      <td>0.648559</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.889458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.682531</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.897031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>0.714732</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.889291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>0.730981</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.897315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.746225</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.763615</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.889458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.808597</td>\n",
       "      <td>0.882500</td>\n",
       "      <td>0.881790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.826008</td>\n",
       "      <td>0.882500</td>\n",
       "      <td>0.881790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.828754</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.886906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.832112</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.889458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.840160</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.889458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.841006</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.845835</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.850357</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.854464</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.857854</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.860627</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.863645</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.866598</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.868479</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.892008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.869423</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.892008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.869733</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.892008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SI2M-Lab/DarijaBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SI2M-Lab/DarijaBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 01:52, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.518600</td>\n",
       "      <td>0.573056</td>\n",
       "      <td>0.790000</td>\n",
       "      <td>0.775395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.269800</td>\n",
       "      <td>0.359069</td>\n",
       "      <td>0.877500</td>\n",
       "      <td>0.877370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.341114</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.889901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.100300</td>\n",
       "      <td>0.423064</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.889102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.056400</td>\n",
       "      <td>0.580996</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.859996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.035500</td>\n",
       "      <td>0.519589</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.892078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.011400</td>\n",
       "      <td>0.634894</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.887189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.026400</td>\n",
       "      <td>0.517325</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.887296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>0.742547</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.873469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.007600</td>\n",
       "      <td>0.648559</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.889458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.682531</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.897031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>0.714732</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.889291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>0.730981</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.897315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.746225</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.763615</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.889458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.808597</td>\n",
       "      <td>0.882500</td>\n",
       "      <td>0.881790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.826008</td>\n",
       "      <td>0.882500</td>\n",
       "      <td>0.881790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.828754</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.886906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.832112</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.889458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.840160</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.889458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.841006</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.845835</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.850357</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.854464</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.857854</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.860627</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.863645</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.866598</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.868479</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.892008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.869423</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.892008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.869733</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.892008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SI2M-Lab/DarijaBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SI2M-Lab/DarijaBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 01:52, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.518600</td>\n",
       "      <td>0.573056</td>\n",
       "      <td>0.790000</td>\n",
       "      <td>0.775395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.269800</td>\n",
       "      <td>0.359069</td>\n",
       "      <td>0.877500</td>\n",
       "      <td>0.877370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.341114</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.889901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.100300</td>\n",
       "      <td>0.423064</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.889102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.056400</td>\n",
       "      <td>0.580996</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.859996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.035500</td>\n",
       "      <td>0.519589</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.892078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.011400</td>\n",
       "      <td>0.634894</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.887189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.026400</td>\n",
       "      <td>0.517325</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.887296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>0.742547</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.873469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.007600</td>\n",
       "      <td>0.648559</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.889458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.682531</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.897031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>0.714732</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.889291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>0.730981</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.897315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.746225</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.763615</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.889458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.808597</td>\n",
       "      <td>0.882500</td>\n",
       "      <td>0.881790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.826008</td>\n",
       "      <td>0.882500</td>\n",
       "      <td>0.881790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.828754</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.886906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.832112</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.889458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.840160</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.889458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.841006</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.845835</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.850357</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.854464</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.857854</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.860627</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.863645</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.866598</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.868479</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.892008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.869423</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.892008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.869733</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.892008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SI2M-Lab/DarijaBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SI2M-Lab/DarijaBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 01:53, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.445600</td>\n",
       "      <td>0.293966</td>\n",
       "      <td>0.885000</td>\n",
       "      <td>0.884997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.246000</td>\n",
       "      <td>0.260554</td>\n",
       "      <td>0.907500</td>\n",
       "      <td>0.907402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.157000</td>\n",
       "      <td>0.314758</td>\n",
       "      <td>0.877500</td>\n",
       "      <td>0.877462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.098900</td>\n",
       "      <td>0.341360</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.896302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.071900</td>\n",
       "      <td>0.321921</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.914864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.017800</td>\n",
       "      <td>0.424079</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.914828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.013400</td>\n",
       "      <td>0.541909</td>\n",
       "      <td>0.902500</td>\n",
       "      <td>0.902118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>0.630132</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>0.674232</td>\n",
       "      <td>0.905000</td>\n",
       "      <td>0.904463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.720992</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.899977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.669992</td>\n",
       "      <td>0.905000</td>\n",
       "      <td>0.904848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.675298</td>\n",
       "      <td>0.907500</td>\n",
       "      <td>0.907291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.699885</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.899639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.706659</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.897160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.711117</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.899797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.727181</td>\n",
       "      <td>0.902500</td>\n",
       "      <td>0.902324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.733201</td>\n",
       "      <td>0.902500</td>\n",
       "      <td>0.902324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.736386</td>\n",
       "      <td>0.902500</td>\n",
       "      <td>0.902324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.770711</td>\n",
       "      <td>0.902500</td>\n",
       "      <td>0.901911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>0.731977</td>\n",
       "      <td>0.905000</td>\n",
       "      <td>0.904762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.742127</td>\n",
       "      <td>0.905000</td>\n",
       "      <td>0.904883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.734921</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.899749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.735524</td>\n",
       "      <td>0.905000</td>\n",
       "      <td>0.904848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.738574</td>\n",
       "      <td>0.905000</td>\n",
       "      <td>0.904848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>0.768071</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.909944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.773291</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.912456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.767852</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.909944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.766824</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.909944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.766749</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.909944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.770036</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.909944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.769984</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.909944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SI2M-Lab/DarijaBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SI2M-Lab/DarijaBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 01:52, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.445600</td>\n",
       "      <td>0.293966</td>\n",
       "      <td>0.885000</td>\n",
       "      <td>0.884997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.246000</td>\n",
       "      <td>0.260554</td>\n",
       "      <td>0.907500</td>\n",
       "      <td>0.907402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.157000</td>\n",
       "      <td>0.314758</td>\n",
       "      <td>0.877500</td>\n",
       "      <td>0.877462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.098900</td>\n",
       "      <td>0.341360</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.896302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.071900</td>\n",
       "      <td>0.321921</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.914864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.017800</td>\n",
       "      <td>0.424079</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.914828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.013400</td>\n",
       "      <td>0.541909</td>\n",
       "      <td>0.902500</td>\n",
       "      <td>0.902118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>0.630132</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>0.674232</td>\n",
       "      <td>0.905000</td>\n",
       "      <td>0.904463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.720992</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.899977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.669992</td>\n",
       "      <td>0.905000</td>\n",
       "      <td>0.904848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.675298</td>\n",
       "      <td>0.907500</td>\n",
       "      <td>0.907291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.699885</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.899639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.706659</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.897160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.711117</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.899797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.727181</td>\n",
       "      <td>0.902500</td>\n",
       "      <td>0.902324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.733201</td>\n",
       "      <td>0.902500</td>\n",
       "      <td>0.902324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.736386</td>\n",
       "      <td>0.902500</td>\n",
       "      <td>0.902324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.770711</td>\n",
       "      <td>0.902500</td>\n",
       "      <td>0.901911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>0.731977</td>\n",
       "      <td>0.905000</td>\n",
       "      <td>0.904762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.742127</td>\n",
       "      <td>0.905000</td>\n",
       "      <td>0.904883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.734921</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.899749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.735524</td>\n",
       "      <td>0.905000</td>\n",
       "      <td>0.904848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.738574</td>\n",
       "      <td>0.905000</td>\n",
       "      <td>0.904848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>0.768071</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.909944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.773291</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.912456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.767852</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.909944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.766824</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.909944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.766749</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.909944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.770036</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.909944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.769984</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.909944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SI2M-Lab/DarijaBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SI2M-Lab/DarijaBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 01:52, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.445600</td>\n",
       "      <td>0.293966</td>\n",
       "      <td>0.885000</td>\n",
       "      <td>0.884997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.246000</td>\n",
       "      <td>0.260554</td>\n",
       "      <td>0.907500</td>\n",
       "      <td>0.907402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.157000</td>\n",
       "      <td>0.314758</td>\n",
       "      <td>0.877500</td>\n",
       "      <td>0.877462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.098900</td>\n",
       "      <td>0.341360</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.896302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.071900</td>\n",
       "      <td>0.321921</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.914864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.017800</td>\n",
       "      <td>0.424079</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.914828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.013400</td>\n",
       "      <td>0.541909</td>\n",
       "      <td>0.902500</td>\n",
       "      <td>0.902118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>0.630132</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>0.674232</td>\n",
       "      <td>0.905000</td>\n",
       "      <td>0.904463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.720992</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.899977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.669992</td>\n",
       "      <td>0.905000</td>\n",
       "      <td>0.904848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.675298</td>\n",
       "      <td>0.907500</td>\n",
       "      <td>0.907291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.699885</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.899639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.706659</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.897160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.711117</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.899797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.727181</td>\n",
       "      <td>0.902500</td>\n",
       "      <td>0.902324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.733201</td>\n",
       "      <td>0.902500</td>\n",
       "      <td>0.902324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.736386</td>\n",
       "      <td>0.902500</td>\n",
       "      <td>0.902324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.770711</td>\n",
       "      <td>0.902500</td>\n",
       "      <td>0.901911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>0.731977</td>\n",
       "      <td>0.905000</td>\n",
       "      <td>0.904762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.742127</td>\n",
       "      <td>0.905000</td>\n",
       "      <td>0.904883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.734921</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.899749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.735524</td>\n",
       "      <td>0.905000</td>\n",
       "      <td>0.904848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.738574</td>\n",
       "      <td>0.905000</td>\n",
       "      <td>0.904848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>0.768071</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.909944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.773291</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.912456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.767852</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.909944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.766824</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.909944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.766749</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.909944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.770036</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.909944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.769984</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.909944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 1600\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 400\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorRoBERTa, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at otmangi/MorRoBERTa and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 01:01, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.423400</td>\n",
       "      <td>0.375146</td>\n",
       "      <td>0.862500</td>\n",
       "      <td>0.861040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.191400</td>\n",
       "      <td>0.353061</td>\n",
       "      <td>0.877500</td>\n",
       "      <td>0.875930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.134600</td>\n",
       "      <td>0.415203</td>\n",
       "      <td>0.862500</td>\n",
       "      <td>0.861439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.049200</td>\n",
       "      <td>0.565761</td>\n",
       "      <td>0.867500</td>\n",
       "      <td>0.866228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.028400</td>\n",
       "      <td>0.767492</td>\n",
       "      <td>0.867500</td>\n",
       "      <td>0.865132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.014400</td>\n",
       "      <td>0.774728</td>\n",
       "      <td>0.865000</td>\n",
       "      <td>0.863495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.839078</td>\n",
       "      <td>0.862500</td>\n",
       "      <td>0.860892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>0.898217</td>\n",
       "      <td>0.872500</td>\n",
       "      <td>0.872077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.008300</td>\n",
       "      <td>0.908800</td>\n",
       "      <td>0.867500</td>\n",
       "      <td>0.865951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.958374</td>\n",
       "      <td>0.862500</td>\n",
       "      <td>0.861773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.964773</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.859098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.016644</td>\n",
       "      <td>0.855000</td>\n",
       "      <td>0.854385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.976158</td>\n",
       "      <td>0.865000</td>\n",
       "      <td>0.864018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.001155</td>\n",
       "      <td>0.857500</td>\n",
       "      <td>0.856639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.023242</td>\n",
       "      <td>0.857500</td>\n",
       "      <td>0.856747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.023353</td>\n",
       "      <td>0.857500</td>\n",
       "      <td>0.856639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.048324</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.859311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.056890</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.859311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.055253</td>\n",
       "      <td>0.855000</td>\n",
       "      <td>0.854180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.054034</td>\n",
       "      <td>0.857500</td>\n",
       "      <td>0.856639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.051495</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.859098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.061320</td>\n",
       "      <td>0.857500</td>\n",
       "      <td>0.856639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.080650</td>\n",
       "      <td>0.862500</td>\n",
       "      <td>0.861773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.084691</td>\n",
       "      <td>0.862500</td>\n",
       "      <td>0.861773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.087425</td>\n",
       "      <td>0.862500</td>\n",
       "      <td>0.861773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.071164</td>\n",
       "      <td>0.857500</td>\n",
       "      <td>0.856639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.088587</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.859311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.081717</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.859311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.081825</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.859311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.082290</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.859311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.082456</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.859311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorRoBERTa, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at otmangi/MorRoBERTa and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 00:57, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.423400</td>\n",
       "      <td>0.375146</td>\n",
       "      <td>0.862500</td>\n",
       "      <td>0.861040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.191400</td>\n",
       "      <td>0.353061</td>\n",
       "      <td>0.877500</td>\n",
       "      <td>0.875930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.134600</td>\n",
       "      <td>0.415203</td>\n",
       "      <td>0.862500</td>\n",
       "      <td>0.861439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.049200</td>\n",
       "      <td>0.565761</td>\n",
       "      <td>0.867500</td>\n",
       "      <td>0.866228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.028400</td>\n",
       "      <td>0.767492</td>\n",
       "      <td>0.867500</td>\n",
       "      <td>0.865132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.014400</td>\n",
       "      <td>0.774728</td>\n",
       "      <td>0.865000</td>\n",
       "      <td>0.863495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.839078</td>\n",
       "      <td>0.862500</td>\n",
       "      <td>0.860892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>0.898217</td>\n",
       "      <td>0.872500</td>\n",
       "      <td>0.872077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.008300</td>\n",
       "      <td>0.908800</td>\n",
       "      <td>0.867500</td>\n",
       "      <td>0.865951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.958374</td>\n",
       "      <td>0.862500</td>\n",
       "      <td>0.861773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.964773</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.859098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.016644</td>\n",
       "      <td>0.855000</td>\n",
       "      <td>0.854385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.976158</td>\n",
       "      <td>0.865000</td>\n",
       "      <td>0.864018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.001155</td>\n",
       "      <td>0.857500</td>\n",
       "      <td>0.856639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.023242</td>\n",
       "      <td>0.857500</td>\n",
       "      <td>0.856747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.023353</td>\n",
       "      <td>0.857500</td>\n",
       "      <td>0.856639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.048324</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.859311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.056890</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.859311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.055253</td>\n",
       "      <td>0.855000</td>\n",
       "      <td>0.854180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.054034</td>\n",
       "      <td>0.857500</td>\n",
       "      <td>0.856639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.051495</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.859098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.061320</td>\n",
       "      <td>0.857500</td>\n",
       "      <td>0.856639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.080650</td>\n",
       "      <td>0.862500</td>\n",
       "      <td>0.861773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.084691</td>\n",
       "      <td>0.862500</td>\n",
       "      <td>0.861773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.087425</td>\n",
       "      <td>0.862500</td>\n",
       "      <td>0.861773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.071164</td>\n",
       "      <td>0.857500</td>\n",
       "      <td>0.856639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.088587</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.859311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.081717</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.859311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.081825</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.859311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.082290</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.859311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.082456</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.859311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorRoBERTa, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at otmangi/MorRoBERTa and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 00:30, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.423400</td>\n",
       "      <td>0.375146</td>\n",
       "      <td>0.862500</td>\n",
       "      <td>0.861040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.191400</td>\n",
       "      <td>0.353061</td>\n",
       "      <td>0.877500</td>\n",
       "      <td>0.875930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.134600</td>\n",
       "      <td>0.415203</td>\n",
       "      <td>0.862500</td>\n",
       "      <td>0.861439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.049200</td>\n",
       "      <td>0.565761</td>\n",
       "      <td>0.867500</td>\n",
       "      <td>0.866228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.028400</td>\n",
       "      <td>0.767492</td>\n",
       "      <td>0.867500</td>\n",
       "      <td>0.865132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.014400</td>\n",
       "      <td>0.774728</td>\n",
       "      <td>0.865000</td>\n",
       "      <td>0.863495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.839078</td>\n",
       "      <td>0.862500</td>\n",
       "      <td>0.860892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>0.898217</td>\n",
       "      <td>0.872500</td>\n",
       "      <td>0.872077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.008300</td>\n",
       "      <td>0.908800</td>\n",
       "      <td>0.867500</td>\n",
       "      <td>0.865951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.958374</td>\n",
       "      <td>0.862500</td>\n",
       "      <td>0.861773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.964773</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.859098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.016644</td>\n",
       "      <td>0.855000</td>\n",
       "      <td>0.854385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.976158</td>\n",
       "      <td>0.865000</td>\n",
       "      <td>0.864018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.001155</td>\n",
       "      <td>0.857500</td>\n",
       "      <td>0.856639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.023242</td>\n",
       "      <td>0.857500</td>\n",
       "      <td>0.856747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.023353</td>\n",
       "      <td>0.857500</td>\n",
       "      <td>0.856639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.048324</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.859311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.056890</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.859311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.055253</td>\n",
       "      <td>0.855000</td>\n",
       "      <td>0.854180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.054034</td>\n",
       "      <td>0.857500</td>\n",
       "      <td>0.856639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.051495</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.859098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.061320</td>\n",
       "      <td>0.857500</td>\n",
       "      <td>0.856639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.080650</td>\n",
       "      <td>0.862500</td>\n",
       "      <td>0.861773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.084691</td>\n",
       "      <td>0.862500</td>\n",
       "      <td>0.861773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.087425</td>\n",
       "      <td>0.862500</td>\n",
       "      <td>0.861773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.071164</td>\n",
       "      <td>0.857500</td>\n",
       "      <td>0.856639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.088587</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.859311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.081717</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.859311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.081825</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.859311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.082290</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.859311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.082456</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.859311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorRoBERTa, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at otmangi/MorRoBERTa and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 00:30, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.442300</td>\n",
       "      <td>0.325336</td>\n",
       "      <td>0.885000</td>\n",
       "      <td>0.884163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.197100</td>\n",
       "      <td>0.374105</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>0.869736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.117300</td>\n",
       "      <td>0.382365</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.888653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.052700</td>\n",
       "      <td>0.535645</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.879636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.029100</td>\n",
       "      <td>0.558257</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.892008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.011700</td>\n",
       "      <td>0.647145</td>\n",
       "      <td>0.885000</td>\n",
       "      <td>0.884349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>0.726268</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.878392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>0.775977</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.878095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.773699</td>\n",
       "      <td>0.882500</td>\n",
       "      <td>0.880710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.012400</td>\n",
       "      <td>0.757702</td>\n",
       "      <td>0.902500</td>\n",
       "      <td>0.901748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.775338</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.893593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.796471</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.854566</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.885490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.835899</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.829258</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.897031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.819687</td>\n",
       "      <td>0.902500</td>\n",
       "      <td>0.901985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.843082</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.897031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.849362</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.840726</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.899508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.839197</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.899434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.917944</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.889603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.918772</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.889666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.892387</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.886576</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.892008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.886143</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.892008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.885517</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.892008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.885996</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.892008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.883739</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.892008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.883262</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.892008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.883441</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.892008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.883563</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.892008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorRoBERTa, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at otmangi/MorRoBERTa and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 00:30, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.442300</td>\n",
       "      <td>0.325336</td>\n",
       "      <td>0.885000</td>\n",
       "      <td>0.884163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.197100</td>\n",
       "      <td>0.374105</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>0.869736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.117300</td>\n",
       "      <td>0.382365</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.888653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.052700</td>\n",
       "      <td>0.535645</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.879636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.029100</td>\n",
       "      <td>0.558257</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.892008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.011700</td>\n",
       "      <td>0.647145</td>\n",
       "      <td>0.885000</td>\n",
       "      <td>0.884349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>0.726268</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.878392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>0.775977</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.878095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.773699</td>\n",
       "      <td>0.882500</td>\n",
       "      <td>0.880710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.012400</td>\n",
       "      <td>0.757702</td>\n",
       "      <td>0.902500</td>\n",
       "      <td>0.901748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.775338</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.893593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.796471</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.854566</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.885490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.835899</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.829258</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.897031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.819687</td>\n",
       "      <td>0.902500</td>\n",
       "      <td>0.901985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.843082</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.897031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.849362</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.840726</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.899508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.839197</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.899434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.917944</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.889603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.918772</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.889666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.892387</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.886576</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.892008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.886143</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.892008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.885517</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.892008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.885996</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.892008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.883739</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.892008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.883262</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.892008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.883441</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.892008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.883563</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.892008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorRoBERTa, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at otmangi/MorRoBERTa and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 00:30, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.442300</td>\n",
       "      <td>0.325336</td>\n",
       "      <td>0.885000</td>\n",
       "      <td>0.884163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.197100</td>\n",
       "      <td>0.374105</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>0.869736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.117300</td>\n",
       "      <td>0.382365</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.888653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.052700</td>\n",
       "      <td>0.535645</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.879636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.029100</td>\n",
       "      <td>0.558257</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.892008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.011700</td>\n",
       "      <td>0.647145</td>\n",
       "      <td>0.885000</td>\n",
       "      <td>0.884349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>0.726268</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.878392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>0.775977</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.878095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.773699</td>\n",
       "      <td>0.882500</td>\n",
       "      <td>0.880710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.012400</td>\n",
       "      <td>0.757702</td>\n",
       "      <td>0.902500</td>\n",
       "      <td>0.901748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.775338</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.893593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.796471</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.854566</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.885490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.835899</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.829258</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.897031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.819687</td>\n",
       "      <td>0.902500</td>\n",
       "      <td>0.901985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.843082</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.897031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.849362</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.840726</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.899508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.839197</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.899434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.917944</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.889603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.918772</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.889666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.892387</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.886576</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.892008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.886143</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.892008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.885517</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.892008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.885996</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.892008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.883739</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.892008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.883262</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.892008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.883441</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.892008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.883563</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.892008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorRoBERTa, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at otmangi/MorRoBERTa and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 00:30, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.432900</td>\n",
       "      <td>0.294440</td>\n",
       "      <td>0.872500</td>\n",
       "      <td>0.872077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.235300</td>\n",
       "      <td>0.277948</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.896516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.089100</td>\n",
       "      <td>0.319238</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.896958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.059800</td>\n",
       "      <td>0.348680</td>\n",
       "      <td>0.907500</td>\n",
       "      <td>0.907291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.025500</td>\n",
       "      <td>0.436487</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.899840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>0.525227</td>\n",
       "      <td>0.907500</td>\n",
       "      <td>0.907011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>0.606076</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.615652</td>\n",
       "      <td>0.902500</td>\n",
       "      <td>0.902280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.639148</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.899639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.662997</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.897356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.675245</td>\n",
       "      <td>0.905000</td>\n",
       "      <td>0.904388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.710126</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.899910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.716178</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.725616</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.897160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.739527</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.897268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.748564</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.897268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.760662</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.818924</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.897494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>0.751771</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.899508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.761468</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.750530</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.889865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.750426</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.753031</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.748982</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.897098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.747391</td>\n",
       "      <td>0.902500</td>\n",
       "      <td>0.902054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.748884</td>\n",
       "      <td>0.902500</td>\n",
       "      <td>0.902054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.759136</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.766886</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.897356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.754741</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.752352</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.892257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.752386</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.892257</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorRoBERTa, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at otmangi/MorRoBERTa and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 00:30, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.432900</td>\n",
       "      <td>0.294440</td>\n",
       "      <td>0.872500</td>\n",
       "      <td>0.872077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.235300</td>\n",
       "      <td>0.277948</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.896516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.089100</td>\n",
       "      <td>0.319238</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.896958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.059800</td>\n",
       "      <td>0.348680</td>\n",
       "      <td>0.907500</td>\n",
       "      <td>0.907291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.025500</td>\n",
       "      <td>0.436487</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.899840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>0.525227</td>\n",
       "      <td>0.907500</td>\n",
       "      <td>0.907011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>0.606076</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.615652</td>\n",
       "      <td>0.902500</td>\n",
       "      <td>0.902280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.639148</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.899639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.662997</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.897356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.675245</td>\n",
       "      <td>0.905000</td>\n",
       "      <td>0.904388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.710126</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.899910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.716178</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.725616</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.897160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.739527</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.897268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.748564</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.897268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.760662</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.818924</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.897494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>0.751771</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.899508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.761468</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.750530</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.889865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.750426</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.753031</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.748982</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.897098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.747391</td>\n",
       "      <td>0.902500</td>\n",
       "      <td>0.902054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.748884</td>\n",
       "      <td>0.902500</td>\n",
       "      <td>0.902054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.759136</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.766886</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.897356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.754741</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.752352</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.892257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.752386</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.892257</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorRoBERTa, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at otmangi/MorRoBERTa and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 00:30, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.432900</td>\n",
       "      <td>0.294440</td>\n",
       "      <td>0.872500</td>\n",
       "      <td>0.872077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.235300</td>\n",
       "      <td>0.277948</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.896516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.089100</td>\n",
       "      <td>0.319238</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.896958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.059800</td>\n",
       "      <td>0.348680</td>\n",
       "      <td>0.907500</td>\n",
       "      <td>0.907291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.025500</td>\n",
       "      <td>0.436487</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.899840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>0.525227</td>\n",
       "      <td>0.907500</td>\n",
       "      <td>0.907011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>0.606076</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.615652</td>\n",
       "      <td>0.902500</td>\n",
       "      <td>0.902280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.639148</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.899639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.662997</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.897356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.675245</td>\n",
       "      <td>0.905000</td>\n",
       "      <td>0.904388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.710126</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.899910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.716178</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.725616</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.897160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.739527</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.897268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.748564</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.897268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.760662</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.818924</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.897494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>0.751771</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.899508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.761468</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.750530</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.889865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.750426</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.753031</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.748982</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.897098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.747391</td>\n",
       "      <td>0.902500</td>\n",
       "      <td>0.902054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.748884</td>\n",
       "      <td>0.902500</td>\n",
       "      <td>0.902054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.759136</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.766886</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.897356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.754741</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.752352</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.892257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.752386</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.892257</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 1600\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 400\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorrBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at otmangi/MorrBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 00:56, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.388800</td>\n",
       "      <td>0.430432</td>\n",
       "      <td>0.832500</td>\n",
       "      <td>0.832415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.188000</td>\n",
       "      <td>0.423666</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.859716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.111700</td>\n",
       "      <td>0.479348</td>\n",
       "      <td>0.872500</td>\n",
       "      <td>0.872320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.061000</td>\n",
       "      <td>0.519180</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.874293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.027800</td>\n",
       "      <td>0.636171</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.874746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.013300</td>\n",
       "      <td>0.687853</td>\n",
       "      <td>0.867500</td>\n",
       "      <td>0.866800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.006500</td>\n",
       "      <td>0.735141</td>\n",
       "      <td>0.882500</td>\n",
       "      <td>0.882175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.010500</td>\n",
       "      <td>0.770969</td>\n",
       "      <td>0.882500</td>\n",
       "      <td>0.881790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>0.883838</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>0.869841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.845489</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.879699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.018900</td>\n",
       "      <td>0.858374</td>\n",
       "      <td>0.867500</td>\n",
       "      <td>0.866228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>0.828175</td>\n",
       "      <td>0.872500</td>\n",
       "      <td>0.871626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>0.852706</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.879699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>0.919684</td>\n",
       "      <td>0.865000</td>\n",
       "      <td>0.863495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.010700</td>\n",
       "      <td>0.827830</td>\n",
       "      <td>0.882500</td>\n",
       "      <td>0.882110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>0.840288</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.874293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.881528</td>\n",
       "      <td>0.872500</td>\n",
       "      <td>0.872404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.007200</td>\n",
       "      <td>0.813378</td>\n",
       "      <td>0.877500</td>\n",
       "      <td>0.876853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.886466</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.887246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.008800</td>\n",
       "      <td>0.811803</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.879227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.004900</td>\n",
       "      <td>0.817585</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.879127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.817239</td>\n",
       "      <td>0.877500</td>\n",
       "      <td>0.876939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>0.818258</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.879321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.835647</td>\n",
       "      <td>0.885000</td>\n",
       "      <td>0.884651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>0.840719</td>\n",
       "      <td>0.877500</td>\n",
       "      <td>0.876853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>0.910580</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>0.868551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.898944</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.873979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>0.897576</td>\n",
       "      <td>0.872500</td>\n",
       "      <td>0.871626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.895865</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.874195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>0.894038</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.874195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.894454</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.874090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorrBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at otmangi/MorrBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 00:56, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.388800</td>\n",
       "      <td>0.430432</td>\n",
       "      <td>0.832500</td>\n",
       "      <td>0.832415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.188000</td>\n",
       "      <td>0.423666</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.859716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.111700</td>\n",
       "      <td>0.479348</td>\n",
       "      <td>0.872500</td>\n",
       "      <td>0.872320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.061000</td>\n",
       "      <td>0.519180</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.874293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.027800</td>\n",
       "      <td>0.636171</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.874746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.013300</td>\n",
       "      <td>0.687853</td>\n",
       "      <td>0.867500</td>\n",
       "      <td>0.866800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.006500</td>\n",
       "      <td>0.735141</td>\n",
       "      <td>0.882500</td>\n",
       "      <td>0.882175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.010500</td>\n",
       "      <td>0.770969</td>\n",
       "      <td>0.882500</td>\n",
       "      <td>0.881790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>0.883838</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>0.869841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.845489</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.879699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.018900</td>\n",
       "      <td>0.858374</td>\n",
       "      <td>0.867500</td>\n",
       "      <td>0.866228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>0.828175</td>\n",
       "      <td>0.872500</td>\n",
       "      <td>0.871626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>0.852706</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.879699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>0.919684</td>\n",
       "      <td>0.865000</td>\n",
       "      <td>0.863495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.010700</td>\n",
       "      <td>0.827830</td>\n",
       "      <td>0.882500</td>\n",
       "      <td>0.882110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>0.840288</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.874293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.881528</td>\n",
       "      <td>0.872500</td>\n",
       "      <td>0.872404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.007200</td>\n",
       "      <td>0.813378</td>\n",
       "      <td>0.877500</td>\n",
       "      <td>0.876853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.886466</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.887246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.008800</td>\n",
       "      <td>0.811803</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.879227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.004900</td>\n",
       "      <td>0.817585</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.879127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.817239</td>\n",
       "      <td>0.877500</td>\n",
       "      <td>0.876939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>0.818258</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.879321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.835647</td>\n",
       "      <td>0.885000</td>\n",
       "      <td>0.884651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>0.840719</td>\n",
       "      <td>0.877500</td>\n",
       "      <td>0.876853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>0.910580</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>0.868551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.898944</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.873979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>0.897576</td>\n",
       "      <td>0.872500</td>\n",
       "      <td>0.871626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.895865</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.874195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>0.894038</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.874195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.894454</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.874090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorrBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at otmangi/MorrBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 00:56, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.388800</td>\n",
       "      <td>0.430432</td>\n",
       "      <td>0.832500</td>\n",
       "      <td>0.832415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.188000</td>\n",
       "      <td>0.423666</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.859716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.111700</td>\n",
       "      <td>0.479348</td>\n",
       "      <td>0.872500</td>\n",
       "      <td>0.872320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.061000</td>\n",
       "      <td>0.519180</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.874293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.027800</td>\n",
       "      <td>0.636171</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.874746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.013300</td>\n",
       "      <td>0.687853</td>\n",
       "      <td>0.867500</td>\n",
       "      <td>0.866800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.006500</td>\n",
       "      <td>0.735141</td>\n",
       "      <td>0.882500</td>\n",
       "      <td>0.882175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.010500</td>\n",
       "      <td>0.770969</td>\n",
       "      <td>0.882500</td>\n",
       "      <td>0.881790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>0.883838</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>0.869841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.845489</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.879699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.018900</td>\n",
       "      <td>0.858374</td>\n",
       "      <td>0.867500</td>\n",
       "      <td>0.866228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>0.828175</td>\n",
       "      <td>0.872500</td>\n",
       "      <td>0.871626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>0.852706</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.879699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>0.919684</td>\n",
       "      <td>0.865000</td>\n",
       "      <td>0.863495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.010700</td>\n",
       "      <td>0.827830</td>\n",
       "      <td>0.882500</td>\n",
       "      <td>0.882110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>0.840288</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.874293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.881528</td>\n",
       "      <td>0.872500</td>\n",
       "      <td>0.872404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.007200</td>\n",
       "      <td>0.813378</td>\n",
       "      <td>0.877500</td>\n",
       "      <td>0.876853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.886466</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.887246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.008800</td>\n",
       "      <td>0.811803</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.879227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.004900</td>\n",
       "      <td>0.817585</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.879127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.817239</td>\n",
       "      <td>0.877500</td>\n",
       "      <td>0.876939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>0.818258</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.879321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.835647</td>\n",
       "      <td>0.885000</td>\n",
       "      <td>0.884651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>0.840719</td>\n",
       "      <td>0.877500</td>\n",
       "      <td>0.876853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>0.910580</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>0.868551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.898944</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.873979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>0.897576</td>\n",
       "      <td>0.872500</td>\n",
       "      <td>0.871626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.895865</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.874195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>0.894038</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.874195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.894454</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.874090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorrBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at otmangi/MorrBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 00:56, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.456100</td>\n",
       "      <td>0.386580</td>\n",
       "      <td>0.837500</td>\n",
       "      <td>0.830552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.210300</td>\n",
       "      <td>0.386699</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>0.869919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.111600</td>\n",
       "      <td>0.446450</td>\n",
       "      <td>0.862500</td>\n",
       "      <td>0.861180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.061300</td>\n",
       "      <td>0.536362</td>\n",
       "      <td>0.852500</td>\n",
       "      <td>0.851825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.026400</td>\n",
       "      <td>0.832581</td>\n",
       "      <td>0.842500</td>\n",
       "      <td>0.842475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.009700</td>\n",
       "      <td>0.936490</td>\n",
       "      <td>0.855000</td>\n",
       "      <td>0.854942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>1.076903</td>\n",
       "      <td>0.847500</td>\n",
       "      <td>0.847499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.007800</td>\n",
       "      <td>0.979117</td>\n",
       "      <td>0.847500</td>\n",
       "      <td>0.847285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.009700</td>\n",
       "      <td>0.994744</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.849865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>1.004411</td>\n",
       "      <td>0.855000</td>\n",
       "      <td>0.854706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.010600</td>\n",
       "      <td>1.086788</td>\n",
       "      <td>0.855000</td>\n",
       "      <td>0.854909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>1.073861</td>\n",
       "      <td>0.852500</td>\n",
       "      <td>0.852388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>1.069269</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.849906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.007300</td>\n",
       "      <td>1.015093</td>\n",
       "      <td>0.845000</td>\n",
       "      <td>0.844002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.005900</td>\n",
       "      <td>1.001757</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.849624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.004900</td>\n",
       "      <td>1.063215</td>\n",
       "      <td>0.857500</td>\n",
       "      <td>0.857428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>0.985324</td>\n",
       "      <td>0.857500</td>\n",
       "      <td>0.857178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>1.080585</td>\n",
       "      <td>0.855000</td>\n",
       "      <td>0.854967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.274011</td>\n",
       "      <td>0.827500</td>\n",
       "      <td>0.827413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>1.093839</td>\n",
       "      <td>0.845000</td>\n",
       "      <td>0.842923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.008600</td>\n",
       "      <td>1.060265</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.839212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.110586</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.849816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.006100</td>\n",
       "      <td>1.105483</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.849760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>1.116306</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.849816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>1.124446</td>\n",
       "      <td>0.852500</td>\n",
       "      <td>0.852344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>1.123522</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.849816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>1.131012</td>\n",
       "      <td>0.852500</td>\n",
       "      <td>0.852344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>1.132527</td>\n",
       "      <td>0.852500</td>\n",
       "      <td>0.852344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>1.135337</td>\n",
       "      <td>0.852500</td>\n",
       "      <td>0.852344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>1.135605</td>\n",
       "      <td>0.852500</td>\n",
       "      <td>0.852344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>1.137257</td>\n",
       "      <td>0.852500</td>\n",
       "      <td>0.852344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorrBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at otmangi/MorrBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 00:56, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.456100</td>\n",
       "      <td>0.386580</td>\n",
       "      <td>0.837500</td>\n",
       "      <td>0.830552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.210300</td>\n",
       "      <td>0.386699</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>0.869919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.111600</td>\n",
       "      <td>0.446450</td>\n",
       "      <td>0.862500</td>\n",
       "      <td>0.861180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.061300</td>\n",
       "      <td>0.536362</td>\n",
       "      <td>0.852500</td>\n",
       "      <td>0.851825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.026400</td>\n",
       "      <td>0.832581</td>\n",
       "      <td>0.842500</td>\n",
       "      <td>0.842475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.009700</td>\n",
       "      <td>0.936490</td>\n",
       "      <td>0.855000</td>\n",
       "      <td>0.854942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>1.076903</td>\n",
       "      <td>0.847500</td>\n",
       "      <td>0.847499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.007800</td>\n",
       "      <td>0.979117</td>\n",
       "      <td>0.847500</td>\n",
       "      <td>0.847285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.009700</td>\n",
       "      <td>0.994744</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.849865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>1.004411</td>\n",
       "      <td>0.855000</td>\n",
       "      <td>0.854706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.010600</td>\n",
       "      <td>1.086788</td>\n",
       "      <td>0.855000</td>\n",
       "      <td>0.854909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>1.073861</td>\n",
       "      <td>0.852500</td>\n",
       "      <td>0.852388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>1.069269</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.849906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.007300</td>\n",
       "      <td>1.015093</td>\n",
       "      <td>0.845000</td>\n",
       "      <td>0.844002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.005900</td>\n",
       "      <td>1.001757</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.849624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.004900</td>\n",
       "      <td>1.063215</td>\n",
       "      <td>0.857500</td>\n",
       "      <td>0.857428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>0.985324</td>\n",
       "      <td>0.857500</td>\n",
       "      <td>0.857178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>1.080585</td>\n",
       "      <td>0.855000</td>\n",
       "      <td>0.854967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.274011</td>\n",
       "      <td>0.827500</td>\n",
       "      <td>0.827413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>1.093839</td>\n",
       "      <td>0.845000</td>\n",
       "      <td>0.842923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.008600</td>\n",
       "      <td>1.060265</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.839212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.110586</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.849816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.006100</td>\n",
       "      <td>1.105483</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.849760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>1.116306</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.849816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>1.124446</td>\n",
       "      <td>0.852500</td>\n",
       "      <td>0.852344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>1.123522</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.849816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>1.131012</td>\n",
       "      <td>0.852500</td>\n",
       "      <td>0.852344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>1.132527</td>\n",
       "      <td>0.852500</td>\n",
       "      <td>0.852344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>1.135337</td>\n",
       "      <td>0.852500</td>\n",
       "      <td>0.852344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>1.135605</td>\n",
       "      <td>0.852500</td>\n",
       "      <td>0.852344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>1.137257</td>\n",
       "      <td>0.852500</td>\n",
       "      <td>0.852344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorrBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at otmangi/MorrBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 00:56, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.456100</td>\n",
       "      <td>0.386580</td>\n",
       "      <td>0.837500</td>\n",
       "      <td>0.830552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.210300</td>\n",
       "      <td>0.386699</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>0.869919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.111600</td>\n",
       "      <td>0.446450</td>\n",
       "      <td>0.862500</td>\n",
       "      <td>0.861180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.061300</td>\n",
       "      <td>0.536362</td>\n",
       "      <td>0.852500</td>\n",
       "      <td>0.851825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.026400</td>\n",
       "      <td>0.832581</td>\n",
       "      <td>0.842500</td>\n",
       "      <td>0.842475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.009700</td>\n",
       "      <td>0.936490</td>\n",
       "      <td>0.855000</td>\n",
       "      <td>0.854942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>1.076903</td>\n",
       "      <td>0.847500</td>\n",
       "      <td>0.847499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.007800</td>\n",
       "      <td>0.979117</td>\n",
       "      <td>0.847500</td>\n",
       "      <td>0.847285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.009700</td>\n",
       "      <td>0.994744</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.849865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>1.004411</td>\n",
       "      <td>0.855000</td>\n",
       "      <td>0.854706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.010600</td>\n",
       "      <td>1.086788</td>\n",
       "      <td>0.855000</td>\n",
       "      <td>0.854909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>1.073861</td>\n",
       "      <td>0.852500</td>\n",
       "      <td>0.852388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>1.069269</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.849906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.007300</td>\n",
       "      <td>1.015093</td>\n",
       "      <td>0.845000</td>\n",
       "      <td>0.844002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.005900</td>\n",
       "      <td>1.001757</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.849624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.004900</td>\n",
       "      <td>1.063215</td>\n",
       "      <td>0.857500</td>\n",
       "      <td>0.857428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>0.985324</td>\n",
       "      <td>0.857500</td>\n",
       "      <td>0.857178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>1.080585</td>\n",
       "      <td>0.855000</td>\n",
       "      <td>0.854967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.274011</td>\n",
       "      <td>0.827500</td>\n",
       "      <td>0.827413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>1.093839</td>\n",
       "      <td>0.845000</td>\n",
       "      <td>0.842923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.008600</td>\n",
       "      <td>1.060265</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.839212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.110586</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.849816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.006100</td>\n",
       "      <td>1.105483</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.849760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>1.116306</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.849816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>1.124446</td>\n",
       "      <td>0.852500</td>\n",
       "      <td>0.852344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>1.123522</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.849816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>1.131012</td>\n",
       "      <td>0.852500</td>\n",
       "      <td>0.852344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>1.132527</td>\n",
       "      <td>0.852500</td>\n",
       "      <td>0.852344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>1.135337</td>\n",
       "      <td>0.852500</td>\n",
       "      <td>0.852344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>1.135605</td>\n",
       "      <td>0.852500</td>\n",
       "      <td>0.852344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>1.137257</td>\n",
       "      <td>0.852500</td>\n",
       "      <td>0.852344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorrBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at otmangi/MorrBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 00:56, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.447600</td>\n",
       "      <td>0.282623</td>\n",
       "      <td>0.882500</td>\n",
       "      <td>0.881962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.217200</td>\n",
       "      <td>0.333315</td>\n",
       "      <td>0.885000</td>\n",
       "      <td>0.884163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.104900</td>\n",
       "      <td>0.369374</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.887189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.044800</td>\n",
       "      <td>0.458445</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.893829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.032600</td>\n",
       "      <td>0.468346</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.899508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.021400</td>\n",
       "      <td>0.526556</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.899997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.015600</td>\n",
       "      <td>0.520450</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.897499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.017100</td>\n",
       "      <td>0.551183</td>\n",
       "      <td>0.905000</td>\n",
       "      <td>0.904979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.010100</td>\n",
       "      <td>0.600113</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.006900</td>\n",
       "      <td>0.604532</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.899576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.007400</td>\n",
       "      <td>0.600984</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.899749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.633652</td>\n",
       "      <td>0.902500</td>\n",
       "      <td>0.902231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>0.761992</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.891671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.006900</td>\n",
       "      <td>0.692645</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>0.763278</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.891932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.007600</td>\n",
       "      <td>0.775870</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.889378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>0.765070</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.889533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>0.751086</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.892305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.010600</td>\n",
       "      <td>0.847870</td>\n",
       "      <td>0.885000</td>\n",
       "      <td>0.883953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>0.816788</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.891671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.006200</td>\n",
       "      <td>0.813287</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.889458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.819083</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.889458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>0.822310</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.889458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.006600</td>\n",
       "      <td>0.825857</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.889458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>0.828679</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.889458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.005200</td>\n",
       "      <td>0.826813</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.892008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.007600</td>\n",
       "      <td>0.828104</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.892008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>0.826602</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.826700</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.828270</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.005700</td>\n",
       "      <td>0.828661</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894554</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorrBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at otmangi/MorrBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 01:47, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.447600</td>\n",
       "      <td>0.282623</td>\n",
       "      <td>0.882500</td>\n",
       "      <td>0.881962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.217200</td>\n",
       "      <td>0.333315</td>\n",
       "      <td>0.885000</td>\n",
       "      <td>0.884163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.104900</td>\n",
       "      <td>0.369374</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.887189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.044800</td>\n",
       "      <td>0.458445</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.893829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.032600</td>\n",
       "      <td>0.468346</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.899508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.021400</td>\n",
       "      <td>0.526556</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.899997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.015600</td>\n",
       "      <td>0.520450</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.897499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.017100</td>\n",
       "      <td>0.551183</td>\n",
       "      <td>0.905000</td>\n",
       "      <td>0.904979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.010100</td>\n",
       "      <td>0.600113</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.006900</td>\n",
       "      <td>0.604532</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.899576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.007400</td>\n",
       "      <td>0.600984</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.899749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.633652</td>\n",
       "      <td>0.902500</td>\n",
       "      <td>0.902231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>0.761992</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.891671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.006900</td>\n",
       "      <td>0.692645</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>0.763278</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.891932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.007600</td>\n",
       "      <td>0.775870</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.889378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>0.765070</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.889533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>0.751086</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.892305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.010600</td>\n",
       "      <td>0.847870</td>\n",
       "      <td>0.885000</td>\n",
       "      <td>0.883953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>0.816788</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.891671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.006200</td>\n",
       "      <td>0.813287</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.889458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.819083</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.889458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>0.822310</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.889458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.006600</td>\n",
       "      <td>0.825857</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.889458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>0.828679</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.889458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.005200</td>\n",
       "      <td>0.826813</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.892008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.007600</td>\n",
       "      <td>0.828104</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.892008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>0.826602</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.826700</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.828270</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.005700</td>\n",
       "      <td>0.828661</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894554</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorrBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at otmangi/MorrBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 01:49, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.447600</td>\n",
       "      <td>0.282623</td>\n",
       "      <td>0.882500</td>\n",
       "      <td>0.881962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.217200</td>\n",
       "      <td>0.333315</td>\n",
       "      <td>0.885000</td>\n",
       "      <td>0.884163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.104900</td>\n",
       "      <td>0.369374</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.887189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.044800</td>\n",
       "      <td>0.458445</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.893829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.032600</td>\n",
       "      <td>0.468346</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.899508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.021400</td>\n",
       "      <td>0.526556</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.899997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.015600</td>\n",
       "      <td>0.520450</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.897499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.017100</td>\n",
       "      <td>0.551183</td>\n",
       "      <td>0.905000</td>\n",
       "      <td>0.904979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.010100</td>\n",
       "      <td>0.600113</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.006900</td>\n",
       "      <td>0.604532</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.899576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.007400</td>\n",
       "      <td>0.600984</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.899749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.633652</td>\n",
       "      <td>0.902500</td>\n",
       "      <td>0.902231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>0.761992</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.891671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.006900</td>\n",
       "      <td>0.692645</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>0.763278</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.891932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.007600</td>\n",
       "      <td>0.775870</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.889378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>0.765070</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.889533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>0.751086</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.892305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.010600</td>\n",
       "      <td>0.847870</td>\n",
       "      <td>0.885000</td>\n",
       "      <td>0.883953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>0.816788</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.891671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.006200</td>\n",
       "      <td>0.813287</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.889458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.819083</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.889458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>0.822310</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.889458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.006600</td>\n",
       "      <td>0.825857</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.889458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>0.828679</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.889458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.005200</td>\n",
       "      <td>0.826813</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.892008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.007600</td>\n",
       "      <td>0.828104</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.892008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>0.826602</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.826700</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.828270</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.005700</td>\n",
       "      <td>0.828661</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894554</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SI2M-Lab/DarijaBERT</td>\n",
       "      <td>0.9150</td>\n",
       "      <td>0.914864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alger-ia/dziribert</td>\n",
       "      <td>0.9175</td>\n",
       "      <td>0.917122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>faisalq/EgyBERT</td>\n",
       "      <td>0.9300</td>\n",
       "      <td>0.929788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>faisalq/SaudiBERT</td>\n",
       "      <td>0.9475</td>\n",
       "      <td>0.947426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>otmangi/MorRoBERTa</td>\n",
       "      <td>0.9075</td>\n",
       "      <td>0.907291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>otmangi/MorrBERT</td>\n",
       "      <td>0.9050</td>\n",
       "      <td>0.904979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>tunis-ai/TunBERT</td>\n",
       "      <td>0.7350</td>\n",
       "      <td>0.734196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model  Accuracy        F1\n",
       "0   SI2M-Lab/DarijaBERT    0.9150  0.914864\n",
       "3    alger-ia/dziribert    0.9175  0.917122\n",
       "6       faisalq/EgyBERT    0.9300  0.929788\n",
       "9     faisalq/SaudiBERT    0.9475  0.947426\n",
       "15   otmangi/MorRoBERTa    0.9075  0.907291\n",
       "18     otmangi/MorrBERT    0.9050  0.904979\n",
       "21     tunis-ai/TunBERT    0.7350  0.734196"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" \n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import pyarabic.araby as araby\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.initializers import TruncatedNormal\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from datasets import load_dataset, Dataset, concatenate_datasets\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', 1000)\n",
    "\n",
    "\n",
    "fname = 'MSAC_2'\n",
    "log_file = fname + '.txt'\n",
    "\n",
    "with open(log_file, 'w') as f:\n",
    "    f.write('Model,Accuracy,F1\\n')\n",
    "\n",
    "\n",
    "\n",
    "dataset = load_dataset('AbderrahmanSkiredj1/MSAC_darija_sentiment_analysis')\n",
    "df = pd.DataFrame(dataset['train']) \n",
    "\n",
    "      \n",
    "display(df.columns)\n",
    "display(len(df))\n",
    "display(df[:4])\n",
    "\n",
    "df['label'] = df['label'].replace(',ne', 'neg')\n",
    "\n",
    "\n",
    "classes = set(df['label'].values)\n",
    "display(classes)\n",
    "\n",
    "c = df['label'].value_counts()\n",
    "display(c)\n",
    "\n",
    "df['label'] = df['label'].astype('category')\n",
    "df['label'] = df['label'].cat.codes\n",
    "\n",
    "df = df[['text', 'label']]\n",
    "classes_num = len(classes)\n",
    "display(classes_num)\n",
    "display(len(df))\n",
    "\n",
    "\n",
    "# ds = Dataset.from_pandas(df)\n",
    "# ds = ds.train_test_split(test_size=0.2)\n",
    "\n",
    "# display(ds)\n",
    "\n",
    "max_sequence_length = 128\n",
    "\n",
    "\n",
    "models = [ \n",
    "        'faisalq/EgyBERT',            \n",
    "    'faisalq/SaudiBERT',            \n",
    "    'tunis-ai/TunBERT',\n",
    "    'alger-ia/dziribert',\n",
    "    'SI2M-Lab/DarijaBERT',\n",
    "    'otmangi/MorRoBERTa',\n",
    "    'otmangi/MorrBERT'\n",
    "            \n",
    "]\n",
    "\n",
    "seeds = [0, 1, 42]\n",
    "\n",
    "for model_name in models:\n",
    "    for seed in seeds:\n",
    "        ds = Dataset.from_pandas(df)\n",
    "        ds = ds.train_test_split(test_size=0.2, seed = seed)\n",
    "        if seed==0:\n",
    "            display(ds)\n",
    "    \n",
    "        for i in range(3):\n",
    "            print(f'{model_name}, try:{i}')\n",
    "                  \n",
    "            tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "            model = AutoModelForSequenceClassification.from_pretrained(model_name,\n",
    "                                                                  num_labels=classes_num).to('cuda')                                                 \n",
    "            dataset_train = ds['train']\n",
    "            dataset_validation = ds['test']                                                    \n",
    "            \n",
    "          \n",
    "    \n",
    "            def preprocess_function(examples):\n",
    "                return tokenizer(examples['text'], truncation=True, padding=\"max_length\",\n",
    "                                max_length=max_sequence_length)\n",
    "            \n",
    "            \n",
    "            dataset_train = dataset_train.map(preprocess_function, batched=True) # , batched=True\n",
    "            dataset_validation = dataset_validation.map(preprocess_function, batched=True)  # , batched=True\n",
    "            \n",
    "           \n",
    "            \n",
    "            def compute_metrics(eval_pred):\n",
    "                logits, labels = eval_pred\n",
    "                predictions = np.argmax(logits, axis=-1)    \n",
    "                acc = accuracy_score(labels, predictions)        \n",
    "                f1 = f1_score(labels, predictions, average='macro')   \n",
    "                with open(log_file, 'a') as f:\n",
    "                    f.write(f'{model_name},{acc},{f1}\\n')\n",
    "                return {'accuracy': acc, 'f1_score': f1}\n",
    "    \n",
    "    \n",
    "            \n",
    "            \n",
    "            epochs = 25\n",
    "            save_steps = 10000 #save checkpoint every 10000 steps\n",
    "            batch_size = 64\n",
    "            \n",
    "            training_args = TrainingArguments(\n",
    "                output_dir = 'bert/',\n",
    "                overwrite_output_dir=True,\n",
    "                num_train_epochs = epochs,\n",
    "                per_device_train_batch_size = batch_size,\n",
    "                per_device_eval_batch_size = batch_size,\n",
    "                save_steps = save_steps,\n",
    "                save_total_limit = 1, #only save the last 5 checkpoints\n",
    "                fp16=True,\n",
    "                learning_rate = 5e-5,  # 5e-5 is the default\n",
    "                logging_steps = 20, #50_000\n",
    "                evaluation_strategy = 'steps',\n",
    "                # evaluate_during_training = True,\n",
    "                eval_steps = 20\n",
    "                \n",
    "            )\n",
    "            \n",
    "            trainer = Trainer(\n",
    "                model = model,\n",
    "                args = training_args,\n",
    "                # data_collator=data_collator,\n",
    "                train_dataset=dataset_train,\n",
    "                eval_dataset=dataset_validation,\n",
    "                compute_metrics = compute_metrics\n",
    "            )\n",
    "            \n",
    "            \n",
    "            trainer.train()\n",
    "\n",
    "\n",
    "results = pd.read_csv(log_file)\n",
    "\n",
    "best_results = results.groupby('Model', as_index=False)['F1'].max()\n",
    "\n",
    "best_results = pd.merge(best_results, results, on=['Model', 'F1'])\n",
    "best_results = best_results[['Model', 'Accuracy', 'F1']]\n",
    "best_results = best_results.drop_duplicates()\n",
    "best_results.to_csv(f'{fname}.csv')\n",
    "display(best_results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a213ac86-934f-4e82-a949-0bcdcae2188d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8794b705-31a1-45d7-8e88-4017a9c282aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
