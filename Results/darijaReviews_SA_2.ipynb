{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d804ae66-9435-44be-8aad-beacbdeec0f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/home/ffq/.cache/huggingface/datasets/ohidaoui___parquet/ohidaoui--darija-reviews-34030453886e5230/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e14224af3e84588a95d6d4a44a96c69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "851"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['review', 'label', 'topic', 'writing_style'], dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>topic</th>\n",
       "      <th>writing_style</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>داسيا فقدت أهم ميزة كانت تميزها وهي السعر للأسف !</td>\n",
       "      <td>negative</td>\n",
       "      <td>automotive</td>\n",
       "      <td>Arabic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>لاأظنها ستنجح كالنسخ الأولى</td>\n",
       "      <td>negative</td>\n",
       "      <td>automotive</td>\n",
       "      <td>Arabic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Khas ykon tghyir mbanch li lfar9 rir fa dizayn lkrasa mikanik tablo fih dak lblstik lmryat 3lach mdyrinch lhm daw volm mzl kif mahwa jwant kifma howa fin kyn lfr9 fdizyn ama ljiti tchof mkynch fra9 fra9 howa y9riban 40% mli kt9ol l3mrya hdi bnsba li ana nas 3morya ama l3morya kolchi daw mzl khsha whd 10 ans wnchofo ana knfdl dacia l9dima</td>\n",
       "      <td>negative</td>\n",
       "      <td>automotive</td>\n",
       "      <td>Arabizi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>هناك اختيارات أحسن وماركات عالميه أجود من داصيا.</td>\n",
       "      <td>negative</td>\n",
       "      <td>automotive</td>\n",
       "      <td>Arabic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                review   \n",
       "0                                                                                                                                                                                                                                                                                                    داسيا فقدت أهم ميزة كانت تميزها وهي السعر للأسف !  \\\n",
       "1                                                                                                                                                                                                                                                                                                                          لاأظنها ستنجح كالنسخ الأولى   \n",
       "2  Khas ykon tghyir mbanch li lfar9 rir fa dizayn lkrasa mikanik tablo fih dak lblstik lmryat 3lach mdyrinch lhm daw volm mzl kif mahwa jwant kifma howa fin kyn lfr9 fdizyn ama ljiti tchof mkynch fra9 fra9 howa y9riban 40% mli kt9ol l3mrya hdi bnsba li ana nas 3morya ama l3morya kolchi daw mzl khsha whd 10 ans wnchofo ana knfdl dacia l9dima   \n",
       "3                                                                                                                                                                                                                                                                                                     هناك اختيارات أحسن وماركات عالميه أجود من داصيا.   \n",
       "\n",
       "      label       topic writing_style  \n",
       "0  negative  automotive        Arabic  \n",
       "1  negative  automotive        Arabic  \n",
       "2  negative  automotive       Arabizi  \n",
       "3  negative  automotive        Arabic  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "label\n",
       "positive    456\n",
       "negative    273\n",
       "neutral     122\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'negative', 'neutral', 'positive'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "851"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['review', 'label'],\n",
       "        num_rows: 680\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['review', 'label'],\n",
       "        num_rows: 171\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/EgyBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/EgyBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:38, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.086300</td>\n",
       "      <td>1.061175</td>\n",
       "      <td>0.549708</td>\n",
       "      <td>0.236478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.049500</td>\n",
       "      <td>1.018015</td>\n",
       "      <td>0.549708</td>\n",
       "      <td>0.236478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.022900</td>\n",
       "      <td>0.983613</td>\n",
       "      <td>0.549708</td>\n",
       "      <td>0.236478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.973200</td>\n",
       "      <td>0.942434</td>\n",
       "      <td>0.549708</td>\n",
       "      <td>0.236478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.933200</td>\n",
       "      <td>0.891527</td>\n",
       "      <td>0.549708</td>\n",
       "      <td>0.236478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.873400</td>\n",
       "      <td>0.836687</td>\n",
       "      <td>0.619883</td>\n",
       "      <td>0.362784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.804200</td>\n",
       "      <td>0.786484</td>\n",
       "      <td>0.690058</td>\n",
       "      <td>0.463187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.715800</td>\n",
       "      <td>0.739635</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.508961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.644200</td>\n",
       "      <td>0.705058</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.515048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.551700</td>\n",
       "      <td>0.669328</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.534219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.506500</td>\n",
       "      <td>0.701675</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.512535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.485400</td>\n",
       "      <td>0.719622</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.501367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.463000</td>\n",
       "      <td>0.679291</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.514334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.408500</td>\n",
       "      <td>0.673501</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.521526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.368300</td>\n",
       "      <td>0.708909</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.521250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.371300</td>\n",
       "      <td>0.687282</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.548692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.294500</td>\n",
       "      <td>0.667166</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.647518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.316200</td>\n",
       "      <td>0.649690</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.631377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.277300</td>\n",
       "      <td>0.700131</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.613916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.243000</td>\n",
       "      <td>0.679771</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.646256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.240900</td>\n",
       "      <td>0.673516</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.658211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.219200</td>\n",
       "      <td>0.693713</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.651730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.198900</td>\n",
       "      <td>0.679058</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.646368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.179500</td>\n",
       "      <td>0.699588</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.628667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.158000</td>\n",
       "      <td>0.717404</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.622219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.156200</td>\n",
       "      <td>0.713713</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.660627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.144500</td>\n",
       "      <td>0.709573</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.635367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.138600</td>\n",
       "      <td>0.719318</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.641344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.123900</td>\n",
       "      <td>0.718304</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.643825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.122000</td>\n",
       "      <td>0.730396</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.636239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.123200</td>\n",
       "      <td>0.733981</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.647976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.125500</td>\n",
       "      <td>0.736091</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.647976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.116800</td>\n",
       "      <td>0.740693</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.647976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/EgyBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/EgyBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:55, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.083900</td>\n",
       "      <td>1.060004</td>\n",
       "      <td>0.549708</td>\n",
       "      <td>0.236478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.049200</td>\n",
       "      <td>1.018689</td>\n",
       "      <td>0.549708</td>\n",
       "      <td>0.236478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.024000</td>\n",
       "      <td>0.981788</td>\n",
       "      <td>0.549708</td>\n",
       "      <td>0.236478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.975800</td>\n",
       "      <td>0.942220</td>\n",
       "      <td>0.549708</td>\n",
       "      <td>0.236478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.935700</td>\n",
       "      <td>0.895262</td>\n",
       "      <td>0.549708</td>\n",
       "      <td>0.236478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.869300</td>\n",
       "      <td>0.841421</td>\n",
       "      <td>0.549708</td>\n",
       "      <td>0.236478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.796400</td>\n",
       "      <td>0.805077</td>\n",
       "      <td>0.672515</td>\n",
       "      <td>0.455684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.712700</td>\n",
       "      <td>0.757254</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.566098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.622900</td>\n",
       "      <td>0.713323</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.606044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.542500</td>\n",
       "      <td>0.733059</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.552254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.483200</td>\n",
       "      <td>0.697227</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.563345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.438000</td>\n",
       "      <td>0.670277</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.609440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.394900</td>\n",
       "      <td>0.682895</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.582065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.367200</td>\n",
       "      <td>0.740226</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.602887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.339600</td>\n",
       "      <td>0.668277</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.649831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.332600</td>\n",
       "      <td>0.679898</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.646316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.277000</td>\n",
       "      <td>0.745187</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.634009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.286100</td>\n",
       "      <td>0.655368</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.645068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.236100</td>\n",
       "      <td>0.684198</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.670357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.211700</td>\n",
       "      <td>0.665568</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.664964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.214100</td>\n",
       "      <td>0.703174</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.675493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.211800</td>\n",
       "      <td>0.643890</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.665618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.188400</td>\n",
       "      <td>0.721319</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.671654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.714447</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.640392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.159500</td>\n",
       "      <td>0.717427</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.644292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.141800</td>\n",
       "      <td>0.708680</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.665477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.156100</td>\n",
       "      <td>0.742955</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.639529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.143700</td>\n",
       "      <td>0.722032</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.661254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.127400</td>\n",
       "      <td>0.720645</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.658985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.135900</td>\n",
       "      <td>0.725153</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.657191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.121800</td>\n",
       "      <td>0.737450</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.655560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.133800</td>\n",
       "      <td>0.733746</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.662484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.123500</td>\n",
       "      <td>0.733461</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.662484</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/EgyBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/EgyBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:56, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.083900</td>\n",
       "      <td>1.060004</td>\n",
       "      <td>0.549708</td>\n",
       "      <td>0.236478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.049200</td>\n",
       "      <td>1.018689</td>\n",
       "      <td>0.549708</td>\n",
       "      <td>0.236478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.024000</td>\n",
       "      <td>0.981788</td>\n",
       "      <td>0.549708</td>\n",
       "      <td>0.236478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.975800</td>\n",
       "      <td>0.942220</td>\n",
       "      <td>0.549708</td>\n",
       "      <td>0.236478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.935700</td>\n",
       "      <td>0.895262</td>\n",
       "      <td>0.549708</td>\n",
       "      <td>0.236478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.869300</td>\n",
       "      <td>0.841421</td>\n",
       "      <td>0.549708</td>\n",
       "      <td>0.236478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.796400</td>\n",
       "      <td>0.805077</td>\n",
       "      <td>0.672515</td>\n",
       "      <td>0.455684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.712700</td>\n",
       "      <td>0.757254</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.566098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.622900</td>\n",
       "      <td>0.713323</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.606044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.542500</td>\n",
       "      <td>0.733059</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.552254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.483200</td>\n",
       "      <td>0.697227</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.563345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.438000</td>\n",
       "      <td>0.670277</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.609440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.394900</td>\n",
       "      <td>0.682895</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.582065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.367200</td>\n",
       "      <td>0.740226</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.602887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.339600</td>\n",
       "      <td>0.668277</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.649831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.332600</td>\n",
       "      <td>0.679898</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.646316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.277000</td>\n",
       "      <td>0.745187</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.634009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.286100</td>\n",
       "      <td>0.655368</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.645068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.236100</td>\n",
       "      <td>0.684198</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.670357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.211700</td>\n",
       "      <td>0.665568</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.664964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.214100</td>\n",
       "      <td>0.703174</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.675493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.211800</td>\n",
       "      <td>0.643890</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.665618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.188400</td>\n",
       "      <td>0.721319</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.671654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.714447</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.640392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.159500</td>\n",
       "      <td>0.717427</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.644292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.141800</td>\n",
       "      <td>0.708680</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.665477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.156100</td>\n",
       "      <td>0.742955</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.639529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.143700</td>\n",
       "      <td>0.722032</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.661254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.127400</td>\n",
       "      <td>0.720645</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.658985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.135900</td>\n",
       "      <td>0.725153</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.657191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.121800</td>\n",
       "      <td>0.737450</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.655560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.133800</td>\n",
       "      <td>0.733746</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.662484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.123500</td>\n",
       "      <td>0.733461</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.662484</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/EgyBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/EgyBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:56, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.082900</td>\n",
       "      <td>1.061969</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.229885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.047800</td>\n",
       "      <td>1.023980</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.229885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.014200</td>\n",
       "      <td>0.992162</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.229885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.978300</td>\n",
       "      <td>0.959116</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.229885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.943800</td>\n",
       "      <td>0.919374</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.229885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.887600</td>\n",
       "      <td>0.854469</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.229885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.794300</td>\n",
       "      <td>0.819656</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.495282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.728800</td>\n",
       "      <td>0.776860</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.595314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.657400</td>\n",
       "      <td>0.815678</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.533542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.587600</td>\n",
       "      <td>0.713672</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.524862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.520100</td>\n",
       "      <td>0.704959</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.512863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.466600</td>\n",
       "      <td>0.699829</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.516624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.420800</td>\n",
       "      <td>0.752947</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.512597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.396500</td>\n",
       "      <td>0.660753</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.535450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.398300</td>\n",
       "      <td>0.666889</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.530230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.328300</td>\n",
       "      <td>0.673855</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.626420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.309700</td>\n",
       "      <td>0.654424</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.637593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.287600</td>\n",
       "      <td>0.653477</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.693996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.259200</td>\n",
       "      <td>0.640476</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.681122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.246400</td>\n",
       "      <td>0.651545</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.693625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.212300</td>\n",
       "      <td>0.704833</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.670027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.204200</td>\n",
       "      <td>0.685449</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.653608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.185500</td>\n",
       "      <td>0.716869</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.661545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.180400</td>\n",
       "      <td>0.731241</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.681120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.152000</td>\n",
       "      <td>0.738268</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.673935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.158800</td>\n",
       "      <td>0.752567</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.685413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.150800</td>\n",
       "      <td>0.760337</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.670919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.138900</td>\n",
       "      <td>0.764309</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.674073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.125300</td>\n",
       "      <td>0.766793</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.666895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.126600</td>\n",
       "      <td>0.767006</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.670919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.126000</td>\n",
       "      <td>0.768637</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.670919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.121100</td>\n",
       "      <td>0.773654</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.666895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.123700</td>\n",
       "      <td>0.775022</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.666895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/EgyBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/EgyBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:56, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.082900</td>\n",
       "      <td>1.061969</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.229885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.047800</td>\n",
       "      <td>1.023980</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.229885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.014200</td>\n",
       "      <td>0.992162</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.229885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.978300</td>\n",
       "      <td>0.959116</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.229885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.943800</td>\n",
       "      <td>0.919374</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.229885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.887600</td>\n",
       "      <td>0.854469</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.229885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.794300</td>\n",
       "      <td>0.819656</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.495282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.728800</td>\n",
       "      <td>0.776860</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.595314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.657400</td>\n",
       "      <td>0.815678</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.533542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.587600</td>\n",
       "      <td>0.713672</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.524862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.520100</td>\n",
       "      <td>0.704959</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.512863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.466600</td>\n",
       "      <td>0.699829</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.516624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.420800</td>\n",
       "      <td>0.752947</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.512597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.396500</td>\n",
       "      <td>0.660753</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.535450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.398300</td>\n",
       "      <td>0.666889</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.530230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.328300</td>\n",
       "      <td>0.673855</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.626420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.309700</td>\n",
       "      <td>0.654424</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.637593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.287600</td>\n",
       "      <td>0.653477</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.693996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.259200</td>\n",
       "      <td>0.640476</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.681122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.246400</td>\n",
       "      <td>0.651545</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.693625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.212300</td>\n",
       "      <td>0.704833</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.670027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.204200</td>\n",
       "      <td>0.685449</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.653608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.185500</td>\n",
       "      <td>0.716869</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.661545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.180400</td>\n",
       "      <td>0.731241</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.681120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.152000</td>\n",
       "      <td>0.738268</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.673935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.158800</td>\n",
       "      <td>0.752567</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.685413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.150800</td>\n",
       "      <td>0.760337</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.670919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.138900</td>\n",
       "      <td>0.764309</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.674073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.125300</td>\n",
       "      <td>0.766793</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.666895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.126600</td>\n",
       "      <td>0.767006</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.670919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.126000</td>\n",
       "      <td>0.768637</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.670919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.121100</td>\n",
       "      <td>0.773654</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.666895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.123700</td>\n",
       "      <td>0.775022</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.666895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/EgyBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/EgyBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:56, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.082900</td>\n",
       "      <td>1.061969</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.229885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.047800</td>\n",
       "      <td>1.023980</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.229885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.014200</td>\n",
       "      <td>0.992162</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.229885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.978300</td>\n",
       "      <td>0.959116</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.229885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.943800</td>\n",
       "      <td>0.919374</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.229885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.887600</td>\n",
       "      <td>0.854469</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.229885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.794300</td>\n",
       "      <td>0.819656</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.495282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.728800</td>\n",
       "      <td>0.776860</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.595314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.657400</td>\n",
       "      <td>0.815678</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.533542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.587600</td>\n",
       "      <td>0.713672</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.524862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.520100</td>\n",
       "      <td>0.704959</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.512863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.466600</td>\n",
       "      <td>0.699829</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.516624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.420800</td>\n",
       "      <td>0.752947</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.512597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.396500</td>\n",
       "      <td>0.660753</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.535450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.398300</td>\n",
       "      <td>0.666889</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.530230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.328300</td>\n",
       "      <td>0.673855</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.626420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.309700</td>\n",
       "      <td>0.654424</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.637593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.287600</td>\n",
       "      <td>0.653477</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.693996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.259200</td>\n",
       "      <td>0.640476</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.681122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.246400</td>\n",
       "      <td>0.651545</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.693625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.212300</td>\n",
       "      <td>0.704833</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.670027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.204200</td>\n",
       "      <td>0.685449</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.653608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.185500</td>\n",
       "      <td>0.716869</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.661545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.180400</td>\n",
       "      <td>0.731241</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.681120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.152000</td>\n",
       "      <td>0.738268</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.673935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.158800</td>\n",
       "      <td>0.752567</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.685413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.150800</td>\n",
       "      <td>0.760337</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.670919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.138900</td>\n",
       "      <td>0.764309</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.674073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.125300</td>\n",
       "      <td>0.766793</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.666895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.126600</td>\n",
       "      <td>0.767006</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.670919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.126000</td>\n",
       "      <td>0.768637</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.670919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.121100</td>\n",
       "      <td>0.773654</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.666895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.123700</td>\n",
       "      <td>0.775022</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.666895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/EgyBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/EgyBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:56, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.082700</td>\n",
       "      <td>1.064542</td>\n",
       "      <td>0.502924</td>\n",
       "      <td>0.223087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.048900</td>\n",
       "      <td>1.030953</td>\n",
       "      <td>0.502924</td>\n",
       "      <td>0.223087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.007100</td>\n",
       "      <td>1.000320</td>\n",
       "      <td>0.502924</td>\n",
       "      <td>0.223087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.968800</td>\n",
       "      <td>0.971300</td>\n",
       "      <td>0.502924</td>\n",
       "      <td>0.223087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.918700</td>\n",
       "      <td>0.923463</td>\n",
       "      <td>0.549708</td>\n",
       "      <td>0.325537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.846100</td>\n",
       "      <td>0.866802</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.483655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.755100</td>\n",
       "      <td>0.824547</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.488144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.668300</td>\n",
       "      <td>0.799418</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.484285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.602100</td>\n",
       "      <td>0.796208</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.482764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.550800</td>\n",
       "      <td>0.796175</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.490355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.492100</td>\n",
       "      <td>0.882488</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.465128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.480300</td>\n",
       "      <td>0.775132</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.494949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.419200</td>\n",
       "      <td>0.837428</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.491231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.427700</td>\n",
       "      <td>0.847407</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.495563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.371200</td>\n",
       "      <td>0.835507</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.480694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.383100</td>\n",
       "      <td>0.951040</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.479423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.356900</td>\n",
       "      <td>0.827221</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.499638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.341300</td>\n",
       "      <td>0.969801</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.480694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.332100</td>\n",
       "      <td>0.836133</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.499638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.311300</td>\n",
       "      <td>0.935885</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.489500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.306500</td>\n",
       "      <td>0.904609</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.571484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.282500</td>\n",
       "      <td>0.909655</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.601331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.272600</td>\n",
       "      <td>0.864134</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.600634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.233300</td>\n",
       "      <td>0.887377</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.652698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>0.887992</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.643647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.223000</td>\n",
       "      <td>0.867260</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.611509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.198800</td>\n",
       "      <td>0.873682</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.652308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.188500</td>\n",
       "      <td>0.863297</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.671375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.177400</td>\n",
       "      <td>0.868657</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.663603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.176400</td>\n",
       "      <td>0.846497</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.657969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.177900</td>\n",
       "      <td>0.856280</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.657969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.168100</td>\n",
       "      <td>0.859993</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.669175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.167600</td>\n",
       "      <td>0.866806</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.669175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/EgyBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/EgyBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:56, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.082700</td>\n",
       "      <td>1.064542</td>\n",
       "      <td>0.502924</td>\n",
       "      <td>0.223087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.048900</td>\n",
       "      <td>1.030953</td>\n",
       "      <td>0.502924</td>\n",
       "      <td>0.223087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.007100</td>\n",
       "      <td>1.000320</td>\n",
       "      <td>0.502924</td>\n",
       "      <td>0.223087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.968800</td>\n",
       "      <td>0.971300</td>\n",
       "      <td>0.502924</td>\n",
       "      <td>0.223087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.918700</td>\n",
       "      <td>0.923463</td>\n",
       "      <td>0.549708</td>\n",
       "      <td>0.325537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.846100</td>\n",
       "      <td>0.866802</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.483655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.755100</td>\n",
       "      <td>0.824547</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.488144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.668300</td>\n",
       "      <td>0.799418</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.484285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.602100</td>\n",
       "      <td>0.796208</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.482764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.550800</td>\n",
       "      <td>0.796175</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.490355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.492100</td>\n",
       "      <td>0.882488</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.465128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.480300</td>\n",
       "      <td>0.775132</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.494949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.419200</td>\n",
       "      <td>0.837428</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.491231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.427700</td>\n",
       "      <td>0.847407</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.495563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.371200</td>\n",
       "      <td>0.835507</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.480694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.383100</td>\n",
       "      <td>0.951040</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.479423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.356900</td>\n",
       "      <td>0.827221</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.499638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.341300</td>\n",
       "      <td>0.969801</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.480694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.332100</td>\n",
       "      <td>0.836133</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.499638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.311300</td>\n",
       "      <td>0.935885</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.489500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.306500</td>\n",
       "      <td>0.904609</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.571484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.282500</td>\n",
       "      <td>0.909655</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.601331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.272600</td>\n",
       "      <td>0.864134</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.600634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.233300</td>\n",
       "      <td>0.887377</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.652698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>0.887992</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.643647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.223000</td>\n",
       "      <td>0.867260</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.611509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.198800</td>\n",
       "      <td>0.873682</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.652308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.188500</td>\n",
       "      <td>0.863297</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.671375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.177400</td>\n",
       "      <td>0.868657</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.663603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.176400</td>\n",
       "      <td>0.846497</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.657969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.177900</td>\n",
       "      <td>0.856280</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.657969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.168100</td>\n",
       "      <td>0.859993</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.669175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.167600</td>\n",
       "      <td>0.866806</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.669175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/EgyBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/EgyBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05769609c4084181aa15290ca9f1041a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a09eb0a61a3b47b69fdbc9cec1be360e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:55, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.082700</td>\n",
       "      <td>1.064542</td>\n",
       "      <td>0.502924</td>\n",
       "      <td>0.223087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.048900</td>\n",
       "      <td>1.030953</td>\n",
       "      <td>0.502924</td>\n",
       "      <td>0.223087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.007100</td>\n",
       "      <td>1.000320</td>\n",
       "      <td>0.502924</td>\n",
       "      <td>0.223087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.968800</td>\n",
       "      <td>0.971300</td>\n",
       "      <td>0.502924</td>\n",
       "      <td>0.223087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.918700</td>\n",
       "      <td>0.923463</td>\n",
       "      <td>0.549708</td>\n",
       "      <td>0.325537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.846100</td>\n",
       "      <td>0.866802</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.483655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.755100</td>\n",
       "      <td>0.824547</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.488144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.668300</td>\n",
       "      <td>0.799418</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.484285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.602100</td>\n",
       "      <td>0.796208</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.482764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.550800</td>\n",
       "      <td>0.796175</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.490355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.492100</td>\n",
       "      <td>0.882488</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.465128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.480300</td>\n",
       "      <td>0.775132</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.494949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.419200</td>\n",
       "      <td>0.837428</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.491231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.427700</td>\n",
       "      <td>0.847407</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.495563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.371200</td>\n",
       "      <td>0.835507</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.480694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.383100</td>\n",
       "      <td>0.951040</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.479423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.356900</td>\n",
       "      <td>0.827221</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.499638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.341300</td>\n",
       "      <td>0.969801</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.480694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.332100</td>\n",
       "      <td>0.836133</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.499638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.311300</td>\n",
       "      <td>0.935885</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.489500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.306500</td>\n",
       "      <td>0.904609</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.571484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.282500</td>\n",
       "      <td>0.909655</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.601331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.272600</td>\n",
       "      <td>0.864134</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.600634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.233300</td>\n",
       "      <td>0.887377</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.652698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>0.887992</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.643647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.223000</td>\n",
       "      <td>0.867260</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.611509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.198800</td>\n",
       "      <td>0.873682</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.652308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.188500</td>\n",
       "      <td>0.863297</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.671375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.177400</td>\n",
       "      <td>0.868657</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.663603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.176400</td>\n",
       "      <td>0.846497</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.657969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.177900</td>\n",
       "      <td>0.856280</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.657969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.168100</td>\n",
       "      <td>0.859993</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.669175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.167600</td>\n",
       "      <td>0.866806</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.669175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['review', 'label'],\n",
       "        num_rows: 680\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['review', 'label'],\n",
       "        num_rows: 171\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24c6e3747d4a48bc8d14d041ea183c7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "704e34d5de434e1c948025d318266ab3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:54, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.930700</td>\n",
       "      <td>0.738917</td>\n",
       "      <td>0.660819</td>\n",
       "      <td>0.448640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.665200</td>\n",
       "      <td>0.576352</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.567377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.460700</td>\n",
       "      <td>0.550605</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.672391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.291300</td>\n",
       "      <td>0.594780</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.677774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.180100</td>\n",
       "      <td>0.761205</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.628363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.929222</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.649259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.084300</td>\n",
       "      <td>0.856290</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.639832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.043700</td>\n",
       "      <td>0.964261</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.639065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.009400</td>\n",
       "      <td>1.310681</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.651979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.035900</td>\n",
       "      <td>1.172758</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.681196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>1.286178</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.643816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.013300</td>\n",
       "      <td>1.246638</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.671903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>1.368842</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.670375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>1.265685</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.691062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>1.291858</td>\n",
       "      <td>0.783626</td>\n",
       "      <td>0.685310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>1.325960</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.669869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>1.403453</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.643597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>1.476449</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.643309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>1.467385</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.654275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.387660</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.664793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.417144</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.657974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.438307</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.657974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.450986</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.657974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.460657</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.657974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.468727</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.657974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.475628</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.657974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.481433</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.657974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.485929</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.657974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.489510</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.657974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.493455</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.657974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.496022</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.657974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>1.500969</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.651217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.502909</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.651217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfc1722cfc324201b0133ae1192f2b44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a2ec2098b444565982e088447708ca1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:54, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.930700</td>\n",
       "      <td>0.738917</td>\n",
       "      <td>0.660819</td>\n",
       "      <td>0.448640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.665200</td>\n",
       "      <td>0.576352</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.567377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.460700</td>\n",
       "      <td>0.550605</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.672391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.291300</td>\n",
       "      <td>0.594780</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.677774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.180100</td>\n",
       "      <td>0.761205</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.628363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.929222</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.649259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.084300</td>\n",
       "      <td>0.856290</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.639832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.043700</td>\n",
       "      <td>0.964261</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.639065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.009400</td>\n",
       "      <td>1.310681</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.651979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.035900</td>\n",
       "      <td>1.172758</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.681196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>1.286178</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.643816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.013300</td>\n",
       "      <td>1.246638</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.671903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>1.368842</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.670375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>1.265685</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.691062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>1.291858</td>\n",
       "      <td>0.783626</td>\n",
       "      <td>0.685310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>1.325960</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.669869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>1.403453</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.643597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>1.476449</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.643309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>1.467385</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.654275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.387660</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.664793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.417144</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.657974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.438307</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.657974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.450986</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.657974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.460657</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.657974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.468727</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.657974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.475628</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.657974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.481433</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.657974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.485929</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.657974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.489510</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.657974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.493455</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.657974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.496022</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.657974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>1.500969</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.651217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.502909</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.651217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "179f81ac324a48abadf2a4f01009549a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6163c5cacfde440bbf430eb2b4497b7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:54, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.930700</td>\n",
       "      <td>0.738917</td>\n",
       "      <td>0.660819</td>\n",
       "      <td>0.448640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.665200</td>\n",
       "      <td>0.576352</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.567377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.460700</td>\n",
       "      <td>0.550605</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.672391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.291300</td>\n",
       "      <td>0.594780</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.677774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.180100</td>\n",
       "      <td>0.761205</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.628363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.929222</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.649259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.084300</td>\n",
       "      <td>0.856290</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.639832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.043700</td>\n",
       "      <td>0.964261</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.639065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.009400</td>\n",
       "      <td>1.310681</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.651979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.035900</td>\n",
       "      <td>1.172758</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.681196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>1.286178</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.643816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.013300</td>\n",
       "      <td>1.246638</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.671903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>1.368842</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.670375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>1.265685</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.691062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>1.291858</td>\n",
       "      <td>0.783626</td>\n",
       "      <td>0.685310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>1.325960</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.669869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>1.403453</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.643597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>1.476449</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.643309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>1.467385</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.654275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.387660</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.664793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.417144</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.657974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.438307</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.657974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.450986</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.657974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.460657</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.657974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.468727</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.657974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.475628</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.657974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.481433</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.657974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.485929</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.657974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.489510</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.657974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.493455</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.657974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.496022</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.657974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>1.500969</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.651217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.502909</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.651217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "969e6be2077540ef94aeedfedd02e53d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f30efd3d8e34c5a8bd4b653a6f8d096",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:54, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.903800</td>\n",
       "      <td>0.683332</td>\n",
       "      <td>0.690058</td>\n",
       "      <td>0.473939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.585500</td>\n",
       "      <td>0.597106</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.630041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.349800</td>\n",
       "      <td>0.606022</td>\n",
       "      <td>0.783626</td>\n",
       "      <td>0.653465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.243000</td>\n",
       "      <td>0.616928</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.662947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.176100</td>\n",
       "      <td>0.820560</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.699440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.101600</td>\n",
       "      <td>0.691121</td>\n",
       "      <td>0.795322</td>\n",
       "      <td>0.711636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.076000</td>\n",
       "      <td>0.773662</td>\n",
       "      <td>0.783626</td>\n",
       "      <td>0.718335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.014200</td>\n",
       "      <td>0.894750</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.691300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.019600</td>\n",
       "      <td>1.029151</td>\n",
       "      <td>0.795322</td>\n",
       "      <td>0.704484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>1.089019</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.678863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.007400</td>\n",
       "      <td>1.102167</td>\n",
       "      <td>0.801170</td>\n",
       "      <td>0.709263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>1.039286</td>\n",
       "      <td>0.824561</td>\n",
       "      <td>0.752299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>1.135609</td>\n",
       "      <td>0.795322</td>\n",
       "      <td>0.723535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>1.282049</td>\n",
       "      <td>0.783626</td>\n",
       "      <td>0.716178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>1.212520</td>\n",
       "      <td>0.807018</td>\n",
       "      <td>0.729738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.007300</td>\n",
       "      <td>1.270236</td>\n",
       "      <td>0.818713</td>\n",
       "      <td>0.751945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.328835</td>\n",
       "      <td>0.801170</td>\n",
       "      <td>0.701195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.350881</td>\n",
       "      <td>0.801170</td>\n",
       "      <td>0.701195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>1.380926</td>\n",
       "      <td>0.801170</td>\n",
       "      <td>0.719743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.433386</td>\n",
       "      <td>0.795322</td>\n",
       "      <td>0.713720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.007200</td>\n",
       "      <td>1.361741</td>\n",
       "      <td>0.801170</td>\n",
       "      <td>0.724036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>1.364303</td>\n",
       "      <td>0.801170</td>\n",
       "      <td>0.730170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.386969</td>\n",
       "      <td>0.807018</td>\n",
       "      <td>0.725988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.395152</td>\n",
       "      <td>0.801170</td>\n",
       "      <td>0.721785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.391892</td>\n",
       "      <td>0.801170</td>\n",
       "      <td>0.721785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>1.377979</td>\n",
       "      <td>0.801170</td>\n",
       "      <td>0.720279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.422408</td>\n",
       "      <td>0.795322</td>\n",
       "      <td>0.696414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.443293</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.688800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.405194</td>\n",
       "      <td>0.795322</td>\n",
       "      <td>0.712247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.395993</td>\n",
       "      <td>0.783626</td>\n",
       "      <td>0.706108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.404453</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.701427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.406234</td>\n",
       "      <td>0.783626</td>\n",
       "      <td>0.714315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.406955</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.701427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e7439de590d40f8ae4c4c7fc4d03f9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b222adabac314475ae1264c985022761",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:54, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.903800</td>\n",
       "      <td>0.683332</td>\n",
       "      <td>0.690058</td>\n",
       "      <td>0.473939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.585500</td>\n",
       "      <td>0.597106</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.630041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.349800</td>\n",
       "      <td>0.606022</td>\n",
       "      <td>0.783626</td>\n",
       "      <td>0.653465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.243000</td>\n",
       "      <td>0.616928</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.662947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.176100</td>\n",
       "      <td>0.820560</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.699440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.101600</td>\n",
       "      <td>0.691121</td>\n",
       "      <td>0.795322</td>\n",
       "      <td>0.711636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.076000</td>\n",
       "      <td>0.773662</td>\n",
       "      <td>0.783626</td>\n",
       "      <td>0.718335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.014200</td>\n",
       "      <td>0.894750</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.691300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.019600</td>\n",
       "      <td>1.029151</td>\n",
       "      <td>0.795322</td>\n",
       "      <td>0.704484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>1.089019</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.678863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.007400</td>\n",
       "      <td>1.102167</td>\n",
       "      <td>0.801170</td>\n",
       "      <td>0.709263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>1.039286</td>\n",
       "      <td>0.824561</td>\n",
       "      <td>0.752299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>1.135609</td>\n",
       "      <td>0.795322</td>\n",
       "      <td>0.723535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>1.282049</td>\n",
       "      <td>0.783626</td>\n",
       "      <td>0.716178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>1.212520</td>\n",
       "      <td>0.807018</td>\n",
       "      <td>0.729738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.007300</td>\n",
       "      <td>1.270236</td>\n",
       "      <td>0.818713</td>\n",
       "      <td>0.751945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.328835</td>\n",
       "      <td>0.801170</td>\n",
       "      <td>0.701195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.350881</td>\n",
       "      <td>0.801170</td>\n",
       "      <td>0.701195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>1.380926</td>\n",
       "      <td>0.801170</td>\n",
       "      <td>0.719743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.433386</td>\n",
       "      <td>0.795322</td>\n",
       "      <td>0.713720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.007200</td>\n",
       "      <td>1.361741</td>\n",
       "      <td>0.801170</td>\n",
       "      <td>0.724036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>1.364303</td>\n",
       "      <td>0.801170</td>\n",
       "      <td>0.730170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.386969</td>\n",
       "      <td>0.807018</td>\n",
       "      <td>0.725988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.395152</td>\n",
       "      <td>0.801170</td>\n",
       "      <td>0.721785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.391892</td>\n",
       "      <td>0.801170</td>\n",
       "      <td>0.721785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>1.377979</td>\n",
       "      <td>0.801170</td>\n",
       "      <td>0.720279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.422408</td>\n",
       "      <td>0.795322</td>\n",
       "      <td>0.696414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.443293</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.688800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.405194</td>\n",
       "      <td>0.795322</td>\n",
       "      <td>0.712247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.395993</td>\n",
       "      <td>0.783626</td>\n",
       "      <td>0.706108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.404453</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.701427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.406234</td>\n",
       "      <td>0.783626</td>\n",
       "      <td>0.714315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.406955</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.701427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32f6de19812347708014047cf0e5cfec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeb070ec9b904abdb5cb843e34a182fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:54, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.903800</td>\n",
       "      <td>0.683332</td>\n",
       "      <td>0.690058</td>\n",
       "      <td>0.473939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.585500</td>\n",
       "      <td>0.597106</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.630041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.349800</td>\n",
       "      <td>0.606022</td>\n",
       "      <td>0.783626</td>\n",
       "      <td>0.653465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.243000</td>\n",
       "      <td>0.616928</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.662947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.176100</td>\n",
       "      <td>0.820560</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.699440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.101600</td>\n",
       "      <td>0.691121</td>\n",
       "      <td>0.795322</td>\n",
       "      <td>0.711636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.076000</td>\n",
       "      <td>0.773662</td>\n",
       "      <td>0.783626</td>\n",
       "      <td>0.718335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.014200</td>\n",
       "      <td>0.894750</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.691300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.019600</td>\n",
       "      <td>1.029151</td>\n",
       "      <td>0.795322</td>\n",
       "      <td>0.704484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>1.089019</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.678863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.007400</td>\n",
       "      <td>1.102167</td>\n",
       "      <td>0.801170</td>\n",
       "      <td>0.709263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>1.039286</td>\n",
       "      <td>0.824561</td>\n",
       "      <td>0.752299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>1.135609</td>\n",
       "      <td>0.795322</td>\n",
       "      <td>0.723535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>1.282049</td>\n",
       "      <td>0.783626</td>\n",
       "      <td>0.716178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>1.212520</td>\n",
       "      <td>0.807018</td>\n",
       "      <td>0.729738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.007300</td>\n",
       "      <td>1.270236</td>\n",
       "      <td>0.818713</td>\n",
       "      <td>0.751945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.328835</td>\n",
       "      <td>0.801170</td>\n",
       "      <td>0.701195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.350881</td>\n",
       "      <td>0.801170</td>\n",
       "      <td>0.701195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>1.380926</td>\n",
       "      <td>0.801170</td>\n",
       "      <td>0.719743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.433386</td>\n",
       "      <td>0.795322</td>\n",
       "      <td>0.713720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.007200</td>\n",
       "      <td>1.361741</td>\n",
       "      <td>0.801170</td>\n",
       "      <td>0.724036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>1.364303</td>\n",
       "      <td>0.801170</td>\n",
       "      <td>0.730170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.386969</td>\n",
       "      <td>0.807018</td>\n",
       "      <td>0.725988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.395152</td>\n",
       "      <td>0.801170</td>\n",
       "      <td>0.721785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.391892</td>\n",
       "      <td>0.801170</td>\n",
       "      <td>0.721785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>1.377979</td>\n",
       "      <td>0.801170</td>\n",
       "      <td>0.720279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.422408</td>\n",
       "      <td>0.795322</td>\n",
       "      <td>0.696414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.443293</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.688800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.405194</td>\n",
       "      <td>0.795322</td>\n",
       "      <td>0.712247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.395993</td>\n",
       "      <td>0.783626</td>\n",
       "      <td>0.706108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.404453</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.701427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.406234</td>\n",
       "      <td>0.783626</td>\n",
       "      <td>0.714315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.406955</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.701427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "429e3acb1a834942a0fb97c65cf3d6de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77462883c25f487cb8c5b3b0632a2bb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:53, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.912700</td>\n",
       "      <td>0.795531</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>0.447115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.660900</td>\n",
       "      <td>0.602636</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.637984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.391700</td>\n",
       "      <td>0.579485</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.672766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.251600</td>\n",
       "      <td>0.665673</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.710119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.123000</td>\n",
       "      <td>0.974034</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.672331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.098700</td>\n",
       "      <td>0.884375</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.643262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.054400</td>\n",
       "      <td>1.225827</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.616235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.040300</td>\n",
       "      <td>1.136976</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.652168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.014300</td>\n",
       "      <td>1.165173</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.696989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.027900</td>\n",
       "      <td>1.434041</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.653632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.021900</td>\n",
       "      <td>1.204250</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.678328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.013800</td>\n",
       "      <td>1.280959</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.681217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>1.375260</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.668897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>1.518480</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.675650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.484113</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.698249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.005900</td>\n",
       "      <td>1.496401</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.708155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>1.520757</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.701754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>1.509609</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.703046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>1.537267</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.709930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.562958</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.693015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.573905</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.699429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.581029</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.698718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.587894</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.698718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.591592</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.698718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.596198</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.698718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.601058</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.698718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.605639</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.694381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.609261</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.694381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.612729</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.694381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.615456</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.694381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.617258</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.694381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.618843</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.694381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.618928</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.694381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d1c0ebd71b44cd08cd84eee70362767",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57d31347d8f047129be8154332dac1c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:54, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.912700</td>\n",
       "      <td>0.795531</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>0.447115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.660900</td>\n",
       "      <td>0.602636</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.637984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.391700</td>\n",
       "      <td>0.579485</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.672766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.251600</td>\n",
       "      <td>0.665673</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.710119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.123000</td>\n",
       "      <td>0.974034</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.672331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.098700</td>\n",
       "      <td>0.884375</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.643262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.054400</td>\n",
       "      <td>1.225827</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.616235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.040300</td>\n",
       "      <td>1.136976</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.652168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.014300</td>\n",
       "      <td>1.165173</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.696989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.027900</td>\n",
       "      <td>1.434041</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.653632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.021900</td>\n",
       "      <td>1.204250</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.678328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.013800</td>\n",
       "      <td>1.280959</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.681217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>1.375260</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.668897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>1.518480</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.675650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.484113</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.698249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.005900</td>\n",
       "      <td>1.496401</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.708155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>1.520757</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.701754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>1.509609</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.703046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>1.537267</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.709930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.562958</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.693015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.573905</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.699429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.581029</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.698718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.587894</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.698718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.591592</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.698718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.596198</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.698718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.601058</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.698718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.605639</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.694381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.609261</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.694381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.612729</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.694381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.615456</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.694381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.617258</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.694381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.618843</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.694381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.618928</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.694381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8260c9bda0df431082a879b129eb4ad9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "864b1e599f55494e9e31fccbce0c6747",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:54, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.912700</td>\n",
       "      <td>0.795531</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>0.447115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.660900</td>\n",
       "      <td>0.602636</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.637984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.391700</td>\n",
       "      <td>0.579485</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.672766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.251600</td>\n",
       "      <td>0.665673</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.710119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.123000</td>\n",
       "      <td>0.974034</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.672331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.098700</td>\n",
       "      <td>0.884375</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.643262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.054400</td>\n",
       "      <td>1.225827</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.616235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.040300</td>\n",
       "      <td>1.136976</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.652168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.014300</td>\n",
       "      <td>1.165173</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.696989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.027900</td>\n",
       "      <td>1.434041</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.653632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.021900</td>\n",
       "      <td>1.204250</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.678328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.013800</td>\n",
       "      <td>1.280959</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.681217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>1.375260</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.668897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>1.518480</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.675650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.484113</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.698249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.005900</td>\n",
       "      <td>1.496401</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.708155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>1.520757</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.701754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>1.509609</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.703046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>1.537267</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.709930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.562958</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.693015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.573905</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.699429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.581029</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.698718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.587894</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.698718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.591592</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.698718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.596198</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.698718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.601058</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.698718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.605639</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.694381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.609261</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.694381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.612729</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.694381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.615456</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.694381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.617258</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.694381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.618843</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.694381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.618928</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.694381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['review', 'label'],\n",
       "        num_rows: 680\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['review', 'label'],\n",
       "        num_rows: 171\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunis-ai/TunBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tunis-ai/TunBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72b2aee579ed4463a2d1f1792fa47566",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56aa82e56c0248e687ab925bb38e49da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:52, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.103800</td>\n",
       "      <td>0.955955</td>\n",
       "      <td>0.549708</td>\n",
       "      <td>0.236478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.007200</td>\n",
       "      <td>0.983952</td>\n",
       "      <td>0.549708</td>\n",
       "      <td>0.236478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.047700</td>\n",
       "      <td>0.962625</td>\n",
       "      <td>0.549708</td>\n",
       "      <td>0.236478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.985500</td>\n",
       "      <td>0.954538</td>\n",
       "      <td>0.549708</td>\n",
       "      <td>0.236478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.977300</td>\n",
       "      <td>0.907543</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.359120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.978100</td>\n",
       "      <td>0.902185</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.249070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.920100</td>\n",
       "      <td>0.835734</td>\n",
       "      <td>0.625731</td>\n",
       "      <td>0.436129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.864500</td>\n",
       "      <td>0.808866</td>\n",
       "      <td>0.637427</td>\n",
       "      <td>0.433970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.863800</td>\n",
       "      <td>0.791539</td>\n",
       "      <td>0.672515</td>\n",
       "      <td>0.463168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.791400</td>\n",
       "      <td>0.823541</td>\n",
       "      <td>0.654971</td>\n",
       "      <td>0.456836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.790400</td>\n",
       "      <td>0.859324</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>0.413925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.747700</td>\n",
       "      <td>0.790111</td>\n",
       "      <td>0.690058</td>\n",
       "      <td>0.468946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.709500</td>\n",
       "      <td>0.860401</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>0.453053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.791200</td>\n",
       "      <td>0.787909</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.468911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.802300</td>\n",
       "      <td>0.864176</td>\n",
       "      <td>0.643275</td>\n",
       "      <td>0.404495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.670900</td>\n",
       "      <td>0.896829</td>\n",
       "      <td>0.654971</td>\n",
       "      <td>0.457827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.596000</td>\n",
       "      <td>0.955303</td>\n",
       "      <td>0.654971</td>\n",
       "      <td>0.525369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.574900</td>\n",
       "      <td>1.169029</td>\n",
       "      <td>0.596491</td>\n",
       "      <td>0.434700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.666200</td>\n",
       "      <td>0.953796</td>\n",
       "      <td>0.637427</td>\n",
       "      <td>0.521387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.498500</td>\n",
       "      <td>0.896266</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.487046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.499400</td>\n",
       "      <td>1.017110</td>\n",
       "      <td>0.672515</td>\n",
       "      <td>0.517907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.515000</td>\n",
       "      <td>1.123605</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.552825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.457700</td>\n",
       "      <td>0.945975</td>\n",
       "      <td>0.637427</td>\n",
       "      <td>0.453417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.445400</td>\n",
       "      <td>1.136552</td>\n",
       "      <td>0.619883</td>\n",
       "      <td>0.542728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.452500</td>\n",
       "      <td>1.001273</td>\n",
       "      <td>0.637427</td>\n",
       "      <td>0.474946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.379100</td>\n",
       "      <td>1.063471</td>\n",
       "      <td>0.672515</td>\n",
       "      <td>0.567890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.376900</td>\n",
       "      <td>1.104041</td>\n",
       "      <td>0.637427</td>\n",
       "      <td>0.503747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.347800</td>\n",
       "      <td>1.207799</td>\n",
       "      <td>0.637427</td>\n",
       "      <td>0.551467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.328100</td>\n",
       "      <td>1.283649</td>\n",
       "      <td>0.608187</td>\n",
       "      <td>0.518316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.315900</td>\n",
       "      <td>1.223729</td>\n",
       "      <td>0.619883</td>\n",
       "      <td>0.529312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.287200</td>\n",
       "      <td>1.204067</td>\n",
       "      <td>0.654971</td>\n",
       "      <td>0.568556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.286700</td>\n",
       "      <td>1.237219</td>\n",
       "      <td>0.619883</td>\n",
       "      <td>0.526315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.281600</td>\n",
       "      <td>1.246055</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.541671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunis-ai/TunBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tunis-ai/TunBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c566c577daf412ead1965cb68fc6bc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "218f258adb38460eb2ebbbb081438c75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:52, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.103800</td>\n",
       "      <td>0.955955</td>\n",
       "      <td>0.549708</td>\n",
       "      <td>0.236478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.007200</td>\n",
       "      <td>0.983952</td>\n",
       "      <td>0.549708</td>\n",
       "      <td>0.236478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.047700</td>\n",
       "      <td>0.962625</td>\n",
       "      <td>0.549708</td>\n",
       "      <td>0.236478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.985500</td>\n",
       "      <td>0.954538</td>\n",
       "      <td>0.549708</td>\n",
       "      <td>0.236478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.977300</td>\n",
       "      <td>0.907543</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.359120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.978100</td>\n",
       "      <td>0.902185</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.249070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.920100</td>\n",
       "      <td>0.835734</td>\n",
       "      <td>0.625731</td>\n",
       "      <td>0.436129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.864500</td>\n",
       "      <td>0.808866</td>\n",
       "      <td>0.637427</td>\n",
       "      <td>0.433970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.863800</td>\n",
       "      <td>0.791539</td>\n",
       "      <td>0.672515</td>\n",
       "      <td>0.463168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.791400</td>\n",
       "      <td>0.823541</td>\n",
       "      <td>0.654971</td>\n",
       "      <td>0.456836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.790400</td>\n",
       "      <td>0.859324</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>0.413925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.747700</td>\n",
       "      <td>0.790111</td>\n",
       "      <td>0.690058</td>\n",
       "      <td>0.468946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.709500</td>\n",
       "      <td>0.860401</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>0.453053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.791200</td>\n",
       "      <td>0.787909</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.468911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.802300</td>\n",
       "      <td>0.864176</td>\n",
       "      <td>0.643275</td>\n",
       "      <td>0.404495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.670900</td>\n",
       "      <td>0.896829</td>\n",
       "      <td>0.654971</td>\n",
       "      <td>0.457827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.596000</td>\n",
       "      <td>0.955303</td>\n",
       "      <td>0.654971</td>\n",
       "      <td>0.525369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.574900</td>\n",
       "      <td>1.169029</td>\n",
       "      <td>0.596491</td>\n",
       "      <td>0.434700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.666200</td>\n",
       "      <td>0.953796</td>\n",
       "      <td>0.637427</td>\n",
       "      <td>0.521387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.498500</td>\n",
       "      <td>0.896266</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.487046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.499400</td>\n",
       "      <td>1.017110</td>\n",
       "      <td>0.672515</td>\n",
       "      <td>0.517907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.515000</td>\n",
       "      <td>1.123605</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.552825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.457700</td>\n",
       "      <td>0.945975</td>\n",
       "      <td>0.637427</td>\n",
       "      <td>0.453417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.445400</td>\n",
       "      <td>1.136552</td>\n",
       "      <td>0.619883</td>\n",
       "      <td>0.542728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.452500</td>\n",
       "      <td>1.001273</td>\n",
       "      <td>0.637427</td>\n",
       "      <td>0.474946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.379100</td>\n",
       "      <td>1.063471</td>\n",
       "      <td>0.672515</td>\n",
       "      <td>0.567890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.376900</td>\n",
       "      <td>1.104041</td>\n",
       "      <td>0.637427</td>\n",
       "      <td>0.503747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.347800</td>\n",
       "      <td>1.207799</td>\n",
       "      <td>0.637427</td>\n",
       "      <td>0.551467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.328100</td>\n",
       "      <td>1.283649</td>\n",
       "      <td>0.608187</td>\n",
       "      <td>0.518316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.315900</td>\n",
       "      <td>1.223729</td>\n",
       "      <td>0.619883</td>\n",
       "      <td>0.529312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.287200</td>\n",
       "      <td>1.204067</td>\n",
       "      <td>0.654971</td>\n",
       "      <td>0.568556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.286700</td>\n",
       "      <td>1.237219</td>\n",
       "      <td>0.619883</td>\n",
       "      <td>0.526315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.281600</td>\n",
       "      <td>1.246055</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.541671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunis-ai/TunBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tunis-ai/TunBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1746b4389042497b8d1bb9c39d684c45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae0400775ee14453b2116599e057a22a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:52, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.103800</td>\n",
       "      <td>0.955955</td>\n",
       "      <td>0.549708</td>\n",
       "      <td>0.236478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.007200</td>\n",
       "      <td>0.983952</td>\n",
       "      <td>0.549708</td>\n",
       "      <td>0.236478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.047700</td>\n",
       "      <td>0.962625</td>\n",
       "      <td>0.549708</td>\n",
       "      <td>0.236478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.985500</td>\n",
       "      <td>0.954538</td>\n",
       "      <td>0.549708</td>\n",
       "      <td>0.236478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.977300</td>\n",
       "      <td>0.907543</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.359120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.978100</td>\n",
       "      <td>0.902185</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.249070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.920100</td>\n",
       "      <td>0.835734</td>\n",
       "      <td>0.625731</td>\n",
       "      <td>0.436129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.864500</td>\n",
       "      <td>0.808866</td>\n",
       "      <td>0.637427</td>\n",
       "      <td>0.433970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.863800</td>\n",
       "      <td>0.791539</td>\n",
       "      <td>0.672515</td>\n",
       "      <td>0.463168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.791400</td>\n",
       "      <td>0.823541</td>\n",
       "      <td>0.654971</td>\n",
       "      <td>0.456836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.790400</td>\n",
       "      <td>0.859324</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>0.413925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.747700</td>\n",
       "      <td>0.790111</td>\n",
       "      <td>0.690058</td>\n",
       "      <td>0.468946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.709500</td>\n",
       "      <td>0.860401</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>0.453053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.791200</td>\n",
       "      <td>0.787909</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.468911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.802300</td>\n",
       "      <td>0.864176</td>\n",
       "      <td>0.643275</td>\n",
       "      <td>0.404495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.670900</td>\n",
       "      <td>0.896829</td>\n",
       "      <td>0.654971</td>\n",
       "      <td>0.457827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.596000</td>\n",
       "      <td>0.955303</td>\n",
       "      <td>0.654971</td>\n",
       "      <td>0.525369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.574900</td>\n",
       "      <td>1.169029</td>\n",
       "      <td>0.596491</td>\n",
       "      <td>0.434700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.666200</td>\n",
       "      <td>0.953796</td>\n",
       "      <td>0.637427</td>\n",
       "      <td>0.521387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.498500</td>\n",
       "      <td>0.896266</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.487046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.499400</td>\n",
       "      <td>1.017110</td>\n",
       "      <td>0.672515</td>\n",
       "      <td>0.517907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.515000</td>\n",
       "      <td>1.123605</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.552825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.457700</td>\n",
       "      <td>0.945975</td>\n",
       "      <td>0.637427</td>\n",
       "      <td>0.453417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.445400</td>\n",
       "      <td>1.136552</td>\n",
       "      <td>0.619883</td>\n",
       "      <td>0.542728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.452500</td>\n",
       "      <td>1.001273</td>\n",
       "      <td>0.637427</td>\n",
       "      <td>0.474946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.379100</td>\n",
       "      <td>1.063471</td>\n",
       "      <td>0.672515</td>\n",
       "      <td>0.567890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.376900</td>\n",
       "      <td>1.104041</td>\n",
       "      <td>0.637427</td>\n",
       "      <td>0.503747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.347800</td>\n",
       "      <td>1.207799</td>\n",
       "      <td>0.637427</td>\n",
       "      <td>0.551467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.328100</td>\n",
       "      <td>1.283649</td>\n",
       "      <td>0.608187</td>\n",
       "      <td>0.518316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.315900</td>\n",
       "      <td>1.223729</td>\n",
       "      <td>0.619883</td>\n",
       "      <td>0.529312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.287200</td>\n",
       "      <td>1.204067</td>\n",
       "      <td>0.654971</td>\n",
       "      <td>0.568556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.286700</td>\n",
       "      <td>1.237219</td>\n",
       "      <td>0.619883</td>\n",
       "      <td>0.526315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.281600</td>\n",
       "      <td>1.246055</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.541671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunis-ai/TunBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tunis-ai/TunBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "befa3b9cc28d493d90c0bf273e452b57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9aec667291a449efa51c928290127183",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:52, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.133300</td>\n",
       "      <td>0.977088</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.229885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.001300</td>\n",
       "      <td>0.967748</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.229885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.986000</td>\n",
       "      <td>0.963733</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.229885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.991700</td>\n",
       "      <td>0.955471</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.229885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.975800</td>\n",
       "      <td>0.915757</td>\n",
       "      <td>0.590643</td>\n",
       "      <td>0.421618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.962000</td>\n",
       "      <td>0.992535</td>\n",
       "      <td>0.438596</td>\n",
       "      <td>0.287328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.927600</td>\n",
       "      <td>0.888338</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.442307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.901600</td>\n",
       "      <td>0.853217</td>\n",
       "      <td>0.619883</td>\n",
       "      <td>0.434935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.866800</td>\n",
       "      <td>0.897568</td>\n",
       "      <td>0.596491</td>\n",
       "      <td>0.380371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.887200</td>\n",
       "      <td>0.851781</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.442370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.789200</td>\n",
       "      <td>0.922715</td>\n",
       "      <td>0.625731</td>\n",
       "      <td>0.428028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.792100</td>\n",
       "      <td>0.993025</td>\n",
       "      <td>0.625731</td>\n",
       "      <td>0.422299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.691700</td>\n",
       "      <td>0.912650</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.412802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.727000</td>\n",
       "      <td>1.161896</td>\n",
       "      <td>0.567251</td>\n",
       "      <td>0.331464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.741300</td>\n",
       "      <td>1.010297</td>\n",
       "      <td>0.584795</td>\n",
       "      <td>0.367294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.746000</td>\n",
       "      <td>0.994015</td>\n",
       "      <td>0.619883</td>\n",
       "      <td>0.441040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.645400</td>\n",
       "      <td>0.928138</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>0.453621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.620600</td>\n",
       "      <td>0.888544</td>\n",
       "      <td>0.643275</td>\n",
       "      <td>0.454516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.624300</td>\n",
       "      <td>0.914800</td>\n",
       "      <td>0.637427</td>\n",
       "      <td>0.535155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.554700</td>\n",
       "      <td>0.967387</td>\n",
       "      <td>0.654971</td>\n",
       "      <td>0.542356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.527800</td>\n",
       "      <td>1.162543</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.493871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.536600</td>\n",
       "      <td>1.126101</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.447289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.486400</td>\n",
       "      <td>1.056255</td>\n",
       "      <td>0.625731</td>\n",
       "      <td>0.491647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.472200</td>\n",
       "      <td>1.149827</td>\n",
       "      <td>0.637427</td>\n",
       "      <td>0.500379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.463500</td>\n",
       "      <td>1.133056</td>\n",
       "      <td>0.625731</td>\n",
       "      <td>0.524062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.444400</td>\n",
       "      <td>1.190392</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.480025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.394200</td>\n",
       "      <td>1.236243</td>\n",
       "      <td>0.602339</td>\n",
       "      <td>0.487053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.380500</td>\n",
       "      <td>1.223295</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.523362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.368800</td>\n",
       "      <td>1.242169</td>\n",
       "      <td>0.625731</td>\n",
       "      <td>0.488795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.354900</td>\n",
       "      <td>1.267949</td>\n",
       "      <td>0.596491</td>\n",
       "      <td>0.484249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.317400</td>\n",
       "      <td>1.279993</td>\n",
       "      <td>0.625731</td>\n",
       "      <td>0.482133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.319800</td>\n",
       "      <td>1.201420</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.493926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.289500</td>\n",
       "      <td>1.228579</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.491545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunis-ai/TunBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tunis-ai/TunBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78bfd3c907414e7d89bac38786f2dfba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ad8cad0eecb4224bce76dbb15221e4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:52, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.133300</td>\n",
       "      <td>0.977088</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.229885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.001300</td>\n",
       "      <td>0.967748</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.229885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.986000</td>\n",
       "      <td>0.963733</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.229885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.991700</td>\n",
       "      <td>0.955471</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.229885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.975800</td>\n",
       "      <td>0.915757</td>\n",
       "      <td>0.590643</td>\n",
       "      <td>0.421618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.962000</td>\n",
       "      <td>0.992535</td>\n",
       "      <td>0.438596</td>\n",
       "      <td>0.287328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.927600</td>\n",
       "      <td>0.888338</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.442307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.901600</td>\n",
       "      <td>0.853217</td>\n",
       "      <td>0.619883</td>\n",
       "      <td>0.434935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.866800</td>\n",
       "      <td>0.897568</td>\n",
       "      <td>0.596491</td>\n",
       "      <td>0.380371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.887200</td>\n",
       "      <td>0.851781</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.442370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.789200</td>\n",
       "      <td>0.922715</td>\n",
       "      <td>0.625731</td>\n",
       "      <td>0.428028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.792100</td>\n",
       "      <td>0.993025</td>\n",
       "      <td>0.625731</td>\n",
       "      <td>0.422299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.691700</td>\n",
       "      <td>0.912650</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.412802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.727000</td>\n",
       "      <td>1.161896</td>\n",
       "      <td>0.567251</td>\n",
       "      <td>0.331464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.741300</td>\n",
       "      <td>1.010297</td>\n",
       "      <td>0.584795</td>\n",
       "      <td>0.367294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.746000</td>\n",
       "      <td>0.994015</td>\n",
       "      <td>0.619883</td>\n",
       "      <td>0.441040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.645400</td>\n",
       "      <td>0.928138</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>0.453621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.620600</td>\n",
       "      <td>0.888544</td>\n",
       "      <td>0.643275</td>\n",
       "      <td>0.454516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.624300</td>\n",
       "      <td>0.914800</td>\n",
       "      <td>0.637427</td>\n",
       "      <td>0.535155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.554700</td>\n",
       "      <td>0.967387</td>\n",
       "      <td>0.654971</td>\n",
       "      <td>0.542356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.527800</td>\n",
       "      <td>1.162543</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.493871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.536600</td>\n",
       "      <td>1.126101</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.447289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.486400</td>\n",
       "      <td>1.056255</td>\n",
       "      <td>0.625731</td>\n",
       "      <td>0.491647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.472200</td>\n",
       "      <td>1.149827</td>\n",
       "      <td>0.637427</td>\n",
       "      <td>0.500379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.463500</td>\n",
       "      <td>1.133056</td>\n",
       "      <td>0.625731</td>\n",
       "      <td>0.524062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.444400</td>\n",
       "      <td>1.190392</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.480025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.394200</td>\n",
       "      <td>1.236243</td>\n",
       "      <td>0.602339</td>\n",
       "      <td>0.487053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.380500</td>\n",
       "      <td>1.223295</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.523362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.368800</td>\n",
       "      <td>1.242169</td>\n",
       "      <td>0.625731</td>\n",
       "      <td>0.488795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.354900</td>\n",
       "      <td>1.267949</td>\n",
       "      <td>0.596491</td>\n",
       "      <td>0.484249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.317400</td>\n",
       "      <td>1.279993</td>\n",
       "      <td>0.625731</td>\n",
       "      <td>0.482133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.319800</td>\n",
       "      <td>1.201420</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.493926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.289500</td>\n",
       "      <td>1.228579</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.491545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunis-ai/TunBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tunis-ai/TunBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a0744e331754c71afffc9c109f726e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "014d9ea8ed3f4b019dbe616745127674",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:52, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.133300</td>\n",
       "      <td>0.977088</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.229885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.001300</td>\n",
       "      <td>0.967748</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.229885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.986000</td>\n",
       "      <td>0.963733</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.229885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.991700</td>\n",
       "      <td>0.955471</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.229885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.975800</td>\n",
       "      <td>0.915757</td>\n",
       "      <td>0.590643</td>\n",
       "      <td>0.421618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.962000</td>\n",
       "      <td>0.992535</td>\n",
       "      <td>0.438596</td>\n",
       "      <td>0.287328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.927600</td>\n",
       "      <td>0.888338</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.442307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.901600</td>\n",
       "      <td>0.853217</td>\n",
       "      <td>0.619883</td>\n",
       "      <td>0.434935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.866800</td>\n",
       "      <td>0.897568</td>\n",
       "      <td>0.596491</td>\n",
       "      <td>0.380371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.887200</td>\n",
       "      <td>0.851781</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.442370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.789200</td>\n",
       "      <td>0.922715</td>\n",
       "      <td>0.625731</td>\n",
       "      <td>0.428028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.792100</td>\n",
       "      <td>0.993025</td>\n",
       "      <td>0.625731</td>\n",
       "      <td>0.422299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.691700</td>\n",
       "      <td>0.912650</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.412802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.727000</td>\n",
       "      <td>1.161896</td>\n",
       "      <td>0.567251</td>\n",
       "      <td>0.331464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.741300</td>\n",
       "      <td>1.010297</td>\n",
       "      <td>0.584795</td>\n",
       "      <td>0.367294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.746000</td>\n",
       "      <td>0.994015</td>\n",
       "      <td>0.619883</td>\n",
       "      <td>0.441040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.645400</td>\n",
       "      <td>0.928138</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>0.453621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.620600</td>\n",
       "      <td>0.888544</td>\n",
       "      <td>0.643275</td>\n",
       "      <td>0.454516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.624300</td>\n",
       "      <td>0.914800</td>\n",
       "      <td>0.637427</td>\n",
       "      <td>0.535155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.554700</td>\n",
       "      <td>0.967387</td>\n",
       "      <td>0.654971</td>\n",
       "      <td>0.542356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.527800</td>\n",
       "      <td>1.162543</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.493871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.536600</td>\n",
       "      <td>1.126101</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.447289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.486400</td>\n",
       "      <td>1.056255</td>\n",
       "      <td>0.625731</td>\n",
       "      <td>0.491647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.472200</td>\n",
       "      <td>1.149827</td>\n",
       "      <td>0.637427</td>\n",
       "      <td>0.500379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.463500</td>\n",
       "      <td>1.133056</td>\n",
       "      <td>0.625731</td>\n",
       "      <td>0.524062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.444400</td>\n",
       "      <td>1.190392</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.480025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.394200</td>\n",
       "      <td>1.236243</td>\n",
       "      <td>0.602339</td>\n",
       "      <td>0.487053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.380500</td>\n",
       "      <td>1.223295</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.523362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.368800</td>\n",
       "      <td>1.242169</td>\n",
       "      <td>0.625731</td>\n",
       "      <td>0.488795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.354900</td>\n",
       "      <td>1.267949</td>\n",
       "      <td>0.596491</td>\n",
       "      <td>0.484249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.317400</td>\n",
       "      <td>1.279993</td>\n",
       "      <td>0.625731</td>\n",
       "      <td>0.482133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.319800</td>\n",
       "      <td>1.201420</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.493926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.289500</td>\n",
       "      <td>1.228579</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.491545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunis-ai/TunBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tunis-ai/TunBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1ea54e4ae054c5eb025aec0e1937ad5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "766c97a6d8a74af58136da532efd7995",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:52, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.055900</td>\n",
       "      <td>1.030570</td>\n",
       "      <td>0.502924</td>\n",
       "      <td>0.223087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.983100</td>\n",
       "      <td>1.015201</td>\n",
       "      <td>0.502924</td>\n",
       "      <td>0.223087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.981400</td>\n",
       "      <td>0.957794</td>\n",
       "      <td>0.543860</td>\n",
       "      <td>0.351541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.935100</td>\n",
       "      <td>1.042219</td>\n",
       "      <td>0.502924</td>\n",
       "      <td>0.223087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.937600</td>\n",
       "      <td>0.968644</td>\n",
       "      <td>0.573099</td>\n",
       "      <td>0.361605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.912900</td>\n",
       "      <td>1.008590</td>\n",
       "      <td>0.549708</td>\n",
       "      <td>0.320294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.842500</td>\n",
       "      <td>0.933317</td>\n",
       "      <td>0.584795</td>\n",
       "      <td>0.400486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.785600</td>\n",
       "      <td>0.925053</td>\n",
       "      <td>0.596491</td>\n",
       "      <td>0.422775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.769900</td>\n",
       "      <td>1.136351</td>\n",
       "      <td>0.590643</td>\n",
       "      <td>0.394439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.722000</td>\n",
       "      <td>1.049506</td>\n",
       "      <td>0.608187</td>\n",
       "      <td>0.421922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.659300</td>\n",
       "      <td>0.939203</td>\n",
       "      <td>0.584795</td>\n",
       "      <td>0.412061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.681200</td>\n",
       "      <td>1.035740</td>\n",
       "      <td>0.567251</td>\n",
       "      <td>0.406173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.585800</td>\n",
       "      <td>1.035176</td>\n",
       "      <td>0.596491</td>\n",
       "      <td>0.425256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.677800</td>\n",
       "      <td>1.146525</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.395907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.528300</td>\n",
       "      <td>1.186857</td>\n",
       "      <td>0.596491</td>\n",
       "      <td>0.454741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.554400</td>\n",
       "      <td>1.067422</td>\n",
       "      <td>0.596491</td>\n",
       "      <td>0.465679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.482900</td>\n",
       "      <td>1.285731</td>\n",
       "      <td>0.561404</td>\n",
       "      <td>0.454043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.421600</td>\n",
       "      <td>1.351960</td>\n",
       "      <td>0.584795</td>\n",
       "      <td>0.450785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.499800</td>\n",
       "      <td>1.174426</td>\n",
       "      <td>0.590643</td>\n",
       "      <td>0.473853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.436700</td>\n",
       "      <td>1.193352</td>\n",
       "      <td>0.567251</td>\n",
       "      <td>0.451320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.550500</td>\n",
       "      <td>1.205727</td>\n",
       "      <td>0.561404</td>\n",
       "      <td>0.467016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.404300</td>\n",
       "      <td>1.268937</td>\n",
       "      <td>0.549708</td>\n",
       "      <td>0.468244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.417700</td>\n",
       "      <td>1.411458</td>\n",
       "      <td>0.567251</td>\n",
       "      <td>0.493831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.332800</td>\n",
       "      <td>1.266871</td>\n",
       "      <td>0.584795</td>\n",
       "      <td>0.458186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.370600</td>\n",
       "      <td>1.250082</td>\n",
       "      <td>0.602339</td>\n",
       "      <td>0.488723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.351800</td>\n",
       "      <td>1.526607</td>\n",
       "      <td>0.538012</td>\n",
       "      <td>0.482744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.303500</td>\n",
       "      <td>1.387892</td>\n",
       "      <td>0.567251</td>\n",
       "      <td>0.450337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.302700</td>\n",
       "      <td>1.497246</td>\n",
       "      <td>0.573099</td>\n",
       "      <td>0.491228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.279800</td>\n",
       "      <td>1.500980</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.455963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.279200</td>\n",
       "      <td>1.543898</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.499637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.217900</td>\n",
       "      <td>1.518410</td>\n",
       "      <td>0.573099</td>\n",
       "      <td>0.486339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.243100</td>\n",
       "      <td>1.581820</td>\n",
       "      <td>0.561404</td>\n",
       "      <td>0.478000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.253900</td>\n",
       "      <td>1.550180</td>\n",
       "      <td>0.596491</td>\n",
       "      <td>0.513459</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunis-ai/TunBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tunis-ai/TunBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c618ff38abe466ea962eac8ad412a5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afc441ed98444f9ebb8c0328d577b326",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:52, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.055900</td>\n",
       "      <td>1.030570</td>\n",
       "      <td>0.502924</td>\n",
       "      <td>0.223087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.983100</td>\n",
       "      <td>1.015201</td>\n",
       "      <td>0.502924</td>\n",
       "      <td>0.223087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.981400</td>\n",
       "      <td>0.957794</td>\n",
       "      <td>0.543860</td>\n",
       "      <td>0.351541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.935100</td>\n",
       "      <td>1.042219</td>\n",
       "      <td>0.502924</td>\n",
       "      <td>0.223087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.937600</td>\n",
       "      <td>0.968644</td>\n",
       "      <td>0.573099</td>\n",
       "      <td>0.361605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.912900</td>\n",
       "      <td>1.008590</td>\n",
       "      <td>0.549708</td>\n",
       "      <td>0.320294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.842500</td>\n",
       "      <td>0.933317</td>\n",
       "      <td>0.584795</td>\n",
       "      <td>0.400486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.785600</td>\n",
       "      <td>0.925053</td>\n",
       "      <td>0.596491</td>\n",
       "      <td>0.422775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.769900</td>\n",
       "      <td>1.136351</td>\n",
       "      <td>0.590643</td>\n",
       "      <td>0.394439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.722000</td>\n",
       "      <td>1.049506</td>\n",
       "      <td>0.608187</td>\n",
       "      <td>0.421922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.659300</td>\n",
       "      <td>0.939203</td>\n",
       "      <td>0.584795</td>\n",
       "      <td>0.412061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.681200</td>\n",
       "      <td>1.035740</td>\n",
       "      <td>0.567251</td>\n",
       "      <td>0.406173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.585800</td>\n",
       "      <td>1.035176</td>\n",
       "      <td>0.596491</td>\n",
       "      <td>0.425256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.677800</td>\n",
       "      <td>1.146525</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.395907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.528300</td>\n",
       "      <td>1.186857</td>\n",
       "      <td>0.596491</td>\n",
       "      <td>0.454741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.554400</td>\n",
       "      <td>1.067422</td>\n",
       "      <td>0.596491</td>\n",
       "      <td>0.465679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.482900</td>\n",
       "      <td>1.285731</td>\n",
       "      <td>0.561404</td>\n",
       "      <td>0.454043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.421600</td>\n",
       "      <td>1.351960</td>\n",
       "      <td>0.584795</td>\n",
       "      <td>0.450785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.499800</td>\n",
       "      <td>1.174426</td>\n",
       "      <td>0.590643</td>\n",
       "      <td>0.473853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.436700</td>\n",
       "      <td>1.193352</td>\n",
       "      <td>0.567251</td>\n",
       "      <td>0.451320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.550500</td>\n",
       "      <td>1.205727</td>\n",
       "      <td>0.561404</td>\n",
       "      <td>0.467016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.404300</td>\n",
       "      <td>1.268937</td>\n",
       "      <td>0.549708</td>\n",
       "      <td>0.468244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.417700</td>\n",
       "      <td>1.411458</td>\n",
       "      <td>0.567251</td>\n",
       "      <td>0.493831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.332800</td>\n",
       "      <td>1.266871</td>\n",
       "      <td>0.584795</td>\n",
       "      <td>0.458186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.370600</td>\n",
       "      <td>1.250082</td>\n",
       "      <td>0.602339</td>\n",
       "      <td>0.488723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.351800</td>\n",
       "      <td>1.526607</td>\n",
       "      <td>0.538012</td>\n",
       "      <td>0.482744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.303500</td>\n",
       "      <td>1.387892</td>\n",
       "      <td>0.567251</td>\n",
       "      <td>0.450337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.302700</td>\n",
       "      <td>1.497246</td>\n",
       "      <td>0.573099</td>\n",
       "      <td>0.491228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.279800</td>\n",
       "      <td>1.500980</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.455963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.279200</td>\n",
       "      <td>1.543898</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.499637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.217900</td>\n",
       "      <td>1.518410</td>\n",
       "      <td>0.573099</td>\n",
       "      <td>0.486339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.243100</td>\n",
       "      <td>1.581820</td>\n",
       "      <td>0.561404</td>\n",
       "      <td>0.478000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.253900</td>\n",
       "      <td>1.550180</td>\n",
       "      <td>0.596491</td>\n",
       "      <td>0.513459</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunis-ai/TunBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tunis-ai/TunBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "192bd5f2364a4b9ba2151620802d6633",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4027f3fd73c241c1907267a1f07a30ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:52, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.055900</td>\n",
       "      <td>1.030570</td>\n",
       "      <td>0.502924</td>\n",
       "      <td>0.223087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.983100</td>\n",
       "      <td>1.015201</td>\n",
       "      <td>0.502924</td>\n",
       "      <td>0.223087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.981400</td>\n",
       "      <td>0.957794</td>\n",
       "      <td>0.543860</td>\n",
       "      <td>0.351541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.935100</td>\n",
       "      <td>1.042219</td>\n",
       "      <td>0.502924</td>\n",
       "      <td>0.223087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.937600</td>\n",
       "      <td>0.968644</td>\n",
       "      <td>0.573099</td>\n",
       "      <td>0.361605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.912900</td>\n",
       "      <td>1.008590</td>\n",
       "      <td>0.549708</td>\n",
       "      <td>0.320294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.842500</td>\n",
       "      <td>0.933317</td>\n",
       "      <td>0.584795</td>\n",
       "      <td>0.400486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.785600</td>\n",
       "      <td>0.925053</td>\n",
       "      <td>0.596491</td>\n",
       "      <td>0.422775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.769900</td>\n",
       "      <td>1.136351</td>\n",
       "      <td>0.590643</td>\n",
       "      <td>0.394439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.722000</td>\n",
       "      <td>1.049506</td>\n",
       "      <td>0.608187</td>\n",
       "      <td>0.421922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.659300</td>\n",
       "      <td>0.939203</td>\n",
       "      <td>0.584795</td>\n",
       "      <td>0.412061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.681200</td>\n",
       "      <td>1.035740</td>\n",
       "      <td>0.567251</td>\n",
       "      <td>0.406173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.585800</td>\n",
       "      <td>1.035176</td>\n",
       "      <td>0.596491</td>\n",
       "      <td>0.425256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.677800</td>\n",
       "      <td>1.146525</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.395907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.528300</td>\n",
       "      <td>1.186857</td>\n",
       "      <td>0.596491</td>\n",
       "      <td>0.454741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.554400</td>\n",
       "      <td>1.067422</td>\n",
       "      <td>0.596491</td>\n",
       "      <td>0.465679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.482900</td>\n",
       "      <td>1.285731</td>\n",
       "      <td>0.561404</td>\n",
       "      <td>0.454043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.421600</td>\n",
       "      <td>1.351960</td>\n",
       "      <td>0.584795</td>\n",
       "      <td>0.450785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.499800</td>\n",
       "      <td>1.174426</td>\n",
       "      <td>0.590643</td>\n",
       "      <td>0.473853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.436700</td>\n",
       "      <td>1.193352</td>\n",
       "      <td>0.567251</td>\n",
       "      <td>0.451320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.550500</td>\n",
       "      <td>1.205727</td>\n",
       "      <td>0.561404</td>\n",
       "      <td>0.467016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.404300</td>\n",
       "      <td>1.268937</td>\n",
       "      <td>0.549708</td>\n",
       "      <td>0.468244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.417700</td>\n",
       "      <td>1.411458</td>\n",
       "      <td>0.567251</td>\n",
       "      <td>0.493831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.332800</td>\n",
       "      <td>1.266871</td>\n",
       "      <td>0.584795</td>\n",
       "      <td>0.458186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.370600</td>\n",
       "      <td>1.250082</td>\n",
       "      <td>0.602339</td>\n",
       "      <td>0.488723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.351800</td>\n",
       "      <td>1.526607</td>\n",
       "      <td>0.538012</td>\n",
       "      <td>0.482744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.303500</td>\n",
       "      <td>1.387892</td>\n",
       "      <td>0.567251</td>\n",
       "      <td>0.450337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.302700</td>\n",
       "      <td>1.497246</td>\n",
       "      <td>0.573099</td>\n",
       "      <td>0.491228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.279800</td>\n",
       "      <td>1.500980</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.455963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.279200</td>\n",
       "      <td>1.543898</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.499637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.217900</td>\n",
       "      <td>1.518410</td>\n",
       "      <td>0.573099</td>\n",
       "      <td>0.486339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.243100</td>\n",
       "      <td>1.581820</td>\n",
       "      <td>0.561404</td>\n",
       "      <td>0.478000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.253900</td>\n",
       "      <td>1.550180</td>\n",
       "      <td>0.596491</td>\n",
       "      <td>0.513459</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['review', 'label'],\n",
       "        num_rows: 680\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['review', 'label'],\n",
       "        num_rows: 171\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alger-ia/dziribert, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc066d0eb4c8478c90aa9a20220bfb4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88344d5ae7fe47f99bf6246ba2accfb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:53, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.917100</td>\n",
       "      <td>0.657833</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.533519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.629500</td>\n",
       "      <td>0.536412</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.628460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.347600</td>\n",
       "      <td>0.495374</td>\n",
       "      <td>0.812865</td>\n",
       "      <td>0.755253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.149600</td>\n",
       "      <td>0.636637</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.681199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.084000</td>\n",
       "      <td>0.750665</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.643308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.025700</td>\n",
       "      <td>0.800980</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.685436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.004800</td>\n",
       "      <td>0.958777</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.623676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>1.215472</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.690562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>1.130858</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.676093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>1.122306</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.636689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>1.134100</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.712190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>1.186168</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.703995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.208189</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.702426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>1.217663</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.702426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.259698</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.702980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.272272</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.702980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.272967</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.702980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.273569</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.702980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.273216</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.702980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.273763</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.708745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.277373</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.708745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.281778</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.708745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.286319</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.714636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.290316</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.714636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.294658</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.714636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.297337</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.714636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.300263</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.714636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.302555</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.714636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.303691</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.714636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.304760</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.714636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.305800</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.714636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.306311</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.718863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.306411</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.718863</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alger-ia/dziribert, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30b0c9397c1147b694f29c9c6da8cb62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22ecd49eab0e4409ac77975e26386272",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:53, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.917100</td>\n",
       "      <td>0.657833</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.533519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.629500</td>\n",
       "      <td>0.536412</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.628460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.347600</td>\n",
       "      <td>0.495374</td>\n",
       "      <td>0.812865</td>\n",
       "      <td>0.755253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.149600</td>\n",
       "      <td>0.636637</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.681199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.084000</td>\n",
       "      <td>0.750665</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.643308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.025700</td>\n",
       "      <td>0.800980</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.685436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.004800</td>\n",
       "      <td>0.958777</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.623676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>1.215472</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.690562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>1.130858</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.676093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>1.122306</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.636689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>1.134100</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.712190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>1.186168</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.703995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.208189</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.702426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>1.217663</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.702426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.259698</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.702980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.272272</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.702980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.272967</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.702980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.273569</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.702980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.273216</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.702980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.273763</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.708745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.277373</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.708745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.281778</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.708745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.286319</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.714636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.290316</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.714636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.294658</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.714636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.297337</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.714636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.300263</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.714636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.302555</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.714636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.303691</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.714636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.304760</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.714636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.305800</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.714636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.306311</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.718863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.306411</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.718863</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alger-ia/dziribert, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d15c188798804faa960b2a2534ca2369",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58f2b7b2b731422184f4ec3eba652a05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:53, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.917100</td>\n",
       "      <td>0.657833</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.533519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.629500</td>\n",
       "      <td>0.536412</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.628460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.347600</td>\n",
       "      <td>0.495374</td>\n",
       "      <td>0.812865</td>\n",
       "      <td>0.755253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.149600</td>\n",
       "      <td>0.636637</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.681199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.084000</td>\n",
       "      <td>0.750665</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.643308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.025700</td>\n",
       "      <td>0.800980</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.685436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.004800</td>\n",
       "      <td>0.958777</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.623676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>1.215472</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.690562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>1.130858</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.676093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>1.122306</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.636689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>1.134100</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.712190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>1.186168</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.703995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.208189</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.702426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>1.217663</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.702426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.259698</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.702980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.272272</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.702980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.272967</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.702980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.273569</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.702980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.273216</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.702980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.273763</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.708745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.277373</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.708745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.281778</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.708745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.286319</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.714636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.290316</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.714636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.294658</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.714636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.297337</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.714636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.300263</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.714636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.302555</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.714636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.303691</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.714636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.304760</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.714636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.305800</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.714636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.306311</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.718863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.306411</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.718863</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alger-ia/dziribert, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87eb6d66c7b5405d8840655e5416da03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b940b8528dd74586919e111020bf139d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:54, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.894000</td>\n",
       "      <td>0.679346</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.625433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.573200</td>\n",
       "      <td>0.619629</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.608418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.332000</td>\n",
       "      <td>0.641730</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.697090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.170800</td>\n",
       "      <td>0.813177</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.694485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.086400</td>\n",
       "      <td>0.758330</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.663920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.024300</td>\n",
       "      <td>0.909494</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.695552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.008300</td>\n",
       "      <td>1.149382</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.660846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>1.297395</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.693431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>1.391625</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.683767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>1.392861</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.680351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>1.404153</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.694993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>1.415826</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.707961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.430336</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.697090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.446274</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.697090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.460141</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.697090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.472429</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.697090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.482597</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.697090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.493131</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.697090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.504057</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.697090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.513720</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.697090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.521948</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.697090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.531027</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.697090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.547976</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.703770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.557326</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.702766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.563456</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.702766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.567873</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.702766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.571542</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.702766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.574806</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.702766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.577276</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.702766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.578849</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.702766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.580244</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.702766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.580982</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.707961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.581284</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.707961</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alger-ia/dziribert, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fef71e5109024897a07e66600a6d24f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "378f9583806f45c3be12f5a0f1df7440",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:55, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.894000</td>\n",
       "      <td>0.679346</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.625433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.573200</td>\n",
       "      <td>0.619629</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.608418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.332000</td>\n",
       "      <td>0.641730</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.697090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.170800</td>\n",
       "      <td>0.813177</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.694485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.086400</td>\n",
       "      <td>0.758330</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.663920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.024300</td>\n",
       "      <td>0.909494</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.695552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.008300</td>\n",
       "      <td>1.149382</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.660846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>1.297395</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.693431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>1.391625</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.683767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>1.392861</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.680351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>1.404153</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.694993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>1.415826</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.707961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.430336</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.697090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.446274</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.697090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.460141</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.697090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.472429</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.697090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.482597</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.697090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.493131</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.697090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.504057</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.697090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.513720</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.697090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.521948</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.697090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.531027</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.697090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.547976</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.703770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.557326</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.702766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.563456</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.702766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.567873</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.702766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.571542</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.702766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.574806</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.702766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.577276</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.702766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.578849</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.702766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.580244</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.702766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.580982</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.707961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.581284</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.707961</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alger-ia/dziribert, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee29c157a1964cdda9abeab1d52a9b62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fd62db43b584c798a8ffc1b9b2d57c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:54, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.894000</td>\n",
       "      <td>0.679346</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.625433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.573200</td>\n",
       "      <td>0.619629</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.608418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.332000</td>\n",
       "      <td>0.641730</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.697090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.170800</td>\n",
       "      <td>0.813177</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.694485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.086400</td>\n",
       "      <td>0.758330</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.663920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.024300</td>\n",
       "      <td>0.909494</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.695552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.008300</td>\n",
       "      <td>1.149382</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.660846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>1.297395</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.693431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>1.391625</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.683767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>1.392861</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.680351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>1.404153</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.694993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>1.415826</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.707961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.430336</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.697090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.446274</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.697090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.460141</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.697090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.472429</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.697090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.482597</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.697090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.493131</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.697090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.504057</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.697090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.513720</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.697090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.521948</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.697090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.531027</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.697090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.547976</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.703770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.557326</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.702766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.563456</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.702766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.567873</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.702766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.571542</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.702766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.574806</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.702766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.577276</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.702766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.578849</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.702766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.580244</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.702766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.580982</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.707961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.581284</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.707961</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alger-ia/dziribert, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "782a071e18e1451eb4f12b5964ab94f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0637264a00784a49a096f4c489464625",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:53, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.884200</td>\n",
       "      <td>0.767110</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.471041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.580000</td>\n",
       "      <td>0.654289</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.657684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.304500</td>\n",
       "      <td>0.654505</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.699787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.137800</td>\n",
       "      <td>0.750603</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.720009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.043500</td>\n",
       "      <td>0.992158</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.696943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.013000</td>\n",
       "      <td>1.094746</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.719327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>1.235594</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.698679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>1.258340</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.732036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>1.542776</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.676599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>1.440810</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.718544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>1.402654</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.713282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.411538</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.710178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.434670</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.710613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.454471</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.703121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.473391</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.698041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.490512</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.698041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.505516</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.698041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.521101</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.704711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.532396</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.704711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.531479</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.700529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.544129</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.700529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.554718</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.704711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.562523</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.704711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.569512</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.704711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.576052</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.704711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.588048</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.704711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.599847</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.703770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.605255</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.703770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.608469</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.703770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.608040</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.703770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.606413</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.703770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.606473</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.703770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.606644</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.703770</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alger-ia/dziribert, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aad190e7de70426780e5b6f9f9648292",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d578c6af02db4d5c92b652359e6c4263",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:53, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.884200</td>\n",
       "      <td>0.767110</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.471041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.580000</td>\n",
       "      <td>0.654289</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.657684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.304500</td>\n",
       "      <td>0.654505</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.699787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.137800</td>\n",
       "      <td>0.750603</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.720009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.043500</td>\n",
       "      <td>0.992158</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.696943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.013000</td>\n",
       "      <td>1.094746</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.719327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>1.235594</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.698679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>1.258340</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.732036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>1.542776</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.676599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>1.440810</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.718544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>1.402654</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.713282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.411538</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.710178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.434670</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.710613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.454471</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.703121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.473391</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.698041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.490512</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.698041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.505516</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.698041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.521101</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.704711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.532396</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.704711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.531479</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.700529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.544129</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.700529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.554718</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.704711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.562523</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.704711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.569512</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.704711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.576052</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.704711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.588048</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.704711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.599847</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.703770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.605255</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.703770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.608469</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.703770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.608040</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.703770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.606413</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.703770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.606473</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.703770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.606644</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.703770</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alger-ia/dziribert, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "798fc7f3ab4c432cb0a41ea3094d7bf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce486b537c174817895c8b9f057ba5ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:53, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.884200</td>\n",
       "      <td>0.767110</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.471041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.580000</td>\n",
       "      <td>0.654289</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.657684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.304500</td>\n",
       "      <td>0.654505</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.699787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.137800</td>\n",
       "      <td>0.750603</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.720009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.043500</td>\n",
       "      <td>0.992158</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.696943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.013000</td>\n",
       "      <td>1.094746</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.719327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>1.235594</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.698679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>1.258340</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.732036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>1.542776</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.676599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>1.440810</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.718544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>1.402654</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.713282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.411538</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.710178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.434670</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.710613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.454471</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.703121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.473391</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.698041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.490512</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.698041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.505516</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.698041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.521101</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.704711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.532396</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.704711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.531479</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.700529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.544129</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.700529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.554718</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.704711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.562523</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.704711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.569512</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.704711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.576052</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.704711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.588048</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.704711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.599847</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.703770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.605255</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.703770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.608469</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.703770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.608040</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.703770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.606413</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.703770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.606473</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.703770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.606644</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.703770</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['review', 'label'],\n",
       "        num_rows: 680\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['review', 'label'],\n",
       "        num_rows: 171\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SI2M-Lab/DarijaBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SI2M-Lab/DarijaBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2d43f927c5c4209ba1af6dc5fa9dfc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02430205759246108cc2324ede7de0c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:56, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.969600</td>\n",
       "      <td>0.795534</td>\n",
       "      <td>0.637427</td>\n",
       "      <td>0.388846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.727200</td>\n",
       "      <td>0.603909</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.492407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.519400</td>\n",
       "      <td>0.564651</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.665547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.331700</td>\n",
       "      <td>0.588129</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.673016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.233400</td>\n",
       "      <td>0.530724</td>\n",
       "      <td>0.783626</td>\n",
       "      <td>0.677104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.114200</td>\n",
       "      <td>0.962078</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.648224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.194200</td>\n",
       "      <td>0.753961</td>\n",
       "      <td>0.783626</td>\n",
       "      <td>0.731498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.083400</td>\n",
       "      <td>0.914723</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.697170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.084000</td>\n",
       "      <td>0.923592</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.697959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.028300</td>\n",
       "      <td>0.842628</td>\n",
       "      <td>0.795322</td>\n",
       "      <td>0.740021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.048600</td>\n",
       "      <td>0.872524</td>\n",
       "      <td>0.783626</td>\n",
       "      <td>0.711443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.018300</td>\n",
       "      <td>0.935807</td>\n",
       "      <td>0.801170</td>\n",
       "      <td>0.736636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.014800</td>\n",
       "      <td>0.980195</td>\n",
       "      <td>0.812865</td>\n",
       "      <td>0.755959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.014600</td>\n",
       "      <td>1.114277</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.706100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>1.109212</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.658219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>1.156742</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.694146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>1.217588</td>\n",
       "      <td>0.783626</td>\n",
       "      <td>0.710765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>1.214032</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.684520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>1.208261</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.706821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>1.169343</td>\n",
       "      <td>0.783626</td>\n",
       "      <td>0.690591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>1.170583</td>\n",
       "      <td>0.783626</td>\n",
       "      <td>0.699504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.176142</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.709956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.189639</td>\n",
       "      <td>0.795322</td>\n",
       "      <td>0.715171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.200472</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.710996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.197575</td>\n",
       "      <td>0.795322</td>\n",
       "      <td>0.715171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.202203</td>\n",
       "      <td>0.807018</td>\n",
       "      <td>0.723577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.206451</td>\n",
       "      <td>0.795322</td>\n",
       "      <td>0.710290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.209784</td>\n",
       "      <td>0.795322</td>\n",
       "      <td>0.710290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.212589</td>\n",
       "      <td>0.795322</td>\n",
       "      <td>0.710290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.214136</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.706107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.215757</td>\n",
       "      <td>0.795322</td>\n",
       "      <td>0.711404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.216443</td>\n",
       "      <td>0.795322</td>\n",
       "      <td>0.711404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.216833</td>\n",
       "      <td>0.795322</td>\n",
       "      <td>0.711404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SI2M-Lab/DarijaBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SI2M-Lab/DarijaBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdb1cb88ec1d46e198b45b9b4396ab36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3178d27c07aa4b82980a64a8f1ea2461",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:56, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.969600</td>\n",
       "      <td>0.795534</td>\n",
       "      <td>0.637427</td>\n",
       "      <td>0.388846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.727200</td>\n",
       "      <td>0.603909</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.492407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.519400</td>\n",
       "      <td>0.564651</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.665547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.331700</td>\n",
       "      <td>0.588129</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.673016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.233400</td>\n",
       "      <td>0.530724</td>\n",
       "      <td>0.783626</td>\n",
       "      <td>0.677104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.114200</td>\n",
       "      <td>0.962078</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.648224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.194200</td>\n",
       "      <td>0.753961</td>\n",
       "      <td>0.783626</td>\n",
       "      <td>0.731498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.083400</td>\n",
       "      <td>0.914723</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.697170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.084000</td>\n",
       "      <td>0.923592</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.697959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.028300</td>\n",
       "      <td>0.842628</td>\n",
       "      <td>0.795322</td>\n",
       "      <td>0.740021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.048600</td>\n",
       "      <td>0.872524</td>\n",
       "      <td>0.783626</td>\n",
       "      <td>0.711443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.018300</td>\n",
       "      <td>0.935807</td>\n",
       "      <td>0.801170</td>\n",
       "      <td>0.736636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.014800</td>\n",
       "      <td>0.980195</td>\n",
       "      <td>0.812865</td>\n",
       "      <td>0.755959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.014600</td>\n",
       "      <td>1.114277</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.706100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>1.109212</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.658219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>1.156742</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.694146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>1.217588</td>\n",
       "      <td>0.783626</td>\n",
       "      <td>0.710765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>1.214032</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.684520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>1.208261</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.706821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>1.169343</td>\n",
       "      <td>0.783626</td>\n",
       "      <td>0.690591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>1.170583</td>\n",
       "      <td>0.783626</td>\n",
       "      <td>0.699504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.176142</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.709956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.189639</td>\n",
       "      <td>0.795322</td>\n",
       "      <td>0.715171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.200472</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.710996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.197575</td>\n",
       "      <td>0.795322</td>\n",
       "      <td>0.715171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.202203</td>\n",
       "      <td>0.807018</td>\n",
       "      <td>0.723577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.206451</td>\n",
       "      <td>0.795322</td>\n",
       "      <td>0.710290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.209784</td>\n",
       "      <td>0.795322</td>\n",
       "      <td>0.710290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.212589</td>\n",
       "      <td>0.795322</td>\n",
       "      <td>0.710290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.214136</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.706107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.215757</td>\n",
       "      <td>0.795322</td>\n",
       "      <td>0.711404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.216443</td>\n",
       "      <td>0.795322</td>\n",
       "      <td>0.711404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.216833</td>\n",
       "      <td>0.795322</td>\n",
       "      <td>0.711404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SI2M-Lab/DarijaBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SI2M-Lab/DarijaBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e04b4671050454c8fcb587d9011d227",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a492d77108c8468cb02be9d74b69dce9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:56, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.969600</td>\n",
       "      <td>0.795534</td>\n",
       "      <td>0.637427</td>\n",
       "      <td>0.388846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.727200</td>\n",
       "      <td>0.603909</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.492407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.519400</td>\n",
       "      <td>0.564651</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.665547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.331700</td>\n",
       "      <td>0.588129</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.673016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.233400</td>\n",
       "      <td>0.530724</td>\n",
       "      <td>0.783626</td>\n",
       "      <td>0.677104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.114200</td>\n",
       "      <td>0.962078</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.648224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.194200</td>\n",
       "      <td>0.753961</td>\n",
       "      <td>0.783626</td>\n",
       "      <td>0.731498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.083400</td>\n",
       "      <td>0.914723</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.697170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.084000</td>\n",
       "      <td>0.923592</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.697959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.028300</td>\n",
       "      <td>0.842628</td>\n",
       "      <td>0.795322</td>\n",
       "      <td>0.740021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.048600</td>\n",
       "      <td>0.872524</td>\n",
       "      <td>0.783626</td>\n",
       "      <td>0.711443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.018300</td>\n",
       "      <td>0.935807</td>\n",
       "      <td>0.801170</td>\n",
       "      <td>0.736636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.014800</td>\n",
       "      <td>0.980195</td>\n",
       "      <td>0.812865</td>\n",
       "      <td>0.755959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.014600</td>\n",
       "      <td>1.114277</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.706100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>1.109212</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.658219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>1.156742</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.694146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>1.217588</td>\n",
       "      <td>0.783626</td>\n",
       "      <td>0.710765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>1.214032</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.684520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>1.208261</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.706821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>1.169343</td>\n",
       "      <td>0.783626</td>\n",
       "      <td>0.690591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>1.170583</td>\n",
       "      <td>0.783626</td>\n",
       "      <td>0.699504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.176142</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.709956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.189639</td>\n",
       "      <td>0.795322</td>\n",
       "      <td>0.715171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.200472</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.710996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.197575</td>\n",
       "      <td>0.795322</td>\n",
       "      <td>0.715171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.202203</td>\n",
       "      <td>0.807018</td>\n",
       "      <td>0.723577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.206451</td>\n",
       "      <td>0.795322</td>\n",
       "      <td>0.710290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.209784</td>\n",
       "      <td>0.795322</td>\n",
       "      <td>0.710290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.212589</td>\n",
       "      <td>0.795322</td>\n",
       "      <td>0.710290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.214136</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.706107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.215757</td>\n",
       "      <td>0.795322</td>\n",
       "      <td>0.711404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.216443</td>\n",
       "      <td>0.795322</td>\n",
       "      <td>0.711404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.216833</td>\n",
       "      <td>0.795322</td>\n",
       "      <td>0.711404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SI2M-Lab/DarijaBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SI2M-Lab/DarijaBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "703e23dbd9624555ba70bb1f740e3dd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "934b0101ed754f5fabff09ded67cd02a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:56, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.653807</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.484848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.616100</td>\n",
       "      <td>0.681597</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.524411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.366400</td>\n",
       "      <td>0.606385</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.626421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.272300</td>\n",
       "      <td>0.914722</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.637198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.218400</td>\n",
       "      <td>1.022244</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.602758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.747645</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.642876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.072100</td>\n",
       "      <td>0.860162</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.652420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.061600</td>\n",
       "      <td>0.901724</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.695247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.046600</td>\n",
       "      <td>1.096196</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.626874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.038100</td>\n",
       "      <td>1.193590</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.636915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.028100</td>\n",
       "      <td>1.115486</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.646249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.014500</td>\n",
       "      <td>1.259564</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.640782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.021800</td>\n",
       "      <td>1.388124</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.683627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.018300</td>\n",
       "      <td>1.301042</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.662311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.372065</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.666930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>1.465966</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.657848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.542850</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.640861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>1.583666</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.661773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>1.526925</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.670175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>1.533835</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.669355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.456017</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.671132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>1.510079</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.659799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.551227</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.659799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.556222</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.659799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.535717</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.665805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.555779</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.676194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>1.539932</td>\n",
       "      <td>0.783626</td>\n",
       "      <td>0.680490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.517724</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.684223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.516185</td>\n",
       "      <td>0.783626</td>\n",
       "      <td>0.678591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.517963</td>\n",
       "      <td>0.783626</td>\n",
       "      <td>0.678591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.519478</td>\n",
       "      <td>0.783626</td>\n",
       "      <td>0.678591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.520661</td>\n",
       "      <td>0.783626</td>\n",
       "      <td>0.678591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.520720</td>\n",
       "      <td>0.783626</td>\n",
       "      <td>0.678591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SI2M-Lab/DarijaBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SI2M-Lab/DarijaBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66d7b16e9a5b44f4b6ce402e07e9f7b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6506927c84c4491ae0688a50bd16d77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:56, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.653807</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.484848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.616100</td>\n",
       "      <td>0.681597</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.524411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.366400</td>\n",
       "      <td>0.606385</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.626421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.272300</td>\n",
       "      <td>0.914722</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.637198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.218400</td>\n",
       "      <td>1.022244</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.602758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.747645</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.642876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.072100</td>\n",
       "      <td>0.860162</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.652420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.061600</td>\n",
       "      <td>0.901724</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.695247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.046600</td>\n",
       "      <td>1.096196</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.626874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.038100</td>\n",
       "      <td>1.193590</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.636915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.028100</td>\n",
       "      <td>1.115486</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.646249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.014500</td>\n",
       "      <td>1.259564</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.640782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.021800</td>\n",
       "      <td>1.388124</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.683627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.018300</td>\n",
       "      <td>1.301042</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.662311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.372065</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.666930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>1.465966</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.657848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.542850</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.640861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>1.583666</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.661773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>1.526925</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.670175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>1.533835</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.669355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.456017</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.671132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>1.510079</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.659799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.551227</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.659799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.556222</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.659799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.535717</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.665805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.555779</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.676194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>1.539932</td>\n",
       "      <td>0.783626</td>\n",
       "      <td>0.680490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.517724</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.684223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.516185</td>\n",
       "      <td>0.783626</td>\n",
       "      <td>0.678591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.517963</td>\n",
       "      <td>0.783626</td>\n",
       "      <td>0.678591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.519478</td>\n",
       "      <td>0.783626</td>\n",
       "      <td>0.678591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.520661</td>\n",
       "      <td>0.783626</td>\n",
       "      <td>0.678591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.520720</td>\n",
       "      <td>0.783626</td>\n",
       "      <td>0.678591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SI2M-Lab/DarijaBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SI2M-Lab/DarijaBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b64b57ab54784de1af1ebb14e6a4361a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e6625ccdabb4e48aa20e4ee6836ff6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:55, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.653807</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.484848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.616100</td>\n",
       "      <td>0.681597</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.524411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.366400</td>\n",
       "      <td>0.606385</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.626421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.272300</td>\n",
       "      <td>0.914722</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.637198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.218400</td>\n",
       "      <td>1.022244</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.602758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.747645</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.642876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.072100</td>\n",
       "      <td>0.860162</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.652420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.061600</td>\n",
       "      <td>0.901724</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.695247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.046600</td>\n",
       "      <td>1.096196</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.626874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.038100</td>\n",
       "      <td>1.193590</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.636915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.028100</td>\n",
       "      <td>1.115486</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.646249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.014500</td>\n",
       "      <td>1.259564</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.640782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.021800</td>\n",
       "      <td>1.388124</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.683627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.018300</td>\n",
       "      <td>1.301042</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.662311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.372065</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.666930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>1.465966</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.657848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.542850</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.640861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>1.583666</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.661773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>1.526925</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.670175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>1.533835</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.669355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.456017</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.671132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>1.510079</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.659799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.551227</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.659799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.556222</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.659799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.535717</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.665805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.555779</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.676194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>1.539932</td>\n",
       "      <td>0.783626</td>\n",
       "      <td>0.680490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.517724</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.684223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.516185</td>\n",
       "      <td>0.783626</td>\n",
       "      <td>0.678591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.517963</td>\n",
       "      <td>0.783626</td>\n",
       "      <td>0.678591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.519478</td>\n",
       "      <td>0.783626</td>\n",
       "      <td>0.678591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.520661</td>\n",
       "      <td>0.783626</td>\n",
       "      <td>0.678591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.520720</td>\n",
       "      <td>0.783626</td>\n",
       "      <td>0.678591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SI2M-Lab/DarijaBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SI2M-Lab/DarijaBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf1de24e2f604fbeaa658528e6dc596b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "433cd36341e3489886e4b95028368d67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:55, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.916900</td>\n",
       "      <td>0.876244</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.420960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.693100</td>\n",
       "      <td>0.755305</td>\n",
       "      <td>0.660819</td>\n",
       "      <td>0.554742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.454100</td>\n",
       "      <td>0.792554</td>\n",
       "      <td>0.690058</td>\n",
       "      <td>0.537415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.302000</td>\n",
       "      <td>0.766510</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.658538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.179600</td>\n",
       "      <td>0.916187</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.670175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.165200</td>\n",
       "      <td>0.960117</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.691824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.120400</td>\n",
       "      <td>1.012089</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.666215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.071600</td>\n",
       "      <td>1.137959</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.646830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.047100</td>\n",
       "      <td>1.363088</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.661012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.049600</td>\n",
       "      <td>1.407665</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.656993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.037100</td>\n",
       "      <td>1.371889</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.684941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.027900</td>\n",
       "      <td>1.436940</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.684427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.016600</td>\n",
       "      <td>1.465759</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.627107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.009400</td>\n",
       "      <td>1.465173</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.683126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.006900</td>\n",
       "      <td>1.522453</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.689440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.023600</td>\n",
       "      <td>1.665466</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.652413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>1.708059</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.686502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>1.592541</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.684371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>1.689717</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.655373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>1.671796</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.693187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.657901</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.706816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.665911</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.695429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.688813</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.689141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.703451</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.681741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.713502</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.697031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.719829</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.697031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.725491</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.689798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.729080</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.689798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.732085</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.689798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.735678</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.689798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.737804</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.689798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.741307</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.690285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.742100</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.690285</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SI2M-Lab/DarijaBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SI2M-Lab/DarijaBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc049fea0d6542c49eeb05d2e708534d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "503ea62afad24b029f29159e23fd6fbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:56, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.916900</td>\n",
       "      <td>0.876244</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.420960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.693100</td>\n",
       "      <td>0.755305</td>\n",
       "      <td>0.660819</td>\n",
       "      <td>0.554742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.454100</td>\n",
       "      <td>0.792554</td>\n",
       "      <td>0.690058</td>\n",
       "      <td>0.537415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.302000</td>\n",
       "      <td>0.766510</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.658538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.179600</td>\n",
       "      <td>0.916187</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.670175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.165200</td>\n",
       "      <td>0.960117</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.691824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.120400</td>\n",
       "      <td>1.012089</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.666215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.071600</td>\n",
       "      <td>1.137959</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.646830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.047100</td>\n",
       "      <td>1.363088</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.661012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.049600</td>\n",
       "      <td>1.407665</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.656993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.037100</td>\n",
       "      <td>1.371889</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.684941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.027900</td>\n",
       "      <td>1.436940</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.684427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.016600</td>\n",
       "      <td>1.465759</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.627107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.009400</td>\n",
       "      <td>1.465173</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.683126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.006900</td>\n",
       "      <td>1.522453</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.689440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.023600</td>\n",
       "      <td>1.665466</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.652413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>1.708059</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.686502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>1.592541</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.684371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>1.689717</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.655373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>1.671796</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.693187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.657901</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.706816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.665911</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.695429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.688813</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.689141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.703451</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.681741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.713502</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.697031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.719829</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.697031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.725491</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.689798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.729080</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.689798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.732085</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.689798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.735678</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.689798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.737804</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.689798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.741307</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.690285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.742100</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.690285</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SI2M-Lab/DarijaBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SI2M-Lab/DarijaBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e8ea14abadd49c0970b6e9b094bc063",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9bd2228ac924f26968b54d815a91f0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:56, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.916900</td>\n",
       "      <td>0.876244</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.420960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.693100</td>\n",
       "      <td>0.755305</td>\n",
       "      <td>0.660819</td>\n",
       "      <td>0.554742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.454100</td>\n",
       "      <td>0.792554</td>\n",
       "      <td>0.690058</td>\n",
       "      <td>0.537415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.302000</td>\n",
       "      <td>0.766510</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.658538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.179600</td>\n",
       "      <td>0.916187</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.670175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.165200</td>\n",
       "      <td>0.960117</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.691824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.120400</td>\n",
       "      <td>1.012089</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.666215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.071600</td>\n",
       "      <td>1.137959</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.646830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.047100</td>\n",
       "      <td>1.363088</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.661012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.049600</td>\n",
       "      <td>1.407665</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.656993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.037100</td>\n",
       "      <td>1.371889</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.684941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.027900</td>\n",
       "      <td>1.436940</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.684427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.016600</td>\n",
       "      <td>1.465759</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.627107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.009400</td>\n",
       "      <td>1.465173</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.683126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.006900</td>\n",
       "      <td>1.522453</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.689440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.023600</td>\n",
       "      <td>1.665466</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.652413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>1.708059</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.686502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>1.592541</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.684371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>1.689717</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.655373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>1.671796</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.693187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.657901</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.706816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.665911</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.695429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.688813</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.689141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.703451</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.681741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.713502</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.697031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.719829</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.697031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.725491</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.689798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.729080</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.689798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.732085</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.689798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.735678</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.689798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.737804</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.689798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.741307</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.690285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.742100</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.690285</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['review', 'label'],\n",
       "        num_rows: 680\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['review', 'label'],\n",
       "        num_rows: 171\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorRoBERTa, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at otmangi/MorRoBERTa and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8714ed8f85047c69995b4a81eac2cd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ba97282d7f443f3afa12cb9b67db0ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:30, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.940800</td>\n",
       "      <td>0.729024</td>\n",
       "      <td>0.690058</td>\n",
       "      <td>0.473102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.721900</td>\n",
       "      <td>0.652799</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.562824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.487100</td>\n",
       "      <td>0.654006</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.609259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.295000</td>\n",
       "      <td>0.765373</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.602830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.191600</td>\n",
       "      <td>0.769938</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.656474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.083300</td>\n",
       "      <td>0.918485</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.637264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.032100</td>\n",
       "      <td>1.158455</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.626081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>1.356818</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.615735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>1.537312</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.603973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>1.596320</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.603973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>1.620211</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.594718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>1.638651</td>\n",
       "      <td>0.690058</td>\n",
       "      <td>0.590648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.662756</td>\n",
       "      <td>0.690058</td>\n",
       "      <td>0.590648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.684028</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.599297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.691739</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.603973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.702171</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.608755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.711404</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.608755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.717011</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.618072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.724815</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.618072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.733780</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.618072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.743363</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.618072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.749888</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.614033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.754265</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.614033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.759956</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.614033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.765164</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.614033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.770312</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.614033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.775489</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.614033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.778715</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.614033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.781624</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.614033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.783912</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.614033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.785556</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.614033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.786767</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.614033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.787272</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.614033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorRoBERTa, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at otmangi/MorRoBERTa and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62be811dae8245a988254546730d4438",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3c57a2f25a44c2dab361b055b6e1ca0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:31, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.940800</td>\n",
       "      <td>0.729024</td>\n",
       "      <td>0.690058</td>\n",
       "      <td>0.473102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.721900</td>\n",
       "      <td>0.652799</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.562824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.487100</td>\n",
       "      <td>0.654006</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.609259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.295000</td>\n",
       "      <td>0.765373</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.602830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.191600</td>\n",
       "      <td>0.769938</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.656474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.083300</td>\n",
       "      <td>0.918485</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.637264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.032100</td>\n",
       "      <td>1.158455</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.626081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>1.356818</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.615735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>1.537312</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.603973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>1.596320</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.603973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>1.620211</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.594718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>1.638651</td>\n",
       "      <td>0.690058</td>\n",
       "      <td>0.590648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.662756</td>\n",
       "      <td>0.690058</td>\n",
       "      <td>0.590648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.684028</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.599297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.691739</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.603973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.702171</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.608755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.711404</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.608755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.717011</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.618072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.724815</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.618072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.733780</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.618072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.743363</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.618072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.749888</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.614033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.754265</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.614033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.759956</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.614033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.765164</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.614033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.770312</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.614033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.775489</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.614033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.778715</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.614033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.781624</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.614033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.783912</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.614033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.785556</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.614033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.786767</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.614033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.787272</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.614033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorRoBERTa, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at otmangi/MorRoBERTa and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92da9bb80a194fa8882aa026e7c155b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c5b5add7f5e4a03adbe6277344d24e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:30, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.940800</td>\n",
       "      <td>0.729024</td>\n",
       "      <td>0.690058</td>\n",
       "      <td>0.473102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.721900</td>\n",
       "      <td>0.652799</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.562824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.487100</td>\n",
       "      <td>0.654006</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.609259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.295000</td>\n",
       "      <td>0.765373</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.602830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.191600</td>\n",
       "      <td>0.769938</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.656474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.083300</td>\n",
       "      <td>0.918485</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.637264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.032100</td>\n",
       "      <td>1.158455</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.626081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>1.356818</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.615735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>1.537312</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.603973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>1.596320</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.603973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>1.620211</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.594718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>1.638651</td>\n",
       "      <td>0.690058</td>\n",
       "      <td>0.590648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.662756</td>\n",
       "      <td>0.690058</td>\n",
       "      <td>0.590648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.684028</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.599297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.691739</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.603973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.702171</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.608755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.711404</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.608755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.717011</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.618072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.724815</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.618072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.733780</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.618072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.743363</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.618072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.749888</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.614033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.754265</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.614033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.759956</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.614033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.765164</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.614033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.770312</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.614033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.775489</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.614033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.778715</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.614033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.781624</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.614033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.783912</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.614033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.785556</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.614033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.786767</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.614033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.787272</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.614033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorRoBERTa, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at otmangi/MorRoBERTa and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b174b6e369df45cbb6723e317af1d732",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fd0a6554f434356b89949691cb54a82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:30, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.926200</td>\n",
       "      <td>0.727950</td>\n",
       "      <td>0.660819</td>\n",
       "      <td>0.473254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.636500</td>\n",
       "      <td>0.653357</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.645141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.381300</td>\n",
       "      <td>0.748424</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.644090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.237900</td>\n",
       "      <td>0.915584</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.647681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.076600</td>\n",
       "      <td>1.112188</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.663762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.031100</td>\n",
       "      <td>1.194125</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.680167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.012700</td>\n",
       "      <td>1.386351</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.669172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.004800</td>\n",
       "      <td>1.478761</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.637601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>1.518350</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.662626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>1.539509</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.652054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>1.561887</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.660497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>1.597700</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.663122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.621066</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.663122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.640165</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.663122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.650985</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.663122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.663648</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.664981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.674536</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.664981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.685778</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.664981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.695077</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.664981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.705743</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.664981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.713586</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.664981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.720115</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.664981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.725096</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.664981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.731997</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.664981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.737567</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.664981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.741739</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.664981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.746718</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.664981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.750111</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.664981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.753030</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.664981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.755316</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.664981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.756830</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.663122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.757781</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.663122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.758069</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.663122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorRoBERTa, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at otmangi/MorRoBERTa and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2108fbeeb2694726a9eeb2947206fc8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cc23c7dd4c4443292cfc4b752285f6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:31, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.926200</td>\n",
       "      <td>0.727950</td>\n",
       "      <td>0.660819</td>\n",
       "      <td>0.473254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.636500</td>\n",
       "      <td>0.653357</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.645141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.381300</td>\n",
       "      <td>0.748424</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.644090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.237900</td>\n",
       "      <td>0.915584</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.647681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.076600</td>\n",
       "      <td>1.112188</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.663762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.031100</td>\n",
       "      <td>1.194125</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.680167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.012700</td>\n",
       "      <td>1.386351</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.669172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.004800</td>\n",
       "      <td>1.478761</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.637601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>1.518350</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.662626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>1.539509</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.652054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>1.561887</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.660497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>1.597700</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.663122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.621066</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.663122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.640165</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.663122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.650985</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.663122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.663648</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.664981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.674536</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.664981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.685778</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.664981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.695077</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.664981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.705743</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.664981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.713586</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.664981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.720115</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.664981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.725096</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.664981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.731997</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.664981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.737567</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.664981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.741739</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.664981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.746718</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.664981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.750111</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.664981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.753030</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.664981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.755316</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.664981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.756830</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.663122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.757781</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.663122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.758069</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.663122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorRoBERTa, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at otmangi/MorRoBERTa and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90ce51d6a510420d99443279d1bdc86f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e2a58e8053f4122b77da5199599f54a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:30, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.926200</td>\n",
       "      <td>0.727950</td>\n",
       "      <td>0.660819</td>\n",
       "      <td>0.473254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.636500</td>\n",
       "      <td>0.653357</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.645141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.381300</td>\n",
       "      <td>0.748424</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.644090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.237900</td>\n",
       "      <td>0.915584</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.647681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.076600</td>\n",
       "      <td>1.112188</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.663762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.031100</td>\n",
       "      <td>1.194125</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.680167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.012700</td>\n",
       "      <td>1.386351</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.669172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.004800</td>\n",
       "      <td>1.478761</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.637601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>1.518350</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.662626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>1.539509</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.652054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>1.561887</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.660497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>1.597700</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.663122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.621066</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.663122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.640165</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.663122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.650985</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.663122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.663648</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.664981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.674536</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.664981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.685778</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.664981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.695077</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.664981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.705743</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.664981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.713586</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.664981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.720115</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.664981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.725096</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.664981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.731997</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.664981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.737567</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.664981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.741739</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.664981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.746718</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.664981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.750111</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.664981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.753030</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.664981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.755316</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.664981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.756830</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.663122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.757781</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.663122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.758069</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.663122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorRoBERTa, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at otmangi/MorRoBERTa and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba85b7dd3c13446391769f064cb9abd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "014913f655174292b641fc25230271ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:31, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.916600</td>\n",
       "      <td>0.811350</td>\n",
       "      <td>0.637427</td>\n",
       "      <td>0.447965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.681900</td>\n",
       "      <td>0.692657</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.561247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.488200</td>\n",
       "      <td>0.659842</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.638056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.310800</td>\n",
       "      <td>0.714185</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.688676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.163600</td>\n",
       "      <td>0.744598</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.689499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.062200</td>\n",
       "      <td>0.920391</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.661020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.021600</td>\n",
       "      <td>1.079296</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.676982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>1.230929</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.667701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>1.242159</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.680173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>1.301058</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.702497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>1.386848</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.659179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>1.445033</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.657118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.425416</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.669282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>1.438686</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.670121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.451893</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.676563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.466811</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.671573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.481748</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.671573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.496140</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.672053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.505434</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.672053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.511035</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.672053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.517212</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.672053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.522947</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.667029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.526564</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.670121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.530103</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.670121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.531914</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.670121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.535345</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.670121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.537703</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.669658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.540551</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.669658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.542983</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.669658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.545138</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.669658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.546623</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.670121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.547404</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.670121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.547886</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.670121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorRoBERTa, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at otmangi/MorRoBERTa and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce4d1f9ebd5f4fcfac42554343ea02e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68acad8c0427463c9f7d92d9e2ea6b68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:30, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.916600</td>\n",
       "      <td>0.811350</td>\n",
       "      <td>0.637427</td>\n",
       "      <td>0.447965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.681900</td>\n",
       "      <td>0.692657</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.561247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.488200</td>\n",
       "      <td>0.659842</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.638056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.310800</td>\n",
       "      <td>0.714185</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.688676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.163600</td>\n",
       "      <td>0.744598</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.689499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.062200</td>\n",
       "      <td>0.920391</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.661020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.021600</td>\n",
       "      <td>1.079296</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.676982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>1.230929</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.667701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>1.242159</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.680173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>1.301058</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.702497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>1.386848</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.659179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>1.445033</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.657118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.425416</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.669282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>1.438686</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.670121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.451893</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.676563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.466811</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.671573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.481748</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.671573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.496140</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.672053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.505434</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.672053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.511035</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.672053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.517212</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.672053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.522947</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.667029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.526564</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.670121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.530103</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.670121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.531914</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.670121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.535345</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.670121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.537703</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.669658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.540551</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.669658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.542983</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.669658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.545138</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.669658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.546623</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.670121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.547404</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.670121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.547886</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.670121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorRoBERTa, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at otmangi/MorRoBERTa and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d49c5817f214038a7248f568be72b4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "648c961db40441ccbab7a2b493b68d5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:31, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.916600</td>\n",
       "      <td>0.811350</td>\n",
       "      <td>0.637427</td>\n",
       "      <td>0.447965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.681900</td>\n",
       "      <td>0.692657</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.561247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.488200</td>\n",
       "      <td>0.659842</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.638056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.310800</td>\n",
       "      <td>0.714185</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.688676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.163600</td>\n",
       "      <td>0.744598</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.689499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.062200</td>\n",
       "      <td>0.920391</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.661020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.021600</td>\n",
       "      <td>1.079296</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.676982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>1.230929</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.667701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>1.242159</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.680173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>1.301058</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.702497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>1.386848</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.659179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>1.445033</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.657118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.425416</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.669282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>1.438686</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.670121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.451893</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.676563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.466811</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.671573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.481748</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.671573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.496140</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.672053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.505434</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.672053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.511035</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.672053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.517212</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.672053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.522947</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.667029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.526564</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.670121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.530103</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.670121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.531914</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.670121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.535345</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.670121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.537703</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.669658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.540551</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.669658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.542983</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.669658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.545138</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.669658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.546623</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.670121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.547404</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.670121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.547886</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.670121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['review', 'label'],\n",
       "        num_rows: 680\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['review', 'label'],\n",
       "        num_rows: 171\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorrBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at otmangi/MorrBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8576afba2d74ce091515e21a31fe1c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd456d00b80c4be6b25324f74f0c47e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:54, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.890700</td>\n",
       "      <td>0.655918</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.557969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.583200</td>\n",
       "      <td>0.539254</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.672943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.359000</td>\n",
       "      <td>0.530747</td>\n",
       "      <td>0.783626</td>\n",
       "      <td>0.718762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.170200</td>\n",
       "      <td>0.648623</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.700626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.087400</td>\n",
       "      <td>0.793387</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.635815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.023700</td>\n",
       "      <td>0.894862</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.672902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>1.036612</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.656363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.012600</td>\n",
       "      <td>1.109487</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.643343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>1.095922</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.678209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1.100882</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.674938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.007900</td>\n",
       "      <td>1.184865</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.629149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.008700</td>\n",
       "      <td>1.312802</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.614444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.008400</td>\n",
       "      <td>1.110114</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.690191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>1.147763</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.695436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.009400</td>\n",
       "      <td>1.140996</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.678877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>1.291139</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.666383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.006200</td>\n",
       "      <td>1.337791</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.645414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>1.261745</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.665782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>1.253644</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.673401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.005700</td>\n",
       "      <td>1.243951</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.672524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>1.254074</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.671704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>1.263923</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.675925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>1.233766</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.684632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>1.243187</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.684632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>1.248508</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.684632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>1.253061</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.684632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>1.262446</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.684632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>1.263436</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.684632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.010600</td>\n",
       "      <td>1.256806</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.684632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>1.253027</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.690298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>1.254811</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.690298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.007700</td>\n",
       "      <td>1.257765</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.690298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>1.257569</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.690298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorrBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at otmangi/MorrBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63d161adb30d4e138c7f4f518e8491ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee80dfe1b14047828b63fea8207f8af6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:54, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.890700</td>\n",
       "      <td>0.655918</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.557969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.583200</td>\n",
       "      <td>0.539254</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.672943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.359000</td>\n",
       "      <td>0.530747</td>\n",
       "      <td>0.783626</td>\n",
       "      <td>0.718762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.170200</td>\n",
       "      <td>0.648623</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.700626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.087400</td>\n",
       "      <td>0.793387</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.635815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.023700</td>\n",
       "      <td>0.894862</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.672902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>1.036612</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.656363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.012600</td>\n",
       "      <td>1.109487</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.643343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>1.095922</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.678209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1.100882</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.674938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.007900</td>\n",
       "      <td>1.184865</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.629149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.008700</td>\n",
       "      <td>1.312802</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.614444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.008400</td>\n",
       "      <td>1.110114</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.690191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>1.147763</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.695436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.009400</td>\n",
       "      <td>1.140996</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.678877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>1.291139</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.666383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.006200</td>\n",
       "      <td>1.337791</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.645414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>1.261745</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.665782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>1.253644</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.673401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.005700</td>\n",
       "      <td>1.243951</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.672524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>1.254074</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.671704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>1.263923</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.675925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>1.233766</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.684632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>1.243187</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.684632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>1.248508</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.684632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>1.253061</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.684632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>1.262446</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.684632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>1.263436</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.684632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.010600</td>\n",
       "      <td>1.256806</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.684632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>1.253027</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.690298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>1.254811</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.690298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.007700</td>\n",
       "      <td>1.257765</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.690298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>1.257569</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.690298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorrBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at otmangi/MorrBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79de927e6b02425c879129579171417a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cffdd7778ec445028369649daa71fb45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:54, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.890700</td>\n",
       "      <td>0.655918</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.557969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.583200</td>\n",
       "      <td>0.539254</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.672943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.359000</td>\n",
       "      <td>0.530747</td>\n",
       "      <td>0.783626</td>\n",
       "      <td>0.718762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.170200</td>\n",
       "      <td>0.648623</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.700626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.087400</td>\n",
       "      <td>0.793387</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.635815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.023700</td>\n",
       "      <td>0.894862</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.672902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>1.036612</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.656363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.012600</td>\n",
       "      <td>1.109487</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.643343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>1.095922</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.678209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1.100882</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.674938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.007900</td>\n",
       "      <td>1.184865</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.629149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.008700</td>\n",
       "      <td>1.312802</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.614444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.008400</td>\n",
       "      <td>1.110114</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.690191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>1.147763</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.695436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.009400</td>\n",
       "      <td>1.140996</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.678877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>1.291139</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.666383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.006200</td>\n",
       "      <td>1.337791</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.645414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>1.261745</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.665782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>1.253644</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.673401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.005700</td>\n",
       "      <td>1.243951</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.672524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>1.254074</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.671704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>1.263923</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.675925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>1.233766</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.684632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>1.243187</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.684632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>1.248508</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.684632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>1.253061</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.684632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>1.262446</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.684632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>1.263436</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.684632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.010600</td>\n",
       "      <td>1.256806</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.684632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>1.253027</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.690298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>1.254811</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.690298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.007700</td>\n",
       "      <td>1.257765</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.690298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>1.257569</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.690298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorrBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at otmangi/MorrBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08ea3d61eaad4d479ef0c91437f3aa16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4ccbc584f4c4ffe8e4ef4bfe03c3f62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:54, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.882700</td>\n",
       "      <td>0.689102</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.670872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.518600</td>\n",
       "      <td>0.604748</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.694730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.250700</td>\n",
       "      <td>0.655632</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.695343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.125400</td>\n",
       "      <td>0.923887</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.686097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.051300</td>\n",
       "      <td>1.151796</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.657593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.053800</td>\n",
       "      <td>1.132660</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.704831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.032800</td>\n",
       "      <td>1.257689</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.638695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.027700</td>\n",
       "      <td>1.292087</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.688817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>1.419079</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.676613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.008900</td>\n",
       "      <td>1.486625</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.668392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.009800</td>\n",
       "      <td>1.465107</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.690562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>1.472646</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.689360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>1.506930</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.689360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>1.563231</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.683951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.007100</td>\n",
       "      <td>1.575053</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.672160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>1.586040</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.672160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>1.621991</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.672160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>1.636383</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.677984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>1.635362</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.677984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>1.635633</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.674172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.007400</td>\n",
       "      <td>1.674777</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.683951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>1.681661</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.683951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>1.685207</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.683951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>1.693635</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.683951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.698665</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.683951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.698185</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.689360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.703622</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.689360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.707476</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.689360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>1.714110</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.683951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>1.718653</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.683951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.721954</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.683951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.723209</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.683951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.723049</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.683951</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorrBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at otmangi/MorrBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "161781e0784547079dfc794f720a8064",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e516e78f44334e3c8c9718c28c488676",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:54, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.882700</td>\n",
       "      <td>0.689102</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.670872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.518600</td>\n",
       "      <td>0.604748</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.694730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.250700</td>\n",
       "      <td>0.655632</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.695343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.125400</td>\n",
       "      <td>0.923887</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.686097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.051300</td>\n",
       "      <td>1.151796</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.657593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.053800</td>\n",
       "      <td>1.132660</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.704831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.032800</td>\n",
       "      <td>1.257689</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.638695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.027700</td>\n",
       "      <td>1.292087</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.688817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>1.419079</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.676613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.008900</td>\n",
       "      <td>1.486625</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.668392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.009800</td>\n",
       "      <td>1.465107</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.690562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>1.472646</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.689360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>1.506930</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.689360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>1.563231</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.683951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.007100</td>\n",
       "      <td>1.575053</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.672160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>1.586040</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.672160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>1.621991</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.672160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>1.636383</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.677984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>1.635362</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.677984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>1.635633</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.674172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.007400</td>\n",
       "      <td>1.674777</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.683951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>1.681661</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.683951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>1.685207</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.683951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>1.693635</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.683951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.698665</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.683951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.698185</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.689360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.703622</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.689360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.707476</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.689360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>1.714110</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.683951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>1.718653</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.683951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.721954</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.683951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.723209</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.683951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.723049</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.683951</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorrBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at otmangi/MorrBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e7da87b23a145fcb3d09217e156f049",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfe0efaa2aa047129623b6b0e8a24048",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:54, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.882700</td>\n",
       "      <td>0.689102</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.670872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.518600</td>\n",
       "      <td>0.604748</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.694730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.250700</td>\n",
       "      <td>0.655632</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.695343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.125400</td>\n",
       "      <td>0.923887</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.686097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.051300</td>\n",
       "      <td>1.151796</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.657593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.053800</td>\n",
       "      <td>1.132660</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.704831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.032800</td>\n",
       "      <td>1.257689</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.638695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.027700</td>\n",
       "      <td>1.292087</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.688817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>1.419079</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.676613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.008900</td>\n",
       "      <td>1.486625</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.668392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.009800</td>\n",
       "      <td>1.465107</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.690562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>1.472646</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.689360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>1.506930</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.689360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>1.563231</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.683951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.007100</td>\n",
       "      <td>1.575053</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.672160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>1.586040</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.672160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>1.621991</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.672160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>1.636383</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.677984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>1.635362</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.677984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>1.635633</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.674172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.007400</td>\n",
       "      <td>1.674777</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.683951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>1.681661</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.683951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>1.685207</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.683951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>1.693635</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.683951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.698665</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.683951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.698185</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.689360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.703622</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.689360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.707476</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.689360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>1.714110</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.683951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>1.718653</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.683951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.721954</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.683951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.723209</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.683951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.723049</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.683951</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorrBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at otmangi/MorrBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "792eb68399ff4011a1062e5e556c2ebe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea147b96b347499c8c71ed9de756a280",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:54, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.857800</td>\n",
       "      <td>0.737201</td>\n",
       "      <td>0.672515</td>\n",
       "      <td>0.548150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.521200</td>\n",
       "      <td>0.620659</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.682428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.280600</td>\n",
       "      <td>0.628046</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.703291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.147400</td>\n",
       "      <td>0.656563</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.706579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.063700</td>\n",
       "      <td>0.790032</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.696630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.012600</td>\n",
       "      <td>0.940160</td>\n",
       "      <td>0.795322</td>\n",
       "      <td>0.736419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.022900</td>\n",
       "      <td>0.979153</td>\n",
       "      <td>0.795322</td>\n",
       "      <td>0.733234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.015100</td>\n",
       "      <td>1.119048</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.696211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.012400</td>\n",
       "      <td>1.297755</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.663988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.201116</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.717730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.008700</td>\n",
       "      <td>1.158416</td>\n",
       "      <td>0.795322</td>\n",
       "      <td>0.753361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.006300</td>\n",
       "      <td>1.164359</td>\n",
       "      <td>0.801170</td>\n",
       "      <td>0.760085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>1.156988</td>\n",
       "      <td>0.807018</td>\n",
       "      <td>0.757169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>1.231331</td>\n",
       "      <td>0.783626</td>\n",
       "      <td>0.730247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.012300</td>\n",
       "      <td>1.195485</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.735359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>1.175244</td>\n",
       "      <td>0.795322</td>\n",
       "      <td>0.747426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.007700</td>\n",
       "      <td>1.170387</td>\n",
       "      <td>0.812865</td>\n",
       "      <td>0.762196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>1.185748</td>\n",
       "      <td>0.807018</td>\n",
       "      <td>0.757169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>1.200799</td>\n",
       "      <td>0.801170</td>\n",
       "      <td>0.752107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>1.224016</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.735359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>1.251032</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.735359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>1.259752</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.735359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>1.268185</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.735359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>1.277431</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.735359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>1.292286</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.725093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>1.293287</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.735359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>1.292053</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.735359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>1.290711</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.735359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>1.293105</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.735359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>1.298751</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.735359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.007800</td>\n",
       "      <td>1.299413</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.735359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>1.301360</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.735359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>1.302122</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.735359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorrBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at otmangi/MorrBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd7a43a36d074270b40c276744f86a9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b87cae5bc61941c6a27249a912e7b3ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:54, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.857800</td>\n",
       "      <td>0.737201</td>\n",
       "      <td>0.672515</td>\n",
       "      <td>0.548150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.521200</td>\n",
       "      <td>0.620659</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.682428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.280600</td>\n",
       "      <td>0.628046</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.703291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.147400</td>\n",
       "      <td>0.656563</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.706579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.063700</td>\n",
       "      <td>0.790032</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.696630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.012600</td>\n",
       "      <td>0.940160</td>\n",
       "      <td>0.795322</td>\n",
       "      <td>0.736419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.022900</td>\n",
       "      <td>0.979153</td>\n",
       "      <td>0.795322</td>\n",
       "      <td>0.733234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.015100</td>\n",
       "      <td>1.119048</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.696211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.012400</td>\n",
       "      <td>1.297755</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.663988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.201116</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.717730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.008700</td>\n",
       "      <td>1.158416</td>\n",
       "      <td>0.795322</td>\n",
       "      <td>0.753361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.006300</td>\n",
       "      <td>1.164359</td>\n",
       "      <td>0.801170</td>\n",
       "      <td>0.760085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>1.156988</td>\n",
       "      <td>0.807018</td>\n",
       "      <td>0.757169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>1.231331</td>\n",
       "      <td>0.783626</td>\n",
       "      <td>0.730247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.012300</td>\n",
       "      <td>1.195485</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.735359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>1.175244</td>\n",
       "      <td>0.795322</td>\n",
       "      <td>0.747426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.007700</td>\n",
       "      <td>1.170387</td>\n",
       "      <td>0.812865</td>\n",
       "      <td>0.762196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>1.185748</td>\n",
       "      <td>0.807018</td>\n",
       "      <td>0.757169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>1.200799</td>\n",
       "      <td>0.801170</td>\n",
       "      <td>0.752107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>1.224016</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.735359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>1.251032</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.735359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>1.259752</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.735359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>1.268185</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.735359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>1.277431</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.735359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>1.292286</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.725093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>1.293287</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.735359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>1.292053</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.735359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>1.290711</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.735359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>1.293105</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.735359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>1.298751</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.735359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.007800</td>\n",
       "      <td>1.299413</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.735359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>1.301360</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.735359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>1.302122</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.735359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorrBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at otmangi/MorrBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5ff12d2460b42cab6e7db15f08c4ada",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a22f35ca2f9407786fe8db7403fb670",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:53, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.857800</td>\n",
       "      <td>0.737201</td>\n",
       "      <td>0.672515</td>\n",
       "      <td>0.548150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.521200</td>\n",
       "      <td>0.620659</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.682428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.280600</td>\n",
       "      <td>0.628046</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.703291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.147400</td>\n",
       "      <td>0.656563</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.706579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.063700</td>\n",
       "      <td>0.790032</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.696630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.012600</td>\n",
       "      <td>0.940160</td>\n",
       "      <td>0.795322</td>\n",
       "      <td>0.736419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.022900</td>\n",
       "      <td>0.979153</td>\n",
       "      <td>0.795322</td>\n",
       "      <td>0.733234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.015100</td>\n",
       "      <td>1.119048</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.696211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.012400</td>\n",
       "      <td>1.297755</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.663988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.201116</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.717730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.008700</td>\n",
       "      <td>1.158416</td>\n",
       "      <td>0.795322</td>\n",
       "      <td>0.753361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.006300</td>\n",
       "      <td>1.164359</td>\n",
       "      <td>0.801170</td>\n",
       "      <td>0.760085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>1.156988</td>\n",
       "      <td>0.807018</td>\n",
       "      <td>0.757169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>1.231331</td>\n",
       "      <td>0.783626</td>\n",
       "      <td>0.730247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.012300</td>\n",
       "      <td>1.195485</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.735359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>1.175244</td>\n",
       "      <td>0.795322</td>\n",
       "      <td>0.747426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.007700</td>\n",
       "      <td>1.170387</td>\n",
       "      <td>0.812865</td>\n",
       "      <td>0.762196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>1.185748</td>\n",
       "      <td>0.807018</td>\n",
       "      <td>0.757169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>1.200799</td>\n",
       "      <td>0.801170</td>\n",
       "      <td>0.752107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>1.224016</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.735359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>1.251032</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.735359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>1.259752</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.735359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>1.268185</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.735359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>1.277431</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.735359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>1.292286</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.725093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>1.293287</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.735359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>1.292053</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.735359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>1.290711</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.735359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>1.293105</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.735359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>1.298751</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.735359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.007800</td>\n",
       "      <td>1.299413</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.735359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>1.301360</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.735359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>1.302122</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.735359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SI2M-Lab/DarijaBERT</td>\n",
       "      <td>0.812865</td>\n",
       "      <td>0.755959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alger-ia/dziribert</td>\n",
       "      <td>0.812865</td>\n",
       "      <td>0.755253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>faisalq/EgyBERT</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.693996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>faisalq/SaudiBERT</td>\n",
       "      <td>0.824561</td>\n",
       "      <td>0.752299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>otmangi/MorRoBERTa</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.702497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>otmangi/MorrBERT</td>\n",
       "      <td>0.812865</td>\n",
       "      <td>0.762196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>tunis-ai/TunBERT</td>\n",
       "      <td>0.654971</td>\n",
       "      <td>0.568556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model  Accuracy        F1\n",
       "0   SI2M-Lab/DarijaBERT  0.812865  0.755959\n",
       "3    alger-ia/dziribert  0.812865  0.755253\n",
       "6       faisalq/EgyBERT  0.766082  0.693996\n",
       "9     faisalq/SaudiBERT  0.824561  0.752299\n",
       "12   otmangi/MorRoBERTa  0.771930  0.702497\n",
       "15     otmangi/MorrBERT  0.812865  0.762196\n",
       "18     tunis-ai/TunBERT  0.654971  0.568556"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" \n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import pyarabic.araby as araby\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.initializers import TruncatedNormal\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from datasets import load_dataset, Dataset, concatenate_datasets\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', 1000)\n",
    "\n",
    "\n",
    "fname = 'dreviews_2'\n",
    "log_file = fname + '.txt'\n",
    "\n",
    "with open(log_file, 'w') as f:\n",
    "    f.write('Model,Accuracy,F1\\n')\n",
    "\n",
    "\n",
    "dataset = load_dataset('ohidaoui/darija-reviews')\n",
    "\n",
    "\n",
    "df = pd.DataFrame(dataset['test'])\n",
    "\n",
    "display(len(df))\n",
    "      \n",
    "display(df.columns)\n",
    "display(df[:4])\n",
    "\n",
    "df['label'] = df['label'].replace('negative ', 'negative')\n",
    "\n",
    "c = df['label'].value_counts()\n",
    "display(c)\n",
    "\n",
    "classes = set(df['label'].values)\n",
    "display(classes)\n",
    "\n",
    "df['label'] = df['label'].astype('category')\n",
    "df['label'] = df['label'].cat.codes\n",
    "\n",
    "df = df[['review', 'label']]\n",
    "classes_num = len(classes)\n",
    "display(classes_num)\n",
    "display(len(df))\n",
    "\n",
    "\n",
    "\n",
    "max_sequence_length = 128\n",
    "\n",
    "\n",
    "\n",
    "models = [ \n",
    "        'faisalq/EgyBERT',            \n",
    "    'faisalq/SaudiBERT',            \n",
    "    'tunis-ai/TunBERT',\n",
    "    'alger-ia/dziribert',\n",
    "    'SI2M-Lab/DarijaBERT',\n",
    "    'otmangi/MorRoBERTa',\n",
    "    'otmangi/MorrBERT'\n",
    "            \n",
    "]\n",
    "\n",
    "\n",
    "seeds = [0, 1, 42]\n",
    "\n",
    "for model_name in models:\n",
    "    for seed in seeds:\n",
    "        ds = Dataset.from_pandas(df)\n",
    "        ds = ds.train_test_split(test_size=0.2, seed = seed)\n",
    "        if seed==0:\n",
    "            display(ds)\n",
    "            \n",
    "        for i in range(3):\n",
    "            print(f'{model_name}, try:{i}')\n",
    "                  \n",
    "            tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "            model = AutoModelForSequenceClassification.from_pretrained(model_name,\n",
    "                                                                  num_labels=classes_num).to('cuda')                                                 \n",
    "            dataset_train = ds['train']\n",
    "            dataset_validation = ds['test']                                                    \n",
    "            \n",
    "          \n",
    "    \n",
    "            def preprocess_function(examples):\n",
    "                return tokenizer(examples['review'], truncation=True, padding=\"max_length\",\n",
    "                                max_length=max_sequence_length)\n",
    "            \n",
    "            \n",
    "            dataset_train = dataset_train.map(preprocess_function, batched=True)\n",
    "            dataset_validation = dataset_validation.map(preprocess_function, batched=True)\n",
    "            \n",
    "           \n",
    "            \n",
    "            def compute_metrics(eval_pred):\n",
    "                logits, labels = eval_pred\n",
    "                predictions = np.argmax(logits, axis=-1)    \n",
    "                acc = accuracy_score(labels, predictions)        \n",
    "                f1 = f1_score(labels, predictions, average='macro')   \n",
    "                with open(log_file, 'a') as f:\n",
    "                    f.write(f'{model_name},{acc},{f1}\\n')\n",
    "                return {'accuracy': acc, 'f1_score': f1}\n",
    "    \n",
    "    \n",
    "            \n",
    "            \n",
    "            epochs = 30\n",
    "            save_steps = 10000 #save checkpoint every 10000 steps\n",
    "            batch_size = 64\n",
    "            \n",
    "            training_args = TrainingArguments(\n",
    "                output_dir = 'bert/',\n",
    "                overwrite_output_dir=True,\n",
    "                num_train_epochs = epochs,\n",
    "                per_device_train_batch_size = batch_size,\n",
    "                per_device_eval_batch_size = batch_size,\n",
    "                save_steps = save_steps,\n",
    "                save_total_limit = 1, #only save the last 5 checkpoints\n",
    "                fp16=True,\n",
    "                learning_rate = 5e-5,  # 5e-5 is the default\n",
    "                logging_steps = 10, #50_000\n",
    "                evaluation_strategy = 'steps',\n",
    "                # evaluate_during_training = True,\n",
    "                eval_steps = 10\n",
    "                \n",
    "            )\n",
    "            \n",
    "            trainer = Trainer(\n",
    "                model = model,\n",
    "                args = training_args,\n",
    "                # data_collator=data_collator,\n",
    "                train_dataset=dataset_train,\n",
    "                eval_dataset=dataset_validation,\n",
    "                compute_metrics = compute_metrics\n",
    "            )\n",
    "            \n",
    "            \n",
    "            trainer.train()\n",
    "\n",
    "\n",
    "results = pd.read_csv(log_file)\n",
    "\n",
    "best_results = results.groupby('Model', as_index=False)['F1'].max()\n",
    "\n",
    "best_results = pd.merge(best_results, results, on=['Model', 'F1'])\n",
    "best_results = best_results[['Model', 'Accuracy', 'F1']]\n",
    "best_results = best_results.drop_duplicates()\n",
    "best_results.to_csv(f'{fname}.csv')\n",
    "display(best_results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a213ac86-934f-4e82-a949-0bcdcae2188d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220784d6-b06d-4429-adb8-0026654f9d49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8647cf08-3aa6-44eb-846f-4bed97554042",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e203fa6b-c9d7-44a4-b501-a67bfd3e4ce4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8794b705-31a1-45d7-8e88-4017a9c282aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
