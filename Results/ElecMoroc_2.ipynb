{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d804ae66-9435-44be-8aad-beacbdeec0f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-17 08:49:53.047222: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-17 08:49:53.071804: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-17 08:49:53.540790: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['index', 'comment_message', 'sentiment', 'comment_published'], dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "10254"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>comment_message</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>comment_published</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>البكاء ليس سمت الرجال ..البكاء سلطة الضعفاء لكسب التعاطف ..انا لست ضد بنكيران وانما الرجل الصالح هو الذي يفعل ما يقول ولا يبكي الا عند النصر</td>\n",
       "      <td>N</td>\n",
       "      <td>2016-10-01 00:07:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>كلنا بنكيران\\nولاية ثانية ان شاء الله\\nموتوا بحقدكم</td>\n",
       "      <td>P</td>\n",
       "      <td>2016-10-01 00:47:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>الشركات في الدول المتقدمة تساهم في بناء أوطانها بدفع الضرائب وفي بلدنا العزيز الشركات تطلب من الدولة أن تخدم عليها؟</td>\n",
       "      <td>N</td>\n",
       "      <td>2016-10-01 00:48:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>من ينتقد بن كران هم خصوم معارضة لى خاصها هي سلطة لا تهتم لوضعية مواطن</td>\n",
       "      <td>N</td>\n",
       "      <td>2016-10-01 00:49:10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index   \n",
       "0      1  \\\n",
       "1      2   \n",
       "2      3   \n",
       "3      4   \n",
       "\n",
       "                                                                                                                                comment_message   \n",
       "0  البكاء ليس سمت الرجال ..البكاء سلطة الضعفاء لكسب التعاطف ..انا لست ضد بنكيران وانما الرجل الصالح هو الذي يفعل ما يقول ولا يبكي الا عند النصر  \\\n",
       "1                                                                                           كلنا بنكيران\\nولاية ثانية ان شاء الله\\nموتوا بحقدكم   \n",
       "2                           الشركات في الدول المتقدمة تساهم في بناء أوطانها بدفع الضرائب وفي بلدنا العزيز الشركات تطلب من الدولة أن تخدم عليها؟   \n",
       "3                                                                         من ينتقد بن كران هم خصوم معارضة لى خاصها هي سلطة لا تهتم لوضعية مواطن   \n",
       "\n",
       "  sentiment    comment_published  \n",
       "0         N  2016-10-01 00:07:44  \n",
       "1         P  2016-10-01 00:47:37  \n",
       "2         N  2016-10-01 00:48:02  \n",
       "3         N  2016-10-01 00:49:10  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'N', 'P'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "N    6581\n",
       "P    3673\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "10254"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['comment_message', 'label'],\n",
       "        num_rows: 8203\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['comment_message', 'label'],\n",
       "        num_rows: 2051\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/EgyBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/EgyBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8203 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2051 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1935' max='1935' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1935/1935 03:06, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.592400</td>\n",
       "      <td>0.422221</td>\n",
       "      <td>0.855193</td>\n",
       "      <td>0.832285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.427900</td>\n",
       "      <td>0.393563</td>\n",
       "      <td>0.840566</td>\n",
       "      <td>0.825861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.350100</td>\n",
       "      <td>0.371877</td>\n",
       "      <td>0.860556</td>\n",
       "      <td>0.838965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.308400</td>\n",
       "      <td>0.335968</td>\n",
       "      <td>0.865431</td>\n",
       "      <td>0.845727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.273500</td>\n",
       "      <td>0.375797</td>\n",
       "      <td>0.858118</td>\n",
       "      <td>0.843950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.230400</td>\n",
       "      <td>0.363057</td>\n",
       "      <td>0.866894</td>\n",
       "      <td>0.847947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.175200</td>\n",
       "      <td>0.434421</td>\n",
       "      <td>0.862506</td>\n",
       "      <td>0.845805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.166800</td>\n",
       "      <td>0.472654</td>\n",
       "      <td>0.849829</td>\n",
       "      <td>0.835309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.150100</td>\n",
       "      <td>0.462936</td>\n",
       "      <td>0.856168</td>\n",
       "      <td>0.840436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.106100</td>\n",
       "      <td>0.546622</td>\n",
       "      <td>0.836665</td>\n",
       "      <td>0.822890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.114800</td>\n",
       "      <td>0.539000</td>\n",
       "      <td>0.855193</td>\n",
       "      <td>0.836832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.082100</td>\n",
       "      <td>0.550492</td>\n",
       "      <td>0.858118</td>\n",
       "      <td>0.840363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.094900</td>\n",
       "      <td>0.555311</td>\n",
       "      <td>0.854705</td>\n",
       "      <td>0.834986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.560313</td>\n",
       "      <td>0.852267</td>\n",
       "      <td>0.835885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.064300</td>\n",
       "      <td>0.595917</td>\n",
       "      <td>0.860068</td>\n",
       "      <td>0.842210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.050700</td>\n",
       "      <td>0.638482</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.840973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.049000</td>\n",
       "      <td>0.642734</td>\n",
       "      <td>0.855680</td>\n",
       "      <td>0.839066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.034500</td>\n",
       "      <td>0.680906</td>\n",
       "      <td>0.862019</td>\n",
       "      <td>0.841624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.045600</td>\n",
       "      <td>0.674063</td>\n",
       "      <td>0.853730</td>\n",
       "      <td>0.838651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.032300</td>\n",
       "      <td>0.711119</td>\n",
       "      <td>0.852755</td>\n",
       "      <td>0.837144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.035600</td>\n",
       "      <td>0.689080</td>\n",
       "      <td>0.861043</td>\n",
       "      <td>0.842604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.022400</td>\n",
       "      <td>0.691943</td>\n",
       "      <td>0.865431</td>\n",
       "      <td>0.847861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.028100</td>\n",
       "      <td>0.712274</td>\n",
       "      <td>0.861043</td>\n",
       "      <td>0.843309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.020700</td>\n",
       "      <td>0.725044</td>\n",
       "      <td>0.860068</td>\n",
       "      <td>0.842442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.014000</td>\n",
       "      <td>0.754554</td>\n",
       "      <td>0.859581</td>\n",
       "      <td>0.843415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.018000</td>\n",
       "      <td>0.749283</td>\n",
       "      <td>0.864944</td>\n",
       "      <td>0.847708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.018200</td>\n",
       "      <td>0.733151</td>\n",
       "      <td>0.866894</td>\n",
       "      <td>0.848772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.016000</td>\n",
       "      <td>0.796885</td>\n",
       "      <td>0.855193</td>\n",
       "      <td>0.839135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>0.780296</td>\n",
       "      <td>0.865431</td>\n",
       "      <td>0.847168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.011600</td>\n",
       "      <td>0.788550</td>\n",
       "      <td>0.863481</td>\n",
       "      <td>0.846115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.010700</td>\n",
       "      <td>0.802567</td>\n",
       "      <td>0.858118</td>\n",
       "      <td>0.841506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.007900</td>\n",
       "      <td>0.803683</td>\n",
       "      <td>0.858606</td>\n",
       "      <td>0.841995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/EgyBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/EgyBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8203 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2051 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1935' max='1935' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1935/1935 03:06, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.592100</td>\n",
       "      <td>0.432106</td>\n",
       "      <td>0.850804</td>\n",
       "      <td>0.828545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.433000</td>\n",
       "      <td>0.396028</td>\n",
       "      <td>0.840566</td>\n",
       "      <td>0.823604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.355700</td>\n",
       "      <td>0.364594</td>\n",
       "      <td>0.859093</td>\n",
       "      <td>0.835552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.307600</td>\n",
       "      <td>0.343426</td>\n",
       "      <td>0.860068</td>\n",
       "      <td>0.840275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.266400</td>\n",
       "      <td>0.436650</td>\n",
       "      <td>0.840566</td>\n",
       "      <td>0.828212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.219200</td>\n",
       "      <td>0.371049</td>\n",
       "      <td>0.862506</td>\n",
       "      <td>0.846136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.173000</td>\n",
       "      <td>0.485537</td>\n",
       "      <td>0.842028</td>\n",
       "      <td>0.828655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.158800</td>\n",
       "      <td>0.475682</td>\n",
       "      <td>0.837153</td>\n",
       "      <td>0.823470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.136500</td>\n",
       "      <td>0.501470</td>\n",
       "      <td>0.848367</td>\n",
       "      <td>0.834585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.101600</td>\n",
       "      <td>0.522296</td>\n",
       "      <td>0.855680</td>\n",
       "      <td>0.841011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.096900</td>\n",
       "      <td>0.575852</td>\n",
       "      <td>0.855680</td>\n",
       "      <td>0.839066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.082900</td>\n",
       "      <td>0.583193</td>\n",
       "      <td>0.858118</td>\n",
       "      <td>0.837407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.086300</td>\n",
       "      <td>0.633902</td>\n",
       "      <td>0.834715</td>\n",
       "      <td>0.821194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.072600</td>\n",
       "      <td>0.657600</td>\n",
       "      <td>0.840566</td>\n",
       "      <td>0.827017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.059000</td>\n",
       "      <td>0.619126</td>\n",
       "      <td>0.856655</td>\n",
       "      <td>0.841669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.056000</td>\n",
       "      <td>0.624293</td>\n",
       "      <td>0.856655</td>\n",
       "      <td>0.837573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.042700</td>\n",
       "      <td>0.660390</td>\n",
       "      <td>0.856655</td>\n",
       "      <td>0.838776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.044200</td>\n",
       "      <td>0.668435</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.837568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.045700</td>\n",
       "      <td>0.674868</td>\n",
       "      <td>0.858118</td>\n",
       "      <td>0.842168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.033000</td>\n",
       "      <td>0.689943</td>\n",
       "      <td>0.860556</td>\n",
       "      <td>0.841872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.040900</td>\n",
       "      <td>0.686189</td>\n",
       "      <td>0.858118</td>\n",
       "      <td>0.841282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.026900</td>\n",
       "      <td>0.711104</td>\n",
       "      <td>0.859093</td>\n",
       "      <td>0.841460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.032900</td>\n",
       "      <td>0.668673</td>\n",
       "      <td>0.862506</td>\n",
       "      <td>0.847519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.028800</td>\n",
       "      <td>0.736665</td>\n",
       "      <td>0.859093</td>\n",
       "      <td>0.844720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.023800</td>\n",
       "      <td>0.716446</td>\n",
       "      <td>0.858118</td>\n",
       "      <td>0.842168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.032100</td>\n",
       "      <td>0.695088</td>\n",
       "      <td>0.865431</td>\n",
       "      <td>0.849409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.028000</td>\n",
       "      <td>0.706750</td>\n",
       "      <td>0.862506</td>\n",
       "      <td>0.846784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.022000</td>\n",
       "      <td>0.781521</td>\n",
       "      <td>0.844954</td>\n",
       "      <td>0.831223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.018100</td>\n",
       "      <td>0.757615</td>\n",
       "      <td>0.854217</td>\n",
       "      <td>0.839969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.018800</td>\n",
       "      <td>0.722678</td>\n",
       "      <td>0.862994</td>\n",
       "      <td>0.847592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.022600</td>\n",
       "      <td>0.738153</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.842468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.017500</td>\n",
       "      <td>0.744639</td>\n",
       "      <td>0.856168</td>\n",
       "      <td>0.841496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/EgyBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/EgyBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8203 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2051 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1935' max='1935' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1935/1935 03:06, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.592100</td>\n",
       "      <td>0.432106</td>\n",
       "      <td>0.850804</td>\n",
       "      <td>0.828545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.433000</td>\n",
       "      <td>0.396028</td>\n",
       "      <td>0.840566</td>\n",
       "      <td>0.823604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.355700</td>\n",
       "      <td>0.364594</td>\n",
       "      <td>0.859093</td>\n",
       "      <td>0.835552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.307600</td>\n",
       "      <td>0.343426</td>\n",
       "      <td>0.860068</td>\n",
       "      <td>0.840275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.266400</td>\n",
       "      <td>0.436650</td>\n",
       "      <td>0.840566</td>\n",
       "      <td>0.828212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.219200</td>\n",
       "      <td>0.371049</td>\n",
       "      <td>0.862506</td>\n",
       "      <td>0.846136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.173000</td>\n",
       "      <td>0.485537</td>\n",
       "      <td>0.842028</td>\n",
       "      <td>0.828655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.158800</td>\n",
       "      <td>0.475682</td>\n",
       "      <td>0.837153</td>\n",
       "      <td>0.823470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.136500</td>\n",
       "      <td>0.501470</td>\n",
       "      <td>0.848367</td>\n",
       "      <td>0.834585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.101600</td>\n",
       "      <td>0.522296</td>\n",
       "      <td>0.855680</td>\n",
       "      <td>0.841011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.096900</td>\n",
       "      <td>0.575852</td>\n",
       "      <td>0.855680</td>\n",
       "      <td>0.839066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.082900</td>\n",
       "      <td>0.583193</td>\n",
       "      <td>0.858118</td>\n",
       "      <td>0.837407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.086300</td>\n",
       "      <td>0.633902</td>\n",
       "      <td>0.834715</td>\n",
       "      <td>0.821194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.072600</td>\n",
       "      <td>0.657600</td>\n",
       "      <td>0.840566</td>\n",
       "      <td>0.827017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.059000</td>\n",
       "      <td>0.619126</td>\n",
       "      <td>0.856655</td>\n",
       "      <td>0.841669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.056000</td>\n",
       "      <td>0.624293</td>\n",
       "      <td>0.856655</td>\n",
       "      <td>0.837573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.042700</td>\n",
       "      <td>0.660390</td>\n",
       "      <td>0.856655</td>\n",
       "      <td>0.838776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.044200</td>\n",
       "      <td>0.668435</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.837568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.045700</td>\n",
       "      <td>0.674868</td>\n",
       "      <td>0.858118</td>\n",
       "      <td>0.842168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.033000</td>\n",
       "      <td>0.689943</td>\n",
       "      <td>0.860556</td>\n",
       "      <td>0.841872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.040900</td>\n",
       "      <td>0.686189</td>\n",
       "      <td>0.858118</td>\n",
       "      <td>0.841282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.026900</td>\n",
       "      <td>0.711104</td>\n",
       "      <td>0.859093</td>\n",
       "      <td>0.841460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.032900</td>\n",
       "      <td>0.668673</td>\n",
       "      <td>0.862506</td>\n",
       "      <td>0.847519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.028800</td>\n",
       "      <td>0.736665</td>\n",
       "      <td>0.859093</td>\n",
       "      <td>0.844720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.023800</td>\n",
       "      <td>0.716446</td>\n",
       "      <td>0.858118</td>\n",
       "      <td>0.842168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.032100</td>\n",
       "      <td>0.695088</td>\n",
       "      <td>0.865431</td>\n",
       "      <td>0.849409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.028000</td>\n",
       "      <td>0.706750</td>\n",
       "      <td>0.862506</td>\n",
       "      <td>0.846784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.022000</td>\n",
       "      <td>0.781521</td>\n",
       "      <td>0.844954</td>\n",
       "      <td>0.831223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.018100</td>\n",
       "      <td>0.757615</td>\n",
       "      <td>0.854217</td>\n",
       "      <td>0.839969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.018800</td>\n",
       "      <td>0.722678</td>\n",
       "      <td>0.862994</td>\n",
       "      <td>0.847592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.022600</td>\n",
       "      <td>0.738153</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.842468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.017500</td>\n",
       "      <td>0.744639</td>\n",
       "      <td>0.856168</td>\n",
       "      <td>0.841496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/EgyBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/EgyBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8203 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2051 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1935' max='1935' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1935/1935 03:06, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.597100</td>\n",
       "      <td>0.455206</td>\n",
       "      <td>0.836665</td>\n",
       "      <td>0.823304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.432800</td>\n",
       "      <td>0.379707</td>\n",
       "      <td>0.854705</td>\n",
       "      <td>0.831790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.332000</td>\n",
       "      <td>0.353009</td>\n",
       "      <td>0.859581</td>\n",
       "      <td>0.842296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.316900</td>\n",
       "      <td>0.344063</td>\n",
       "      <td>0.860068</td>\n",
       "      <td>0.841857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.245800</td>\n",
       "      <td>0.374030</td>\n",
       "      <td>0.864944</td>\n",
       "      <td>0.849761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.209400</td>\n",
       "      <td>0.383436</td>\n",
       "      <td>0.862506</td>\n",
       "      <td>0.848727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.177800</td>\n",
       "      <td>0.457923</td>\n",
       "      <td>0.861531</td>\n",
       "      <td>0.846748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.146600</td>\n",
       "      <td>0.472021</td>\n",
       "      <td>0.846416</td>\n",
       "      <td>0.836038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.137000</td>\n",
       "      <td>0.568948</td>\n",
       "      <td>0.845441</td>\n",
       "      <td>0.833466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.100800</td>\n",
       "      <td>0.578285</td>\n",
       "      <td>0.849342</td>\n",
       "      <td>0.837299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.114800</td>\n",
       "      <td>0.528802</td>\n",
       "      <td>0.856655</td>\n",
       "      <td>0.840153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.087200</td>\n",
       "      <td>0.568222</td>\n",
       "      <td>0.857630</td>\n",
       "      <td>0.841897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.084900</td>\n",
       "      <td>0.581789</td>\n",
       "      <td>0.851292</td>\n",
       "      <td>0.836336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.068400</td>\n",
       "      <td>0.658182</td>\n",
       "      <td>0.847392</td>\n",
       "      <td>0.836822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.068200</td>\n",
       "      <td>0.600734</td>\n",
       "      <td>0.853730</td>\n",
       "      <td>0.839176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.063900</td>\n",
       "      <td>0.648171</td>\n",
       "      <td>0.856168</td>\n",
       "      <td>0.840218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.059800</td>\n",
       "      <td>0.657693</td>\n",
       "      <td>0.857630</td>\n",
       "      <td>0.845209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.044300</td>\n",
       "      <td>0.653734</td>\n",
       "      <td>0.853730</td>\n",
       "      <td>0.839688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.046800</td>\n",
       "      <td>0.697180</td>\n",
       "      <td>0.854705</td>\n",
       "      <td>0.842217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.037100</td>\n",
       "      <td>0.681338</td>\n",
       "      <td>0.861043</td>\n",
       "      <td>0.845529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.046200</td>\n",
       "      <td>0.686769</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.844726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.045400</td>\n",
       "      <td>0.701989</td>\n",
       "      <td>0.861531</td>\n",
       "      <td>0.847851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.035000</td>\n",
       "      <td>0.701220</td>\n",
       "      <td>0.859093</td>\n",
       "      <td>0.844618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.026100</td>\n",
       "      <td>0.729785</td>\n",
       "      <td>0.859093</td>\n",
       "      <td>0.844821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.024500</td>\n",
       "      <td>0.768659</td>\n",
       "      <td>0.853730</td>\n",
       "      <td>0.840485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.028500</td>\n",
       "      <td>0.800626</td>\n",
       "      <td>0.850804</td>\n",
       "      <td>0.839380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.028500</td>\n",
       "      <td>0.767276</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.844063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.018900</td>\n",
       "      <td>0.781435</td>\n",
       "      <td>0.855193</td>\n",
       "      <td>0.841442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.019200</td>\n",
       "      <td>0.784171</td>\n",
       "      <td>0.861043</td>\n",
       "      <td>0.845949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.021400</td>\n",
       "      <td>0.798854</td>\n",
       "      <td>0.856655</td>\n",
       "      <td>0.842392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.022000</td>\n",
       "      <td>0.819175</td>\n",
       "      <td>0.853730</td>\n",
       "      <td>0.841158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.019600</td>\n",
       "      <td>0.815546</td>\n",
       "      <td>0.852755</td>\n",
       "      <td>0.839520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/EgyBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/EgyBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8203 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2051 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1935' max='1935' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1935/1935 03:04, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.597100</td>\n",
       "      <td>0.455206</td>\n",
       "      <td>0.836665</td>\n",
       "      <td>0.823304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.432800</td>\n",
       "      <td>0.379707</td>\n",
       "      <td>0.854705</td>\n",
       "      <td>0.831790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.332000</td>\n",
       "      <td>0.353009</td>\n",
       "      <td>0.859581</td>\n",
       "      <td>0.842296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.316900</td>\n",
       "      <td>0.344063</td>\n",
       "      <td>0.860068</td>\n",
       "      <td>0.841857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.245800</td>\n",
       "      <td>0.374030</td>\n",
       "      <td>0.864944</td>\n",
       "      <td>0.849761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.209400</td>\n",
       "      <td>0.383436</td>\n",
       "      <td>0.862506</td>\n",
       "      <td>0.848727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.177800</td>\n",
       "      <td>0.457923</td>\n",
       "      <td>0.861531</td>\n",
       "      <td>0.846748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.146600</td>\n",
       "      <td>0.472021</td>\n",
       "      <td>0.846416</td>\n",
       "      <td>0.836038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.137000</td>\n",
       "      <td>0.568948</td>\n",
       "      <td>0.845441</td>\n",
       "      <td>0.833466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.100800</td>\n",
       "      <td>0.578285</td>\n",
       "      <td>0.849342</td>\n",
       "      <td>0.837299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.114800</td>\n",
       "      <td>0.528802</td>\n",
       "      <td>0.856655</td>\n",
       "      <td>0.840153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.087200</td>\n",
       "      <td>0.568222</td>\n",
       "      <td>0.857630</td>\n",
       "      <td>0.841897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.084900</td>\n",
       "      <td>0.581789</td>\n",
       "      <td>0.851292</td>\n",
       "      <td>0.836336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.068400</td>\n",
       "      <td>0.658182</td>\n",
       "      <td>0.847392</td>\n",
       "      <td>0.836822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.068200</td>\n",
       "      <td>0.600734</td>\n",
       "      <td>0.853730</td>\n",
       "      <td>0.839176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.063900</td>\n",
       "      <td>0.648171</td>\n",
       "      <td>0.856168</td>\n",
       "      <td>0.840218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.059800</td>\n",
       "      <td>0.657693</td>\n",
       "      <td>0.857630</td>\n",
       "      <td>0.845209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.044300</td>\n",
       "      <td>0.653734</td>\n",
       "      <td>0.853730</td>\n",
       "      <td>0.839688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.046800</td>\n",
       "      <td>0.697180</td>\n",
       "      <td>0.854705</td>\n",
       "      <td>0.842217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.037100</td>\n",
       "      <td>0.681338</td>\n",
       "      <td>0.861043</td>\n",
       "      <td>0.845529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.046200</td>\n",
       "      <td>0.686769</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.844726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.045400</td>\n",
       "      <td>0.701989</td>\n",
       "      <td>0.861531</td>\n",
       "      <td>0.847851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.035000</td>\n",
       "      <td>0.701220</td>\n",
       "      <td>0.859093</td>\n",
       "      <td>0.844618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.026100</td>\n",
       "      <td>0.729785</td>\n",
       "      <td>0.859093</td>\n",
       "      <td>0.844821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.024500</td>\n",
       "      <td>0.768659</td>\n",
       "      <td>0.853730</td>\n",
       "      <td>0.840485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.028500</td>\n",
       "      <td>0.800626</td>\n",
       "      <td>0.850804</td>\n",
       "      <td>0.839380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.028500</td>\n",
       "      <td>0.767276</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.844063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.018900</td>\n",
       "      <td>0.781435</td>\n",
       "      <td>0.855193</td>\n",
       "      <td>0.841442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.019200</td>\n",
       "      <td>0.784171</td>\n",
       "      <td>0.861043</td>\n",
       "      <td>0.845949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.021400</td>\n",
       "      <td>0.798854</td>\n",
       "      <td>0.856655</td>\n",
       "      <td>0.842392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.022000</td>\n",
       "      <td>0.819175</td>\n",
       "      <td>0.853730</td>\n",
       "      <td>0.841158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.019600</td>\n",
       "      <td>0.815546</td>\n",
       "      <td>0.852755</td>\n",
       "      <td>0.839520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/EgyBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/EgyBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8203 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2051 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1935' max='1935' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1935/1935 03:03, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.597100</td>\n",
       "      <td>0.455206</td>\n",
       "      <td>0.836665</td>\n",
       "      <td>0.823304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.432800</td>\n",
       "      <td>0.379707</td>\n",
       "      <td>0.854705</td>\n",
       "      <td>0.831790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.332000</td>\n",
       "      <td>0.353009</td>\n",
       "      <td>0.859581</td>\n",
       "      <td>0.842296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.316900</td>\n",
       "      <td>0.344063</td>\n",
       "      <td>0.860068</td>\n",
       "      <td>0.841857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.245800</td>\n",
       "      <td>0.374030</td>\n",
       "      <td>0.864944</td>\n",
       "      <td>0.849761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.209400</td>\n",
       "      <td>0.383436</td>\n",
       "      <td>0.862506</td>\n",
       "      <td>0.848727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.177800</td>\n",
       "      <td>0.457923</td>\n",
       "      <td>0.861531</td>\n",
       "      <td>0.846748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.146600</td>\n",
       "      <td>0.472021</td>\n",
       "      <td>0.846416</td>\n",
       "      <td>0.836038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.137000</td>\n",
       "      <td>0.568948</td>\n",
       "      <td>0.845441</td>\n",
       "      <td>0.833466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.100800</td>\n",
       "      <td>0.578285</td>\n",
       "      <td>0.849342</td>\n",
       "      <td>0.837299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.114800</td>\n",
       "      <td>0.528802</td>\n",
       "      <td>0.856655</td>\n",
       "      <td>0.840153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.087200</td>\n",
       "      <td>0.568222</td>\n",
       "      <td>0.857630</td>\n",
       "      <td>0.841897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.084900</td>\n",
       "      <td>0.581789</td>\n",
       "      <td>0.851292</td>\n",
       "      <td>0.836336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.068400</td>\n",
       "      <td>0.658182</td>\n",
       "      <td>0.847392</td>\n",
       "      <td>0.836822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.068200</td>\n",
       "      <td>0.600734</td>\n",
       "      <td>0.853730</td>\n",
       "      <td>0.839176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.063900</td>\n",
       "      <td>0.648171</td>\n",
       "      <td>0.856168</td>\n",
       "      <td>0.840218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.059800</td>\n",
       "      <td>0.657693</td>\n",
       "      <td>0.857630</td>\n",
       "      <td>0.845209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.044300</td>\n",
       "      <td>0.653734</td>\n",
       "      <td>0.853730</td>\n",
       "      <td>0.839688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.046800</td>\n",
       "      <td>0.697180</td>\n",
       "      <td>0.854705</td>\n",
       "      <td>0.842217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.037100</td>\n",
       "      <td>0.681338</td>\n",
       "      <td>0.861043</td>\n",
       "      <td>0.845529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.046200</td>\n",
       "      <td>0.686769</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.844726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.045400</td>\n",
       "      <td>0.701989</td>\n",
       "      <td>0.861531</td>\n",
       "      <td>0.847851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.035000</td>\n",
       "      <td>0.701220</td>\n",
       "      <td>0.859093</td>\n",
       "      <td>0.844618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.026100</td>\n",
       "      <td>0.729785</td>\n",
       "      <td>0.859093</td>\n",
       "      <td>0.844821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.024500</td>\n",
       "      <td>0.768659</td>\n",
       "      <td>0.853730</td>\n",
       "      <td>0.840485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.028500</td>\n",
       "      <td>0.800626</td>\n",
       "      <td>0.850804</td>\n",
       "      <td>0.839380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.028500</td>\n",
       "      <td>0.767276</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.844063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.018900</td>\n",
       "      <td>0.781435</td>\n",
       "      <td>0.855193</td>\n",
       "      <td>0.841442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.019200</td>\n",
       "      <td>0.784171</td>\n",
       "      <td>0.861043</td>\n",
       "      <td>0.845949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.021400</td>\n",
       "      <td>0.798854</td>\n",
       "      <td>0.856655</td>\n",
       "      <td>0.842392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.022000</td>\n",
       "      <td>0.819175</td>\n",
       "      <td>0.853730</td>\n",
       "      <td>0.841158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.019600</td>\n",
       "      <td>0.815546</td>\n",
       "      <td>0.852755</td>\n",
       "      <td>0.839520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/EgyBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/EgyBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8203 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2051 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1935' max='1935' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1935/1935 03:03, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.592900</td>\n",
       "      <td>0.437198</td>\n",
       "      <td>0.848367</td>\n",
       "      <td>0.831552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.427400</td>\n",
       "      <td>0.387166</td>\n",
       "      <td>0.839103</td>\n",
       "      <td>0.823990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.329600</td>\n",
       "      <td>0.382444</td>\n",
       "      <td>0.842516</td>\n",
       "      <td>0.828517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.306300</td>\n",
       "      <td>0.355483</td>\n",
       "      <td>0.859093</td>\n",
       "      <td>0.844206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.236400</td>\n",
       "      <td>0.408674</td>\n",
       "      <td>0.848854</td>\n",
       "      <td>0.835269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.208000</td>\n",
       "      <td>0.389325</td>\n",
       "      <td>0.853242</td>\n",
       "      <td>0.839507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.192300</td>\n",
       "      <td>0.463679</td>\n",
       "      <td>0.861531</td>\n",
       "      <td>0.844487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.459622</td>\n",
       "      <td>0.858118</td>\n",
       "      <td>0.843233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.139000</td>\n",
       "      <td>0.519703</td>\n",
       "      <td>0.849829</td>\n",
       "      <td>0.834993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.106600</td>\n",
       "      <td>0.583407</td>\n",
       "      <td>0.839103</td>\n",
       "      <td>0.826975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.079600</td>\n",
       "      <td>0.642249</td>\n",
       "      <td>0.832765</td>\n",
       "      <td>0.823159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.077300</td>\n",
       "      <td>0.600395</td>\n",
       "      <td>0.854217</td>\n",
       "      <td>0.839347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.079300</td>\n",
       "      <td>0.628991</td>\n",
       "      <td>0.840078</td>\n",
       "      <td>0.828024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.052800</td>\n",
       "      <td>0.642167</td>\n",
       "      <td>0.857630</td>\n",
       "      <td>0.842325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.071100</td>\n",
       "      <td>0.671755</td>\n",
       "      <td>0.841541</td>\n",
       "      <td>0.829549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.043200</td>\n",
       "      <td>0.746033</td>\n",
       "      <td>0.840078</td>\n",
       "      <td>0.828119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.048200</td>\n",
       "      <td>0.678014</td>\n",
       "      <td>0.846904</td>\n",
       "      <td>0.833647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.044700</td>\n",
       "      <td>0.688024</td>\n",
       "      <td>0.855680</td>\n",
       "      <td>0.841826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.037000</td>\n",
       "      <td>0.797637</td>\n",
       "      <td>0.835690</td>\n",
       "      <td>0.824770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.031600</td>\n",
       "      <td>0.711826</td>\n",
       "      <td>0.851292</td>\n",
       "      <td>0.838074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.020900</td>\n",
       "      <td>0.765920</td>\n",
       "      <td>0.850317</td>\n",
       "      <td>0.838444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.027000</td>\n",
       "      <td>0.733731</td>\n",
       "      <td>0.852755</td>\n",
       "      <td>0.838311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.019600</td>\n",
       "      <td>0.802329</td>\n",
       "      <td>0.849342</td>\n",
       "      <td>0.836636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.034000</td>\n",
       "      <td>0.795904</td>\n",
       "      <td>0.847392</td>\n",
       "      <td>0.835474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.011400</td>\n",
       "      <td>0.854224</td>\n",
       "      <td>0.844466</td>\n",
       "      <td>0.832415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.018500</td>\n",
       "      <td>0.871506</td>\n",
       "      <td>0.842516</td>\n",
       "      <td>0.831156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.010600</td>\n",
       "      <td>0.849544</td>\n",
       "      <td>0.849342</td>\n",
       "      <td>0.836923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.017500</td>\n",
       "      <td>0.874427</td>\n",
       "      <td>0.847392</td>\n",
       "      <td>0.835193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.008900</td>\n",
       "      <td>0.911570</td>\n",
       "      <td>0.844954</td>\n",
       "      <td>0.832987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.017200</td>\n",
       "      <td>0.866575</td>\n",
       "      <td>0.851780</td>\n",
       "      <td>0.838457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.881808</td>\n",
       "      <td>0.847392</td>\n",
       "      <td>0.834325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>0.898067</td>\n",
       "      <td>0.849342</td>\n",
       "      <td>0.837017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/EgyBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/EgyBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8203 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2051 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1935' max='1935' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1935/1935 03:03, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.592900</td>\n",
       "      <td>0.437198</td>\n",
       "      <td>0.848367</td>\n",
       "      <td>0.831552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.427400</td>\n",
       "      <td>0.387166</td>\n",
       "      <td>0.839103</td>\n",
       "      <td>0.823990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.329600</td>\n",
       "      <td>0.382444</td>\n",
       "      <td>0.842516</td>\n",
       "      <td>0.828517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.306300</td>\n",
       "      <td>0.355483</td>\n",
       "      <td>0.859093</td>\n",
       "      <td>0.844206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.236400</td>\n",
       "      <td>0.408674</td>\n",
       "      <td>0.848854</td>\n",
       "      <td>0.835269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.208000</td>\n",
       "      <td>0.389325</td>\n",
       "      <td>0.853242</td>\n",
       "      <td>0.839507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.192300</td>\n",
       "      <td>0.463679</td>\n",
       "      <td>0.861531</td>\n",
       "      <td>0.844487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.459622</td>\n",
       "      <td>0.858118</td>\n",
       "      <td>0.843233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.139000</td>\n",
       "      <td>0.519703</td>\n",
       "      <td>0.849829</td>\n",
       "      <td>0.834993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.106600</td>\n",
       "      <td>0.583407</td>\n",
       "      <td>0.839103</td>\n",
       "      <td>0.826975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.079600</td>\n",
       "      <td>0.642249</td>\n",
       "      <td>0.832765</td>\n",
       "      <td>0.823159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.077300</td>\n",
       "      <td>0.600395</td>\n",
       "      <td>0.854217</td>\n",
       "      <td>0.839347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.079300</td>\n",
       "      <td>0.628991</td>\n",
       "      <td>0.840078</td>\n",
       "      <td>0.828024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.052800</td>\n",
       "      <td>0.642167</td>\n",
       "      <td>0.857630</td>\n",
       "      <td>0.842325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.071100</td>\n",
       "      <td>0.671755</td>\n",
       "      <td>0.841541</td>\n",
       "      <td>0.829549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.043200</td>\n",
       "      <td>0.746033</td>\n",
       "      <td>0.840078</td>\n",
       "      <td>0.828119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.048200</td>\n",
       "      <td>0.678014</td>\n",
       "      <td>0.846904</td>\n",
       "      <td>0.833647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.044700</td>\n",
       "      <td>0.688024</td>\n",
       "      <td>0.855680</td>\n",
       "      <td>0.841826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.037000</td>\n",
       "      <td>0.797637</td>\n",
       "      <td>0.835690</td>\n",
       "      <td>0.824770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.031600</td>\n",
       "      <td>0.711826</td>\n",
       "      <td>0.851292</td>\n",
       "      <td>0.838074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.020900</td>\n",
       "      <td>0.765920</td>\n",
       "      <td>0.850317</td>\n",
       "      <td>0.838444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.027000</td>\n",
       "      <td>0.733731</td>\n",
       "      <td>0.852755</td>\n",
       "      <td>0.838311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.019600</td>\n",
       "      <td>0.802329</td>\n",
       "      <td>0.849342</td>\n",
       "      <td>0.836636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.034000</td>\n",
       "      <td>0.795904</td>\n",
       "      <td>0.847392</td>\n",
       "      <td>0.835474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.011400</td>\n",
       "      <td>0.854224</td>\n",
       "      <td>0.844466</td>\n",
       "      <td>0.832415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.018500</td>\n",
       "      <td>0.871506</td>\n",
       "      <td>0.842516</td>\n",
       "      <td>0.831156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.010600</td>\n",
       "      <td>0.849544</td>\n",
       "      <td>0.849342</td>\n",
       "      <td>0.836923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.017500</td>\n",
       "      <td>0.874427</td>\n",
       "      <td>0.847392</td>\n",
       "      <td>0.835193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.008900</td>\n",
       "      <td>0.911570</td>\n",
       "      <td>0.844954</td>\n",
       "      <td>0.832987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.017200</td>\n",
       "      <td>0.866575</td>\n",
       "      <td>0.851780</td>\n",
       "      <td>0.838457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.881808</td>\n",
       "      <td>0.847392</td>\n",
       "      <td>0.834325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>0.898067</td>\n",
       "      <td>0.849342</td>\n",
       "      <td>0.837017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/EgyBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/EgyBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8203 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2051 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1935' max='1935' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1935/1935 03:03, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.592900</td>\n",
       "      <td>0.437198</td>\n",
       "      <td>0.848367</td>\n",
       "      <td>0.831552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.427400</td>\n",
       "      <td>0.387166</td>\n",
       "      <td>0.839103</td>\n",
       "      <td>0.823990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.329600</td>\n",
       "      <td>0.382444</td>\n",
       "      <td>0.842516</td>\n",
       "      <td>0.828517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.306300</td>\n",
       "      <td>0.355483</td>\n",
       "      <td>0.859093</td>\n",
       "      <td>0.844206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.236400</td>\n",
       "      <td>0.408674</td>\n",
       "      <td>0.848854</td>\n",
       "      <td>0.835269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.208000</td>\n",
       "      <td>0.389325</td>\n",
       "      <td>0.853242</td>\n",
       "      <td>0.839507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.192300</td>\n",
       "      <td>0.463679</td>\n",
       "      <td>0.861531</td>\n",
       "      <td>0.844487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.459622</td>\n",
       "      <td>0.858118</td>\n",
       "      <td>0.843233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.139000</td>\n",
       "      <td>0.519703</td>\n",
       "      <td>0.849829</td>\n",
       "      <td>0.834993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.106600</td>\n",
       "      <td>0.583407</td>\n",
       "      <td>0.839103</td>\n",
       "      <td>0.826975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.079600</td>\n",
       "      <td>0.642249</td>\n",
       "      <td>0.832765</td>\n",
       "      <td>0.823159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.077300</td>\n",
       "      <td>0.600395</td>\n",
       "      <td>0.854217</td>\n",
       "      <td>0.839347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.079300</td>\n",
       "      <td>0.628991</td>\n",
       "      <td>0.840078</td>\n",
       "      <td>0.828024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.052800</td>\n",
       "      <td>0.642167</td>\n",
       "      <td>0.857630</td>\n",
       "      <td>0.842325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.071100</td>\n",
       "      <td>0.671755</td>\n",
       "      <td>0.841541</td>\n",
       "      <td>0.829549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.043200</td>\n",
       "      <td>0.746033</td>\n",
       "      <td>0.840078</td>\n",
       "      <td>0.828119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.048200</td>\n",
       "      <td>0.678014</td>\n",
       "      <td>0.846904</td>\n",
       "      <td>0.833647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.044700</td>\n",
       "      <td>0.688024</td>\n",
       "      <td>0.855680</td>\n",
       "      <td>0.841826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.037000</td>\n",
       "      <td>0.797637</td>\n",
       "      <td>0.835690</td>\n",
       "      <td>0.824770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.031600</td>\n",
       "      <td>0.711826</td>\n",
       "      <td>0.851292</td>\n",
       "      <td>0.838074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.020900</td>\n",
       "      <td>0.765920</td>\n",
       "      <td>0.850317</td>\n",
       "      <td>0.838444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.027000</td>\n",
       "      <td>0.733731</td>\n",
       "      <td>0.852755</td>\n",
       "      <td>0.838311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.019600</td>\n",
       "      <td>0.802329</td>\n",
       "      <td>0.849342</td>\n",
       "      <td>0.836636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.034000</td>\n",
       "      <td>0.795904</td>\n",
       "      <td>0.847392</td>\n",
       "      <td>0.835474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.011400</td>\n",
       "      <td>0.854224</td>\n",
       "      <td>0.844466</td>\n",
       "      <td>0.832415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.018500</td>\n",
       "      <td>0.871506</td>\n",
       "      <td>0.842516</td>\n",
       "      <td>0.831156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.010600</td>\n",
       "      <td>0.849544</td>\n",
       "      <td>0.849342</td>\n",
       "      <td>0.836923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.017500</td>\n",
       "      <td>0.874427</td>\n",
       "      <td>0.847392</td>\n",
       "      <td>0.835193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.008900</td>\n",
       "      <td>0.911570</td>\n",
       "      <td>0.844954</td>\n",
       "      <td>0.832987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.017200</td>\n",
       "      <td>0.866575</td>\n",
       "      <td>0.851780</td>\n",
       "      <td>0.838457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.881808</td>\n",
       "      <td>0.847392</td>\n",
       "      <td>0.834325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>0.898067</td>\n",
       "      <td>0.849342</td>\n",
       "      <td>0.837017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['comment_message', 'label'],\n",
       "        num_rows: 8203\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['comment_message', 'label'],\n",
       "        num_rows: 2051\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8203 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2051 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1935' max='1935' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1935/1935 03:03, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.407100</td>\n",
       "      <td>0.339068</td>\n",
       "      <td>0.859581</td>\n",
       "      <td>0.837972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.355700</td>\n",
       "      <td>0.375895</td>\n",
       "      <td>0.849342</td>\n",
       "      <td>0.812414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.247700</td>\n",
       "      <td>0.415771</td>\n",
       "      <td>0.855680</td>\n",
       "      <td>0.839731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.202600</td>\n",
       "      <td>0.407647</td>\n",
       "      <td>0.858606</td>\n",
       "      <td>0.842873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.137300</td>\n",
       "      <td>0.713769</td>\n",
       "      <td>0.827889</td>\n",
       "      <td>0.816828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.097200</td>\n",
       "      <td>0.481525</td>\n",
       "      <td>0.860068</td>\n",
       "      <td>0.844763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.055600</td>\n",
       "      <td>0.718617</td>\n",
       "      <td>0.856168</td>\n",
       "      <td>0.841392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>0.718686</td>\n",
       "      <td>0.833740</td>\n",
       "      <td>0.821454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.045600</td>\n",
       "      <td>0.775834</td>\n",
       "      <td>0.860556</td>\n",
       "      <td>0.845146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.032300</td>\n",
       "      <td>0.795479</td>\n",
       "      <td>0.848367</td>\n",
       "      <td>0.833652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.026000</td>\n",
       "      <td>0.862350</td>\n",
       "      <td>0.859581</td>\n",
       "      <td>0.839276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.019200</td>\n",
       "      <td>0.873568</td>\n",
       "      <td>0.856655</td>\n",
       "      <td>0.839474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.015500</td>\n",
       "      <td>0.895202</td>\n",
       "      <td>0.856168</td>\n",
       "      <td>0.841702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.009900</td>\n",
       "      <td>0.983644</td>\n",
       "      <td>0.864456</td>\n",
       "      <td>0.846759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.014600</td>\n",
       "      <td>0.886728</td>\n",
       "      <td>0.862506</td>\n",
       "      <td>0.844320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>1.037338</td>\n",
       "      <td>0.847879</td>\n",
       "      <td>0.833486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.009900</td>\n",
       "      <td>0.917604</td>\n",
       "      <td>0.861531</td>\n",
       "      <td>0.842739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>0.981179</td>\n",
       "      <td>0.867869</td>\n",
       "      <td>0.851006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.105689</td>\n",
       "      <td>0.851780</td>\n",
       "      <td>0.836820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>1.004535</td>\n",
       "      <td>0.871770</td>\n",
       "      <td>0.852460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>1.096335</td>\n",
       "      <td>0.861531</td>\n",
       "      <td>0.845912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>1.115062</td>\n",
       "      <td>0.864944</td>\n",
       "      <td>0.848593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>1.144299</td>\n",
       "      <td>0.862994</td>\n",
       "      <td>0.845394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>1.120536</td>\n",
       "      <td>0.861531</td>\n",
       "      <td>0.844934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>1.127503</td>\n",
       "      <td>0.865431</td>\n",
       "      <td>0.847401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>1.155776</td>\n",
       "      <td>0.860556</td>\n",
       "      <td>0.844826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>1.160505</td>\n",
       "      <td>0.863481</td>\n",
       "      <td>0.846899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>1.149452</td>\n",
       "      <td>0.865919</td>\n",
       "      <td>0.849141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.156556</td>\n",
       "      <td>0.862994</td>\n",
       "      <td>0.844578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.160056</td>\n",
       "      <td>0.862994</td>\n",
       "      <td>0.843858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>1.164824</td>\n",
       "      <td>0.864944</td>\n",
       "      <td>0.846907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.163623</td>\n",
       "      <td>0.865919</td>\n",
       "      <td>0.848695</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8203 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2051 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1935' max='1935' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1935/1935 03:02, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.407100</td>\n",
       "      <td>0.339068</td>\n",
       "      <td>0.859581</td>\n",
       "      <td>0.837972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.355700</td>\n",
       "      <td>0.375895</td>\n",
       "      <td>0.849342</td>\n",
       "      <td>0.812414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.247700</td>\n",
       "      <td>0.415771</td>\n",
       "      <td>0.855680</td>\n",
       "      <td>0.839731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.202600</td>\n",
       "      <td>0.407647</td>\n",
       "      <td>0.858606</td>\n",
       "      <td>0.842873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.137300</td>\n",
       "      <td>0.713769</td>\n",
       "      <td>0.827889</td>\n",
       "      <td>0.816828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.097200</td>\n",
       "      <td>0.481525</td>\n",
       "      <td>0.860068</td>\n",
       "      <td>0.844763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.055600</td>\n",
       "      <td>0.718617</td>\n",
       "      <td>0.856168</td>\n",
       "      <td>0.841392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>0.718686</td>\n",
       "      <td>0.833740</td>\n",
       "      <td>0.821454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.045600</td>\n",
       "      <td>0.775834</td>\n",
       "      <td>0.860556</td>\n",
       "      <td>0.845146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.032300</td>\n",
       "      <td>0.795479</td>\n",
       "      <td>0.848367</td>\n",
       "      <td>0.833652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.026000</td>\n",
       "      <td>0.862350</td>\n",
       "      <td>0.859581</td>\n",
       "      <td>0.839276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.019200</td>\n",
       "      <td>0.873568</td>\n",
       "      <td>0.856655</td>\n",
       "      <td>0.839474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.015500</td>\n",
       "      <td>0.895202</td>\n",
       "      <td>0.856168</td>\n",
       "      <td>0.841702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.009900</td>\n",
       "      <td>0.983644</td>\n",
       "      <td>0.864456</td>\n",
       "      <td>0.846759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.014600</td>\n",
       "      <td>0.886728</td>\n",
       "      <td>0.862506</td>\n",
       "      <td>0.844320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>1.037338</td>\n",
       "      <td>0.847879</td>\n",
       "      <td>0.833486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.009900</td>\n",
       "      <td>0.917604</td>\n",
       "      <td>0.861531</td>\n",
       "      <td>0.842739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>0.981179</td>\n",
       "      <td>0.867869</td>\n",
       "      <td>0.851006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.105689</td>\n",
       "      <td>0.851780</td>\n",
       "      <td>0.836820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>1.004535</td>\n",
       "      <td>0.871770</td>\n",
       "      <td>0.852460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>1.096335</td>\n",
       "      <td>0.861531</td>\n",
       "      <td>0.845912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>1.115062</td>\n",
       "      <td>0.864944</td>\n",
       "      <td>0.848593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>1.144299</td>\n",
       "      <td>0.862994</td>\n",
       "      <td>0.845394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>1.120536</td>\n",
       "      <td>0.861531</td>\n",
       "      <td>0.844934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>1.127503</td>\n",
       "      <td>0.865431</td>\n",
       "      <td>0.847401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>1.155776</td>\n",
       "      <td>0.860556</td>\n",
       "      <td>0.844826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>1.160505</td>\n",
       "      <td>0.863481</td>\n",
       "      <td>0.846899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>1.149452</td>\n",
       "      <td>0.865919</td>\n",
       "      <td>0.849141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.156556</td>\n",
       "      <td>0.862994</td>\n",
       "      <td>0.844578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.160056</td>\n",
       "      <td>0.862994</td>\n",
       "      <td>0.843858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>1.164824</td>\n",
       "      <td>0.864944</td>\n",
       "      <td>0.846907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.163623</td>\n",
       "      <td>0.865919</td>\n",
       "      <td>0.848695</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8203 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2051 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1935' max='1935' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1935/1935 03:02, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.407100</td>\n",
       "      <td>0.339068</td>\n",
       "      <td>0.859581</td>\n",
       "      <td>0.837972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.355700</td>\n",
       "      <td>0.375895</td>\n",
       "      <td>0.849342</td>\n",
       "      <td>0.812414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.247700</td>\n",
       "      <td>0.415771</td>\n",
       "      <td>0.855680</td>\n",
       "      <td>0.839731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.202600</td>\n",
       "      <td>0.407647</td>\n",
       "      <td>0.858606</td>\n",
       "      <td>0.842873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.137300</td>\n",
       "      <td>0.713769</td>\n",
       "      <td>0.827889</td>\n",
       "      <td>0.816828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.097200</td>\n",
       "      <td>0.481525</td>\n",
       "      <td>0.860068</td>\n",
       "      <td>0.844763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.055600</td>\n",
       "      <td>0.718617</td>\n",
       "      <td>0.856168</td>\n",
       "      <td>0.841392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>0.718686</td>\n",
       "      <td>0.833740</td>\n",
       "      <td>0.821454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.045600</td>\n",
       "      <td>0.775834</td>\n",
       "      <td>0.860556</td>\n",
       "      <td>0.845146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.032300</td>\n",
       "      <td>0.795479</td>\n",
       "      <td>0.848367</td>\n",
       "      <td>0.833652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.026000</td>\n",
       "      <td>0.862350</td>\n",
       "      <td>0.859581</td>\n",
       "      <td>0.839276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.019200</td>\n",
       "      <td>0.873568</td>\n",
       "      <td>0.856655</td>\n",
       "      <td>0.839474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.015500</td>\n",
       "      <td>0.895202</td>\n",
       "      <td>0.856168</td>\n",
       "      <td>0.841702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.009900</td>\n",
       "      <td>0.983644</td>\n",
       "      <td>0.864456</td>\n",
       "      <td>0.846759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.014600</td>\n",
       "      <td>0.886728</td>\n",
       "      <td>0.862506</td>\n",
       "      <td>0.844320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>1.037338</td>\n",
       "      <td>0.847879</td>\n",
       "      <td>0.833486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.009900</td>\n",
       "      <td>0.917604</td>\n",
       "      <td>0.861531</td>\n",
       "      <td>0.842739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>0.981179</td>\n",
       "      <td>0.867869</td>\n",
       "      <td>0.851006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.105689</td>\n",
       "      <td>0.851780</td>\n",
       "      <td>0.836820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>1.004535</td>\n",
       "      <td>0.871770</td>\n",
       "      <td>0.852460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>1.096335</td>\n",
       "      <td>0.861531</td>\n",
       "      <td>0.845912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>1.115062</td>\n",
       "      <td>0.864944</td>\n",
       "      <td>0.848593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>1.144299</td>\n",
       "      <td>0.862994</td>\n",
       "      <td>0.845394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>1.120536</td>\n",
       "      <td>0.861531</td>\n",
       "      <td>0.844934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>1.127503</td>\n",
       "      <td>0.865431</td>\n",
       "      <td>0.847401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>1.155776</td>\n",
       "      <td>0.860556</td>\n",
       "      <td>0.844826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>1.160505</td>\n",
       "      <td>0.863481</td>\n",
       "      <td>0.846899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>1.149452</td>\n",
       "      <td>0.865919</td>\n",
       "      <td>0.849141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.156556</td>\n",
       "      <td>0.862994</td>\n",
       "      <td>0.844578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.160056</td>\n",
       "      <td>0.862994</td>\n",
       "      <td>0.843858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>1.164824</td>\n",
       "      <td>0.864944</td>\n",
       "      <td>0.846907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.163623</td>\n",
       "      <td>0.865919</td>\n",
       "      <td>0.848695</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8203 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2051 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1935' max='1935' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1935/1935 03:02, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.344543</td>\n",
       "      <td>0.862506</td>\n",
       "      <td>0.844084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.366600</td>\n",
       "      <td>0.335693</td>\n",
       "      <td>0.864456</td>\n",
       "      <td>0.848640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.229100</td>\n",
       "      <td>0.356427</td>\n",
       "      <td>0.857630</td>\n",
       "      <td>0.843363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.208700</td>\n",
       "      <td>0.334456</td>\n",
       "      <td>0.864944</td>\n",
       "      <td>0.849448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.109900</td>\n",
       "      <td>0.640940</td>\n",
       "      <td>0.833740</td>\n",
       "      <td>0.824021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.071500</td>\n",
       "      <td>0.616793</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.838551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.058200</td>\n",
       "      <td>0.750071</td>\n",
       "      <td>0.867382</td>\n",
       "      <td>0.848918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.071800</td>\n",
       "      <td>0.651529</td>\n",
       "      <td>0.853730</td>\n",
       "      <td>0.840090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.027800</td>\n",
       "      <td>0.894167</td>\n",
       "      <td>0.857630</td>\n",
       "      <td>0.845302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.024400</td>\n",
       "      <td>0.851236</td>\n",
       "      <td>0.862994</td>\n",
       "      <td>0.848316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.022600</td>\n",
       "      <td>0.802616</td>\n",
       "      <td>0.864456</td>\n",
       "      <td>0.851445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.014800</td>\n",
       "      <td>1.017132</td>\n",
       "      <td>0.843491</td>\n",
       "      <td>0.832828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.012700</td>\n",
       "      <td>0.949537</td>\n",
       "      <td>0.858606</td>\n",
       "      <td>0.845802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.008100</td>\n",
       "      <td>0.938925</td>\n",
       "      <td>0.861531</td>\n",
       "      <td>0.847256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>0.906882</td>\n",
       "      <td>0.860556</td>\n",
       "      <td>0.847362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>0.984733</td>\n",
       "      <td>0.865431</td>\n",
       "      <td>0.851065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>1.022465</td>\n",
       "      <td>0.865431</td>\n",
       "      <td>0.850044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.006200</td>\n",
       "      <td>1.124318</td>\n",
       "      <td>0.850804</td>\n",
       "      <td>0.839470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>1.050660</td>\n",
       "      <td>0.867382</td>\n",
       "      <td>0.853420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.005900</td>\n",
       "      <td>1.125998</td>\n",
       "      <td>0.853242</td>\n",
       "      <td>0.841145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>1.099455</td>\n",
       "      <td>0.862019</td>\n",
       "      <td>0.849292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>1.066037</td>\n",
       "      <td>0.868844</td>\n",
       "      <td>0.854100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>1.171435</td>\n",
       "      <td>0.853730</td>\n",
       "      <td>0.842352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.091027</td>\n",
       "      <td>0.864944</td>\n",
       "      <td>0.851932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.118701</td>\n",
       "      <td>0.865431</td>\n",
       "      <td>0.851559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.129372</td>\n",
       "      <td>0.866407</td>\n",
       "      <td>0.852440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.134162</td>\n",
       "      <td>0.868357</td>\n",
       "      <td>0.854400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.157394</td>\n",
       "      <td>0.865431</td>\n",
       "      <td>0.852232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.149695</td>\n",
       "      <td>0.865431</td>\n",
       "      <td>0.851753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.143162</td>\n",
       "      <td>0.866407</td>\n",
       "      <td>0.851542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.146445</td>\n",
       "      <td>0.866407</td>\n",
       "      <td>0.851234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>1.147476</td>\n",
       "      <td>0.866407</td>\n",
       "      <td>0.851542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8203 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2051 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1935' max='1935' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1935/1935 03:03, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.344543</td>\n",
       "      <td>0.862506</td>\n",
       "      <td>0.844084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.366600</td>\n",
       "      <td>0.335693</td>\n",
       "      <td>0.864456</td>\n",
       "      <td>0.848640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.229100</td>\n",
       "      <td>0.356427</td>\n",
       "      <td>0.857630</td>\n",
       "      <td>0.843363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.208700</td>\n",
       "      <td>0.334456</td>\n",
       "      <td>0.864944</td>\n",
       "      <td>0.849448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.109900</td>\n",
       "      <td>0.640940</td>\n",
       "      <td>0.833740</td>\n",
       "      <td>0.824021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.071500</td>\n",
       "      <td>0.616793</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.838551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.058200</td>\n",
       "      <td>0.750071</td>\n",
       "      <td>0.867382</td>\n",
       "      <td>0.848918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.071800</td>\n",
       "      <td>0.651529</td>\n",
       "      <td>0.853730</td>\n",
       "      <td>0.840090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.027800</td>\n",
       "      <td>0.894167</td>\n",
       "      <td>0.857630</td>\n",
       "      <td>0.845302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.024400</td>\n",
       "      <td>0.851236</td>\n",
       "      <td>0.862994</td>\n",
       "      <td>0.848316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.022600</td>\n",
       "      <td>0.802616</td>\n",
       "      <td>0.864456</td>\n",
       "      <td>0.851445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.014800</td>\n",
       "      <td>1.017132</td>\n",
       "      <td>0.843491</td>\n",
       "      <td>0.832828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.012700</td>\n",
       "      <td>0.949537</td>\n",
       "      <td>0.858606</td>\n",
       "      <td>0.845802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.008100</td>\n",
       "      <td>0.938925</td>\n",
       "      <td>0.861531</td>\n",
       "      <td>0.847256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>0.906882</td>\n",
       "      <td>0.860556</td>\n",
       "      <td>0.847362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>0.984733</td>\n",
       "      <td>0.865431</td>\n",
       "      <td>0.851065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>1.022465</td>\n",
       "      <td>0.865431</td>\n",
       "      <td>0.850044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.006200</td>\n",
       "      <td>1.124318</td>\n",
       "      <td>0.850804</td>\n",
       "      <td>0.839470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>1.050660</td>\n",
       "      <td>0.867382</td>\n",
       "      <td>0.853420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.005900</td>\n",
       "      <td>1.125998</td>\n",
       "      <td>0.853242</td>\n",
       "      <td>0.841145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>1.099455</td>\n",
       "      <td>0.862019</td>\n",
       "      <td>0.849292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>1.066037</td>\n",
       "      <td>0.868844</td>\n",
       "      <td>0.854100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>1.171435</td>\n",
       "      <td>0.853730</td>\n",
       "      <td>0.842352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.091027</td>\n",
       "      <td>0.864944</td>\n",
       "      <td>0.851932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.118701</td>\n",
       "      <td>0.865431</td>\n",
       "      <td>0.851559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.129372</td>\n",
       "      <td>0.866407</td>\n",
       "      <td>0.852440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.134162</td>\n",
       "      <td>0.868357</td>\n",
       "      <td>0.854400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.157394</td>\n",
       "      <td>0.865431</td>\n",
       "      <td>0.852232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.149695</td>\n",
       "      <td>0.865431</td>\n",
       "      <td>0.851753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.143162</td>\n",
       "      <td>0.866407</td>\n",
       "      <td>0.851542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.146445</td>\n",
       "      <td>0.866407</td>\n",
       "      <td>0.851234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>1.147476</td>\n",
       "      <td>0.866407</td>\n",
       "      <td>0.851542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8203 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2051 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1935' max='1935' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1935/1935 03:03, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.344543</td>\n",
       "      <td>0.862506</td>\n",
       "      <td>0.844084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.366600</td>\n",
       "      <td>0.335693</td>\n",
       "      <td>0.864456</td>\n",
       "      <td>0.848640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.229100</td>\n",
       "      <td>0.356427</td>\n",
       "      <td>0.857630</td>\n",
       "      <td>0.843363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.208700</td>\n",
       "      <td>0.334456</td>\n",
       "      <td>0.864944</td>\n",
       "      <td>0.849448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.109900</td>\n",
       "      <td>0.640940</td>\n",
       "      <td>0.833740</td>\n",
       "      <td>0.824021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.071500</td>\n",
       "      <td>0.616793</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.838551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.058200</td>\n",
       "      <td>0.750071</td>\n",
       "      <td>0.867382</td>\n",
       "      <td>0.848918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.071800</td>\n",
       "      <td>0.651529</td>\n",
       "      <td>0.853730</td>\n",
       "      <td>0.840090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.027800</td>\n",
       "      <td>0.894167</td>\n",
       "      <td>0.857630</td>\n",
       "      <td>0.845302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.024400</td>\n",
       "      <td>0.851236</td>\n",
       "      <td>0.862994</td>\n",
       "      <td>0.848316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.022600</td>\n",
       "      <td>0.802616</td>\n",
       "      <td>0.864456</td>\n",
       "      <td>0.851445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.014800</td>\n",
       "      <td>1.017132</td>\n",
       "      <td>0.843491</td>\n",
       "      <td>0.832828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.012700</td>\n",
       "      <td>0.949537</td>\n",
       "      <td>0.858606</td>\n",
       "      <td>0.845802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.008100</td>\n",
       "      <td>0.938925</td>\n",
       "      <td>0.861531</td>\n",
       "      <td>0.847256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>0.906882</td>\n",
       "      <td>0.860556</td>\n",
       "      <td>0.847362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>0.984733</td>\n",
       "      <td>0.865431</td>\n",
       "      <td>0.851065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>1.022465</td>\n",
       "      <td>0.865431</td>\n",
       "      <td>0.850044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.006200</td>\n",
       "      <td>1.124318</td>\n",
       "      <td>0.850804</td>\n",
       "      <td>0.839470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>1.050660</td>\n",
       "      <td>0.867382</td>\n",
       "      <td>0.853420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.005900</td>\n",
       "      <td>1.125998</td>\n",
       "      <td>0.853242</td>\n",
       "      <td>0.841145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>1.099455</td>\n",
       "      <td>0.862019</td>\n",
       "      <td>0.849292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>1.066037</td>\n",
       "      <td>0.868844</td>\n",
       "      <td>0.854100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>1.171435</td>\n",
       "      <td>0.853730</td>\n",
       "      <td>0.842352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.091027</td>\n",
       "      <td>0.864944</td>\n",
       "      <td>0.851932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.118701</td>\n",
       "      <td>0.865431</td>\n",
       "      <td>0.851559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.129372</td>\n",
       "      <td>0.866407</td>\n",
       "      <td>0.852440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.134162</td>\n",
       "      <td>0.868357</td>\n",
       "      <td>0.854400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.157394</td>\n",
       "      <td>0.865431</td>\n",
       "      <td>0.852232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.149695</td>\n",
       "      <td>0.865431</td>\n",
       "      <td>0.851753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.143162</td>\n",
       "      <td>0.866407</td>\n",
       "      <td>0.851542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.146445</td>\n",
       "      <td>0.866407</td>\n",
       "      <td>0.851234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>1.147476</td>\n",
       "      <td>0.866407</td>\n",
       "      <td>0.851542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8203 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2051 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1935' max='1935' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1935/1935 03:03, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.410100</td>\n",
       "      <td>0.362402</td>\n",
       "      <td>0.855680</td>\n",
       "      <td>0.842418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.353000</td>\n",
       "      <td>0.365166</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.832404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.234000</td>\n",
       "      <td>0.397220</td>\n",
       "      <td>0.862994</td>\n",
       "      <td>0.846517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.204300</td>\n",
       "      <td>0.404338</td>\n",
       "      <td>0.868844</td>\n",
       "      <td>0.852754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.129500</td>\n",
       "      <td>0.690832</td>\n",
       "      <td>0.814725</td>\n",
       "      <td>0.805913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.524158</td>\n",
       "      <td>0.853730</td>\n",
       "      <td>0.841347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.070300</td>\n",
       "      <td>0.687232</td>\n",
       "      <td>0.858606</td>\n",
       "      <td>0.846635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.027900</td>\n",
       "      <td>0.784624</td>\n",
       "      <td>0.856655</td>\n",
       "      <td>0.842290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.031600</td>\n",
       "      <td>0.872327</td>\n",
       "      <td>0.849829</td>\n",
       "      <td>0.836825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.038900</td>\n",
       "      <td>0.805670</td>\n",
       "      <td>0.859581</td>\n",
       "      <td>0.845308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.035900</td>\n",
       "      <td>0.802948</td>\n",
       "      <td>0.856168</td>\n",
       "      <td>0.842410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.017100</td>\n",
       "      <td>0.817196</td>\n",
       "      <td>0.861043</td>\n",
       "      <td>0.842604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.010500</td>\n",
       "      <td>0.973082</td>\n",
       "      <td>0.850317</td>\n",
       "      <td>0.837693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>1.144333</td>\n",
       "      <td>0.859093</td>\n",
       "      <td>0.837209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.023700</td>\n",
       "      <td>1.003543</td>\n",
       "      <td>0.844466</td>\n",
       "      <td>0.832603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.006500</td>\n",
       "      <td>0.970669</td>\n",
       "      <td>0.856168</td>\n",
       "      <td>0.843192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.009400</td>\n",
       "      <td>0.965146</td>\n",
       "      <td>0.853242</td>\n",
       "      <td>0.841782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>0.997393</td>\n",
       "      <td>0.859581</td>\n",
       "      <td>0.847421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.008500</td>\n",
       "      <td>1.006125</td>\n",
       "      <td>0.862506</td>\n",
       "      <td>0.849212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>1.046915</td>\n",
       "      <td>0.863969</td>\n",
       "      <td>0.852145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>1.036225</td>\n",
       "      <td>0.868357</td>\n",
       "      <td>0.854786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>1.060337</td>\n",
       "      <td>0.866407</td>\n",
       "      <td>0.850713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>1.063564</td>\n",
       "      <td>0.868844</td>\n",
       "      <td>0.854598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>1.088006</td>\n",
       "      <td>0.866894</td>\n",
       "      <td>0.851205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.108440</td>\n",
       "      <td>0.867382</td>\n",
       "      <td>0.852422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.125893</td>\n",
       "      <td>0.871770</td>\n",
       "      <td>0.858690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>1.135151</td>\n",
       "      <td>0.869820</td>\n",
       "      <td>0.856820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>1.125212</td>\n",
       "      <td>0.868844</td>\n",
       "      <td>0.856025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>1.122576</td>\n",
       "      <td>0.868844</td>\n",
       "      <td>0.854400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>1.126759</td>\n",
       "      <td>0.868844</td>\n",
       "      <td>0.854201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.124839</td>\n",
       "      <td>0.867869</td>\n",
       "      <td>0.853616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.126027</td>\n",
       "      <td>0.867869</td>\n",
       "      <td>0.853616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8203 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2051 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1935' max='1935' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1935/1935 03:03, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.410100</td>\n",
       "      <td>0.362402</td>\n",
       "      <td>0.855680</td>\n",
       "      <td>0.842418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.353000</td>\n",
       "      <td>0.365166</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.832404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.234000</td>\n",
       "      <td>0.397220</td>\n",
       "      <td>0.862994</td>\n",
       "      <td>0.846517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.204300</td>\n",
       "      <td>0.404338</td>\n",
       "      <td>0.868844</td>\n",
       "      <td>0.852754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.129500</td>\n",
       "      <td>0.690832</td>\n",
       "      <td>0.814725</td>\n",
       "      <td>0.805913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.524158</td>\n",
       "      <td>0.853730</td>\n",
       "      <td>0.841347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.070300</td>\n",
       "      <td>0.687232</td>\n",
       "      <td>0.858606</td>\n",
       "      <td>0.846635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.027900</td>\n",
       "      <td>0.784624</td>\n",
       "      <td>0.856655</td>\n",
       "      <td>0.842290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.031600</td>\n",
       "      <td>0.872327</td>\n",
       "      <td>0.849829</td>\n",
       "      <td>0.836825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.038900</td>\n",
       "      <td>0.805670</td>\n",
       "      <td>0.859581</td>\n",
       "      <td>0.845308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.035900</td>\n",
       "      <td>0.802948</td>\n",
       "      <td>0.856168</td>\n",
       "      <td>0.842410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.017100</td>\n",
       "      <td>0.817196</td>\n",
       "      <td>0.861043</td>\n",
       "      <td>0.842604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.010500</td>\n",
       "      <td>0.973082</td>\n",
       "      <td>0.850317</td>\n",
       "      <td>0.837693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>1.144333</td>\n",
       "      <td>0.859093</td>\n",
       "      <td>0.837209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.023700</td>\n",
       "      <td>1.003543</td>\n",
       "      <td>0.844466</td>\n",
       "      <td>0.832603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.006500</td>\n",
       "      <td>0.970669</td>\n",
       "      <td>0.856168</td>\n",
       "      <td>0.843192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.009400</td>\n",
       "      <td>0.965146</td>\n",
       "      <td>0.853242</td>\n",
       "      <td>0.841782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>0.997393</td>\n",
       "      <td>0.859581</td>\n",
       "      <td>0.847421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.008500</td>\n",
       "      <td>1.006125</td>\n",
       "      <td>0.862506</td>\n",
       "      <td>0.849212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>1.046915</td>\n",
       "      <td>0.863969</td>\n",
       "      <td>0.852145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>1.036225</td>\n",
       "      <td>0.868357</td>\n",
       "      <td>0.854786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>1.060337</td>\n",
       "      <td>0.866407</td>\n",
       "      <td>0.850713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>1.063564</td>\n",
       "      <td>0.868844</td>\n",
       "      <td>0.854598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>1.088006</td>\n",
       "      <td>0.866894</td>\n",
       "      <td>0.851205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.108440</td>\n",
       "      <td>0.867382</td>\n",
       "      <td>0.852422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.125893</td>\n",
       "      <td>0.871770</td>\n",
       "      <td>0.858690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>1.135151</td>\n",
       "      <td>0.869820</td>\n",
       "      <td>0.856820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>1.125212</td>\n",
       "      <td>0.868844</td>\n",
       "      <td>0.856025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>1.122576</td>\n",
       "      <td>0.868844</td>\n",
       "      <td>0.854400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>1.126759</td>\n",
       "      <td>0.868844</td>\n",
       "      <td>0.854201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.124839</td>\n",
       "      <td>0.867869</td>\n",
       "      <td>0.853616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.126027</td>\n",
       "      <td>0.867869</td>\n",
       "      <td>0.853616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8203 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2051 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1935' max='1935' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1935/1935 03:03, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.410100</td>\n",
       "      <td>0.362402</td>\n",
       "      <td>0.855680</td>\n",
       "      <td>0.842418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.353000</td>\n",
       "      <td>0.365166</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.832404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.234000</td>\n",
       "      <td>0.397220</td>\n",
       "      <td>0.862994</td>\n",
       "      <td>0.846517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.204300</td>\n",
       "      <td>0.404338</td>\n",
       "      <td>0.868844</td>\n",
       "      <td>0.852754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.129500</td>\n",
       "      <td>0.690832</td>\n",
       "      <td>0.814725</td>\n",
       "      <td>0.805913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.524158</td>\n",
       "      <td>0.853730</td>\n",
       "      <td>0.841347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.070300</td>\n",
       "      <td>0.687232</td>\n",
       "      <td>0.858606</td>\n",
       "      <td>0.846635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.027900</td>\n",
       "      <td>0.784624</td>\n",
       "      <td>0.856655</td>\n",
       "      <td>0.842290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.031600</td>\n",
       "      <td>0.872327</td>\n",
       "      <td>0.849829</td>\n",
       "      <td>0.836825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.038900</td>\n",
       "      <td>0.805670</td>\n",
       "      <td>0.859581</td>\n",
       "      <td>0.845308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.035900</td>\n",
       "      <td>0.802948</td>\n",
       "      <td>0.856168</td>\n",
       "      <td>0.842410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.017100</td>\n",
       "      <td>0.817196</td>\n",
       "      <td>0.861043</td>\n",
       "      <td>0.842604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.010500</td>\n",
       "      <td>0.973082</td>\n",
       "      <td>0.850317</td>\n",
       "      <td>0.837693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>1.144333</td>\n",
       "      <td>0.859093</td>\n",
       "      <td>0.837209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.023700</td>\n",
       "      <td>1.003543</td>\n",
       "      <td>0.844466</td>\n",
       "      <td>0.832603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.006500</td>\n",
       "      <td>0.970669</td>\n",
       "      <td>0.856168</td>\n",
       "      <td>0.843192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.009400</td>\n",
       "      <td>0.965146</td>\n",
       "      <td>0.853242</td>\n",
       "      <td>0.841782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>0.997393</td>\n",
       "      <td>0.859581</td>\n",
       "      <td>0.847421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.008500</td>\n",
       "      <td>1.006125</td>\n",
       "      <td>0.862506</td>\n",
       "      <td>0.849212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>1.046915</td>\n",
       "      <td>0.863969</td>\n",
       "      <td>0.852145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>1.036225</td>\n",
       "      <td>0.868357</td>\n",
       "      <td>0.854786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>1.060337</td>\n",
       "      <td>0.866407</td>\n",
       "      <td>0.850713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>1.063564</td>\n",
       "      <td>0.868844</td>\n",
       "      <td>0.854598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>1.088006</td>\n",
       "      <td>0.866894</td>\n",
       "      <td>0.851205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.108440</td>\n",
       "      <td>0.867382</td>\n",
       "      <td>0.852422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.125893</td>\n",
       "      <td>0.871770</td>\n",
       "      <td>0.858690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>1.135151</td>\n",
       "      <td>0.869820</td>\n",
       "      <td>0.856820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>1.125212</td>\n",
       "      <td>0.868844</td>\n",
       "      <td>0.856025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>1.122576</td>\n",
       "      <td>0.868844</td>\n",
       "      <td>0.854400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>1.126759</td>\n",
       "      <td>0.868844</td>\n",
       "      <td>0.854201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.124839</td>\n",
       "      <td>0.867869</td>\n",
       "      <td>0.853616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.126027</td>\n",
       "      <td>0.867869</td>\n",
       "      <td>0.853616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['comment_message', 'label'],\n",
       "        num_rows: 8203\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['comment_message', 'label'],\n",
       "        num_rows: 2051\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunis-ai/TunBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tunis-ai/TunBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8203 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2051 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1935' max='1935' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1935/1935 02:54, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.692100</td>\n",
       "      <td>0.682247</td>\n",
       "      <td>0.660653</td>\n",
       "      <td>0.397827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.668700</td>\n",
       "      <td>0.640720</td>\n",
       "      <td>0.660653</td>\n",
       "      <td>0.397827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.661400</td>\n",
       "      <td>0.666089</td>\n",
       "      <td>0.584105</td>\n",
       "      <td>0.577934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.624400</td>\n",
       "      <td>0.613072</td>\n",
       "      <td>0.694295</td>\n",
       "      <td>0.519073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.613200</td>\n",
       "      <td>0.642346</td>\n",
       "      <td>0.618723</td>\n",
       "      <td>0.611534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.591700</td>\n",
       "      <td>0.609124</td>\n",
       "      <td>0.678693</td>\n",
       "      <td>0.641578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.588200</td>\n",
       "      <td>0.622257</td>\n",
       "      <td>0.670892</td>\n",
       "      <td>0.632876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.577200</td>\n",
       "      <td>0.573352</td>\n",
       "      <td>0.727450</td>\n",
       "      <td>0.629643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.570900</td>\n",
       "      <td>0.584806</td>\n",
       "      <td>0.700634</td>\n",
       "      <td>0.647073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.556300</td>\n",
       "      <td>0.581575</td>\n",
       "      <td>0.706972</td>\n",
       "      <td>0.644814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.560300</td>\n",
       "      <td>0.563382</td>\n",
       "      <td>0.719161</td>\n",
       "      <td>0.575556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.547800</td>\n",
       "      <td>0.594093</td>\n",
       "      <td>0.700634</td>\n",
       "      <td>0.650770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.541300</td>\n",
       "      <td>0.582706</td>\n",
       "      <td>0.712823</td>\n",
       "      <td>0.653609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.519300</td>\n",
       "      <td>0.576445</td>\n",
       "      <td>0.711360</td>\n",
       "      <td>0.651335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.544800</td>\n",
       "      <td>0.571658</td>\n",
       "      <td>0.713311</td>\n",
       "      <td>0.643616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.531500</td>\n",
       "      <td>0.567961</td>\n",
       "      <td>0.717211</td>\n",
       "      <td>0.657732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.510100</td>\n",
       "      <td>0.577514</td>\n",
       "      <td>0.726475</td>\n",
       "      <td>0.645979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.515800</td>\n",
       "      <td>0.583873</td>\n",
       "      <td>0.698196</td>\n",
       "      <td>0.661658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.524000</td>\n",
       "      <td>0.599905</td>\n",
       "      <td>0.705997</td>\n",
       "      <td>0.658051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.502300</td>\n",
       "      <td>0.582502</td>\n",
       "      <td>0.722087</td>\n",
       "      <td>0.628603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.516200</td>\n",
       "      <td>0.582138</td>\n",
       "      <td>0.712335</td>\n",
       "      <td>0.653525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.488500</td>\n",
       "      <td>0.584051</td>\n",
       "      <td>0.725987</td>\n",
       "      <td>0.649727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.489300</td>\n",
       "      <td>0.608530</td>\n",
       "      <td>0.725012</td>\n",
       "      <td>0.637210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.498900</td>\n",
       "      <td>0.592754</td>\n",
       "      <td>0.722087</td>\n",
       "      <td>0.652274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.487300</td>\n",
       "      <td>0.599591</td>\n",
       "      <td>0.727450</td>\n",
       "      <td>0.645094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.475700</td>\n",
       "      <td>0.608958</td>\n",
       "      <td>0.717699</td>\n",
       "      <td>0.664919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.485800</td>\n",
       "      <td>0.588492</td>\n",
       "      <td>0.721599</td>\n",
       "      <td>0.657728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.478100</td>\n",
       "      <td>0.602484</td>\n",
       "      <td>0.718674</td>\n",
       "      <td>0.663261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.454100</td>\n",
       "      <td>0.602375</td>\n",
       "      <td>0.719161</td>\n",
       "      <td>0.658743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.473100</td>\n",
       "      <td>0.595051</td>\n",
       "      <td>0.717211</td>\n",
       "      <td>0.664186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.482100</td>\n",
       "      <td>0.615606</td>\n",
       "      <td>0.715261</td>\n",
       "      <td>0.663409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.447500</td>\n",
       "      <td>0.610264</td>\n",
       "      <td>0.720624</td>\n",
       "      <td>0.665912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunis-ai/TunBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tunis-ai/TunBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8203 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2051 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1935' max='1935' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1935/1935 02:55, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.692100</td>\n",
       "      <td>0.682247</td>\n",
       "      <td>0.660653</td>\n",
       "      <td>0.397827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.668700</td>\n",
       "      <td>0.640720</td>\n",
       "      <td>0.660653</td>\n",
       "      <td>0.397827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.661400</td>\n",
       "      <td>0.666089</td>\n",
       "      <td>0.584105</td>\n",
       "      <td>0.577934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.624400</td>\n",
       "      <td>0.613072</td>\n",
       "      <td>0.694295</td>\n",
       "      <td>0.519073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.613200</td>\n",
       "      <td>0.642346</td>\n",
       "      <td>0.618723</td>\n",
       "      <td>0.611534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.591700</td>\n",
       "      <td>0.609124</td>\n",
       "      <td>0.678693</td>\n",
       "      <td>0.641578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.588200</td>\n",
       "      <td>0.622257</td>\n",
       "      <td>0.670892</td>\n",
       "      <td>0.632876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.577200</td>\n",
       "      <td>0.573352</td>\n",
       "      <td>0.727450</td>\n",
       "      <td>0.629643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.570900</td>\n",
       "      <td>0.584806</td>\n",
       "      <td>0.700634</td>\n",
       "      <td>0.647073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.556300</td>\n",
       "      <td>0.581575</td>\n",
       "      <td>0.706972</td>\n",
       "      <td>0.644814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.560300</td>\n",
       "      <td>0.563382</td>\n",
       "      <td>0.719161</td>\n",
       "      <td>0.575556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.547800</td>\n",
       "      <td>0.594093</td>\n",
       "      <td>0.700634</td>\n",
       "      <td>0.650770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.541300</td>\n",
       "      <td>0.582706</td>\n",
       "      <td>0.712823</td>\n",
       "      <td>0.653609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.519300</td>\n",
       "      <td>0.576445</td>\n",
       "      <td>0.711360</td>\n",
       "      <td>0.651335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.544800</td>\n",
       "      <td>0.571658</td>\n",
       "      <td>0.713311</td>\n",
       "      <td>0.643616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.531500</td>\n",
       "      <td>0.567961</td>\n",
       "      <td>0.717211</td>\n",
       "      <td>0.657732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.510100</td>\n",
       "      <td>0.577514</td>\n",
       "      <td>0.726475</td>\n",
       "      <td>0.645979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.515800</td>\n",
       "      <td>0.583873</td>\n",
       "      <td>0.698196</td>\n",
       "      <td>0.661658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.524000</td>\n",
       "      <td>0.599905</td>\n",
       "      <td>0.705997</td>\n",
       "      <td>0.658051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.502300</td>\n",
       "      <td>0.582502</td>\n",
       "      <td>0.722087</td>\n",
       "      <td>0.628603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.516200</td>\n",
       "      <td>0.582138</td>\n",
       "      <td>0.712335</td>\n",
       "      <td>0.653525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.488500</td>\n",
       "      <td>0.584051</td>\n",
       "      <td>0.725987</td>\n",
       "      <td>0.649727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.489300</td>\n",
       "      <td>0.608530</td>\n",
       "      <td>0.725012</td>\n",
       "      <td>0.637210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.498900</td>\n",
       "      <td>0.592754</td>\n",
       "      <td>0.722087</td>\n",
       "      <td>0.652274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.487300</td>\n",
       "      <td>0.599591</td>\n",
       "      <td>0.727450</td>\n",
       "      <td>0.645094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.475700</td>\n",
       "      <td>0.608958</td>\n",
       "      <td>0.717699</td>\n",
       "      <td>0.664919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.485800</td>\n",
       "      <td>0.588492</td>\n",
       "      <td>0.721599</td>\n",
       "      <td>0.657728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.478100</td>\n",
       "      <td>0.602484</td>\n",
       "      <td>0.718674</td>\n",
       "      <td>0.663261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.454100</td>\n",
       "      <td>0.602375</td>\n",
       "      <td>0.719161</td>\n",
       "      <td>0.658743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.473100</td>\n",
       "      <td>0.595051</td>\n",
       "      <td>0.717211</td>\n",
       "      <td>0.664186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.482100</td>\n",
       "      <td>0.615606</td>\n",
       "      <td>0.715261</td>\n",
       "      <td>0.663409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.447500</td>\n",
       "      <td>0.610264</td>\n",
       "      <td>0.720624</td>\n",
       "      <td>0.665912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunis-ai/TunBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tunis-ai/TunBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8203 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2051 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1935' max='1935' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1935/1935 02:55, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.692100</td>\n",
       "      <td>0.682247</td>\n",
       "      <td>0.660653</td>\n",
       "      <td>0.397827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.668700</td>\n",
       "      <td>0.640720</td>\n",
       "      <td>0.660653</td>\n",
       "      <td>0.397827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.661400</td>\n",
       "      <td>0.666089</td>\n",
       "      <td>0.584105</td>\n",
       "      <td>0.577934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.624400</td>\n",
       "      <td>0.613072</td>\n",
       "      <td>0.694295</td>\n",
       "      <td>0.519073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.613200</td>\n",
       "      <td>0.642346</td>\n",
       "      <td>0.618723</td>\n",
       "      <td>0.611534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.591700</td>\n",
       "      <td>0.609124</td>\n",
       "      <td>0.678693</td>\n",
       "      <td>0.641578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.588200</td>\n",
       "      <td>0.622257</td>\n",
       "      <td>0.670892</td>\n",
       "      <td>0.632876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.577200</td>\n",
       "      <td>0.573352</td>\n",
       "      <td>0.727450</td>\n",
       "      <td>0.629643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.570900</td>\n",
       "      <td>0.584806</td>\n",
       "      <td>0.700634</td>\n",
       "      <td>0.647073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.556300</td>\n",
       "      <td>0.581575</td>\n",
       "      <td>0.706972</td>\n",
       "      <td>0.644814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.560300</td>\n",
       "      <td>0.563382</td>\n",
       "      <td>0.719161</td>\n",
       "      <td>0.575556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.547800</td>\n",
       "      <td>0.594093</td>\n",
       "      <td>0.700634</td>\n",
       "      <td>0.650770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.541300</td>\n",
       "      <td>0.582706</td>\n",
       "      <td>0.712823</td>\n",
       "      <td>0.653609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.519300</td>\n",
       "      <td>0.576445</td>\n",
       "      <td>0.711360</td>\n",
       "      <td>0.651335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.544800</td>\n",
       "      <td>0.571658</td>\n",
       "      <td>0.713311</td>\n",
       "      <td>0.643616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.531500</td>\n",
       "      <td>0.567961</td>\n",
       "      <td>0.717211</td>\n",
       "      <td>0.657732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.510100</td>\n",
       "      <td>0.577514</td>\n",
       "      <td>0.726475</td>\n",
       "      <td>0.645979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.515800</td>\n",
       "      <td>0.583873</td>\n",
       "      <td>0.698196</td>\n",
       "      <td>0.661658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.524000</td>\n",
       "      <td>0.599905</td>\n",
       "      <td>0.705997</td>\n",
       "      <td>0.658051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.502300</td>\n",
       "      <td>0.582502</td>\n",
       "      <td>0.722087</td>\n",
       "      <td>0.628603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.516200</td>\n",
       "      <td>0.582138</td>\n",
       "      <td>0.712335</td>\n",
       "      <td>0.653525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.488500</td>\n",
       "      <td>0.584051</td>\n",
       "      <td>0.725987</td>\n",
       "      <td>0.649727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.489300</td>\n",
       "      <td>0.608530</td>\n",
       "      <td>0.725012</td>\n",
       "      <td>0.637210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.498900</td>\n",
       "      <td>0.592754</td>\n",
       "      <td>0.722087</td>\n",
       "      <td>0.652274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.487300</td>\n",
       "      <td>0.599591</td>\n",
       "      <td>0.727450</td>\n",
       "      <td>0.645094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.475700</td>\n",
       "      <td>0.608958</td>\n",
       "      <td>0.717699</td>\n",
       "      <td>0.664919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.485800</td>\n",
       "      <td>0.588492</td>\n",
       "      <td>0.721599</td>\n",
       "      <td>0.657728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.478100</td>\n",
       "      <td>0.602484</td>\n",
       "      <td>0.718674</td>\n",
       "      <td>0.663261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.454100</td>\n",
       "      <td>0.602375</td>\n",
       "      <td>0.719161</td>\n",
       "      <td>0.658743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.473100</td>\n",
       "      <td>0.595051</td>\n",
       "      <td>0.717211</td>\n",
       "      <td>0.664186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.482100</td>\n",
       "      <td>0.615606</td>\n",
       "      <td>0.715261</td>\n",
       "      <td>0.663409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.447500</td>\n",
       "      <td>0.610264</td>\n",
       "      <td>0.720624</td>\n",
       "      <td>0.665912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunis-ai/TunBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tunis-ai/TunBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8203 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2051 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1935' max='1935' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1935/1935 02:55, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.718300</td>\n",
       "      <td>0.651238</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.669200</td>\n",
       "      <td>0.655292</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.652700</td>\n",
       "      <td>0.650757</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.666300</td>\n",
       "      <td>0.650815</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.661400</td>\n",
       "      <td>0.654513</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.653500</td>\n",
       "      <td>0.651553</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.661300</td>\n",
       "      <td>0.656096</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.660800</td>\n",
       "      <td>0.651376</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.661500</td>\n",
       "      <td>0.643682</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.643500</td>\n",
       "      <td>0.622946</td>\n",
       "      <td>0.679181</td>\n",
       "      <td>0.550625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.653100</td>\n",
       "      <td>0.650750</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.650200</td>\n",
       "      <td>0.665867</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.672700</td>\n",
       "      <td>0.663825</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.655600</td>\n",
       "      <td>0.651063</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.659300</td>\n",
       "      <td>0.653867</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.659100</td>\n",
       "      <td>0.651539</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.660600</td>\n",
       "      <td>0.656623</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.662300</td>\n",
       "      <td>0.656070</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.649700</td>\n",
       "      <td>0.652873</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.667000</td>\n",
       "      <td>0.662711</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.658000</td>\n",
       "      <td>0.650838</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.656700</td>\n",
       "      <td>0.650703</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.655400</td>\n",
       "      <td>0.651256</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.661500</td>\n",
       "      <td>0.653179</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.655600</td>\n",
       "      <td>0.650762</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.656900</td>\n",
       "      <td>0.652500</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.656000</td>\n",
       "      <td>0.650692</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.657900</td>\n",
       "      <td>0.651658</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.659000</td>\n",
       "      <td>0.651180</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.655900</td>\n",
       "      <td>0.651011</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.652000</td>\n",
       "      <td>0.651532</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.650936</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunis-ai/TunBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tunis-ai/TunBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8203 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2051 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1935' max='1935' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1935/1935 02:55, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.718300</td>\n",
       "      <td>0.651238</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.669200</td>\n",
       "      <td>0.655292</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.652700</td>\n",
       "      <td>0.650757</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.666300</td>\n",
       "      <td>0.650815</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.661400</td>\n",
       "      <td>0.654513</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.653500</td>\n",
       "      <td>0.651553</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.661300</td>\n",
       "      <td>0.656096</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.660800</td>\n",
       "      <td>0.651376</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.661500</td>\n",
       "      <td>0.643682</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.643500</td>\n",
       "      <td>0.622946</td>\n",
       "      <td>0.679181</td>\n",
       "      <td>0.550625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.653100</td>\n",
       "      <td>0.650750</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.650200</td>\n",
       "      <td>0.665867</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.672700</td>\n",
       "      <td>0.663825</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.655600</td>\n",
       "      <td>0.651063</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.659300</td>\n",
       "      <td>0.653867</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.659100</td>\n",
       "      <td>0.651539</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.660600</td>\n",
       "      <td>0.656623</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.662300</td>\n",
       "      <td>0.656070</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.649700</td>\n",
       "      <td>0.652873</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.667000</td>\n",
       "      <td>0.662711</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.658000</td>\n",
       "      <td>0.650838</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.656700</td>\n",
       "      <td>0.650703</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.655400</td>\n",
       "      <td>0.651256</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.661500</td>\n",
       "      <td>0.653179</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.655600</td>\n",
       "      <td>0.650762</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.656900</td>\n",
       "      <td>0.652500</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.656000</td>\n",
       "      <td>0.650692</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.657900</td>\n",
       "      <td>0.651658</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.659000</td>\n",
       "      <td>0.651180</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.655900</td>\n",
       "      <td>0.651011</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.652000</td>\n",
       "      <td>0.651532</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.650936</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunis-ai/TunBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tunis-ai/TunBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8203 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2051 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1935' max='1935' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1935/1935 02:55, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.718300</td>\n",
       "      <td>0.651238</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.669200</td>\n",
       "      <td>0.655292</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.652700</td>\n",
       "      <td>0.650757</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.666300</td>\n",
       "      <td>0.650815</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.661400</td>\n",
       "      <td>0.654513</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.653500</td>\n",
       "      <td>0.651553</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.661300</td>\n",
       "      <td>0.656096</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.660800</td>\n",
       "      <td>0.651376</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.661500</td>\n",
       "      <td>0.643682</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.643500</td>\n",
       "      <td>0.622946</td>\n",
       "      <td>0.679181</td>\n",
       "      <td>0.550625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.653100</td>\n",
       "      <td>0.650750</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.650200</td>\n",
       "      <td>0.665867</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.672700</td>\n",
       "      <td>0.663825</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.655600</td>\n",
       "      <td>0.651063</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.659300</td>\n",
       "      <td>0.653867</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.659100</td>\n",
       "      <td>0.651539</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.660600</td>\n",
       "      <td>0.656623</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.662300</td>\n",
       "      <td>0.656070</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.649700</td>\n",
       "      <td>0.652873</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.667000</td>\n",
       "      <td>0.662711</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.658000</td>\n",
       "      <td>0.650838</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.656700</td>\n",
       "      <td>0.650703</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.655400</td>\n",
       "      <td>0.651256</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.661500</td>\n",
       "      <td>0.653179</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.655600</td>\n",
       "      <td>0.650762</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.656900</td>\n",
       "      <td>0.652500</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.656000</td>\n",
       "      <td>0.650692</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.657900</td>\n",
       "      <td>0.651658</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.659000</td>\n",
       "      <td>0.651180</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.655900</td>\n",
       "      <td>0.651011</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.652000</td>\n",
       "      <td>0.651532</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.650936</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.391936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunis-ai/TunBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tunis-ai/TunBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8203 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2051 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1935' max='1935' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1935/1935 02:55, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.689800</td>\n",
       "      <td>0.668852</td>\n",
       "      <td>0.646514</td>\n",
       "      <td>0.392656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.665700</td>\n",
       "      <td>0.649804</td>\n",
       "      <td>0.646514</td>\n",
       "      <td>0.392656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.654300</td>\n",
       "      <td>0.649029</td>\n",
       "      <td>0.646514</td>\n",
       "      <td>0.392656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.671900</td>\n",
       "      <td>0.644625</td>\n",
       "      <td>0.658703</td>\n",
       "      <td>0.442635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.644800</td>\n",
       "      <td>0.606122</td>\n",
       "      <td>0.686007</td>\n",
       "      <td>0.614567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.613200</td>\n",
       "      <td>0.597165</td>\n",
       "      <td>0.692345</td>\n",
       "      <td>0.581370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.614600</td>\n",
       "      <td>0.576854</td>\n",
       "      <td>0.712335</td>\n",
       "      <td>0.653189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.586200</td>\n",
       "      <td>0.595224</td>\n",
       "      <td>0.705022</td>\n",
       "      <td>0.596405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.591700</td>\n",
       "      <td>0.575157</td>\n",
       "      <td>0.710873</td>\n",
       "      <td>0.614372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.570000</td>\n",
       "      <td>0.603274</td>\n",
       "      <td>0.701121</td>\n",
       "      <td>0.675723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.571200</td>\n",
       "      <td>0.569537</td>\n",
       "      <td>0.724037</td>\n",
       "      <td>0.643038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.551500</td>\n",
       "      <td>0.579089</td>\n",
       "      <td>0.724525</td>\n",
       "      <td>0.636796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.570300</td>\n",
       "      <td>0.565331</td>\n",
       "      <td>0.725012</td>\n",
       "      <td>0.659615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.563100</td>\n",
       "      <td>0.567566</td>\n",
       "      <td>0.720624</td>\n",
       "      <td>0.685433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.542900</td>\n",
       "      <td>0.556780</td>\n",
       "      <td>0.725500</td>\n",
       "      <td>0.642116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.544400</td>\n",
       "      <td>0.564267</td>\n",
       "      <td>0.716236</td>\n",
       "      <td>0.671483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.536800</td>\n",
       "      <td>0.554786</td>\n",
       "      <td>0.727450</td>\n",
       "      <td>0.644222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.530600</td>\n",
       "      <td>0.561122</td>\n",
       "      <td>0.725500</td>\n",
       "      <td>0.649714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.535100</td>\n",
       "      <td>0.568394</td>\n",
       "      <td>0.716724</td>\n",
       "      <td>0.607484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.535700</td>\n",
       "      <td>0.570320</td>\n",
       "      <td>0.725012</td>\n",
       "      <td>0.629094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.526700</td>\n",
       "      <td>0.559761</td>\n",
       "      <td>0.725012</td>\n",
       "      <td>0.659615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.521800</td>\n",
       "      <td>0.559176</td>\n",
       "      <td>0.732326</td>\n",
       "      <td>0.679602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.514300</td>\n",
       "      <td>0.562651</td>\n",
       "      <td>0.728425</td>\n",
       "      <td>0.685464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.536900</td>\n",
       "      <td>0.562139</td>\n",
       "      <td>0.723062</td>\n",
       "      <td>0.626962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.509000</td>\n",
       "      <td>0.575708</td>\n",
       "      <td>0.728913</td>\n",
       "      <td>0.655065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.517400</td>\n",
       "      <td>0.561262</td>\n",
       "      <td>0.732326</td>\n",
       "      <td>0.656829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.506800</td>\n",
       "      <td>0.586112</td>\n",
       "      <td>0.710385</td>\n",
       "      <td>0.677044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.500200</td>\n",
       "      <td>0.560941</td>\n",
       "      <td>0.728425</td>\n",
       "      <td>0.661128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.485000</td>\n",
       "      <td>0.565584</td>\n",
       "      <td>0.728425</td>\n",
       "      <td>0.669172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.506300</td>\n",
       "      <td>0.561446</td>\n",
       "      <td>0.732813</td>\n",
       "      <td>0.658453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.503900</td>\n",
       "      <td>0.564305</td>\n",
       "      <td>0.726475</td>\n",
       "      <td>0.664415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.484500</td>\n",
       "      <td>0.565354</td>\n",
       "      <td>0.727938</td>\n",
       "      <td>0.663946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunis-ai/TunBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tunis-ai/TunBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8203 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2051 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1935' max='1935' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1935/1935 02:55, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.689800</td>\n",
       "      <td>0.668852</td>\n",
       "      <td>0.646514</td>\n",
       "      <td>0.392656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.665700</td>\n",
       "      <td>0.649804</td>\n",
       "      <td>0.646514</td>\n",
       "      <td>0.392656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.654300</td>\n",
       "      <td>0.649029</td>\n",
       "      <td>0.646514</td>\n",
       "      <td>0.392656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.671900</td>\n",
       "      <td>0.644625</td>\n",
       "      <td>0.658703</td>\n",
       "      <td>0.442635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.644800</td>\n",
       "      <td>0.606122</td>\n",
       "      <td>0.686007</td>\n",
       "      <td>0.614567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.613200</td>\n",
       "      <td>0.597165</td>\n",
       "      <td>0.692345</td>\n",
       "      <td>0.581370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.614600</td>\n",
       "      <td>0.576854</td>\n",
       "      <td>0.712335</td>\n",
       "      <td>0.653189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.586200</td>\n",
       "      <td>0.595224</td>\n",
       "      <td>0.705022</td>\n",
       "      <td>0.596405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.591700</td>\n",
       "      <td>0.575157</td>\n",
       "      <td>0.710873</td>\n",
       "      <td>0.614372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.570000</td>\n",
       "      <td>0.603274</td>\n",
       "      <td>0.701121</td>\n",
       "      <td>0.675723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.571200</td>\n",
       "      <td>0.569537</td>\n",
       "      <td>0.724037</td>\n",
       "      <td>0.643038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.551500</td>\n",
       "      <td>0.579089</td>\n",
       "      <td>0.724525</td>\n",
       "      <td>0.636796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.570300</td>\n",
       "      <td>0.565331</td>\n",
       "      <td>0.725012</td>\n",
       "      <td>0.659615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.563100</td>\n",
       "      <td>0.567566</td>\n",
       "      <td>0.720624</td>\n",
       "      <td>0.685433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.542900</td>\n",
       "      <td>0.556780</td>\n",
       "      <td>0.725500</td>\n",
       "      <td>0.642116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.544400</td>\n",
       "      <td>0.564267</td>\n",
       "      <td>0.716236</td>\n",
       "      <td>0.671483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.536800</td>\n",
       "      <td>0.554786</td>\n",
       "      <td>0.727450</td>\n",
       "      <td>0.644222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.530600</td>\n",
       "      <td>0.561122</td>\n",
       "      <td>0.725500</td>\n",
       "      <td>0.649714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.535100</td>\n",
       "      <td>0.568394</td>\n",
       "      <td>0.716724</td>\n",
       "      <td>0.607484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.535700</td>\n",
       "      <td>0.570320</td>\n",
       "      <td>0.725012</td>\n",
       "      <td>0.629094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.526700</td>\n",
       "      <td>0.559761</td>\n",
       "      <td>0.725012</td>\n",
       "      <td>0.659615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.521800</td>\n",
       "      <td>0.559176</td>\n",
       "      <td>0.732326</td>\n",
       "      <td>0.679602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.514300</td>\n",
       "      <td>0.562651</td>\n",
       "      <td>0.728425</td>\n",
       "      <td>0.685464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.536900</td>\n",
       "      <td>0.562139</td>\n",
       "      <td>0.723062</td>\n",
       "      <td>0.626962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.509000</td>\n",
       "      <td>0.575708</td>\n",
       "      <td>0.728913</td>\n",
       "      <td>0.655065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.517400</td>\n",
       "      <td>0.561262</td>\n",
       "      <td>0.732326</td>\n",
       "      <td>0.656829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.506800</td>\n",
       "      <td>0.586112</td>\n",
       "      <td>0.710385</td>\n",
       "      <td>0.677044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.500200</td>\n",
       "      <td>0.560941</td>\n",
       "      <td>0.728425</td>\n",
       "      <td>0.661128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.485000</td>\n",
       "      <td>0.565584</td>\n",
       "      <td>0.728425</td>\n",
       "      <td>0.669172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.506300</td>\n",
       "      <td>0.561446</td>\n",
       "      <td>0.732813</td>\n",
       "      <td>0.658453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.503900</td>\n",
       "      <td>0.564305</td>\n",
       "      <td>0.726475</td>\n",
       "      <td>0.664415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.484500</td>\n",
       "      <td>0.565354</td>\n",
       "      <td>0.727938</td>\n",
       "      <td>0.663946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunis-ai/TunBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tunis-ai/TunBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8203 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2051 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1935' max='1935' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1935/1935 02:55, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.689800</td>\n",
       "      <td>0.668852</td>\n",
       "      <td>0.646514</td>\n",
       "      <td>0.392656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.665700</td>\n",
       "      <td>0.649804</td>\n",
       "      <td>0.646514</td>\n",
       "      <td>0.392656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.654300</td>\n",
       "      <td>0.649029</td>\n",
       "      <td>0.646514</td>\n",
       "      <td>0.392656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.671900</td>\n",
       "      <td>0.644625</td>\n",
       "      <td>0.658703</td>\n",
       "      <td>0.442635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.644800</td>\n",
       "      <td>0.606122</td>\n",
       "      <td>0.686007</td>\n",
       "      <td>0.614567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.613200</td>\n",
       "      <td>0.597165</td>\n",
       "      <td>0.692345</td>\n",
       "      <td>0.581370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.614600</td>\n",
       "      <td>0.576854</td>\n",
       "      <td>0.712335</td>\n",
       "      <td>0.653189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.586200</td>\n",
       "      <td>0.595224</td>\n",
       "      <td>0.705022</td>\n",
       "      <td>0.596405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.591700</td>\n",
       "      <td>0.575157</td>\n",
       "      <td>0.710873</td>\n",
       "      <td>0.614372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.570000</td>\n",
       "      <td>0.603274</td>\n",
       "      <td>0.701121</td>\n",
       "      <td>0.675723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.571200</td>\n",
       "      <td>0.569537</td>\n",
       "      <td>0.724037</td>\n",
       "      <td>0.643038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.551500</td>\n",
       "      <td>0.579089</td>\n",
       "      <td>0.724525</td>\n",
       "      <td>0.636796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.570300</td>\n",
       "      <td>0.565331</td>\n",
       "      <td>0.725012</td>\n",
       "      <td>0.659615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.563100</td>\n",
       "      <td>0.567566</td>\n",
       "      <td>0.720624</td>\n",
       "      <td>0.685433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.542900</td>\n",
       "      <td>0.556780</td>\n",
       "      <td>0.725500</td>\n",
       "      <td>0.642116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.544400</td>\n",
       "      <td>0.564267</td>\n",
       "      <td>0.716236</td>\n",
       "      <td>0.671483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.536800</td>\n",
       "      <td>0.554786</td>\n",
       "      <td>0.727450</td>\n",
       "      <td>0.644222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.530600</td>\n",
       "      <td>0.561122</td>\n",
       "      <td>0.725500</td>\n",
       "      <td>0.649714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.535100</td>\n",
       "      <td>0.568394</td>\n",
       "      <td>0.716724</td>\n",
       "      <td>0.607484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.535700</td>\n",
       "      <td>0.570320</td>\n",
       "      <td>0.725012</td>\n",
       "      <td>0.629094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.526700</td>\n",
       "      <td>0.559761</td>\n",
       "      <td>0.725012</td>\n",
       "      <td>0.659615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.521800</td>\n",
       "      <td>0.559176</td>\n",
       "      <td>0.732326</td>\n",
       "      <td>0.679602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.514300</td>\n",
       "      <td>0.562651</td>\n",
       "      <td>0.728425</td>\n",
       "      <td>0.685464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.536900</td>\n",
       "      <td>0.562139</td>\n",
       "      <td>0.723062</td>\n",
       "      <td>0.626962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.509000</td>\n",
       "      <td>0.575708</td>\n",
       "      <td>0.728913</td>\n",
       "      <td>0.655065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.517400</td>\n",
       "      <td>0.561262</td>\n",
       "      <td>0.732326</td>\n",
       "      <td>0.656829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.506800</td>\n",
       "      <td>0.586112</td>\n",
       "      <td>0.710385</td>\n",
       "      <td>0.677044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.500200</td>\n",
       "      <td>0.560941</td>\n",
       "      <td>0.728425</td>\n",
       "      <td>0.661128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.485000</td>\n",
       "      <td>0.565584</td>\n",
       "      <td>0.728425</td>\n",
       "      <td>0.669172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.506300</td>\n",
       "      <td>0.561446</td>\n",
       "      <td>0.732813</td>\n",
       "      <td>0.658453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.503900</td>\n",
       "      <td>0.564305</td>\n",
       "      <td>0.726475</td>\n",
       "      <td>0.664415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.484500</td>\n",
       "      <td>0.565354</td>\n",
       "      <td>0.727938</td>\n",
       "      <td>0.663946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['comment_message', 'label'],\n",
       "        num_rows: 8203\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['comment_message', 'label'],\n",
       "        num_rows: 2051\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alger-ia/dziribert, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8203 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2051 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1935' max='1935' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1935/1935 02:59, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.436000</td>\n",
       "      <td>0.488974</td>\n",
       "      <td>0.783520</td>\n",
       "      <td>0.772002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.382700</td>\n",
       "      <td>0.357678</td>\n",
       "      <td>0.849342</td>\n",
       "      <td>0.823561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.251700</td>\n",
       "      <td>0.441415</td>\n",
       "      <td>0.849342</td>\n",
       "      <td>0.826513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.213100</td>\n",
       "      <td>0.430861</td>\n",
       "      <td>0.840078</td>\n",
       "      <td>0.822647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.127700</td>\n",
       "      <td>0.596211</td>\n",
       "      <td>0.838615</td>\n",
       "      <td>0.817200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.090200</td>\n",
       "      <td>0.575850</td>\n",
       "      <td>0.822526</td>\n",
       "      <td>0.802642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.056300</td>\n",
       "      <td>1.216122</td>\n",
       "      <td>0.772306</td>\n",
       "      <td>0.761736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.062000</td>\n",
       "      <td>0.874954</td>\n",
       "      <td>0.808386</td>\n",
       "      <td>0.794114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.034800</td>\n",
       "      <td>0.889992</td>\n",
       "      <td>0.836177</td>\n",
       "      <td>0.816803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.031600</td>\n",
       "      <td>0.998999</td>\n",
       "      <td>0.822038</td>\n",
       "      <td>0.806219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.017100</td>\n",
       "      <td>1.038710</td>\n",
       "      <td>0.844954</td>\n",
       "      <td>0.819745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.009200</td>\n",
       "      <td>1.114640</td>\n",
       "      <td>0.845929</td>\n",
       "      <td>0.825019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.013300</td>\n",
       "      <td>1.122225</td>\n",
       "      <td>0.849342</td>\n",
       "      <td>0.825654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.004800</td>\n",
       "      <td>1.215549</td>\n",
       "      <td>0.842028</td>\n",
       "      <td>0.820726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.005200</td>\n",
       "      <td>1.198126</td>\n",
       "      <td>0.828864</td>\n",
       "      <td>0.811775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>1.334594</td>\n",
       "      <td>0.832765</td>\n",
       "      <td>0.813964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.006300</td>\n",
       "      <td>1.321703</td>\n",
       "      <td>0.848854</td>\n",
       "      <td>0.822913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>1.399787</td>\n",
       "      <td>0.829352</td>\n",
       "      <td>0.810622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>1.361942</td>\n",
       "      <td>0.838128</td>\n",
       "      <td>0.816855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>1.364185</td>\n",
       "      <td>0.844466</td>\n",
       "      <td>0.823018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.005900</td>\n",
       "      <td>1.395078</td>\n",
       "      <td>0.845929</td>\n",
       "      <td>0.819800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>1.362200</td>\n",
       "      <td>0.840566</td>\n",
       "      <td>0.818719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>1.391587</td>\n",
       "      <td>0.840566</td>\n",
       "      <td>0.818997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.426660</td>\n",
       "      <td>0.840566</td>\n",
       "      <td>0.819409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>1.443213</td>\n",
       "      <td>0.839590</td>\n",
       "      <td>0.815733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>1.512932</td>\n",
       "      <td>0.824963</td>\n",
       "      <td>0.808342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.438551</td>\n",
       "      <td>0.840566</td>\n",
       "      <td>0.818439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>1.453290</td>\n",
       "      <td>0.838615</td>\n",
       "      <td>0.819336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>1.465679</td>\n",
       "      <td>0.835690</td>\n",
       "      <td>0.816710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>1.464952</td>\n",
       "      <td>0.838128</td>\n",
       "      <td>0.818855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.457490</td>\n",
       "      <td>0.837640</td>\n",
       "      <td>0.817323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.458264</td>\n",
       "      <td>0.838615</td>\n",
       "      <td>0.818420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alger-ia/dziribert, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8203 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2051 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1935' max='1935' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1935/1935 02:58, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.436000</td>\n",
       "      <td>0.488974</td>\n",
       "      <td>0.783520</td>\n",
       "      <td>0.772002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.382700</td>\n",
       "      <td>0.357678</td>\n",
       "      <td>0.849342</td>\n",
       "      <td>0.823561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.251700</td>\n",
       "      <td>0.441415</td>\n",
       "      <td>0.849342</td>\n",
       "      <td>0.826513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.213100</td>\n",
       "      <td>0.430861</td>\n",
       "      <td>0.840078</td>\n",
       "      <td>0.822647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.127700</td>\n",
       "      <td>0.596211</td>\n",
       "      <td>0.838615</td>\n",
       "      <td>0.817200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.090200</td>\n",
       "      <td>0.575850</td>\n",
       "      <td>0.822526</td>\n",
       "      <td>0.802642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.056300</td>\n",
       "      <td>1.216122</td>\n",
       "      <td>0.772306</td>\n",
       "      <td>0.761736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.062000</td>\n",
       "      <td>0.874954</td>\n",
       "      <td>0.808386</td>\n",
       "      <td>0.794114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.034800</td>\n",
       "      <td>0.889992</td>\n",
       "      <td>0.836177</td>\n",
       "      <td>0.816803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.031600</td>\n",
       "      <td>0.998999</td>\n",
       "      <td>0.822038</td>\n",
       "      <td>0.806219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.017100</td>\n",
       "      <td>1.038710</td>\n",
       "      <td>0.844954</td>\n",
       "      <td>0.819745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.009200</td>\n",
       "      <td>1.114640</td>\n",
       "      <td>0.845929</td>\n",
       "      <td>0.825019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.013300</td>\n",
       "      <td>1.122225</td>\n",
       "      <td>0.849342</td>\n",
       "      <td>0.825654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.004800</td>\n",
       "      <td>1.215549</td>\n",
       "      <td>0.842028</td>\n",
       "      <td>0.820726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.005200</td>\n",
       "      <td>1.198126</td>\n",
       "      <td>0.828864</td>\n",
       "      <td>0.811775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>1.334594</td>\n",
       "      <td>0.832765</td>\n",
       "      <td>0.813964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.006300</td>\n",
       "      <td>1.321703</td>\n",
       "      <td>0.848854</td>\n",
       "      <td>0.822913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>1.399787</td>\n",
       "      <td>0.829352</td>\n",
       "      <td>0.810622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>1.361942</td>\n",
       "      <td>0.838128</td>\n",
       "      <td>0.816855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>1.364185</td>\n",
       "      <td>0.844466</td>\n",
       "      <td>0.823018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.005900</td>\n",
       "      <td>1.395078</td>\n",
       "      <td>0.845929</td>\n",
       "      <td>0.819800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>1.362200</td>\n",
       "      <td>0.840566</td>\n",
       "      <td>0.818719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>1.391587</td>\n",
       "      <td>0.840566</td>\n",
       "      <td>0.818997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.426660</td>\n",
       "      <td>0.840566</td>\n",
       "      <td>0.819409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>1.443213</td>\n",
       "      <td>0.839590</td>\n",
       "      <td>0.815733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>1.512932</td>\n",
       "      <td>0.824963</td>\n",
       "      <td>0.808342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.438551</td>\n",
       "      <td>0.840566</td>\n",
       "      <td>0.818439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>1.453290</td>\n",
       "      <td>0.838615</td>\n",
       "      <td>0.819336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>1.465679</td>\n",
       "      <td>0.835690</td>\n",
       "      <td>0.816710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>1.464952</td>\n",
       "      <td>0.838128</td>\n",
       "      <td>0.818855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.457490</td>\n",
       "      <td>0.837640</td>\n",
       "      <td>0.817323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.458264</td>\n",
       "      <td>0.838615</td>\n",
       "      <td>0.818420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alger-ia/dziribert, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8203 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2051 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1935' max='1935' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1935/1935 02:58, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.436000</td>\n",
       "      <td>0.488974</td>\n",
       "      <td>0.783520</td>\n",
       "      <td>0.772002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.382700</td>\n",
       "      <td>0.357678</td>\n",
       "      <td>0.849342</td>\n",
       "      <td>0.823561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.251700</td>\n",
       "      <td>0.441415</td>\n",
       "      <td>0.849342</td>\n",
       "      <td>0.826513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.213100</td>\n",
       "      <td>0.430861</td>\n",
       "      <td>0.840078</td>\n",
       "      <td>0.822647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.127700</td>\n",
       "      <td>0.596211</td>\n",
       "      <td>0.838615</td>\n",
       "      <td>0.817200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.090200</td>\n",
       "      <td>0.575850</td>\n",
       "      <td>0.822526</td>\n",
       "      <td>0.802642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.056300</td>\n",
       "      <td>1.216122</td>\n",
       "      <td>0.772306</td>\n",
       "      <td>0.761736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.062000</td>\n",
       "      <td>0.874954</td>\n",
       "      <td>0.808386</td>\n",
       "      <td>0.794114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.034800</td>\n",
       "      <td>0.889992</td>\n",
       "      <td>0.836177</td>\n",
       "      <td>0.816803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.031600</td>\n",
       "      <td>0.998999</td>\n",
       "      <td>0.822038</td>\n",
       "      <td>0.806219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.017100</td>\n",
       "      <td>1.038710</td>\n",
       "      <td>0.844954</td>\n",
       "      <td>0.819745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.009200</td>\n",
       "      <td>1.114640</td>\n",
       "      <td>0.845929</td>\n",
       "      <td>0.825019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.013300</td>\n",
       "      <td>1.122225</td>\n",
       "      <td>0.849342</td>\n",
       "      <td>0.825654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.004800</td>\n",
       "      <td>1.215549</td>\n",
       "      <td>0.842028</td>\n",
       "      <td>0.820726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.005200</td>\n",
       "      <td>1.198126</td>\n",
       "      <td>0.828864</td>\n",
       "      <td>0.811775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>1.334594</td>\n",
       "      <td>0.832765</td>\n",
       "      <td>0.813964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.006300</td>\n",
       "      <td>1.321703</td>\n",
       "      <td>0.848854</td>\n",
       "      <td>0.822913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>1.399787</td>\n",
       "      <td>0.829352</td>\n",
       "      <td>0.810622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>1.361942</td>\n",
       "      <td>0.838128</td>\n",
       "      <td>0.816855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>1.364185</td>\n",
       "      <td>0.844466</td>\n",
       "      <td>0.823018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.005900</td>\n",
       "      <td>1.395078</td>\n",
       "      <td>0.845929</td>\n",
       "      <td>0.819800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>1.362200</td>\n",
       "      <td>0.840566</td>\n",
       "      <td>0.818719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>1.391587</td>\n",
       "      <td>0.840566</td>\n",
       "      <td>0.818997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.426660</td>\n",
       "      <td>0.840566</td>\n",
       "      <td>0.819409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>1.443213</td>\n",
       "      <td>0.839590</td>\n",
       "      <td>0.815733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>1.512932</td>\n",
       "      <td>0.824963</td>\n",
       "      <td>0.808342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.438551</td>\n",
       "      <td>0.840566</td>\n",
       "      <td>0.818439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>1.453290</td>\n",
       "      <td>0.838615</td>\n",
       "      <td>0.819336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>1.465679</td>\n",
       "      <td>0.835690</td>\n",
       "      <td>0.816710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>1.464952</td>\n",
       "      <td>0.838128</td>\n",
       "      <td>0.818855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.457490</td>\n",
       "      <td>0.837640</td>\n",
       "      <td>0.817323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.458264</td>\n",
       "      <td>0.838615</td>\n",
       "      <td>0.818420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alger-ia/dziribert, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8203 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2051 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1935' max='1935' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1935/1935 02:58, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.452000</td>\n",
       "      <td>0.367254</td>\n",
       "      <td>0.844466</td>\n",
       "      <td>0.815046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.388800</td>\n",
       "      <td>0.348174</td>\n",
       "      <td>0.853730</td>\n",
       "      <td>0.835963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.240300</td>\n",
       "      <td>0.409674</td>\n",
       "      <td>0.837640</td>\n",
       "      <td>0.828397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.211700</td>\n",
       "      <td>0.360200</td>\n",
       "      <td>0.855193</td>\n",
       "      <td>0.838914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.118800</td>\n",
       "      <td>0.634799</td>\n",
       "      <td>0.835202</td>\n",
       "      <td>0.820608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.084300</td>\n",
       "      <td>0.657396</td>\n",
       "      <td>0.849829</td>\n",
       "      <td>0.823434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.048500</td>\n",
       "      <td>0.885559</td>\n",
       "      <td>0.853242</td>\n",
       "      <td>0.835118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.051300</td>\n",
       "      <td>0.737983</td>\n",
       "      <td>0.844954</td>\n",
       "      <td>0.828054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.036000</td>\n",
       "      <td>0.855884</td>\n",
       "      <td>0.852267</td>\n",
       "      <td>0.834382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.017000</td>\n",
       "      <td>0.825284</td>\n",
       "      <td>0.854705</td>\n",
       "      <td>0.834476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.023200</td>\n",
       "      <td>0.818288</td>\n",
       "      <td>0.849342</td>\n",
       "      <td>0.830613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.013700</td>\n",
       "      <td>0.966903</td>\n",
       "      <td>0.847392</td>\n",
       "      <td>0.827659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>1.103268</td>\n",
       "      <td>0.845441</td>\n",
       "      <td>0.832798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>1.070937</td>\n",
       "      <td>0.848367</td>\n",
       "      <td>0.833652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>1.138682</td>\n",
       "      <td>0.857630</td>\n",
       "      <td>0.838185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.008200</td>\n",
       "      <td>1.162807</td>\n",
       "      <td>0.847879</td>\n",
       "      <td>0.833694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>1.279726</td>\n",
       "      <td>0.833252</td>\n",
       "      <td>0.820783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.006900</td>\n",
       "      <td>1.165644</td>\n",
       "      <td>0.853730</td>\n",
       "      <td>0.838757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>1.169081</td>\n",
       "      <td>0.851780</td>\n",
       "      <td>0.835956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>1.195302</td>\n",
       "      <td>0.853730</td>\n",
       "      <td>0.836198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>1.214936</td>\n",
       "      <td>0.854217</td>\n",
       "      <td>0.838708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>1.275697</td>\n",
       "      <td>0.847392</td>\n",
       "      <td>0.833109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>1.288289</td>\n",
       "      <td>0.846416</td>\n",
       "      <td>0.832458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.240807</td>\n",
       "      <td>0.854217</td>\n",
       "      <td>0.838491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>1.231068</td>\n",
       "      <td>0.853242</td>\n",
       "      <td>0.837191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.300172</td>\n",
       "      <td>0.846904</td>\n",
       "      <td>0.833245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>1.319671</td>\n",
       "      <td>0.847392</td>\n",
       "      <td>0.834226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.274784</td>\n",
       "      <td>0.849829</td>\n",
       "      <td>0.834565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.285829</td>\n",
       "      <td>0.850317</td>\n",
       "      <td>0.835263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.277319</td>\n",
       "      <td>0.850804</td>\n",
       "      <td>0.835424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.270036</td>\n",
       "      <td>0.852267</td>\n",
       "      <td>0.836331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.275586</td>\n",
       "      <td>0.851780</td>\n",
       "      <td>0.836284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alger-ia/dziribert, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8203 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2051 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1935' max='1935' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1935/1935 02:58, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.452000</td>\n",
       "      <td>0.367254</td>\n",
       "      <td>0.844466</td>\n",
       "      <td>0.815046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.388800</td>\n",
       "      <td>0.348174</td>\n",
       "      <td>0.853730</td>\n",
       "      <td>0.835963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.240300</td>\n",
       "      <td>0.409674</td>\n",
       "      <td>0.837640</td>\n",
       "      <td>0.828397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.211700</td>\n",
       "      <td>0.360200</td>\n",
       "      <td>0.855193</td>\n",
       "      <td>0.838914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.118800</td>\n",
       "      <td>0.634799</td>\n",
       "      <td>0.835202</td>\n",
       "      <td>0.820608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.084300</td>\n",
       "      <td>0.657396</td>\n",
       "      <td>0.849829</td>\n",
       "      <td>0.823434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.048500</td>\n",
       "      <td>0.885559</td>\n",
       "      <td>0.853242</td>\n",
       "      <td>0.835118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.051300</td>\n",
       "      <td>0.737983</td>\n",
       "      <td>0.844954</td>\n",
       "      <td>0.828054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.036000</td>\n",
       "      <td>0.855884</td>\n",
       "      <td>0.852267</td>\n",
       "      <td>0.834382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.017000</td>\n",
       "      <td>0.825284</td>\n",
       "      <td>0.854705</td>\n",
       "      <td>0.834476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.023200</td>\n",
       "      <td>0.818288</td>\n",
       "      <td>0.849342</td>\n",
       "      <td>0.830613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.013700</td>\n",
       "      <td>0.966903</td>\n",
       "      <td>0.847392</td>\n",
       "      <td>0.827659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>1.103268</td>\n",
       "      <td>0.845441</td>\n",
       "      <td>0.832798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>1.070937</td>\n",
       "      <td>0.848367</td>\n",
       "      <td>0.833652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>1.138682</td>\n",
       "      <td>0.857630</td>\n",
       "      <td>0.838185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.008200</td>\n",
       "      <td>1.162807</td>\n",
       "      <td>0.847879</td>\n",
       "      <td>0.833694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>1.279726</td>\n",
       "      <td>0.833252</td>\n",
       "      <td>0.820783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.006900</td>\n",
       "      <td>1.165644</td>\n",
       "      <td>0.853730</td>\n",
       "      <td>0.838757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>1.169081</td>\n",
       "      <td>0.851780</td>\n",
       "      <td>0.835956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>1.195302</td>\n",
       "      <td>0.853730</td>\n",
       "      <td>0.836198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>1.214936</td>\n",
       "      <td>0.854217</td>\n",
       "      <td>0.838708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>1.275697</td>\n",
       "      <td>0.847392</td>\n",
       "      <td>0.833109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>1.288289</td>\n",
       "      <td>0.846416</td>\n",
       "      <td>0.832458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.240807</td>\n",
       "      <td>0.854217</td>\n",
       "      <td>0.838491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>1.231068</td>\n",
       "      <td>0.853242</td>\n",
       "      <td>0.837191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.300172</td>\n",
       "      <td>0.846904</td>\n",
       "      <td>0.833245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>1.319671</td>\n",
       "      <td>0.847392</td>\n",
       "      <td>0.834226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.274784</td>\n",
       "      <td>0.849829</td>\n",
       "      <td>0.834565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.285829</td>\n",
       "      <td>0.850317</td>\n",
       "      <td>0.835263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.277319</td>\n",
       "      <td>0.850804</td>\n",
       "      <td>0.835424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.270036</td>\n",
       "      <td>0.852267</td>\n",
       "      <td>0.836331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.275586</td>\n",
       "      <td>0.851780</td>\n",
       "      <td>0.836284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alger-ia/dziribert, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8203 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2051 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1935' max='1935' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1935/1935 02:58, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.452000</td>\n",
       "      <td>0.367254</td>\n",
       "      <td>0.844466</td>\n",
       "      <td>0.815046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.388800</td>\n",
       "      <td>0.348174</td>\n",
       "      <td>0.853730</td>\n",
       "      <td>0.835963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.240300</td>\n",
       "      <td>0.409674</td>\n",
       "      <td>0.837640</td>\n",
       "      <td>0.828397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.211700</td>\n",
       "      <td>0.360200</td>\n",
       "      <td>0.855193</td>\n",
       "      <td>0.838914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.118800</td>\n",
       "      <td>0.634799</td>\n",
       "      <td>0.835202</td>\n",
       "      <td>0.820608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.084300</td>\n",
       "      <td>0.657396</td>\n",
       "      <td>0.849829</td>\n",
       "      <td>0.823434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.048500</td>\n",
       "      <td>0.885559</td>\n",
       "      <td>0.853242</td>\n",
       "      <td>0.835118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.051300</td>\n",
       "      <td>0.737983</td>\n",
       "      <td>0.844954</td>\n",
       "      <td>0.828054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.036000</td>\n",
       "      <td>0.855884</td>\n",
       "      <td>0.852267</td>\n",
       "      <td>0.834382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.017000</td>\n",
       "      <td>0.825284</td>\n",
       "      <td>0.854705</td>\n",
       "      <td>0.834476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.023200</td>\n",
       "      <td>0.818288</td>\n",
       "      <td>0.849342</td>\n",
       "      <td>0.830613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.013700</td>\n",
       "      <td>0.966903</td>\n",
       "      <td>0.847392</td>\n",
       "      <td>0.827659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>1.103268</td>\n",
       "      <td>0.845441</td>\n",
       "      <td>0.832798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>1.070937</td>\n",
       "      <td>0.848367</td>\n",
       "      <td>0.833652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>1.138682</td>\n",
       "      <td>0.857630</td>\n",
       "      <td>0.838185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.008200</td>\n",
       "      <td>1.162807</td>\n",
       "      <td>0.847879</td>\n",
       "      <td>0.833694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>1.279726</td>\n",
       "      <td>0.833252</td>\n",
       "      <td>0.820783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.006900</td>\n",
       "      <td>1.165644</td>\n",
       "      <td>0.853730</td>\n",
       "      <td>0.838757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>1.169081</td>\n",
       "      <td>0.851780</td>\n",
       "      <td>0.835956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>1.195302</td>\n",
       "      <td>0.853730</td>\n",
       "      <td>0.836198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>1.214936</td>\n",
       "      <td>0.854217</td>\n",
       "      <td>0.838708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>1.275697</td>\n",
       "      <td>0.847392</td>\n",
       "      <td>0.833109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>1.288289</td>\n",
       "      <td>0.846416</td>\n",
       "      <td>0.832458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.240807</td>\n",
       "      <td>0.854217</td>\n",
       "      <td>0.838491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>1.231068</td>\n",
       "      <td>0.853242</td>\n",
       "      <td>0.837191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.300172</td>\n",
       "      <td>0.846904</td>\n",
       "      <td>0.833245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>1.319671</td>\n",
       "      <td>0.847392</td>\n",
       "      <td>0.834226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.274784</td>\n",
       "      <td>0.849829</td>\n",
       "      <td>0.834565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.285829</td>\n",
       "      <td>0.850317</td>\n",
       "      <td>0.835263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.277319</td>\n",
       "      <td>0.850804</td>\n",
       "      <td>0.835424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.270036</td>\n",
       "      <td>0.852267</td>\n",
       "      <td>0.836331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.275586</td>\n",
       "      <td>0.851780</td>\n",
       "      <td>0.836284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alger-ia/dziribert, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8203 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2051 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1935' max='1935' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1935/1935 02:59, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.431600</td>\n",
       "      <td>0.380915</td>\n",
       "      <td>0.834715</td>\n",
       "      <td>0.812640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.377400</td>\n",
       "      <td>0.384359</td>\n",
       "      <td>0.843003</td>\n",
       "      <td>0.816058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.249200</td>\n",
       "      <td>0.429136</td>\n",
       "      <td>0.839103</td>\n",
       "      <td>0.815982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.199900</td>\n",
       "      <td>0.446112</td>\n",
       "      <td>0.830327</td>\n",
       "      <td>0.814620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.130600</td>\n",
       "      <td>0.799213</td>\n",
       "      <td>0.817162</td>\n",
       "      <td>0.805708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.090400</td>\n",
       "      <td>0.608350</td>\n",
       "      <td>0.831789</td>\n",
       "      <td>0.810040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>0.946399</td>\n",
       "      <td>0.825939</td>\n",
       "      <td>0.807421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.044400</td>\n",
       "      <td>0.953896</td>\n",
       "      <td>0.814725</td>\n",
       "      <td>0.799972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.023600</td>\n",
       "      <td>1.114560</td>\n",
       "      <td>0.823013</td>\n",
       "      <td>0.808199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.015100</td>\n",
       "      <td>1.174286</td>\n",
       "      <td>0.818137</td>\n",
       "      <td>0.803031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.022300</td>\n",
       "      <td>1.049718</td>\n",
       "      <td>0.826426</td>\n",
       "      <td>0.809400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.009600</td>\n",
       "      <td>1.194133</td>\n",
       "      <td>0.828376</td>\n",
       "      <td>0.810181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1.204442</td>\n",
       "      <td>0.834227</td>\n",
       "      <td>0.815143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.437631</td>\n",
       "      <td>0.815700</td>\n",
       "      <td>0.800215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.010300</td>\n",
       "      <td>1.304199</td>\n",
       "      <td>0.827889</td>\n",
       "      <td>0.809958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>1.336773</td>\n",
       "      <td>0.831302</td>\n",
       "      <td>0.812787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>1.352295</td>\n",
       "      <td>0.830327</td>\n",
       "      <td>0.812588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>1.382855</td>\n",
       "      <td>0.831789</td>\n",
       "      <td>0.814510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>1.529278</td>\n",
       "      <td>0.810824</td>\n",
       "      <td>0.796452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>1.487441</td>\n",
       "      <td>0.822526</td>\n",
       "      <td>0.806217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>1.517515</td>\n",
       "      <td>0.824476</td>\n",
       "      <td>0.808932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>1.436631</td>\n",
       "      <td>0.838615</td>\n",
       "      <td>0.818553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.477196</td>\n",
       "      <td>0.835202</td>\n",
       "      <td>0.814239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>1.520633</td>\n",
       "      <td>0.826426</td>\n",
       "      <td>0.809400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.561404</td>\n",
       "      <td>0.822526</td>\n",
       "      <td>0.807157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>1.526992</td>\n",
       "      <td>0.830327</td>\n",
       "      <td>0.812087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>1.552961</td>\n",
       "      <td>0.827401</td>\n",
       "      <td>0.809357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.542467</td>\n",
       "      <td>0.827889</td>\n",
       "      <td>0.808008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>1.557461</td>\n",
       "      <td>0.826914</td>\n",
       "      <td>0.807588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>1.557637</td>\n",
       "      <td>0.828864</td>\n",
       "      <td>0.809362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.577588</td>\n",
       "      <td>0.825451</td>\n",
       "      <td>0.807457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.578215</td>\n",
       "      <td>0.825451</td>\n",
       "      <td>0.807457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alger-ia/dziribert, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8203 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2051 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1935' max='1935' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1935/1935 02:58, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.431600</td>\n",
       "      <td>0.380915</td>\n",
       "      <td>0.834715</td>\n",
       "      <td>0.812640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.377400</td>\n",
       "      <td>0.384359</td>\n",
       "      <td>0.843003</td>\n",
       "      <td>0.816058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.249200</td>\n",
       "      <td>0.429136</td>\n",
       "      <td>0.839103</td>\n",
       "      <td>0.815982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.199900</td>\n",
       "      <td>0.446112</td>\n",
       "      <td>0.830327</td>\n",
       "      <td>0.814620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.130600</td>\n",
       "      <td>0.799213</td>\n",
       "      <td>0.817162</td>\n",
       "      <td>0.805708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.090400</td>\n",
       "      <td>0.608350</td>\n",
       "      <td>0.831789</td>\n",
       "      <td>0.810040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>0.946399</td>\n",
       "      <td>0.825939</td>\n",
       "      <td>0.807421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.044400</td>\n",
       "      <td>0.953896</td>\n",
       "      <td>0.814725</td>\n",
       "      <td>0.799972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.023600</td>\n",
       "      <td>1.114560</td>\n",
       "      <td>0.823013</td>\n",
       "      <td>0.808199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.015100</td>\n",
       "      <td>1.174286</td>\n",
       "      <td>0.818137</td>\n",
       "      <td>0.803031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.022300</td>\n",
       "      <td>1.049718</td>\n",
       "      <td>0.826426</td>\n",
       "      <td>0.809400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.009600</td>\n",
       "      <td>1.194133</td>\n",
       "      <td>0.828376</td>\n",
       "      <td>0.810181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1.204442</td>\n",
       "      <td>0.834227</td>\n",
       "      <td>0.815143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.437631</td>\n",
       "      <td>0.815700</td>\n",
       "      <td>0.800215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.010300</td>\n",
       "      <td>1.304199</td>\n",
       "      <td>0.827889</td>\n",
       "      <td>0.809958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>1.336773</td>\n",
       "      <td>0.831302</td>\n",
       "      <td>0.812787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>1.352295</td>\n",
       "      <td>0.830327</td>\n",
       "      <td>0.812588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>1.382855</td>\n",
       "      <td>0.831789</td>\n",
       "      <td>0.814510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>1.529278</td>\n",
       "      <td>0.810824</td>\n",
       "      <td>0.796452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>1.487441</td>\n",
       "      <td>0.822526</td>\n",
       "      <td>0.806217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>1.517515</td>\n",
       "      <td>0.824476</td>\n",
       "      <td>0.808932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>1.436631</td>\n",
       "      <td>0.838615</td>\n",
       "      <td>0.818553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.477196</td>\n",
       "      <td>0.835202</td>\n",
       "      <td>0.814239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>1.520633</td>\n",
       "      <td>0.826426</td>\n",
       "      <td>0.809400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.561404</td>\n",
       "      <td>0.822526</td>\n",
       "      <td>0.807157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>1.526992</td>\n",
       "      <td>0.830327</td>\n",
       "      <td>0.812087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>1.552961</td>\n",
       "      <td>0.827401</td>\n",
       "      <td>0.809357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.542467</td>\n",
       "      <td>0.827889</td>\n",
       "      <td>0.808008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>1.557461</td>\n",
       "      <td>0.826914</td>\n",
       "      <td>0.807588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>1.557637</td>\n",
       "      <td>0.828864</td>\n",
       "      <td>0.809362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.577588</td>\n",
       "      <td>0.825451</td>\n",
       "      <td>0.807457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.578215</td>\n",
       "      <td>0.825451</td>\n",
       "      <td>0.807457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alger-ia/dziribert, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8203 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2051 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1935' max='1935' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1935/1935 02:59, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.431600</td>\n",
       "      <td>0.380915</td>\n",
       "      <td>0.834715</td>\n",
       "      <td>0.812640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.377400</td>\n",
       "      <td>0.384359</td>\n",
       "      <td>0.843003</td>\n",
       "      <td>0.816058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.249200</td>\n",
       "      <td>0.429136</td>\n",
       "      <td>0.839103</td>\n",
       "      <td>0.815982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.199900</td>\n",
       "      <td>0.446112</td>\n",
       "      <td>0.830327</td>\n",
       "      <td>0.814620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.130600</td>\n",
       "      <td>0.799213</td>\n",
       "      <td>0.817162</td>\n",
       "      <td>0.805708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.090400</td>\n",
       "      <td>0.608350</td>\n",
       "      <td>0.831789</td>\n",
       "      <td>0.810040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>0.946399</td>\n",
       "      <td>0.825939</td>\n",
       "      <td>0.807421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.044400</td>\n",
       "      <td>0.953896</td>\n",
       "      <td>0.814725</td>\n",
       "      <td>0.799972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.023600</td>\n",
       "      <td>1.114560</td>\n",
       "      <td>0.823013</td>\n",
       "      <td>0.808199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.015100</td>\n",
       "      <td>1.174286</td>\n",
       "      <td>0.818137</td>\n",
       "      <td>0.803031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.022300</td>\n",
       "      <td>1.049718</td>\n",
       "      <td>0.826426</td>\n",
       "      <td>0.809400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.009600</td>\n",
       "      <td>1.194133</td>\n",
       "      <td>0.828376</td>\n",
       "      <td>0.810181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1.204442</td>\n",
       "      <td>0.834227</td>\n",
       "      <td>0.815143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.437631</td>\n",
       "      <td>0.815700</td>\n",
       "      <td>0.800215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.010300</td>\n",
       "      <td>1.304199</td>\n",
       "      <td>0.827889</td>\n",
       "      <td>0.809958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>1.336773</td>\n",
       "      <td>0.831302</td>\n",
       "      <td>0.812787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>1.352295</td>\n",
       "      <td>0.830327</td>\n",
       "      <td>0.812588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>1.382855</td>\n",
       "      <td>0.831789</td>\n",
       "      <td>0.814510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>1.529278</td>\n",
       "      <td>0.810824</td>\n",
       "      <td>0.796452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>1.487441</td>\n",
       "      <td>0.822526</td>\n",
       "      <td>0.806217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>1.517515</td>\n",
       "      <td>0.824476</td>\n",
       "      <td>0.808932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>1.436631</td>\n",
       "      <td>0.838615</td>\n",
       "      <td>0.818553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.477196</td>\n",
       "      <td>0.835202</td>\n",
       "      <td>0.814239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>1.520633</td>\n",
       "      <td>0.826426</td>\n",
       "      <td>0.809400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.561404</td>\n",
       "      <td>0.822526</td>\n",
       "      <td>0.807157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>1.526992</td>\n",
       "      <td>0.830327</td>\n",
       "      <td>0.812087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>1.552961</td>\n",
       "      <td>0.827401</td>\n",
       "      <td>0.809357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.542467</td>\n",
       "      <td>0.827889</td>\n",
       "      <td>0.808008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>1.557461</td>\n",
       "      <td>0.826914</td>\n",
       "      <td>0.807588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>1.557637</td>\n",
       "      <td>0.828864</td>\n",
       "      <td>0.809362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.577588</td>\n",
       "      <td>0.825451</td>\n",
       "      <td>0.807457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.578215</td>\n",
       "      <td>0.825451</td>\n",
       "      <td>0.807457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['comment_message', 'label'],\n",
       "        num_rows: 8203\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['comment_message', 'label'],\n",
       "        num_rows: 2051\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SI2M-Lab/DarijaBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SI2M-Lab/DarijaBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8203 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2051 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1935' max='1935' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1935/1935 03:04, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.472300</td>\n",
       "      <td>0.456162</td>\n",
       "      <td>0.799610</td>\n",
       "      <td>0.784803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.412200</td>\n",
       "      <td>0.390766</td>\n",
       "      <td>0.837153</td>\n",
       "      <td>0.800716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.311300</td>\n",
       "      <td>0.394975</td>\n",
       "      <td>0.844466</td>\n",
       "      <td>0.821905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.269300</td>\n",
       "      <td>0.389533</td>\n",
       "      <td>0.837153</td>\n",
       "      <td>0.817240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.193600</td>\n",
       "      <td>0.677393</td>\n",
       "      <td>0.787421</td>\n",
       "      <td>0.775480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.123100</td>\n",
       "      <td>0.506526</td>\n",
       "      <td>0.838128</td>\n",
       "      <td>0.818334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.082500</td>\n",
       "      <td>0.695141</td>\n",
       "      <td>0.836177</td>\n",
       "      <td>0.808395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.080300</td>\n",
       "      <td>0.716687</td>\n",
       "      <td>0.818137</td>\n",
       "      <td>0.802211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.046600</td>\n",
       "      <td>0.871809</td>\n",
       "      <td>0.826426</td>\n",
       "      <td>0.809278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.041500</td>\n",
       "      <td>0.680296</td>\n",
       "      <td>0.829839</td>\n",
       "      <td>0.811736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.032000</td>\n",
       "      <td>0.911688</td>\n",
       "      <td>0.838128</td>\n",
       "      <td>0.814573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.016200</td>\n",
       "      <td>1.034118</td>\n",
       "      <td>0.824963</td>\n",
       "      <td>0.809172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.019700</td>\n",
       "      <td>1.192085</td>\n",
       "      <td>0.834227</td>\n",
       "      <td>0.814883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.018300</td>\n",
       "      <td>1.020887</td>\n",
       "      <td>0.833252</td>\n",
       "      <td>0.815326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.016900</td>\n",
       "      <td>1.048476</td>\n",
       "      <td>0.837640</td>\n",
       "      <td>0.817721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.012800</td>\n",
       "      <td>1.130038</td>\n",
       "      <td>0.839590</td>\n",
       "      <td>0.818714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.011900</td>\n",
       "      <td>1.143605</td>\n",
       "      <td>0.839590</td>\n",
       "      <td>0.816322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>1.222717</td>\n",
       "      <td>0.832277</td>\n",
       "      <td>0.809805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.009900</td>\n",
       "      <td>1.247114</td>\n",
       "      <td>0.840566</td>\n",
       "      <td>0.819951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>1.261663</td>\n",
       "      <td>0.836665</td>\n",
       "      <td>0.815408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>1.319794</td>\n",
       "      <td>0.834715</td>\n",
       "      <td>0.813620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.383860</td>\n",
       "      <td>0.825939</td>\n",
       "      <td>0.808433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.369371</td>\n",
       "      <td>0.830814</td>\n",
       "      <td>0.811403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>1.366606</td>\n",
       "      <td>0.836177</td>\n",
       "      <td>0.815610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>1.431720</td>\n",
       "      <td>0.828376</td>\n",
       "      <td>0.810181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.417182</td>\n",
       "      <td>0.831789</td>\n",
       "      <td>0.812880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>1.388731</td>\n",
       "      <td>0.840078</td>\n",
       "      <td>0.819062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>1.445885</td>\n",
       "      <td>0.830814</td>\n",
       "      <td>0.813064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.486898</td>\n",
       "      <td>0.828864</td>\n",
       "      <td>0.811775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.457211</td>\n",
       "      <td>0.829839</td>\n",
       "      <td>0.810970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>1.460798</td>\n",
       "      <td>0.830814</td>\n",
       "      <td>0.812437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.469307</td>\n",
       "      <td>0.830327</td>\n",
       "      <td>0.812213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SI2M-Lab/DarijaBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SI2M-Lab/DarijaBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8203 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2051 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1935' max='1935' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1935/1935 03:04, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.472300</td>\n",
       "      <td>0.456162</td>\n",
       "      <td>0.799610</td>\n",
       "      <td>0.784803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.412200</td>\n",
       "      <td>0.390766</td>\n",
       "      <td>0.837153</td>\n",
       "      <td>0.800716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.311300</td>\n",
       "      <td>0.394975</td>\n",
       "      <td>0.844466</td>\n",
       "      <td>0.821905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.269300</td>\n",
       "      <td>0.389533</td>\n",
       "      <td>0.837153</td>\n",
       "      <td>0.817240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.193600</td>\n",
       "      <td>0.677393</td>\n",
       "      <td>0.787421</td>\n",
       "      <td>0.775480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.123100</td>\n",
       "      <td>0.506526</td>\n",
       "      <td>0.838128</td>\n",
       "      <td>0.818334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.082500</td>\n",
       "      <td>0.695141</td>\n",
       "      <td>0.836177</td>\n",
       "      <td>0.808395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.080300</td>\n",
       "      <td>0.716687</td>\n",
       "      <td>0.818137</td>\n",
       "      <td>0.802211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.046600</td>\n",
       "      <td>0.871809</td>\n",
       "      <td>0.826426</td>\n",
       "      <td>0.809278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.041500</td>\n",
       "      <td>0.680296</td>\n",
       "      <td>0.829839</td>\n",
       "      <td>0.811736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.032000</td>\n",
       "      <td>0.911688</td>\n",
       "      <td>0.838128</td>\n",
       "      <td>0.814573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.016200</td>\n",
       "      <td>1.034118</td>\n",
       "      <td>0.824963</td>\n",
       "      <td>0.809172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.019700</td>\n",
       "      <td>1.192085</td>\n",
       "      <td>0.834227</td>\n",
       "      <td>0.814883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.018300</td>\n",
       "      <td>1.020887</td>\n",
       "      <td>0.833252</td>\n",
       "      <td>0.815326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.016900</td>\n",
       "      <td>1.048476</td>\n",
       "      <td>0.837640</td>\n",
       "      <td>0.817721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.012800</td>\n",
       "      <td>1.130038</td>\n",
       "      <td>0.839590</td>\n",
       "      <td>0.818714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.011900</td>\n",
       "      <td>1.143605</td>\n",
       "      <td>0.839590</td>\n",
       "      <td>0.816322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>1.222717</td>\n",
       "      <td>0.832277</td>\n",
       "      <td>0.809805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.009900</td>\n",
       "      <td>1.247114</td>\n",
       "      <td>0.840566</td>\n",
       "      <td>0.819951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>1.261663</td>\n",
       "      <td>0.836665</td>\n",
       "      <td>0.815408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>1.319794</td>\n",
       "      <td>0.834715</td>\n",
       "      <td>0.813620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.383860</td>\n",
       "      <td>0.825939</td>\n",
       "      <td>0.808433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.369371</td>\n",
       "      <td>0.830814</td>\n",
       "      <td>0.811403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>1.366606</td>\n",
       "      <td>0.836177</td>\n",
       "      <td>0.815610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>1.431720</td>\n",
       "      <td>0.828376</td>\n",
       "      <td>0.810181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.417182</td>\n",
       "      <td>0.831789</td>\n",
       "      <td>0.812880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>1.388731</td>\n",
       "      <td>0.840078</td>\n",
       "      <td>0.819062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>1.445885</td>\n",
       "      <td>0.830814</td>\n",
       "      <td>0.813064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.486898</td>\n",
       "      <td>0.828864</td>\n",
       "      <td>0.811775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.457211</td>\n",
       "      <td>0.829839</td>\n",
       "      <td>0.810970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>1.460798</td>\n",
       "      <td>0.830814</td>\n",
       "      <td>0.812437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.469307</td>\n",
       "      <td>0.830327</td>\n",
       "      <td>0.812213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SI2M-Lab/DarijaBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SI2M-Lab/DarijaBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8203 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2051 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1935' max='1935' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1935/1935 03:04, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.472300</td>\n",
       "      <td>0.456162</td>\n",
       "      <td>0.799610</td>\n",
       "      <td>0.784803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.412200</td>\n",
       "      <td>0.390766</td>\n",
       "      <td>0.837153</td>\n",
       "      <td>0.800716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.311300</td>\n",
       "      <td>0.394975</td>\n",
       "      <td>0.844466</td>\n",
       "      <td>0.821905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.269300</td>\n",
       "      <td>0.389533</td>\n",
       "      <td>0.837153</td>\n",
       "      <td>0.817240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.193600</td>\n",
       "      <td>0.677393</td>\n",
       "      <td>0.787421</td>\n",
       "      <td>0.775480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.123100</td>\n",
       "      <td>0.506526</td>\n",
       "      <td>0.838128</td>\n",
       "      <td>0.818334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.082500</td>\n",
       "      <td>0.695141</td>\n",
       "      <td>0.836177</td>\n",
       "      <td>0.808395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.080300</td>\n",
       "      <td>0.716687</td>\n",
       "      <td>0.818137</td>\n",
       "      <td>0.802211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.046600</td>\n",
       "      <td>0.871809</td>\n",
       "      <td>0.826426</td>\n",
       "      <td>0.809278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.041500</td>\n",
       "      <td>0.680296</td>\n",
       "      <td>0.829839</td>\n",
       "      <td>0.811736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.032000</td>\n",
       "      <td>0.911688</td>\n",
       "      <td>0.838128</td>\n",
       "      <td>0.814573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.016200</td>\n",
       "      <td>1.034118</td>\n",
       "      <td>0.824963</td>\n",
       "      <td>0.809172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.019700</td>\n",
       "      <td>1.192085</td>\n",
       "      <td>0.834227</td>\n",
       "      <td>0.814883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.018300</td>\n",
       "      <td>1.020887</td>\n",
       "      <td>0.833252</td>\n",
       "      <td>0.815326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.016900</td>\n",
       "      <td>1.048476</td>\n",
       "      <td>0.837640</td>\n",
       "      <td>0.817721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.012800</td>\n",
       "      <td>1.130038</td>\n",
       "      <td>0.839590</td>\n",
       "      <td>0.818714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.011900</td>\n",
       "      <td>1.143605</td>\n",
       "      <td>0.839590</td>\n",
       "      <td>0.816322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>1.222717</td>\n",
       "      <td>0.832277</td>\n",
       "      <td>0.809805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.009900</td>\n",
       "      <td>1.247114</td>\n",
       "      <td>0.840566</td>\n",
       "      <td>0.819951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>1.261663</td>\n",
       "      <td>0.836665</td>\n",
       "      <td>0.815408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>1.319794</td>\n",
       "      <td>0.834715</td>\n",
       "      <td>0.813620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.383860</td>\n",
       "      <td>0.825939</td>\n",
       "      <td>0.808433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.369371</td>\n",
       "      <td>0.830814</td>\n",
       "      <td>0.811403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>1.366606</td>\n",
       "      <td>0.836177</td>\n",
       "      <td>0.815610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>1.431720</td>\n",
       "      <td>0.828376</td>\n",
       "      <td>0.810181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.417182</td>\n",
       "      <td>0.831789</td>\n",
       "      <td>0.812880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>1.388731</td>\n",
       "      <td>0.840078</td>\n",
       "      <td>0.819062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>1.445885</td>\n",
       "      <td>0.830814</td>\n",
       "      <td>0.813064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.486898</td>\n",
       "      <td>0.828864</td>\n",
       "      <td>0.811775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.457211</td>\n",
       "      <td>0.829839</td>\n",
       "      <td>0.810970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>1.460798</td>\n",
       "      <td>0.830814</td>\n",
       "      <td>0.812437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.469307</td>\n",
       "      <td>0.830327</td>\n",
       "      <td>0.812213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SI2M-Lab/DarijaBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SI2M-Lab/DarijaBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8203 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2051 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1935' max='1935' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1935/1935 03:04, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.490400</td>\n",
       "      <td>0.387721</td>\n",
       "      <td>0.832765</td>\n",
       "      <td>0.811281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.404500</td>\n",
       "      <td>0.391415</td>\n",
       "      <td>0.833252</td>\n",
       "      <td>0.820783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.295500</td>\n",
       "      <td>0.370939</td>\n",
       "      <td>0.845929</td>\n",
       "      <td>0.831245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.278500</td>\n",
       "      <td>0.347078</td>\n",
       "      <td>0.850317</td>\n",
       "      <td>0.834723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.186200</td>\n",
       "      <td>0.505740</td>\n",
       "      <td>0.853730</td>\n",
       "      <td>0.837343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.121500</td>\n",
       "      <td>0.495098</td>\n",
       "      <td>0.848854</td>\n",
       "      <td>0.828210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.098500</td>\n",
       "      <td>0.739702</td>\n",
       "      <td>0.846416</td>\n",
       "      <td>0.828914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.075500</td>\n",
       "      <td>0.610108</td>\n",
       "      <td>0.842516</td>\n",
       "      <td>0.823703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.053500</td>\n",
       "      <td>0.856280</td>\n",
       "      <td>0.839590</td>\n",
       "      <td>0.817890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.030300</td>\n",
       "      <td>0.892444</td>\n",
       "      <td>0.835202</td>\n",
       "      <td>0.818213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.041500</td>\n",
       "      <td>0.927721</td>\n",
       "      <td>0.833252</td>\n",
       "      <td>0.818264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.031200</td>\n",
       "      <td>0.723748</td>\n",
       "      <td>0.843491</td>\n",
       "      <td>0.823777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.033700</td>\n",
       "      <td>0.849999</td>\n",
       "      <td>0.838615</td>\n",
       "      <td>0.815643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.017400</td>\n",
       "      <td>0.986882</td>\n",
       "      <td>0.841053</td>\n",
       "      <td>0.824319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.018600</td>\n",
       "      <td>0.978419</td>\n",
       "      <td>0.843491</td>\n",
       "      <td>0.825534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>1.178699</td>\n",
       "      <td>0.823988</td>\n",
       "      <td>0.813055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>1.053191</td>\n",
       "      <td>0.837640</td>\n",
       "      <td>0.821885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.007600</td>\n",
       "      <td>1.120599</td>\n",
       "      <td>0.845929</td>\n",
       "      <td>0.827089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.005700</td>\n",
       "      <td>1.149691</td>\n",
       "      <td>0.837153</td>\n",
       "      <td>0.824186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.006500</td>\n",
       "      <td>1.122977</td>\n",
       "      <td>0.841053</td>\n",
       "      <td>0.823001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>1.210509</td>\n",
       "      <td>0.829352</td>\n",
       "      <td>0.817484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.010100</td>\n",
       "      <td>1.237725</td>\n",
       "      <td>0.831789</td>\n",
       "      <td>0.820234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>1.255454</td>\n",
       "      <td>0.836177</td>\n",
       "      <td>0.821123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.224888</td>\n",
       "      <td>0.840566</td>\n",
       "      <td>0.825753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>1.226794</td>\n",
       "      <td>0.844954</td>\n",
       "      <td>0.827820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>1.236752</td>\n",
       "      <td>0.845929</td>\n",
       "      <td>0.829366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>1.259045</td>\n",
       "      <td>0.848367</td>\n",
       "      <td>0.831204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>1.280114</td>\n",
       "      <td>0.843979</td>\n",
       "      <td>0.827667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>1.291841</td>\n",
       "      <td>0.844466</td>\n",
       "      <td>0.828601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.305995</td>\n",
       "      <td>0.843979</td>\n",
       "      <td>0.829216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.306112</td>\n",
       "      <td>0.845441</td>\n",
       "      <td>0.829897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.308949</td>\n",
       "      <td>0.845441</td>\n",
       "      <td>0.829897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SI2M-Lab/DarijaBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SI2M-Lab/DarijaBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8203 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2051 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1935' max='1935' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1935/1935 03:04, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.490400</td>\n",
       "      <td>0.387721</td>\n",
       "      <td>0.832765</td>\n",
       "      <td>0.811281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.404500</td>\n",
       "      <td>0.391415</td>\n",
       "      <td>0.833252</td>\n",
       "      <td>0.820783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.295500</td>\n",
       "      <td>0.370939</td>\n",
       "      <td>0.845929</td>\n",
       "      <td>0.831245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.278500</td>\n",
       "      <td>0.347078</td>\n",
       "      <td>0.850317</td>\n",
       "      <td>0.834723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.186200</td>\n",
       "      <td>0.505740</td>\n",
       "      <td>0.853730</td>\n",
       "      <td>0.837343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.121500</td>\n",
       "      <td>0.495098</td>\n",
       "      <td>0.848854</td>\n",
       "      <td>0.828210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.098500</td>\n",
       "      <td>0.739702</td>\n",
       "      <td>0.846416</td>\n",
       "      <td>0.828914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.075500</td>\n",
       "      <td>0.610108</td>\n",
       "      <td>0.842516</td>\n",
       "      <td>0.823703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.053500</td>\n",
       "      <td>0.856280</td>\n",
       "      <td>0.839590</td>\n",
       "      <td>0.817890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.030300</td>\n",
       "      <td>0.892444</td>\n",
       "      <td>0.835202</td>\n",
       "      <td>0.818213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.041500</td>\n",
       "      <td>0.927721</td>\n",
       "      <td>0.833252</td>\n",
       "      <td>0.818264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.031200</td>\n",
       "      <td>0.723748</td>\n",
       "      <td>0.843491</td>\n",
       "      <td>0.823777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.033700</td>\n",
       "      <td>0.849999</td>\n",
       "      <td>0.838615</td>\n",
       "      <td>0.815643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.017400</td>\n",
       "      <td>0.986882</td>\n",
       "      <td>0.841053</td>\n",
       "      <td>0.824319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.018600</td>\n",
       "      <td>0.978419</td>\n",
       "      <td>0.843491</td>\n",
       "      <td>0.825534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>1.178699</td>\n",
       "      <td>0.823988</td>\n",
       "      <td>0.813055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>1.053191</td>\n",
       "      <td>0.837640</td>\n",
       "      <td>0.821885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.007600</td>\n",
       "      <td>1.120599</td>\n",
       "      <td>0.845929</td>\n",
       "      <td>0.827089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.005700</td>\n",
       "      <td>1.149691</td>\n",
       "      <td>0.837153</td>\n",
       "      <td>0.824186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.006500</td>\n",
       "      <td>1.122977</td>\n",
       "      <td>0.841053</td>\n",
       "      <td>0.823001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>1.210509</td>\n",
       "      <td>0.829352</td>\n",
       "      <td>0.817484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.010100</td>\n",
       "      <td>1.237725</td>\n",
       "      <td>0.831789</td>\n",
       "      <td>0.820234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>1.255454</td>\n",
       "      <td>0.836177</td>\n",
       "      <td>0.821123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.224888</td>\n",
       "      <td>0.840566</td>\n",
       "      <td>0.825753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>1.226794</td>\n",
       "      <td>0.844954</td>\n",
       "      <td>0.827820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>1.236752</td>\n",
       "      <td>0.845929</td>\n",
       "      <td>0.829366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>1.259045</td>\n",
       "      <td>0.848367</td>\n",
       "      <td>0.831204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>1.280114</td>\n",
       "      <td>0.843979</td>\n",
       "      <td>0.827667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>1.291841</td>\n",
       "      <td>0.844466</td>\n",
       "      <td>0.828601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.305995</td>\n",
       "      <td>0.843979</td>\n",
       "      <td>0.829216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.306112</td>\n",
       "      <td>0.845441</td>\n",
       "      <td>0.829897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.308949</td>\n",
       "      <td>0.845441</td>\n",
       "      <td>0.829897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SI2M-Lab/DarijaBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SI2M-Lab/DarijaBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8203 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2051 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1935' max='1935' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1935/1935 03:04, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.490400</td>\n",
       "      <td>0.387721</td>\n",
       "      <td>0.832765</td>\n",
       "      <td>0.811281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.404500</td>\n",
       "      <td>0.391415</td>\n",
       "      <td>0.833252</td>\n",
       "      <td>0.820783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.295500</td>\n",
       "      <td>0.370939</td>\n",
       "      <td>0.845929</td>\n",
       "      <td>0.831245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.278500</td>\n",
       "      <td>0.347078</td>\n",
       "      <td>0.850317</td>\n",
       "      <td>0.834723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.186200</td>\n",
       "      <td>0.505740</td>\n",
       "      <td>0.853730</td>\n",
       "      <td>0.837343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.121500</td>\n",
       "      <td>0.495098</td>\n",
       "      <td>0.848854</td>\n",
       "      <td>0.828210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.098500</td>\n",
       "      <td>0.739702</td>\n",
       "      <td>0.846416</td>\n",
       "      <td>0.828914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.075500</td>\n",
       "      <td>0.610108</td>\n",
       "      <td>0.842516</td>\n",
       "      <td>0.823703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.053500</td>\n",
       "      <td>0.856280</td>\n",
       "      <td>0.839590</td>\n",
       "      <td>0.817890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.030300</td>\n",
       "      <td>0.892444</td>\n",
       "      <td>0.835202</td>\n",
       "      <td>0.818213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.041500</td>\n",
       "      <td>0.927721</td>\n",
       "      <td>0.833252</td>\n",
       "      <td>0.818264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.031200</td>\n",
       "      <td>0.723748</td>\n",
       "      <td>0.843491</td>\n",
       "      <td>0.823777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.033700</td>\n",
       "      <td>0.849999</td>\n",
       "      <td>0.838615</td>\n",
       "      <td>0.815643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.017400</td>\n",
       "      <td>0.986882</td>\n",
       "      <td>0.841053</td>\n",
       "      <td>0.824319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.018600</td>\n",
       "      <td>0.978419</td>\n",
       "      <td>0.843491</td>\n",
       "      <td>0.825534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>1.178699</td>\n",
       "      <td>0.823988</td>\n",
       "      <td>0.813055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>1.053191</td>\n",
       "      <td>0.837640</td>\n",
       "      <td>0.821885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.007600</td>\n",
       "      <td>1.120599</td>\n",
       "      <td>0.845929</td>\n",
       "      <td>0.827089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.005700</td>\n",
       "      <td>1.149691</td>\n",
       "      <td>0.837153</td>\n",
       "      <td>0.824186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.006500</td>\n",
       "      <td>1.122977</td>\n",
       "      <td>0.841053</td>\n",
       "      <td>0.823001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>1.210509</td>\n",
       "      <td>0.829352</td>\n",
       "      <td>0.817484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.010100</td>\n",
       "      <td>1.237725</td>\n",
       "      <td>0.831789</td>\n",
       "      <td>0.820234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>1.255454</td>\n",
       "      <td>0.836177</td>\n",
       "      <td>0.821123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.224888</td>\n",
       "      <td>0.840566</td>\n",
       "      <td>0.825753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>1.226794</td>\n",
       "      <td>0.844954</td>\n",
       "      <td>0.827820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>1.236752</td>\n",
       "      <td>0.845929</td>\n",
       "      <td>0.829366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>1.259045</td>\n",
       "      <td>0.848367</td>\n",
       "      <td>0.831204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>1.280114</td>\n",
       "      <td>0.843979</td>\n",
       "      <td>0.827667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>1.291841</td>\n",
       "      <td>0.844466</td>\n",
       "      <td>0.828601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.305995</td>\n",
       "      <td>0.843979</td>\n",
       "      <td>0.829216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.306112</td>\n",
       "      <td>0.845441</td>\n",
       "      <td>0.829897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.308949</td>\n",
       "      <td>0.845441</td>\n",
       "      <td>0.829897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SI2M-Lab/DarijaBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SI2M-Lab/DarijaBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8203 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2051 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1935' max='1935' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1935/1935 03:04, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.484800</td>\n",
       "      <td>0.397666</td>\n",
       "      <td>0.828864</td>\n",
       "      <td>0.806008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.412400</td>\n",
       "      <td>0.430290</td>\n",
       "      <td>0.817650</td>\n",
       "      <td>0.773804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.400648</td>\n",
       "      <td>0.818137</td>\n",
       "      <td>0.806937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.285100</td>\n",
       "      <td>0.386833</td>\n",
       "      <td>0.837640</td>\n",
       "      <td>0.823101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.200900</td>\n",
       "      <td>0.562182</td>\n",
       "      <td>0.828376</td>\n",
       "      <td>0.815338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.147600</td>\n",
       "      <td>0.441995</td>\n",
       "      <td>0.841053</td>\n",
       "      <td>0.826447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.098600</td>\n",
       "      <td>0.790847</td>\n",
       "      <td>0.836177</td>\n",
       "      <td>0.821670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.056600</td>\n",
       "      <td>0.817972</td>\n",
       "      <td>0.814725</td>\n",
       "      <td>0.806575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.048200</td>\n",
       "      <td>0.857923</td>\n",
       "      <td>0.829352</td>\n",
       "      <td>0.815445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.044500</td>\n",
       "      <td>0.721300</td>\n",
       "      <td>0.843003</td>\n",
       "      <td>0.824311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.034000</td>\n",
       "      <td>0.911586</td>\n",
       "      <td>0.821550</td>\n",
       "      <td>0.807669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.015600</td>\n",
       "      <td>1.004632</td>\n",
       "      <td>0.831789</td>\n",
       "      <td>0.809612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.027500</td>\n",
       "      <td>0.974955</td>\n",
       "      <td>0.843003</td>\n",
       "      <td>0.823422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.013300</td>\n",
       "      <td>1.030382</td>\n",
       "      <td>0.828376</td>\n",
       "      <td>0.811662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.013600</td>\n",
       "      <td>1.029089</td>\n",
       "      <td>0.844954</td>\n",
       "      <td>0.824446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>1.120023</td>\n",
       "      <td>0.836177</td>\n",
       "      <td>0.814509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.010400</td>\n",
       "      <td>1.176525</td>\n",
       "      <td>0.831789</td>\n",
       "      <td>0.816948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.008100</td>\n",
       "      <td>1.170773</td>\n",
       "      <td>0.841053</td>\n",
       "      <td>0.824552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>1.167866</td>\n",
       "      <td>0.840078</td>\n",
       "      <td>0.821291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.007200</td>\n",
       "      <td>1.176706</td>\n",
       "      <td>0.843491</td>\n",
       "      <td>0.824794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>1.222450</td>\n",
       "      <td>0.839590</td>\n",
       "      <td>0.825119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>1.225638</td>\n",
       "      <td>0.844466</td>\n",
       "      <td>0.829803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.257247</td>\n",
       "      <td>0.843003</td>\n",
       "      <td>0.825654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.270331</td>\n",
       "      <td>0.838128</td>\n",
       "      <td>0.822701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>1.315648</td>\n",
       "      <td>0.839590</td>\n",
       "      <td>0.825543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>1.322375</td>\n",
       "      <td>0.841053</td>\n",
       "      <td>0.824897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>1.325162</td>\n",
       "      <td>0.845441</td>\n",
       "      <td>0.827708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>1.339156</td>\n",
       "      <td>0.837153</td>\n",
       "      <td>0.822298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.337277</td>\n",
       "      <td>0.838128</td>\n",
       "      <td>0.820847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.331376</td>\n",
       "      <td>0.838615</td>\n",
       "      <td>0.821802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.337695</td>\n",
       "      <td>0.843491</td>\n",
       "      <td>0.824543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>1.336652</td>\n",
       "      <td>0.843491</td>\n",
       "      <td>0.825534</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SI2M-Lab/DarijaBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SI2M-Lab/DarijaBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8203 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2051 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1935' max='1935' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1935/1935 03:04, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.484800</td>\n",
       "      <td>0.397666</td>\n",
       "      <td>0.828864</td>\n",
       "      <td>0.806008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.412400</td>\n",
       "      <td>0.430290</td>\n",
       "      <td>0.817650</td>\n",
       "      <td>0.773804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.400648</td>\n",
       "      <td>0.818137</td>\n",
       "      <td>0.806937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.285100</td>\n",
       "      <td>0.386833</td>\n",
       "      <td>0.837640</td>\n",
       "      <td>0.823101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.200900</td>\n",
       "      <td>0.562182</td>\n",
       "      <td>0.828376</td>\n",
       "      <td>0.815338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.147600</td>\n",
       "      <td>0.441995</td>\n",
       "      <td>0.841053</td>\n",
       "      <td>0.826447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.098600</td>\n",
       "      <td>0.790847</td>\n",
       "      <td>0.836177</td>\n",
       "      <td>0.821670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.056600</td>\n",
       "      <td>0.817972</td>\n",
       "      <td>0.814725</td>\n",
       "      <td>0.806575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.048200</td>\n",
       "      <td>0.857923</td>\n",
       "      <td>0.829352</td>\n",
       "      <td>0.815445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.044500</td>\n",
       "      <td>0.721300</td>\n",
       "      <td>0.843003</td>\n",
       "      <td>0.824311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.034000</td>\n",
       "      <td>0.911586</td>\n",
       "      <td>0.821550</td>\n",
       "      <td>0.807669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.015600</td>\n",
       "      <td>1.004632</td>\n",
       "      <td>0.831789</td>\n",
       "      <td>0.809612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.027500</td>\n",
       "      <td>0.974955</td>\n",
       "      <td>0.843003</td>\n",
       "      <td>0.823422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.013300</td>\n",
       "      <td>1.030382</td>\n",
       "      <td>0.828376</td>\n",
       "      <td>0.811662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.013600</td>\n",
       "      <td>1.029089</td>\n",
       "      <td>0.844954</td>\n",
       "      <td>0.824446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>1.120023</td>\n",
       "      <td>0.836177</td>\n",
       "      <td>0.814509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.010400</td>\n",
       "      <td>1.176525</td>\n",
       "      <td>0.831789</td>\n",
       "      <td>0.816948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.008100</td>\n",
       "      <td>1.170773</td>\n",
       "      <td>0.841053</td>\n",
       "      <td>0.824552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>1.167866</td>\n",
       "      <td>0.840078</td>\n",
       "      <td>0.821291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.007200</td>\n",
       "      <td>1.176706</td>\n",
       "      <td>0.843491</td>\n",
       "      <td>0.824794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>1.222450</td>\n",
       "      <td>0.839590</td>\n",
       "      <td>0.825119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>1.225638</td>\n",
       "      <td>0.844466</td>\n",
       "      <td>0.829803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.257247</td>\n",
       "      <td>0.843003</td>\n",
       "      <td>0.825654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.270331</td>\n",
       "      <td>0.838128</td>\n",
       "      <td>0.822701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>1.315648</td>\n",
       "      <td>0.839590</td>\n",
       "      <td>0.825543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>1.322375</td>\n",
       "      <td>0.841053</td>\n",
       "      <td>0.824897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>1.325162</td>\n",
       "      <td>0.845441</td>\n",
       "      <td>0.827708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>1.339156</td>\n",
       "      <td>0.837153</td>\n",
       "      <td>0.822298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.337277</td>\n",
       "      <td>0.838128</td>\n",
       "      <td>0.820847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.331376</td>\n",
       "      <td>0.838615</td>\n",
       "      <td>0.821802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.337695</td>\n",
       "      <td>0.843491</td>\n",
       "      <td>0.824543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>1.336652</td>\n",
       "      <td>0.843491</td>\n",
       "      <td>0.825534</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SI2M-Lab/DarijaBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SI2M-Lab/DarijaBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8203 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2051 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1935' max='1935' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1935/1935 03:04, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.484800</td>\n",
       "      <td>0.397666</td>\n",
       "      <td>0.828864</td>\n",
       "      <td>0.806008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.412400</td>\n",
       "      <td>0.430290</td>\n",
       "      <td>0.817650</td>\n",
       "      <td>0.773804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.400648</td>\n",
       "      <td>0.818137</td>\n",
       "      <td>0.806937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.285100</td>\n",
       "      <td>0.386833</td>\n",
       "      <td>0.837640</td>\n",
       "      <td>0.823101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.200900</td>\n",
       "      <td>0.562182</td>\n",
       "      <td>0.828376</td>\n",
       "      <td>0.815338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.147600</td>\n",
       "      <td>0.441995</td>\n",
       "      <td>0.841053</td>\n",
       "      <td>0.826447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.098600</td>\n",
       "      <td>0.790847</td>\n",
       "      <td>0.836177</td>\n",
       "      <td>0.821670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.056600</td>\n",
       "      <td>0.817972</td>\n",
       "      <td>0.814725</td>\n",
       "      <td>0.806575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.048200</td>\n",
       "      <td>0.857923</td>\n",
       "      <td>0.829352</td>\n",
       "      <td>0.815445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.044500</td>\n",
       "      <td>0.721300</td>\n",
       "      <td>0.843003</td>\n",
       "      <td>0.824311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.034000</td>\n",
       "      <td>0.911586</td>\n",
       "      <td>0.821550</td>\n",
       "      <td>0.807669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.015600</td>\n",
       "      <td>1.004632</td>\n",
       "      <td>0.831789</td>\n",
       "      <td>0.809612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.027500</td>\n",
       "      <td>0.974955</td>\n",
       "      <td>0.843003</td>\n",
       "      <td>0.823422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.013300</td>\n",
       "      <td>1.030382</td>\n",
       "      <td>0.828376</td>\n",
       "      <td>0.811662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.013600</td>\n",
       "      <td>1.029089</td>\n",
       "      <td>0.844954</td>\n",
       "      <td>0.824446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>1.120023</td>\n",
       "      <td>0.836177</td>\n",
       "      <td>0.814509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.010400</td>\n",
       "      <td>1.176525</td>\n",
       "      <td>0.831789</td>\n",
       "      <td>0.816948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.008100</td>\n",
       "      <td>1.170773</td>\n",
       "      <td>0.841053</td>\n",
       "      <td>0.824552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>1.167866</td>\n",
       "      <td>0.840078</td>\n",
       "      <td>0.821291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.007200</td>\n",
       "      <td>1.176706</td>\n",
       "      <td>0.843491</td>\n",
       "      <td>0.824794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>1.222450</td>\n",
       "      <td>0.839590</td>\n",
       "      <td>0.825119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>1.225638</td>\n",
       "      <td>0.844466</td>\n",
       "      <td>0.829803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.257247</td>\n",
       "      <td>0.843003</td>\n",
       "      <td>0.825654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.270331</td>\n",
       "      <td>0.838128</td>\n",
       "      <td>0.822701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>1.315648</td>\n",
       "      <td>0.839590</td>\n",
       "      <td>0.825543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>1.322375</td>\n",
       "      <td>0.841053</td>\n",
       "      <td>0.824897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>1.325162</td>\n",
       "      <td>0.845441</td>\n",
       "      <td>0.827708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>1.339156</td>\n",
       "      <td>0.837153</td>\n",
       "      <td>0.822298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.337277</td>\n",
       "      <td>0.838128</td>\n",
       "      <td>0.820847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.331376</td>\n",
       "      <td>0.838615</td>\n",
       "      <td>0.821802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.337695</td>\n",
       "      <td>0.843491</td>\n",
       "      <td>0.824543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>1.336652</td>\n",
       "      <td>0.843491</td>\n",
       "      <td>0.825534</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['comment_message', 'label'],\n",
       "        num_rows: 8203\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['comment_message', 'label'],\n",
       "        num_rows: 2051\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorRoBERTa, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at otmangi/MorRoBERTa and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8203 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2051 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1935' max='1935' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1935/1935 01:38, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.462500</td>\n",
       "      <td>0.405493</td>\n",
       "      <td>0.824963</td>\n",
       "      <td>0.804607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.413500</td>\n",
       "      <td>0.385709</td>\n",
       "      <td>0.833740</td>\n",
       "      <td>0.800613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.291500</td>\n",
       "      <td>0.442406</td>\n",
       "      <td>0.826426</td>\n",
       "      <td>0.804202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.274900</td>\n",
       "      <td>0.423580</td>\n",
       "      <td>0.823501</td>\n",
       "      <td>0.804395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.216100</td>\n",
       "      <td>0.751645</td>\n",
       "      <td>0.745490</td>\n",
       "      <td>0.738167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.152900</td>\n",
       "      <td>0.635465</td>\n",
       "      <td>0.814725</td>\n",
       "      <td>0.793539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.097800</td>\n",
       "      <td>0.915021</td>\n",
       "      <td>0.812774</td>\n",
       "      <td>0.794145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.077400</td>\n",
       "      <td>0.855674</td>\n",
       "      <td>0.806923</td>\n",
       "      <td>0.784696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.067900</td>\n",
       "      <td>1.010729</td>\n",
       "      <td>0.816187</td>\n",
       "      <td>0.790351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.045100</td>\n",
       "      <td>1.006372</td>\n",
       "      <td>0.807411</td>\n",
       "      <td>0.786347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.045200</td>\n",
       "      <td>0.931410</td>\n",
       "      <td>0.818625</td>\n",
       "      <td>0.795854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.028700</td>\n",
       "      <td>1.147062</td>\n",
       "      <td>0.821550</td>\n",
       "      <td>0.796548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.014600</td>\n",
       "      <td>1.198654</td>\n",
       "      <td>0.810824</td>\n",
       "      <td>0.788300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.017700</td>\n",
       "      <td>1.196658</td>\n",
       "      <td>0.818137</td>\n",
       "      <td>0.794469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.012600</td>\n",
       "      <td>1.246475</td>\n",
       "      <td>0.814725</td>\n",
       "      <td>0.793105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>1.328572</td>\n",
       "      <td>0.810336</td>\n",
       "      <td>0.788279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.014900</td>\n",
       "      <td>1.132824</td>\n",
       "      <td>0.822038</td>\n",
       "      <td>0.795239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>1.353095</td>\n",
       "      <td>0.802535</td>\n",
       "      <td>0.782957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>1.290098</td>\n",
       "      <td>0.823501</td>\n",
       "      <td>0.795835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.005200</td>\n",
       "      <td>1.378503</td>\n",
       "      <td>0.813262</td>\n",
       "      <td>0.790047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.009900</td>\n",
       "      <td>1.432632</td>\n",
       "      <td>0.814237</td>\n",
       "      <td>0.788620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>1.454436</td>\n",
       "      <td>0.815212</td>\n",
       "      <td>0.791163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>1.499745</td>\n",
       "      <td>0.813749</td>\n",
       "      <td>0.792016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>1.564287</td>\n",
       "      <td>0.807411</td>\n",
       "      <td>0.788042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>1.549232</td>\n",
       "      <td>0.814237</td>\n",
       "      <td>0.793068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.580467</td>\n",
       "      <td>0.808874</td>\n",
       "      <td>0.788469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>1.520110</td>\n",
       "      <td>0.822038</td>\n",
       "      <td>0.796546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>1.556597</td>\n",
       "      <td>0.814237</td>\n",
       "      <td>0.792193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>1.552414</td>\n",
       "      <td>0.820088</td>\n",
       "      <td>0.796060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>1.577243</td>\n",
       "      <td>0.816675</td>\n",
       "      <td>0.794554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>1.571277</td>\n",
       "      <td>0.815700</td>\n",
       "      <td>0.793164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.572888</td>\n",
       "      <td>0.816187</td>\n",
       "      <td>0.793786</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorRoBERTa, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at otmangi/MorRoBERTa and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8203 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2051 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1935' max='1935' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1935/1935 01:39, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.462500</td>\n",
       "      <td>0.405493</td>\n",
       "      <td>0.824963</td>\n",
       "      <td>0.804607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.413500</td>\n",
       "      <td>0.385709</td>\n",
       "      <td>0.833740</td>\n",
       "      <td>0.800613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.291500</td>\n",
       "      <td>0.442406</td>\n",
       "      <td>0.826426</td>\n",
       "      <td>0.804202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.274900</td>\n",
       "      <td>0.423580</td>\n",
       "      <td>0.823501</td>\n",
       "      <td>0.804395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.216100</td>\n",
       "      <td>0.751645</td>\n",
       "      <td>0.745490</td>\n",
       "      <td>0.738167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.152900</td>\n",
       "      <td>0.635465</td>\n",
       "      <td>0.814725</td>\n",
       "      <td>0.793539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.097800</td>\n",
       "      <td>0.915021</td>\n",
       "      <td>0.812774</td>\n",
       "      <td>0.794145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.077400</td>\n",
       "      <td>0.855674</td>\n",
       "      <td>0.806923</td>\n",
       "      <td>0.784696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.067900</td>\n",
       "      <td>1.010729</td>\n",
       "      <td>0.816187</td>\n",
       "      <td>0.790351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.045100</td>\n",
       "      <td>1.006372</td>\n",
       "      <td>0.807411</td>\n",
       "      <td>0.786347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.045200</td>\n",
       "      <td>0.931410</td>\n",
       "      <td>0.818625</td>\n",
       "      <td>0.795854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.028700</td>\n",
       "      <td>1.147062</td>\n",
       "      <td>0.821550</td>\n",
       "      <td>0.796548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.014600</td>\n",
       "      <td>1.198654</td>\n",
       "      <td>0.810824</td>\n",
       "      <td>0.788300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.017700</td>\n",
       "      <td>1.196658</td>\n",
       "      <td>0.818137</td>\n",
       "      <td>0.794469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.012600</td>\n",
       "      <td>1.246475</td>\n",
       "      <td>0.814725</td>\n",
       "      <td>0.793105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>1.328572</td>\n",
       "      <td>0.810336</td>\n",
       "      <td>0.788279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.014900</td>\n",
       "      <td>1.132824</td>\n",
       "      <td>0.822038</td>\n",
       "      <td>0.795239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>1.353095</td>\n",
       "      <td>0.802535</td>\n",
       "      <td>0.782957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>1.290098</td>\n",
       "      <td>0.823501</td>\n",
       "      <td>0.795835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.005200</td>\n",
       "      <td>1.378503</td>\n",
       "      <td>0.813262</td>\n",
       "      <td>0.790047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.009900</td>\n",
       "      <td>1.432632</td>\n",
       "      <td>0.814237</td>\n",
       "      <td>0.788620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>1.454436</td>\n",
       "      <td>0.815212</td>\n",
       "      <td>0.791163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>1.499745</td>\n",
       "      <td>0.813749</td>\n",
       "      <td>0.792016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>1.564287</td>\n",
       "      <td>0.807411</td>\n",
       "      <td>0.788042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>1.549232</td>\n",
       "      <td>0.814237</td>\n",
       "      <td>0.793068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.580467</td>\n",
       "      <td>0.808874</td>\n",
       "      <td>0.788469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>1.520110</td>\n",
       "      <td>0.822038</td>\n",
       "      <td>0.796546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>1.556597</td>\n",
       "      <td>0.814237</td>\n",
       "      <td>0.792193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>1.552414</td>\n",
       "      <td>0.820088</td>\n",
       "      <td>0.796060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>1.577243</td>\n",
       "      <td>0.816675</td>\n",
       "      <td>0.794554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>1.571277</td>\n",
       "      <td>0.815700</td>\n",
       "      <td>0.793164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.572888</td>\n",
       "      <td>0.816187</td>\n",
       "      <td>0.793786</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorRoBERTa, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at otmangi/MorRoBERTa and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8203 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2051 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1935' max='1935' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1935/1935 01:39, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.462500</td>\n",
       "      <td>0.405493</td>\n",
       "      <td>0.824963</td>\n",
       "      <td>0.804607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.413500</td>\n",
       "      <td>0.385709</td>\n",
       "      <td>0.833740</td>\n",
       "      <td>0.800613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.291500</td>\n",
       "      <td>0.442406</td>\n",
       "      <td>0.826426</td>\n",
       "      <td>0.804202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.274900</td>\n",
       "      <td>0.423580</td>\n",
       "      <td>0.823501</td>\n",
       "      <td>0.804395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.216100</td>\n",
       "      <td>0.751645</td>\n",
       "      <td>0.745490</td>\n",
       "      <td>0.738167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.152900</td>\n",
       "      <td>0.635465</td>\n",
       "      <td>0.814725</td>\n",
       "      <td>0.793539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.097800</td>\n",
       "      <td>0.915021</td>\n",
       "      <td>0.812774</td>\n",
       "      <td>0.794145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.077400</td>\n",
       "      <td>0.855674</td>\n",
       "      <td>0.806923</td>\n",
       "      <td>0.784696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.067900</td>\n",
       "      <td>1.010729</td>\n",
       "      <td>0.816187</td>\n",
       "      <td>0.790351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.045100</td>\n",
       "      <td>1.006372</td>\n",
       "      <td>0.807411</td>\n",
       "      <td>0.786347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.045200</td>\n",
       "      <td>0.931410</td>\n",
       "      <td>0.818625</td>\n",
       "      <td>0.795854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.028700</td>\n",
       "      <td>1.147062</td>\n",
       "      <td>0.821550</td>\n",
       "      <td>0.796548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.014600</td>\n",
       "      <td>1.198654</td>\n",
       "      <td>0.810824</td>\n",
       "      <td>0.788300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.017700</td>\n",
       "      <td>1.196658</td>\n",
       "      <td>0.818137</td>\n",
       "      <td>0.794469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.012600</td>\n",
       "      <td>1.246475</td>\n",
       "      <td>0.814725</td>\n",
       "      <td>0.793105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>1.328572</td>\n",
       "      <td>0.810336</td>\n",
       "      <td>0.788279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.014900</td>\n",
       "      <td>1.132824</td>\n",
       "      <td>0.822038</td>\n",
       "      <td>0.795239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>1.353095</td>\n",
       "      <td>0.802535</td>\n",
       "      <td>0.782957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>1.290098</td>\n",
       "      <td>0.823501</td>\n",
       "      <td>0.795835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.005200</td>\n",
       "      <td>1.378503</td>\n",
       "      <td>0.813262</td>\n",
       "      <td>0.790047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.009900</td>\n",
       "      <td>1.432632</td>\n",
       "      <td>0.814237</td>\n",
       "      <td>0.788620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>1.454436</td>\n",
       "      <td>0.815212</td>\n",
       "      <td>0.791163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>1.499745</td>\n",
       "      <td>0.813749</td>\n",
       "      <td>0.792016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>1.564287</td>\n",
       "      <td>0.807411</td>\n",
       "      <td>0.788042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>1.549232</td>\n",
       "      <td>0.814237</td>\n",
       "      <td>0.793068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.580467</td>\n",
       "      <td>0.808874</td>\n",
       "      <td>0.788469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>1.520110</td>\n",
       "      <td>0.822038</td>\n",
       "      <td>0.796546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>1.556597</td>\n",
       "      <td>0.814237</td>\n",
       "      <td>0.792193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>1.552414</td>\n",
       "      <td>0.820088</td>\n",
       "      <td>0.796060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>1.577243</td>\n",
       "      <td>0.816675</td>\n",
       "      <td>0.794554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>1.571277</td>\n",
       "      <td>0.815700</td>\n",
       "      <td>0.793164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.572888</td>\n",
       "      <td>0.816187</td>\n",
       "      <td>0.793786</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorRoBERTa, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at otmangi/MorRoBERTa and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8203 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2051 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1935' max='1935' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1935/1935 01:38, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.482000</td>\n",
       "      <td>0.401274</td>\n",
       "      <td>0.818625</td>\n",
       "      <td>0.782590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.412400</td>\n",
       "      <td>0.383543</td>\n",
       "      <td>0.829839</td>\n",
       "      <td>0.800196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.309100</td>\n",
       "      <td>0.411904</td>\n",
       "      <td>0.821063</td>\n",
       "      <td>0.807415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.289600</td>\n",
       "      <td>0.399416</td>\n",
       "      <td>0.826914</td>\n",
       "      <td>0.810238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.192500</td>\n",
       "      <td>0.527012</td>\n",
       "      <td>0.831302</td>\n",
       "      <td>0.813788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.146700</td>\n",
       "      <td>0.573057</td>\n",
       "      <td>0.830814</td>\n",
       "      <td>0.806731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.110700</td>\n",
       "      <td>0.844610</td>\n",
       "      <td>0.814725</td>\n",
       "      <td>0.800980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.759821</td>\n",
       "      <td>0.835202</td>\n",
       "      <td>0.811222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.054200</td>\n",
       "      <td>0.853862</td>\n",
       "      <td>0.830814</td>\n",
       "      <td>0.806731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.040100</td>\n",
       "      <td>0.938953</td>\n",
       "      <td>0.828864</td>\n",
       "      <td>0.810146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.034700</td>\n",
       "      <td>0.941021</td>\n",
       "      <td>0.824963</td>\n",
       "      <td>0.805687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.024800</td>\n",
       "      <td>1.016489</td>\n",
       "      <td>0.821063</td>\n",
       "      <td>0.801492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.023600</td>\n",
       "      <td>0.991574</td>\n",
       "      <td>0.838128</td>\n",
       "      <td>0.815734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.009800</td>\n",
       "      <td>1.083109</td>\n",
       "      <td>0.831789</td>\n",
       "      <td>0.809612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.010100</td>\n",
       "      <td>1.272160</td>\n",
       "      <td>0.830814</td>\n",
       "      <td>0.804376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.010600</td>\n",
       "      <td>1.360231</td>\n",
       "      <td>0.819113</td>\n",
       "      <td>0.803857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.010900</td>\n",
       "      <td>1.242412</td>\n",
       "      <td>0.831789</td>\n",
       "      <td>0.809034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>1.312336</td>\n",
       "      <td>0.825939</td>\n",
       "      <td>0.807031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.005200</td>\n",
       "      <td>1.345847</td>\n",
       "      <td>0.825451</td>\n",
       "      <td>0.805762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>1.373308</td>\n",
       "      <td>0.827401</td>\n",
       "      <td>0.806015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>1.391179</td>\n",
       "      <td>0.829352</td>\n",
       "      <td>0.808485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>1.427396</td>\n",
       "      <td>0.824963</td>\n",
       "      <td>0.805554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>1.521786</td>\n",
       "      <td>0.809849</td>\n",
       "      <td>0.795058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>1.392816</td>\n",
       "      <td>0.830814</td>\n",
       "      <td>0.809782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>1.435171</td>\n",
       "      <td>0.823988</td>\n",
       "      <td>0.805522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.454600</td>\n",
       "      <td>0.826426</td>\n",
       "      <td>0.807637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>1.497788</td>\n",
       "      <td>0.822038</td>\n",
       "      <td>0.804140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.485849</td>\n",
       "      <td>0.826426</td>\n",
       "      <td>0.807245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.503617</td>\n",
       "      <td>0.825451</td>\n",
       "      <td>0.806817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>1.503700</td>\n",
       "      <td>0.827401</td>\n",
       "      <td>0.808588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>1.513438</td>\n",
       "      <td>0.823501</td>\n",
       "      <td>0.805048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.514174</td>\n",
       "      <td>0.824476</td>\n",
       "      <td>0.805997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorRoBERTa, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at otmangi/MorRoBERTa and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8203 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2051 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1935' max='1935' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1935/1935 01:38, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.482000</td>\n",
       "      <td>0.401274</td>\n",
       "      <td>0.818625</td>\n",
       "      <td>0.782590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.412400</td>\n",
       "      <td>0.383543</td>\n",
       "      <td>0.829839</td>\n",
       "      <td>0.800196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.309100</td>\n",
       "      <td>0.411904</td>\n",
       "      <td>0.821063</td>\n",
       "      <td>0.807415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.289600</td>\n",
       "      <td>0.399416</td>\n",
       "      <td>0.826914</td>\n",
       "      <td>0.810238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.192500</td>\n",
       "      <td>0.527012</td>\n",
       "      <td>0.831302</td>\n",
       "      <td>0.813788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.146700</td>\n",
       "      <td>0.573057</td>\n",
       "      <td>0.830814</td>\n",
       "      <td>0.806731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.110700</td>\n",
       "      <td>0.844610</td>\n",
       "      <td>0.814725</td>\n",
       "      <td>0.800980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.759821</td>\n",
       "      <td>0.835202</td>\n",
       "      <td>0.811222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.054200</td>\n",
       "      <td>0.853862</td>\n",
       "      <td>0.830814</td>\n",
       "      <td>0.806731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.040100</td>\n",
       "      <td>0.938953</td>\n",
       "      <td>0.828864</td>\n",
       "      <td>0.810146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.034700</td>\n",
       "      <td>0.941021</td>\n",
       "      <td>0.824963</td>\n",
       "      <td>0.805687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.024800</td>\n",
       "      <td>1.016489</td>\n",
       "      <td>0.821063</td>\n",
       "      <td>0.801492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.023600</td>\n",
       "      <td>0.991574</td>\n",
       "      <td>0.838128</td>\n",
       "      <td>0.815734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.009800</td>\n",
       "      <td>1.083109</td>\n",
       "      <td>0.831789</td>\n",
       "      <td>0.809612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.010100</td>\n",
       "      <td>1.272160</td>\n",
       "      <td>0.830814</td>\n",
       "      <td>0.804376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.010600</td>\n",
       "      <td>1.360231</td>\n",
       "      <td>0.819113</td>\n",
       "      <td>0.803857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.010900</td>\n",
       "      <td>1.242412</td>\n",
       "      <td>0.831789</td>\n",
       "      <td>0.809034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>1.312336</td>\n",
       "      <td>0.825939</td>\n",
       "      <td>0.807031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.005200</td>\n",
       "      <td>1.345847</td>\n",
       "      <td>0.825451</td>\n",
       "      <td>0.805762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>1.373308</td>\n",
       "      <td>0.827401</td>\n",
       "      <td>0.806015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>1.391179</td>\n",
       "      <td>0.829352</td>\n",
       "      <td>0.808485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>1.427396</td>\n",
       "      <td>0.824963</td>\n",
       "      <td>0.805554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>1.521786</td>\n",
       "      <td>0.809849</td>\n",
       "      <td>0.795058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>1.392816</td>\n",
       "      <td>0.830814</td>\n",
       "      <td>0.809782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>1.435171</td>\n",
       "      <td>0.823988</td>\n",
       "      <td>0.805522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.454600</td>\n",
       "      <td>0.826426</td>\n",
       "      <td>0.807637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>1.497788</td>\n",
       "      <td>0.822038</td>\n",
       "      <td>0.804140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.485849</td>\n",
       "      <td>0.826426</td>\n",
       "      <td>0.807245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.503617</td>\n",
       "      <td>0.825451</td>\n",
       "      <td>0.806817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>1.503700</td>\n",
       "      <td>0.827401</td>\n",
       "      <td>0.808588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>1.513438</td>\n",
       "      <td>0.823501</td>\n",
       "      <td>0.805048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.514174</td>\n",
       "      <td>0.824476</td>\n",
       "      <td>0.805997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorRoBERTa, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at otmangi/MorRoBERTa and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8203 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2051 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1935' max='1935' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1935/1935 01:38, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.482000</td>\n",
       "      <td>0.401274</td>\n",
       "      <td>0.818625</td>\n",
       "      <td>0.782590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.412400</td>\n",
       "      <td>0.383543</td>\n",
       "      <td>0.829839</td>\n",
       "      <td>0.800196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.309100</td>\n",
       "      <td>0.411904</td>\n",
       "      <td>0.821063</td>\n",
       "      <td>0.807415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.289600</td>\n",
       "      <td>0.399416</td>\n",
       "      <td>0.826914</td>\n",
       "      <td>0.810238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.192500</td>\n",
       "      <td>0.527012</td>\n",
       "      <td>0.831302</td>\n",
       "      <td>0.813788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.146700</td>\n",
       "      <td>0.573057</td>\n",
       "      <td>0.830814</td>\n",
       "      <td>0.806731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.110700</td>\n",
       "      <td>0.844610</td>\n",
       "      <td>0.814725</td>\n",
       "      <td>0.800980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.759821</td>\n",
       "      <td>0.835202</td>\n",
       "      <td>0.811222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.054200</td>\n",
       "      <td>0.853862</td>\n",
       "      <td>0.830814</td>\n",
       "      <td>0.806731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.040100</td>\n",
       "      <td>0.938953</td>\n",
       "      <td>0.828864</td>\n",
       "      <td>0.810146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.034700</td>\n",
       "      <td>0.941021</td>\n",
       "      <td>0.824963</td>\n",
       "      <td>0.805687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.024800</td>\n",
       "      <td>1.016489</td>\n",
       "      <td>0.821063</td>\n",
       "      <td>0.801492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.023600</td>\n",
       "      <td>0.991574</td>\n",
       "      <td>0.838128</td>\n",
       "      <td>0.815734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.009800</td>\n",
       "      <td>1.083109</td>\n",
       "      <td>0.831789</td>\n",
       "      <td>0.809612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.010100</td>\n",
       "      <td>1.272160</td>\n",
       "      <td>0.830814</td>\n",
       "      <td>0.804376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.010600</td>\n",
       "      <td>1.360231</td>\n",
       "      <td>0.819113</td>\n",
       "      <td>0.803857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.010900</td>\n",
       "      <td>1.242412</td>\n",
       "      <td>0.831789</td>\n",
       "      <td>0.809034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>1.312336</td>\n",
       "      <td>0.825939</td>\n",
       "      <td>0.807031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.005200</td>\n",
       "      <td>1.345847</td>\n",
       "      <td>0.825451</td>\n",
       "      <td>0.805762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>1.373308</td>\n",
       "      <td>0.827401</td>\n",
       "      <td>0.806015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>1.391179</td>\n",
       "      <td>0.829352</td>\n",
       "      <td>0.808485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>1.427396</td>\n",
       "      <td>0.824963</td>\n",
       "      <td>0.805554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>1.521786</td>\n",
       "      <td>0.809849</td>\n",
       "      <td>0.795058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>1.392816</td>\n",
       "      <td>0.830814</td>\n",
       "      <td>0.809782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>1.435171</td>\n",
       "      <td>0.823988</td>\n",
       "      <td>0.805522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.454600</td>\n",
       "      <td>0.826426</td>\n",
       "      <td>0.807637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>1.497788</td>\n",
       "      <td>0.822038</td>\n",
       "      <td>0.804140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.485849</td>\n",
       "      <td>0.826426</td>\n",
       "      <td>0.807245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.503617</td>\n",
       "      <td>0.825451</td>\n",
       "      <td>0.806817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>1.503700</td>\n",
       "      <td>0.827401</td>\n",
       "      <td>0.808588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>1.513438</td>\n",
       "      <td>0.823501</td>\n",
       "      <td>0.805048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.514174</td>\n",
       "      <td>0.824476</td>\n",
       "      <td>0.805997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorRoBERTa, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at otmangi/MorRoBERTa and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8203 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2051 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1935' max='1935' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1935/1935 01:39, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.473900</td>\n",
       "      <td>0.403473</td>\n",
       "      <td>0.823501</td>\n",
       "      <td>0.789233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.410800</td>\n",
       "      <td>0.395607</td>\n",
       "      <td>0.826914</td>\n",
       "      <td>0.807055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.296200</td>\n",
       "      <td>0.440381</td>\n",
       "      <td>0.827889</td>\n",
       "      <td>0.807465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.264400</td>\n",
       "      <td>0.433899</td>\n",
       "      <td>0.830327</td>\n",
       "      <td>0.807593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.191700</td>\n",
       "      <td>0.650751</td>\n",
       "      <td>0.825939</td>\n",
       "      <td>0.800531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.141400</td>\n",
       "      <td>0.529259</td>\n",
       "      <td>0.808386</td>\n",
       "      <td>0.792591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.095500</td>\n",
       "      <td>0.975958</td>\n",
       "      <td>0.811799</td>\n",
       "      <td>0.797388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.062200</td>\n",
       "      <td>0.798646</td>\n",
       "      <td>0.804486</td>\n",
       "      <td>0.791600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.052900</td>\n",
       "      <td>1.022648</td>\n",
       "      <td>0.815212</td>\n",
       "      <td>0.797021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.039900</td>\n",
       "      <td>0.968345</td>\n",
       "      <td>0.823501</td>\n",
       "      <td>0.803319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.027100</td>\n",
       "      <td>1.055818</td>\n",
       "      <td>0.822038</td>\n",
       "      <td>0.803237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.012200</td>\n",
       "      <td>1.191351</td>\n",
       "      <td>0.833252</td>\n",
       "      <td>0.812454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.034000</td>\n",
       "      <td>1.116166</td>\n",
       "      <td>0.828864</td>\n",
       "      <td>0.810146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.008700</td>\n",
       "      <td>1.317195</td>\n",
       "      <td>0.828376</td>\n",
       "      <td>0.802771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>1.350296</td>\n",
       "      <td>0.825939</td>\n",
       "      <td>0.805284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.007900</td>\n",
       "      <td>1.363266</td>\n",
       "      <td>0.819113</td>\n",
       "      <td>0.800661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>1.380175</td>\n",
       "      <td>0.829839</td>\n",
       "      <td>0.812726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>1.452153</td>\n",
       "      <td>0.825939</td>\n",
       "      <td>0.802990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>1.460473</td>\n",
       "      <td>0.827401</td>\n",
       "      <td>0.806713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>1.511298</td>\n",
       "      <td>0.823988</td>\n",
       "      <td>0.806537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>1.494590</td>\n",
       "      <td>0.828376</td>\n",
       "      <td>0.807668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.005700</td>\n",
       "      <td>1.499247</td>\n",
       "      <td>0.827401</td>\n",
       "      <td>0.808196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>1.514387</td>\n",
       "      <td>0.826426</td>\n",
       "      <td>0.808532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.530525</td>\n",
       "      <td>0.826914</td>\n",
       "      <td>0.807852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.580705</td>\n",
       "      <td>0.822526</td>\n",
       "      <td>0.805976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.575268</td>\n",
       "      <td>0.829352</td>\n",
       "      <td>0.807927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.580453</td>\n",
       "      <td>0.826426</td>\n",
       "      <td>0.807245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>1.591293</td>\n",
       "      <td>0.827889</td>\n",
       "      <td>0.809578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>1.591197</td>\n",
       "      <td>0.828864</td>\n",
       "      <td>0.810146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.595882</td>\n",
       "      <td>0.828864</td>\n",
       "      <td>0.807165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>1.595208</td>\n",
       "      <td>0.829352</td>\n",
       "      <td>0.810233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>1.595881</td>\n",
       "      <td>0.828864</td>\n",
       "      <td>0.810017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorRoBERTa, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at otmangi/MorRoBERTa and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8203 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2051 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1935' max='1935' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1935/1935 01:40, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.473900</td>\n",
       "      <td>0.403473</td>\n",
       "      <td>0.823501</td>\n",
       "      <td>0.789233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.410800</td>\n",
       "      <td>0.395607</td>\n",
       "      <td>0.826914</td>\n",
       "      <td>0.807055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.296200</td>\n",
       "      <td>0.440381</td>\n",
       "      <td>0.827889</td>\n",
       "      <td>0.807465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.264400</td>\n",
       "      <td>0.433899</td>\n",
       "      <td>0.830327</td>\n",
       "      <td>0.807593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.191700</td>\n",
       "      <td>0.650751</td>\n",
       "      <td>0.825939</td>\n",
       "      <td>0.800531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.141400</td>\n",
       "      <td>0.529259</td>\n",
       "      <td>0.808386</td>\n",
       "      <td>0.792591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.095500</td>\n",
       "      <td>0.975958</td>\n",
       "      <td>0.811799</td>\n",
       "      <td>0.797388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.062200</td>\n",
       "      <td>0.798646</td>\n",
       "      <td>0.804486</td>\n",
       "      <td>0.791600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.052900</td>\n",
       "      <td>1.022648</td>\n",
       "      <td>0.815212</td>\n",
       "      <td>0.797021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.039900</td>\n",
       "      <td>0.968345</td>\n",
       "      <td>0.823501</td>\n",
       "      <td>0.803319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.027100</td>\n",
       "      <td>1.055818</td>\n",
       "      <td>0.822038</td>\n",
       "      <td>0.803237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.012200</td>\n",
       "      <td>1.191351</td>\n",
       "      <td>0.833252</td>\n",
       "      <td>0.812454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.034000</td>\n",
       "      <td>1.116166</td>\n",
       "      <td>0.828864</td>\n",
       "      <td>0.810146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.008700</td>\n",
       "      <td>1.317195</td>\n",
       "      <td>0.828376</td>\n",
       "      <td>0.802771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>1.350296</td>\n",
       "      <td>0.825939</td>\n",
       "      <td>0.805284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.007900</td>\n",
       "      <td>1.363266</td>\n",
       "      <td>0.819113</td>\n",
       "      <td>0.800661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>1.380175</td>\n",
       "      <td>0.829839</td>\n",
       "      <td>0.812726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>1.452153</td>\n",
       "      <td>0.825939</td>\n",
       "      <td>0.802990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>1.460473</td>\n",
       "      <td>0.827401</td>\n",
       "      <td>0.806713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>1.511298</td>\n",
       "      <td>0.823988</td>\n",
       "      <td>0.806537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>1.494590</td>\n",
       "      <td>0.828376</td>\n",
       "      <td>0.807668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.005700</td>\n",
       "      <td>1.499247</td>\n",
       "      <td>0.827401</td>\n",
       "      <td>0.808196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>1.514387</td>\n",
       "      <td>0.826426</td>\n",
       "      <td>0.808532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.530525</td>\n",
       "      <td>0.826914</td>\n",
       "      <td>0.807852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.580705</td>\n",
       "      <td>0.822526</td>\n",
       "      <td>0.805976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.575268</td>\n",
       "      <td>0.829352</td>\n",
       "      <td>0.807927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.580453</td>\n",
       "      <td>0.826426</td>\n",
       "      <td>0.807245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>1.591293</td>\n",
       "      <td>0.827889</td>\n",
       "      <td>0.809578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>1.591197</td>\n",
       "      <td>0.828864</td>\n",
       "      <td>0.810146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.595882</td>\n",
       "      <td>0.828864</td>\n",
       "      <td>0.807165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>1.595208</td>\n",
       "      <td>0.829352</td>\n",
       "      <td>0.810233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>1.595881</td>\n",
       "      <td>0.828864</td>\n",
       "      <td>0.810017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorRoBERTa, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at otmangi/MorRoBERTa and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8203 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2051 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1935' max='1935' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1935/1935 01:39, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.473900</td>\n",
       "      <td>0.403473</td>\n",
       "      <td>0.823501</td>\n",
       "      <td>0.789233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.410800</td>\n",
       "      <td>0.395607</td>\n",
       "      <td>0.826914</td>\n",
       "      <td>0.807055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.296200</td>\n",
       "      <td>0.440381</td>\n",
       "      <td>0.827889</td>\n",
       "      <td>0.807465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.264400</td>\n",
       "      <td>0.433899</td>\n",
       "      <td>0.830327</td>\n",
       "      <td>0.807593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.191700</td>\n",
       "      <td>0.650751</td>\n",
       "      <td>0.825939</td>\n",
       "      <td>0.800531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.141400</td>\n",
       "      <td>0.529259</td>\n",
       "      <td>0.808386</td>\n",
       "      <td>0.792591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.095500</td>\n",
       "      <td>0.975958</td>\n",
       "      <td>0.811799</td>\n",
       "      <td>0.797388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.062200</td>\n",
       "      <td>0.798646</td>\n",
       "      <td>0.804486</td>\n",
       "      <td>0.791600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.052900</td>\n",
       "      <td>1.022648</td>\n",
       "      <td>0.815212</td>\n",
       "      <td>0.797021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.039900</td>\n",
       "      <td>0.968345</td>\n",
       "      <td>0.823501</td>\n",
       "      <td>0.803319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.027100</td>\n",
       "      <td>1.055818</td>\n",
       "      <td>0.822038</td>\n",
       "      <td>0.803237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.012200</td>\n",
       "      <td>1.191351</td>\n",
       "      <td>0.833252</td>\n",
       "      <td>0.812454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.034000</td>\n",
       "      <td>1.116166</td>\n",
       "      <td>0.828864</td>\n",
       "      <td>0.810146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.008700</td>\n",
       "      <td>1.317195</td>\n",
       "      <td>0.828376</td>\n",
       "      <td>0.802771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>1.350296</td>\n",
       "      <td>0.825939</td>\n",
       "      <td>0.805284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.007900</td>\n",
       "      <td>1.363266</td>\n",
       "      <td>0.819113</td>\n",
       "      <td>0.800661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>1.380175</td>\n",
       "      <td>0.829839</td>\n",
       "      <td>0.812726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>1.452153</td>\n",
       "      <td>0.825939</td>\n",
       "      <td>0.802990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>1.460473</td>\n",
       "      <td>0.827401</td>\n",
       "      <td>0.806713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>1.511298</td>\n",
       "      <td>0.823988</td>\n",
       "      <td>0.806537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>1.494590</td>\n",
       "      <td>0.828376</td>\n",
       "      <td>0.807668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.005700</td>\n",
       "      <td>1.499247</td>\n",
       "      <td>0.827401</td>\n",
       "      <td>0.808196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>1.514387</td>\n",
       "      <td>0.826426</td>\n",
       "      <td>0.808532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.530525</td>\n",
       "      <td>0.826914</td>\n",
       "      <td>0.807852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.580705</td>\n",
       "      <td>0.822526</td>\n",
       "      <td>0.805976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.575268</td>\n",
       "      <td>0.829352</td>\n",
       "      <td>0.807927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.580453</td>\n",
       "      <td>0.826426</td>\n",
       "      <td>0.807245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>1.591293</td>\n",
       "      <td>0.827889</td>\n",
       "      <td>0.809578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>1.591197</td>\n",
       "      <td>0.828864</td>\n",
       "      <td>0.810146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.595882</td>\n",
       "      <td>0.828864</td>\n",
       "      <td>0.807165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>1.595208</td>\n",
       "      <td>0.829352</td>\n",
       "      <td>0.810233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>1.595881</td>\n",
       "      <td>0.828864</td>\n",
       "      <td>0.810017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['comment_message', 'label'],\n",
       "        num_rows: 8203\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['comment_message', 'label'],\n",
       "        num_rows: 2051\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorrBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at otmangi/MorrBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8203 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2051 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1935' max='1935' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1935/1935 03:00, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.381549</td>\n",
       "      <td>0.829352</td>\n",
       "      <td>0.801606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.413100</td>\n",
       "      <td>0.372231</td>\n",
       "      <td>0.835690</td>\n",
       "      <td>0.806206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.284300</td>\n",
       "      <td>0.431767</td>\n",
       "      <td>0.837640</td>\n",
       "      <td>0.811482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.242900</td>\n",
       "      <td>0.432236</td>\n",
       "      <td>0.831789</td>\n",
       "      <td>0.814142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.164200</td>\n",
       "      <td>0.587135</td>\n",
       "      <td>0.825939</td>\n",
       "      <td>0.803579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.111600</td>\n",
       "      <td>0.659150</td>\n",
       "      <td>0.800585</td>\n",
       "      <td>0.782859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.071200</td>\n",
       "      <td>0.852131</td>\n",
       "      <td>0.827889</td>\n",
       "      <td>0.805490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.052400</td>\n",
       "      <td>0.864715</td>\n",
       "      <td>0.783520</td>\n",
       "      <td>0.770131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.043200</td>\n",
       "      <td>0.925716</td>\n",
       "      <td>0.818137</td>\n",
       "      <td>0.795230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.026600</td>\n",
       "      <td>0.966699</td>\n",
       "      <td>0.825451</td>\n",
       "      <td>0.804249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.026400</td>\n",
       "      <td>1.042270</td>\n",
       "      <td>0.828864</td>\n",
       "      <td>0.807448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.013400</td>\n",
       "      <td>1.204667</td>\n",
       "      <td>0.808386</td>\n",
       "      <td>0.790584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.018600</td>\n",
       "      <td>1.075482</td>\n",
       "      <td>0.824963</td>\n",
       "      <td>0.805950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.008100</td>\n",
       "      <td>1.137865</td>\n",
       "      <td>0.831789</td>\n",
       "      <td>0.807389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.016600</td>\n",
       "      <td>1.066970</td>\n",
       "      <td>0.836665</td>\n",
       "      <td>0.807009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.012300</td>\n",
       "      <td>1.171510</td>\n",
       "      <td>0.819113</td>\n",
       "      <td>0.799868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.011000</td>\n",
       "      <td>1.173727</td>\n",
       "      <td>0.842516</td>\n",
       "      <td>0.817755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.009700</td>\n",
       "      <td>1.236292</td>\n",
       "      <td>0.830327</td>\n",
       "      <td>0.807593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>1.321301</td>\n",
       "      <td>0.831302</td>\n",
       "      <td>0.806907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.008400</td>\n",
       "      <td>1.273794</td>\n",
       "      <td>0.827889</td>\n",
       "      <td>0.806209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.007900</td>\n",
       "      <td>1.311764</td>\n",
       "      <td>0.825451</td>\n",
       "      <td>0.803680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>1.388457</td>\n",
       "      <td>0.816675</td>\n",
       "      <td>0.797776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>1.351237</td>\n",
       "      <td>0.833740</td>\n",
       "      <td>0.808702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.400325</td>\n",
       "      <td>0.833252</td>\n",
       "      <td>0.809740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>1.408290</td>\n",
       "      <td>0.828864</td>\n",
       "      <td>0.807729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>1.413236</td>\n",
       "      <td>0.833740</td>\n",
       "      <td>0.807758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>1.409130</td>\n",
       "      <td>0.832765</td>\n",
       "      <td>0.807736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>1.409146</td>\n",
       "      <td>0.834227</td>\n",
       "      <td>0.811729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>1.417138</td>\n",
       "      <td>0.834715</td>\n",
       "      <td>0.813620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>1.411267</td>\n",
       "      <td>0.834715</td>\n",
       "      <td>0.809514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>1.416328</td>\n",
       "      <td>0.835690</td>\n",
       "      <td>0.813887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>1.419111</td>\n",
       "      <td>0.835202</td>\n",
       "      <td>0.813405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorrBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at otmangi/MorrBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8203 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2051 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1935' max='1935' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1935/1935 03:00, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.381549</td>\n",
       "      <td>0.829352</td>\n",
       "      <td>0.801606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.413100</td>\n",
       "      <td>0.372231</td>\n",
       "      <td>0.835690</td>\n",
       "      <td>0.806206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.284300</td>\n",
       "      <td>0.431767</td>\n",
       "      <td>0.837640</td>\n",
       "      <td>0.811482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.242900</td>\n",
       "      <td>0.432236</td>\n",
       "      <td>0.831789</td>\n",
       "      <td>0.814142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.164200</td>\n",
       "      <td>0.587135</td>\n",
       "      <td>0.825939</td>\n",
       "      <td>0.803579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.111600</td>\n",
       "      <td>0.659150</td>\n",
       "      <td>0.800585</td>\n",
       "      <td>0.782859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.071200</td>\n",
       "      <td>0.852131</td>\n",
       "      <td>0.827889</td>\n",
       "      <td>0.805490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.052400</td>\n",
       "      <td>0.864715</td>\n",
       "      <td>0.783520</td>\n",
       "      <td>0.770131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.043200</td>\n",
       "      <td>0.925716</td>\n",
       "      <td>0.818137</td>\n",
       "      <td>0.795230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.026600</td>\n",
       "      <td>0.966699</td>\n",
       "      <td>0.825451</td>\n",
       "      <td>0.804249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.026400</td>\n",
       "      <td>1.042270</td>\n",
       "      <td>0.828864</td>\n",
       "      <td>0.807448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.013400</td>\n",
       "      <td>1.204667</td>\n",
       "      <td>0.808386</td>\n",
       "      <td>0.790584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.018600</td>\n",
       "      <td>1.075482</td>\n",
       "      <td>0.824963</td>\n",
       "      <td>0.805950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.008100</td>\n",
       "      <td>1.137865</td>\n",
       "      <td>0.831789</td>\n",
       "      <td>0.807389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.016600</td>\n",
       "      <td>1.066970</td>\n",
       "      <td>0.836665</td>\n",
       "      <td>0.807009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.012300</td>\n",
       "      <td>1.171510</td>\n",
       "      <td>0.819113</td>\n",
       "      <td>0.799868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.011000</td>\n",
       "      <td>1.173727</td>\n",
       "      <td>0.842516</td>\n",
       "      <td>0.817755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.009700</td>\n",
       "      <td>1.236292</td>\n",
       "      <td>0.830327</td>\n",
       "      <td>0.807593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>1.321301</td>\n",
       "      <td>0.831302</td>\n",
       "      <td>0.806907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.008400</td>\n",
       "      <td>1.273794</td>\n",
       "      <td>0.827889</td>\n",
       "      <td>0.806209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.007900</td>\n",
       "      <td>1.311764</td>\n",
       "      <td>0.825451</td>\n",
       "      <td>0.803680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>1.388457</td>\n",
       "      <td>0.816675</td>\n",
       "      <td>0.797776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>1.351237</td>\n",
       "      <td>0.833740</td>\n",
       "      <td>0.808702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.400325</td>\n",
       "      <td>0.833252</td>\n",
       "      <td>0.809740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>1.408290</td>\n",
       "      <td>0.828864</td>\n",
       "      <td>0.807729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>1.413236</td>\n",
       "      <td>0.833740</td>\n",
       "      <td>0.807758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>1.409130</td>\n",
       "      <td>0.832765</td>\n",
       "      <td>0.807736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>1.409146</td>\n",
       "      <td>0.834227</td>\n",
       "      <td>0.811729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>1.417138</td>\n",
       "      <td>0.834715</td>\n",
       "      <td>0.813620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>1.411267</td>\n",
       "      <td>0.834715</td>\n",
       "      <td>0.809514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>1.416328</td>\n",
       "      <td>0.835690</td>\n",
       "      <td>0.813887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>1.419111</td>\n",
       "      <td>0.835202</td>\n",
       "      <td>0.813405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorrBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at otmangi/MorrBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8203 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2051 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1935' max='1935' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1935/1935 02:59, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.381549</td>\n",
       "      <td>0.829352</td>\n",
       "      <td>0.801606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.413100</td>\n",
       "      <td>0.372231</td>\n",
       "      <td>0.835690</td>\n",
       "      <td>0.806206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.284300</td>\n",
       "      <td>0.431767</td>\n",
       "      <td>0.837640</td>\n",
       "      <td>0.811482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.242900</td>\n",
       "      <td>0.432236</td>\n",
       "      <td>0.831789</td>\n",
       "      <td>0.814142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.164200</td>\n",
       "      <td>0.587135</td>\n",
       "      <td>0.825939</td>\n",
       "      <td>0.803579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.111600</td>\n",
       "      <td>0.659150</td>\n",
       "      <td>0.800585</td>\n",
       "      <td>0.782859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.071200</td>\n",
       "      <td>0.852131</td>\n",
       "      <td>0.827889</td>\n",
       "      <td>0.805490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.052400</td>\n",
       "      <td>0.864715</td>\n",
       "      <td>0.783520</td>\n",
       "      <td>0.770131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.043200</td>\n",
       "      <td>0.925716</td>\n",
       "      <td>0.818137</td>\n",
       "      <td>0.795230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.026600</td>\n",
       "      <td>0.966699</td>\n",
       "      <td>0.825451</td>\n",
       "      <td>0.804249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.026400</td>\n",
       "      <td>1.042270</td>\n",
       "      <td>0.828864</td>\n",
       "      <td>0.807448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.013400</td>\n",
       "      <td>1.204667</td>\n",
       "      <td>0.808386</td>\n",
       "      <td>0.790584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.018600</td>\n",
       "      <td>1.075482</td>\n",
       "      <td>0.824963</td>\n",
       "      <td>0.805950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.008100</td>\n",
       "      <td>1.137865</td>\n",
       "      <td>0.831789</td>\n",
       "      <td>0.807389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.016600</td>\n",
       "      <td>1.066970</td>\n",
       "      <td>0.836665</td>\n",
       "      <td>0.807009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.012300</td>\n",
       "      <td>1.171510</td>\n",
       "      <td>0.819113</td>\n",
       "      <td>0.799868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.011000</td>\n",
       "      <td>1.173727</td>\n",
       "      <td>0.842516</td>\n",
       "      <td>0.817755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.009700</td>\n",
       "      <td>1.236292</td>\n",
       "      <td>0.830327</td>\n",
       "      <td>0.807593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>1.321301</td>\n",
       "      <td>0.831302</td>\n",
       "      <td>0.806907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.008400</td>\n",
       "      <td>1.273794</td>\n",
       "      <td>0.827889</td>\n",
       "      <td>0.806209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.007900</td>\n",
       "      <td>1.311764</td>\n",
       "      <td>0.825451</td>\n",
       "      <td>0.803680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>1.388457</td>\n",
       "      <td>0.816675</td>\n",
       "      <td>0.797776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>1.351237</td>\n",
       "      <td>0.833740</td>\n",
       "      <td>0.808702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.400325</td>\n",
       "      <td>0.833252</td>\n",
       "      <td>0.809740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>1.408290</td>\n",
       "      <td>0.828864</td>\n",
       "      <td>0.807729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>1.413236</td>\n",
       "      <td>0.833740</td>\n",
       "      <td>0.807758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>1.409130</td>\n",
       "      <td>0.832765</td>\n",
       "      <td>0.807736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>1.409146</td>\n",
       "      <td>0.834227</td>\n",
       "      <td>0.811729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>1.417138</td>\n",
       "      <td>0.834715</td>\n",
       "      <td>0.813620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>1.411267</td>\n",
       "      <td>0.834715</td>\n",
       "      <td>0.809514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>1.416328</td>\n",
       "      <td>0.835690</td>\n",
       "      <td>0.813887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>1.419111</td>\n",
       "      <td>0.835202</td>\n",
       "      <td>0.813405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorrBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at otmangi/MorrBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8203 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2051 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1935' max='1935' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1935/1935 02:59, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.481900</td>\n",
       "      <td>0.435585</td>\n",
       "      <td>0.810824</td>\n",
       "      <td>0.764073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.398665</td>\n",
       "      <td>0.828376</td>\n",
       "      <td>0.806687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.282500</td>\n",
       "      <td>0.400458</td>\n",
       "      <td>0.829352</td>\n",
       "      <td>0.811635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.248500</td>\n",
       "      <td>0.416887</td>\n",
       "      <td>0.829352</td>\n",
       "      <td>0.809034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.142600</td>\n",
       "      <td>0.741510</td>\n",
       "      <td>0.793759</td>\n",
       "      <td>0.782735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.093300</td>\n",
       "      <td>0.666622</td>\n",
       "      <td>0.817650</td>\n",
       "      <td>0.797081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.061900</td>\n",
       "      <td>0.864834</td>\n",
       "      <td>0.823988</td>\n",
       "      <td>0.802251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.049600</td>\n",
       "      <td>0.866010</td>\n",
       "      <td>0.823988</td>\n",
       "      <td>0.801230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.036200</td>\n",
       "      <td>0.997435</td>\n",
       "      <td>0.819600</td>\n",
       "      <td>0.796802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.030800</td>\n",
       "      <td>1.046841</td>\n",
       "      <td>0.827401</td>\n",
       "      <td>0.797954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.022000</td>\n",
       "      <td>1.093318</td>\n",
       "      <td>0.817650</td>\n",
       "      <td>0.798047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.020800</td>\n",
       "      <td>1.121901</td>\n",
       "      <td>0.819600</td>\n",
       "      <td>0.797687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.016100</td>\n",
       "      <td>1.219151</td>\n",
       "      <td>0.800098</td>\n",
       "      <td>0.785620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.012700</td>\n",
       "      <td>1.262162</td>\n",
       "      <td>0.820088</td>\n",
       "      <td>0.801080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>1.437835</td>\n",
       "      <td>0.798635</td>\n",
       "      <td>0.782539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.011900</td>\n",
       "      <td>1.341142</td>\n",
       "      <td>0.823988</td>\n",
       "      <td>0.797152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.008600</td>\n",
       "      <td>1.373273</td>\n",
       "      <td>0.800098</td>\n",
       "      <td>0.780629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>1.386473</td>\n",
       "      <td>0.828864</td>\n",
       "      <td>0.804962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>1.373956</td>\n",
       "      <td>0.823501</td>\n",
       "      <td>0.798928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.006100</td>\n",
       "      <td>1.461491</td>\n",
       "      <td>0.813749</td>\n",
       "      <td>0.797255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>1.390323</td>\n",
       "      <td>0.822038</td>\n",
       "      <td>0.797808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>1.431297</td>\n",
       "      <td>0.820088</td>\n",
       "      <td>0.799446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>1.515676</td>\n",
       "      <td>0.806436</td>\n",
       "      <td>0.788844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.455475</td>\n",
       "      <td>0.819113</td>\n",
       "      <td>0.796027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>1.475231</td>\n",
       "      <td>0.817162</td>\n",
       "      <td>0.797439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>1.487975</td>\n",
       "      <td>0.822526</td>\n",
       "      <td>0.803447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>1.473193</td>\n",
       "      <td>0.823013</td>\n",
       "      <td>0.800277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.521652</td>\n",
       "      <td>0.819600</td>\n",
       "      <td>0.802031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.486514</td>\n",
       "      <td>0.823988</td>\n",
       "      <td>0.804202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>1.498426</td>\n",
       "      <td>0.821063</td>\n",
       "      <td>0.800947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>1.495372</td>\n",
       "      <td>0.825939</td>\n",
       "      <td>0.804584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>1.494750</td>\n",
       "      <td>0.825939</td>\n",
       "      <td>0.804725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorrBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at otmangi/MorrBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8203 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2051 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1935' max='1935' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1935/1935 02:59, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.481900</td>\n",
       "      <td>0.435585</td>\n",
       "      <td>0.810824</td>\n",
       "      <td>0.764073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.398665</td>\n",
       "      <td>0.828376</td>\n",
       "      <td>0.806687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.282500</td>\n",
       "      <td>0.400458</td>\n",
       "      <td>0.829352</td>\n",
       "      <td>0.811635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.248500</td>\n",
       "      <td>0.416887</td>\n",
       "      <td>0.829352</td>\n",
       "      <td>0.809034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.142600</td>\n",
       "      <td>0.741510</td>\n",
       "      <td>0.793759</td>\n",
       "      <td>0.782735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.093300</td>\n",
       "      <td>0.666622</td>\n",
       "      <td>0.817650</td>\n",
       "      <td>0.797081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.061900</td>\n",
       "      <td>0.864834</td>\n",
       "      <td>0.823988</td>\n",
       "      <td>0.802251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.049600</td>\n",
       "      <td>0.866010</td>\n",
       "      <td>0.823988</td>\n",
       "      <td>0.801230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.036200</td>\n",
       "      <td>0.997435</td>\n",
       "      <td>0.819600</td>\n",
       "      <td>0.796802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.030800</td>\n",
       "      <td>1.046841</td>\n",
       "      <td>0.827401</td>\n",
       "      <td>0.797954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.022000</td>\n",
       "      <td>1.093318</td>\n",
       "      <td>0.817650</td>\n",
       "      <td>0.798047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.020800</td>\n",
       "      <td>1.121901</td>\n",
       "      <td>0.819600</td>\n",
       "      <td>0.797687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.016100</td>\n",
       "      <td>1.219151</td>\n",
       "      <td>0.800098</td>\n",
       "      <td>0.785620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.012700</td>\n",
       "      <td>1.262162</td>\n",
       "      <td>0.820088</td>\n",
       "      <td>0.801080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>1.437835</td>\n",
       "      <td>0.798635</td>\n",
       "      <td>0.782539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.011900</td>\n",
       "      <td>1.341142</td>\n",
       "      <td>0.823988</td>\n",
       "      <td>0.797152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.008600</td>\n",
       "      <td>1.373273</td>\n",
       "      <td>0.800098</td>\n",
       "      <td>0.780629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>1.386473</td>\n",
       "      <td>0.828864</td>\n",
       "      <td>0.804962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>1.373956</td>\n",
       "      <td>0.823501</td>\n",
       "      <td>0.798928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.006100</td>\n",
       "      <td>1.461491</td>\n",
       "      <td>0.813749</td>\n",
       "      <td>0.797255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>1.390323</td>\n",
       "      <td>0.822038</td>\n",
       "      <td>0.797808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>1.431297</td>\n",
       "      <td>0.820088</td>\n",
       "      <td>0.799446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>1.515676</td>\n",
       "      <td>0.806436</td>\n",
       "      <td>0.788844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.455475</td>\n",
       "      <td>0.819113</td>\n",
       "      <td>0.796027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>1.475231</td>\n",
       "      <td>0.817162</td>\n",
       "      <td>0.797439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>1.487975</td>\n",
       "      <td>0.822526</td>\n",
       "      <td>0.803447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>1.473193</td>\n",
       "      <td>0.823013</td>\n",
       "      <td>0.800277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.521652</td>\n",
       "      <td>0.819600</td>\n",
       "      <td>0.802031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.486514</td>\n",
       "      <td>0.823988</td>\n",
       "      <td>0.804202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>1.498426</td>\n",
       "      <td>0.821063</td>\n",
       "      <td>0.800947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>1.495372</td>\n",
       "      <td>0.825939</td>\n",
       "      <td>0.804584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>1.494750</td>\n",
       "      <td>0.825939</td>\n",
       "      <td>0.804725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorrBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at otmangi/MorrBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8203 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2051 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1935' max='1935' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1935/1935 02:59, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.481900</td>\n",
       "      <td>0.435585</td>\n",
       "      <td>0.810824</td>\n",
       "      <td>0.764073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.398665</td>\n",
       "      <td>0.828376</td>\n",
       "      <td>0.806687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.282500</td>\n",
       "      <td>0.400458</td>\n",
       "      <td>0.829352</td>\n",
       "      <td>0.811635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.248500</td>\n",
       "      <td>0.416887</td>\n",
       "      <td>0.829352</td>\n",
       "      <td>0.809034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.142600</td>\n",
       "      <td>0.741510</td>\n",
       "      <td>0.793759</td>\n",
       "      <td>0.782735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.093300</td>\n",
       "      <td>0.666622</td>\n",
       "      <td>0.817650</td>\n",
       "      <td>0.797081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.061900</td>\n",
       "      <td>0.864834</td>\n",
       "      <td>0.823988</td>\n",
       "      <td>0.802251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.049600</td>\n",
       "      <td>0.866010</td>\n",
       "      <td>0.823988</td>\n",
       "      <td>0.801230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.036200</td>\n",
       "      <td>0.997435</td>\n",
       "      <td>0.819600</td>\n",
       "      <td>0.796802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.030800</td>\n",
       "      <td>1.046841</td>\n",
       "      <td>0.827401</td>\n",
       "      <td>0.797954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.022000</td>\n",
       "      <td>1.093318</td>\n",
       "      <td>0.817650</td>\n",
       "      <td>0.798047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.020800</td>\n",
       "      <td>1.121901</td>\n",
       "      <td>0.819600</td>\n",
       "      <td>0.797687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.016100</td>\n",
       "      <td>1.219151</td>\n",
       "      <td>0.800098</td>\n",
       "      <td>0.785620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.012700</td>\n",
       "      <td>1.262162</td>\n",
       "      <td>0.820088</td>\n",
       "      <td>0.801080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>1.437835</td>\n",
       "      <td>0.798635</td>\n",
       "      <td>0.782539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.011900</td>\n",
       "      <td>1.341142</td>\n",
       "      <td>0.823988</td>\n",
       "      <td>0.797152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.008600</td>\n",
       "      <td>1.373273</td>\n",
       "      <td>0.800098</td>\n",
       "      <td>0.780629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>1.386473</td>\n",
       "      <td>0.828864</td>\n",
       "      <td>0.804962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>1.373956</td>\n",
       "      <td>0.823501</td>\n",
       "      <td>0.798928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.006100</td>\n",
       "      <td>1.461491</td>\n",
       "      <td>0.813749</td>\n",
       "      <td>0.797255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>1.390323</td>\n",
       "      <td>0.822038</td>\n",
       "      <td>0.797808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>1.431297</td>\n",
       "      <td>0.820088</td>\n",
       "      <td>0.799446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>1.515676</td>\n",
       "      <td>0.806436</td>\n",
       "      <td>0.788844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.455475</td>\n",
       "      <td>0.819113</td>\n",
       "      <td>0.796027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>1.475231</td>\n",
       "      <td>0.817162</td>\n",
       "      <td>0.797439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>1.487975</td>\n",
       "      <td>0.822526</td>\n",
       "      <td>0.803447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>1.473193</td>\n",
       "      <td>0.823013</td>\n",
       "      <td>0.800277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.521652</td>\n",
       "      <td>0.819600</td>\n",
       "      <td>0.802031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.486514</td>\n",
       "      <td>0.823988</td>\n",
       "      <td>0.804202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>1.498426</td>\n",
       "      <td>0.821063</td>\n",
       "      <td>0.800947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>1.495372</td>\n",
       "      <td>0.825939</td>\n",
       "      <td>0.804584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>1.494750</td>\n",
       "      <td>0.825939</td>\n",
       "      <td>0.804725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorrBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at otmangi/MorrBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8203 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2051 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1935' max='1935' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1935/1935 02:59, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.453200</td>\n",
       "      <td>0.422600</td>\n",
       "      <td>0.814237</td>\n",
       "      <td>0.794474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.394500</td>\n",
       "      <td>0.435166</td>\n",
       "      <td>0.818137</td>\n",
       "      <td>0.783336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.281800</td>\n",
       "      <td>0.466164</td>\n",
       "      <td>0.823013</td>\n",
       "      <td>0.797178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.249900</td>\n",
       "      <td>0.468977</td>\n",
       "      <td>0.823501</td>\n",
       "      <td>0.801631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.149100</td>\n",
       "      <td>0.646361</td>\n",
       "      <td>0.821550</td>\n",
       "      <td>0.799293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.100200</td>\n",
       "      <td>0.636942</td>\n",
       "      <td>0.807899</td>\n",
       "      <td>0.783780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.080900</td>\n",
       "      <td>0.975180</td>\n",
       "      <td>0.823013</td>\n",
       "      <td>0.794671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.048200</td>\n",
       "      <td>0.908475</td>\n",
       "      <td>0.817650</td>\n",
       "      <td>0.803576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.031800</td>\n",
       "      <td>1.035337</td>\n",
       "      <td>0.815212</td>\n",
       "      <td>0.793137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.041300</td>\n",
       "      <td>1.054035</td>\n",
       "      <td>0.817650</td>\n",
       "      <td>0.796940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.021200</td>\n",
       "      <td>1.032281</td>\n",
       "      <td>0.817162</td>\n",
       "      <td>0.793980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.014800</td>\n",
       "      <td>1.219170</td>\n",
       "      <td>0.819113</td>\n",
       "      <td>0.805316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.012400</td>\n",
       "      <td>1.295547</td>\n",
       "      <td>0.817162</td>\n",
       "      <td>0.797026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.008500</td>\n",
       "      <td>1.237022</td>\n",
       "      <td>0.822038</td>\n",
       "      <td>0.801620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.015700</td>\n",
       "      <td>1.308425</td>\n",
       "      <td>0.819113</td>\n",
       "      <td>0.789969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.011200</td>\n",
       "      <td>1.266788</td>\n",
       "      <td>0.822526</td>\n",
       "      <td>0.805241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>1.366402</td>\n",
       "      <td>0.813262</td>\n",
       "      <td>0.796415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.009400</td>\n",
       "      <td>1.321877</td>\n",
       "      <td>0.815700</td>\n",
       "      <td>0.796966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.008300</td>\n",
       "      <td>1.377270</td>\n",
       "      <td>0.817650</td>\n",
       "      <td>0.797081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.006600</td>\n",
       "      <td>1.390754</td>\n",
       "      <td>0.820575</td>\n",
       "      <td>0.798636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>1.420853</td>\n",
       "      <td>0.816187</td>\n",
       "      <td>0.794521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>1.415641</td>\n",
       "      <td>0.817162</td>\n",
       "      <td>0.798905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>1.462672</td>\n",
       "      <td>0.819113</td>\n",
       "      <td>0.798639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>1.424989</td>\n",
       "      <td>0.818625</td>\n",
       "      <td>0.800706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>1.455116</td>\n",
       "      <td>0.816675</td>\n",
       "      <td>0.795996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>1.479064</td>\n",
       "      <td>0.819113</td>\n",
       "      <td>0.797359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>1.515703</td>\n",
       "      <td>0.816187</td>\n",
       "      <td>0.800802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>1.522439</td>\n",
       "      <td>0.821550</td>\n",
       "      <td>0.801146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>1.528804</td>\n",
       "      <td>0.819600</td>\n",
       "      <td>0.801133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>1.529488</td>\n",
       "      <td>0.817650</td>\n",
       "      <td>0.798318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.531594</td>\n",
       "      <td>0.820575</td>\n",
       "      <td>0.799639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>1.530669</td>\n",
       "      <td>0.819600</td>\n",
       "      <td>0.799251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorrBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at otmangi/MorrBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8203 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2051 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1935' max='1935' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1935/1935 03:00, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.453200</td>\n",
       "      <td>0.422600</td>\n",
       "      <td>0.814237</td>\n",
       "      <td>0.794474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.394500</td>\n",
       "      <td>0.435166</td>\n",
       "      <td>0.818137</td>\n",
       "      <td>0.783336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.281800</td>\n",
       "      <td>0.466164</td>\n",
       "      <td>0.823013</td>\n",
       "      <td>0.797178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.249900</td>\n",
       "      <td>0.468977</td>\n",
       "      <td>0.823501</td>\n",
       "      <td>0.801631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.149100</td>\n",
       "      <td>0.646361</td>\n",
       "      <td>0.821550</td>\n",
       "      <td>0.799293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.100200</td>\n",
       "      <td>0.636942</td>\n",
       "      <td>0.807899</td>\n",
       "      <td>0.783780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.080900</td>\n",
       "      <td>0.975180</td>\n",
       "      <td>0.823013</td>\n",
       "      <td>0.794671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.048200</td>\n",
       "      <td>0.908475</td>\n",
       "      <td>0.817650</td>\n",
       "      <td>0.803576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.031800</td>\n",
       "      <td>1.035337</td>\n",
       "      <td>0.815212</td>\n",
       "      <td>0.793137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.041300</td>\n",
       "      <td>1.054035</td>\n",
       "      <td>0.817650</td>\n",
       "      <td>0.796940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.021200</td>\n",
       "      <td>1.032281</td>\n",
       "      <td>0.817162</td>\n",
       "      <td>0.793980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.014800</td>\n",
       "      <td>1.219170</td>\n",
       "      <td>0.819113</td>\n",
       "      <td>0.805316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.012400</td>\n",
       "      <td>1.295547</td>\n",
       "      <td>0.817162</td>\n",
       "      <td>0.797026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.008500</td>\n",
       "      <td>1.237022</td>\n",
       "      <td>0.822038</td>\n",
       "      <td>0.801620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.015700</td>\n",
       "      <td>1.308425</td>\n",
       "      <td>0.819113</td>\n",
       "      <td>0.789969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.011200</td>\n",
       "      <td>1.266788</td>\n",
       "      <td>0.822526</td>\n",
       "      <td>0.805241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>1.366402</td>\n",
       "      <td>0.813262</td>\n",
       "      <td>0.796415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.009400</td>\n",
       "      <td>1.321877</td>\n",
       "      <td>0.815700</td>\n",
       "      <td>0.796966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.008300</td>\n",
       "      <td>1.377270</td>\n",
       "      <td>0.817650</td>\n",
       "      <td>0.797081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.006600</td>\n",
       "      <td>1.390754</td>\n",
       "      <td>0.820575</td>\n",
       "      <td>0.798636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>1.420853</td>\n",
       "      <td>0.816187</td>\n",
       "      <td>0.794521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>1.415641</td>\n",
       "      <td>0.817162</td>\n",
       "      <td>0.798905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>1.462672</td>\n",
       "      <td>0.819113</td>\n",
       "      <td>0.798639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>1.424989</td>\n",
       "      <td>0.818625</td>\n",
       "      <td>0.800706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>1.455116</td>\n",
       "      <td>0.816675</td>\n",
       "      <td>0.795996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>1.479064</td>\n",
       "      <td>0.819113</td>\n",
       "      <td>0.797359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>1.515703</td>\n",
       "      <td>0.816187</td>\n",
       "      <td>0.800802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>1.522439</td>\n",
       "      <td>0.821550</td>\n",
       "      <td>0.801146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>1.528804</td>\n",
       "      <td>0.819600</td>\n",
       "      <td>0.801133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>1.529488</td>\n",
       "      <td>0.817650</td>\n",
       "      <td>0.798318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.531594</td>\n",
       "      <td>0.820575</td>\n",
       "      <td>0.799639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>1.530669</td>\n",
       "      <td>0.819600</td>\n",
       "      <td>0.799251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorrBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at otmangi/MorrBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8203 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2051 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1935' max='1935' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1935/1935 03:00, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.453200</td>\n",
       "      <td>0.422600</td>\n",
       "      <td>0.814237</td>\n",
       "      <td>0.794474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.394500</td>\n",
       "      <td>0.435166</td>\n",
       "      <td>0.818137</td>\n",
       "      <td>0.783336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.281800</td>\n",
       "      <td>0.466164</td>\n",
       "      <td>0.823013</td>\n",
       "      <td>0.797178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.249900</td>\n",
       "      <td>0.468977</td>\n",
       "      <td>0.823501</td>\n",
       "      <td>0.801631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.149100</td>\n",
       "      <td>0.646361</td>\n",
       "      <td>0.821550</td>\n",
       "      <td>0.799293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.100200</td>\n",
       "      <td>0.636942</td>\n",
       "      <td>0.807899</td>\n",
       "      <td>0.783780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.080900</td>\n",
       "      <td>0.975180</td>\n",
       "      <td>0.823013</td>\n",
       "      <td>0.794671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.048200</td>\n",
       "      <td>0.908475</td>\n",
       "      <td>0.817650</td>\n",
       "      <td>0.803576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.031800</td>\n",
       "      <td>1.035337</td>\n",
       "      <td>0.815212</td>\n",
       "      <td>0.793137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.041300</td>\n",
       "      <td>1.054035</td>\n",
       "      <td>0.817650</td>\n",
       "      <td>0.796940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.021200</td>\n",
       "      <td>1.032281</td>\n",
       "      <td>0.817162</td>\n",
       "      <td>0.793980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.014800</td>\n",
       "      <td>1.219170</td>\n",
       "      <td>0.819113</td>\n",
       "      <td>0.805316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.012400</td>\n",
       "      <td>1.295547</td>\n",
       "      <td>0.817162</td>\n",
       "      <td>0.797026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.008500</td>\n",
       "      <td>1.237022</td>\n",
       "      <td>0.822038</td>\n",
       "      <td>0.801620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.015700</td>\n",
       "      <td>1.308425</td>\n",
       "      <td>0.819113</td>\n",
       "      <td>0.789969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.011200</td>\n",
       "      <td>1.266788</td>\n",
       "      <td>0.822526</td>\n",
       "      <td>0.805241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>1.366402</td>\n",
       "      <td>0.813262</td>\n",
       "      <td>0.796415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.009400</td>\n",
       "      <td>1.321877</td>\n",
       "      <td>0.815700</td>\n",
       "      <td>0.796966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.008300</td>\n",
       "      <td>1.377270</td>\n",
       "      <td>0.817650</td>\n",
       "      <td>0.797081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.006600</td>\n",
       "      <td>1.390754</td>\n",
       "      <td>0.820575</td>\n",
       "      <td>0.798636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>1.420853</td>\n",
       "      <td>0.816187</td>\n",
       "      <td>0.794521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>1.415641</td>\n",
       "      <td>0.817162</td>\n",
       "      <td>0.798905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>1.462672</td>\n",
       "      <td>0.819113</td>\n",
       "      <td>0.798639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>1.424989</td>\n",
       "      <td>0.818625</td>\n",
       "      <td>0.800706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>1.455116</td>\n",
       "      <td>0.816675</td>\n",
       "      <td>0.795996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>1.479064</td>\n",
       "      <td>0.819113</td>\n",
       "      <td>0.797359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>1.515703</td>\n",
       "      <td>0.816187</td>\n",
       "      <td>0.800802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>1.522439</td>\n",
       "      <td>0.821550</td>\n",
       "      <td>0.801146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>1.528804</td>\n",
       "      <td>0.819600</td>\n",
       "      <td>0.801133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>1.529488</td>\n",
       "      <td>0.817650</td>\n",
       "      <td>0.798318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.531594</td>\n",
       "      <td>0.820575</td>\n",
       "      <td>0.799639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>1.530669</td>\n",
       "      <td>0.819600</td>\n",
       "      <td>0.799251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SI2M-Lab/DarijaBERT</td>\n",
       "      <td>0.853730</td>\n",
       "      <td>0.837343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alger-ia/dziribert</td>\n",
       "      <td>0.855193</td>\n",
       "      <td>0.838914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>faisalq/EgyBERT</td>\n",
       "      <td>0.864944</td>\n",
       "      <td>0.849761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>faisalq/SaudiBERT</td>\n",
       "      <td>0.871770</td>\n",
       "      <td>0.858690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>otmangi/MorRoBERTa</td>\n",
       "      <td>0.838128</td>\n",
       "      <td>0.815734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>otmangi/MorrBERT</td>\n",
       "      <td>0.842516</td>\n",
       "      <td>0.817755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>tunis-ai/TunBERT</td>\n",
       "      <td>0.728425</td>\n",
       "      <td>0.685464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model  Accuracy        F1\n",
       "0   SI2M-Lab/DarijaBERT  0.853730  0.837343\n",
       "3    alger-ia/dziribert  0.855193  0.838914\n",
       "6       faisalq/EgyBERT  0.864944  0.849761\n",
       "9     faisalq/SaudiBERT  0.871770  0.858690\n",
       "12   otmangi/MorRoBERTa  0.838128  0.815734\n",
       "15     otmangi/MorrBERT  0.842516  0.817755\n",
       "18     tunis-ai/TunBERT  0.728425  0.685464"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" \n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import pyarabic.araby as araby\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.initializers import TruncatedNormal\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from datasets import load_dataset, Dataset, concatenate_datasets\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', 1000)\n",
    "\n",
    "\n",
    "fname = 'Elec_2'\n",
    "log_file = fname + '.txt'\n",
    "\n",
    "with open(log_file, 'w') as f:\n",
    "    f.write('Model,Accuracy,F1\\n')\n",
    "\n",
    "\n",
    "df = pd.read_csv('datasets/ElecMorocco2016.csv', encoding='utf-8', engine='python', sep='\\t') #, quotechar=\"'\"  , quoting=3\n",
    "\n",
    "\n",
    "      \n",
    "display(df.columns)\n",
    "display(len(df))\n",
    "display(df[:4])\n",
    "\n",
    "\n",
    "\n",
    "classes = set(df['sentiment'].values)\n",
    "display(classes)\n",
    "\n",
    "c = df['sentiment'].value_counts()\n",
    "display(c)\n",
    "\n",
    "df['sentiment'] = df['sentiment'].astype('category')\n",
    "df['label'] = df['sentiment'].cat.codes\n",
    "\n",
    "df = df[['comment_message', 'label']]\n",
    "classes_num = len(classes)\n",
    "display(classes_num)\n",
    "display(len(df))\n",
    "\n",
    "\n",
    "# ds = Dataset.from_pandas(df)\n",
    "# ds = ds.train_test_split(test_size=0.2)\n",
    "\n",
    "# display(ds)\n",
    "\n",
    "max_sequence_length = 128\n",
    "\n",
    "\n",
    "models = [ \n",
    "        'faisalq/EgyBERT',            \n",
    "    'faisalq/SaudiBERT',            \n",
    "    'tunis-ai/TunBERT',\n",
    "    'alger-ia/dziribert',\n",
    "    'SI2M-Lab/DarijaBERT',\n",
    "    'otmangi/MorRoBERTa',\n",
    "    'otmangi/MorrBERT'\n",
    "            \n",
    "]\n",
    "\n",
    "seeds = [0, 1, 42]\n",
    "\n",
    "for model_name in models:\n",
    "    for seed in seeds:\n",
    "        ds = Dataset.from_pandas(df)\n",
    "        ds = ds.train_test_split(test_size=0.2, seed = seed)\n",
    "        if seed==0:\n",
    "            display(ds)\n",
    "    \n",
    "        for i in range(3):\n",
    "            print(f'{model_name}, try:{i}')\n",
    "                  \n",
    "            tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "            model = AutoModelForSequenceClassification.from_pretrained(model_name,\n",
    "                                                                  num_labels=classes_num).to('cuda')                                                 \n",
    "            dataset_train = ds['train']\n",
    "            dataset_validation = ds['test']                                                    \n",
    "            \n",
    "          \n",
    "    \n",
    "            def preprocess_function(examples):\n",
    "                return tokenizer(examples['comment_message'], truncation=True, padding=\"max_length\",\n",
    "                                max_length=max_sequence_length)\n",
    "            \n",
    "            \n",
    "            dataset_train = dataset_train.map(preprocess_function, batched=True) # , batched=True\n",
    "            dataset_validation = dataset_validation.map(preprocess_function, batched=True)  # , batched=True\n",
    "            \n",
    "           \n",
    "            \n",
    "            def compute_metrics(eval_pred):\n",
    "                logits, labels = eval_pred\n",
    "                predictions = np.argmax(logits, axis=-1)    \n",
    "                acc = accuracy_score(labels, predictions)        \n",
    "                f1 = f1_score(labels, predictions, average='macro')   \n",
    "                with open(log_file, 'a') as f:\n",
    "                    f.write(f'{model_name},{acc},{f1}\\n')\n",
    "                return {'accuracy': acc, 'f1_score': f1}\n",
    "    \n",
    "    \n",
    "            \n",
    "            \n",
    "            epochs = 15\n",
    "            save_steps = 10000 #save checkpoint every 10000 steps\n",
    "            batch_size = 64\n",
    "            \n",
    "            training_args = TrainingArguments(\n",
    "                output_dir = 'bert/',\n",
    "                overwrite_output_dir=True,\n",
    "                num_train_epochs = epochs,\n",
    "                per_device_train_batch_size = batch_size,\n",
    "                per_device_eval_batch_size = batch_size,\n",
    "                save_steps = save_steps,\n",
    "                save_total_limit = 1, #only save the last 5 checkpoints\n",
    "                fp16=True,\n",
    "                learning_rate = 5e-5,  # 5e-5 is the default\n",
    "                logging_steps = 60, #50_000\n",
    "                evaluation_strategy = 'steps',\n",
    "                # evaluate_during_training = True,\n",
    "                eval_steps = 60\n",
    "                \n",
    "            )\n",
    "            \n",
    "            trainer = Trainer(\n",
    "                model = model,\n",
    "                args = training_args,\n",
    "                # data_collator=data_collator,\n",
    "                train_dataset=dataset_train,\n",
    "                eval_dataset=dataset_validation,\n",
    "                compute_metrics = compute_metrics\n",
    "            )\n",
    "            \n",
    "            \n",
    "            trainer.train()\n",
    "\n",
    "\n",
    "results = pd.read_csv(log_file)\n",
    "\n",
    "best_results = results.groupby('Model', as_index=False)['F1'].max()\n",
    "\n",
    "best_results = pd.merge(best_results, results, on=['Model', 'F1'])\n",
    "best_results = best_results[['Model', 'Accuracy', 'F1']]\n",
    "best_results = best_results.drop_duplicates()\n",
    "best_results.to_csv(f'{fname}.csv')\n",
    "display(best_results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a213ac86-934f-4e82-a949-0bcdcae2188d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220784d6-b06d-4429-adb8-0026654f9d49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8647cf08-3aa6-44eb-846f-4bed97554042",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8794b705-31a1-45d7-8e88-4017a9c282aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
