{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d804ae66-9435-44be-8aad-beacbdeec0f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-17 22:17:45.014631: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-17 22:17:45.038444: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-17 22:17:45.427738: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['text', 'labels'], dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>خويا نصيحة مني. كمل فخدمتك ومتديهاش فكلام ناس داك لقاليك نقاشة ولانگافة. اتلقا ختو لكتصرف عليه.</td>\n",
       "      <td>News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ضربناكم كاملين ١😂🖕🇲🇦🇲🇦🇲🇦🇲🇦</td>\n",
       "      <td>Sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>بغيت نشارك فشي مسابقة حيت عندي 90 فتخفيض</td>\n",
       "      <td>Gaming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>چاتني 92ف10</td>\n",
       "      <td>Gaming</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                              text   \n",
       "0  خويا نصيحة مني. كمل فخدمتك ومتديهاش فكلام ناس داك لقاليك نقاشة ولانگافة. اتلقا ختو لكتصرف عليه.  \\\n",
       "1                                                                       ضربناكم كاملين ١😂🖕🇲🇦🇲🇦🇲🇦🇲🇦   \n",
       "2                                                         بغيت نشارك فشي مسابقة حيت عندي 90 فتخفيض   \n",
       "3                                                                                      چاتني 92ف10   \n",
       "\n",
       "   labels  \n",
       "0    News  \n",
       "1   Sport  \n",
       "2  Gaming  \n",
       "3  Gaming  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'Gaming', 'Kitchen', 'News', 'Sport'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "64222"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 51377\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 12845\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/EgyBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/EgyBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51377 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12845 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6424' max='6424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6424/6424 11:14, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.929000</td>\n",
       "      <td>0.616749</td>\n",
       "      <td>0.820864</td>\n",
       "      <td>0.823962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.492100</td>\n",
       "      <td>0.422066</td>\n",
       "      <td>0.860490</td>\n",
       "      <td>0.861489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.397200</td>\n",
       "      <td>0.348336</td>\n",
       "      <td>0.879019</td>\n",
       "      <td>0.880999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.343300</td>\n",
       "      <td>0.317970</td>\n",
       "      <td>0.885559</td>\n",
       "      <td>0.886289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.254900</td>\n",
       "      <td>0.325807</td>\n",
       "      <td>0.893422</td>\n",
       "      <td>0.893806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.243100</td>\n",
       "      <td>0.293945</td>\n",
       "      <td>0.893110</td>\n",
       "      <td>0.893277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.220800</td>\n",
       "      <td>0.301899</td>\n",
       "      <td>0.893655</td>\n",
       "      <td>0.893183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.220300</td>\n",
       "      <td>0.280600</td>\n",
       "      <td>0.900973</td>\n",
       "      <td>0.902185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.144900</td>\n",
       "      <td>0.312061</td>\n",
       "      <td>0.897081</td>\n",
       "      <td>0.897773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.161500</td>\n",
       "      <td>0.324024</td>\n",
       "      <td>0.901051</td>\n",
       "      <td>0.900966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.156000</td>\n",
       "      <td>0.317134</td>\n",
       "      <td>0.901596</td>\n",
       "      <td>0.902027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.147600</td>\n",
       "      <td>0.326917</td>\n",
       "      <td>0.900895</td>\n",
       "      <td>0.901267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.343430</td>\n",
       "      <td>0.900195</td>\n",
       "      <td>0.901390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.106300</td>\n",
       "      <td>0.344214</td>\n",
       "      <td>0.900740</td>\n",
       "      <td>0.902045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.102400</td>\n",
       "      <td>0.337046</td>\n",
       "      <td>0.903542</td>\n",
       "      <td>0.904636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.099700</td>\n",
       "      <td>0.341737</td>\n",
       "      <td>0.903854</td>\n",
       "      <td>0.904426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.065500</td>\n",
       "      <td>0.422526</td>\n",
       "      <td>0.900506</td>\n",
       "      <td>0.902104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.069300</td>\n",
       "      <td>0.395134</td>\n",
       "      <td>0.898715</td>\n",
       "      <td>0.899297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.079100</td>\n",
       "      <td>0.412676</td>\n",
       "      <td>0.904866</td>\n",
       "      <td>0.905723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.080300</td>\n",
       "      <td>0.394504</td>\n",
       "      <td>0.902997</td>\n",
       "      <td>0.903423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.049000</td>\n",
       "      <td>0.438452</td>\n",
       "      <td>0.904165</td>\n",
       "      <td>0.905120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.055900</td>\n",
       "      <td>0.424019</td>\n",
       "      <td>0.905177</td>\n",
       "      <td>0.906173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.054200</td>\n",
       "      <td>0.443733</td>\n",
       "      <td>0.902919</td>\n",
       "      <td>0.903610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.054900</td>\n",
       "      <td>0.439700</td>\n",
       "      <td>0.904243</td>\n",
       "      <td>0.905476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.044800</td>\n",
       "      <td>0.466219</td>\n",
       "      <td>0.905489</td>\n",
       "      <td>0.906025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.038200</td>\n",
       "      <td>0.479516</td>\n",
       "      <td>0.904009</td>\n",
       "      <td>0.904593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.042700</td>\n",
       "      <td>0.495976</td>\n",
       "      <td>0.903854</td>\n",
       "      <td>0.904601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.041700</td>\n",
       "      <td>0.486808</td>\n",
       "      <td>0.904476</td>\n",
       "      <td>0.905575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.037000</td>\n",
       "      <td>0.499065</td>\n",
       "      <td>0.903309</td>\n",
       "      <td>0.904237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.031800</td>\n",
       "      <td>0.498002</td>\n",
       "      <td>0.904165</td>\n",
       "      <td>0.904944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.033800</td>\n",
       "      <td>0.505656</td>\n",
       "      <td>0.903387</td>\n",
       "      <td>0.904211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.027800</td>\n",
       "      <td>0.505214</td>\n",
       "      <td>0.904243</td>\n",
       "      <td>0.904948</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/EgyBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/EgyBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51377 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12845 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6424' max='6424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6424/6424 11:15, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.950200</td>\n",
       "      <td>0.608003</td>\n",
       "      <td>0.828182</td>\n",
       "      <td>0.828298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.499200</td>\n",
       "      <td>0.396968</td>\n",
       "      <td>0.865629</td>\n",
       "      <td>0.866011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.391100</td>\n",
       "      <td>0.343391</td>\n",
       "      <td>0.879330</td>\n",
       "      <td>0.881157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.341900</td>\n",
       "      <td>0.313798</td>\n",
       "      <td>0.889062</td>\n",
       "      <td>0.890391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.251600</td>\n",
       "      <td>0.326478</td>\n",
       "      <td>0.889763</td>\n",
       "      <td>0.890736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.239500</td>\n",
       "      <td>0.302679</td>\n",
       "      <td>0.894434</td>\n",
       "      <td>0.894402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.223600</td>\n",
       "      <td>0.306024</td>\n",
       "      <td>0.893110</td>\n",
       "      <td>0.892339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.225200</td>\n",
       "      <td>0.272342</td>\n",
       "      <td>0.902141</td>\n",
       "      <td>0.903595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.143000</td>\n",
       "      <td>0.313990</td>\n",
       "      <td>0.901907</td>\n",
       "      <td>0.902743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.165900</td>\n",
       "      <td>0.325984</td>\n",
       "      <td>0.896536</td>\n",
       "      <td>0.897074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.154700</td>\n",
       "      <td>0.301247</td>\n",
       "      <td>0.899961</td>\n",
       "      <td>0.900338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.155400</td>\n",
       "      <td>0.310657</td>\n",
       "      <td>0.901596</td>\n",
       "      <td>0.901930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.103000</td>\n",
       "      <td>0.358620</td>\n",
       "      <td>0.898248</td>\n",
       "      <td>0.897451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.106500</td>\n",
       "      <td>0.352906</td>\n",
       "      <td>0.901596</td>\n",
       "      <td>0.901425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.106100</td>\n",
       "      <td>0.338523</td>\n",
       "      <td>0.901129</td>\n",
       "      <td>0.901443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.097800</td>\n",
       "      <td>0.369383</td>\n",
       "      <td>0.903464</td>\n",
       "      <td>0.903795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.066600</td>\n",
       "      <td>0.432715</td>\n",
       "      <td>0.901596</td>\n",
       "      <td>0.902442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.066900</td>\n",
       "      <td>0.410476</td>\n",
       "      <td>0.901752</td>\n",
       "      <td>0.901909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.082900</td>\n",
       "      <td>0.403331</td>\n",
       "      <td>0.905800</td>\n",
       "      <td>0.906273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.080400</td>\n",
       "      <td>0.398601</td>\n",
       "      <td>0.904710</td>\n",
       "      <td>0.905179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.049200</td>\n",
       "      <td>0.454908</td>\n",
       "      <td>0.905021</td>\n",
       "      <td>0.905625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.058900</td>\n",
       "      <td>0.438609</td>\n",
       "      <td>0.904788</td>\n",
       "      <td>0.905390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.420850</td>\n",
       "      <td>0.905333</td>\n",
       "      <td>0.905821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.053700</td>\n",
       "      <td>0.454221</td>\n",
       "      <td>0.904165</td>\n",
       "      <td>0.904667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.045200</td>\n",
       "      <td>0.456304</td>\n",
       "      <td>0.905411</td>\n",
       "      <td>0.906060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.039800</td>\n",
       "      <td>0.480757</td>\n",
       "      <td>0.902530</td>\n",
       "      <td>0.902990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.044700</td>\n",
       "      <td>0.481822</td>\n",
       "      <td>0.902919</td>\n",
       "      <td>0.903282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.041300</td>\n",
       "      <td>0.482065</td>\n",
       "      <td>0.905644</td>\n",
       "      <td>0.906086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.033000</td>\n",
       "      <td>0.489731</td>\n",
       "      <td>0.904632</td>\n",
       "      <td>0.904868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.032200</td>\n",
       "      <td>0.498216</td>\n",
       "      <td>0.906890</td>\n",
       "      <td>0.907006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.032900</td>\n",
       "      <td>0.505352</td>\n",
       "      <td>0.906189</td>\n",
       "      <td>0.906670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.030800</td>\n",
       "      <td>0.504769</td>\n",
       "      <td>0.906501</td>\n",
       "      <td>0.906803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/EgyBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/EgyBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51377 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12845 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6424' max='6424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6424/6424 11:17, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.950200</td>\n",
       "      <td>0.608003</td>\n",
       "      <td>0.828182</td>\n",
       "      <td>0.828298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.499200</td>\n",
       "      <td>0.396968</td>\n",
       "      <td>0.865629</td>\n",
       "      <td>0.866011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.391100</td>\n",
       "      <td>0.343391</td>\n",
       "      <td>0.879330</td>\n",
       "      <td>0.881157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.341900</td>\n",
       "      <td>0.313798</td>\n",
       "      <td>0.889062</td>\n",
       "      <td>0.890391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.251600</td>\n",
       "      <td>0.326478</td>\n",
       "      <td>0.889763</td>\n",
       "      <td>0.890736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.239500</td>\n",
       "      <td>0.302679</td>\n",
       "      <td>0.894434</td>\n",
       "      <td>0.894402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.223600</td>\n",
       "      <td>0.306024</td>\n",
       "      <td>0.893110</td>\n",
       "      <td>0.892339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.225200</td>\n",
       "      <td>0.272342</td>\n",
       "      <td>0.902141</td>\n",
       "      <td>0.903595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.143000</td>\n",
       "      <td>0.313990</td>\n",
       "      <td>0.901907</td>\n",
       "      <td>0.902743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.165900</td>\n",
       "      <td>0.325984</td>\n",
       "      <td>0.896536</td>\n",
       "      <td>0.897074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.154700</td>\n",
       "      <td>0.301247</td>\n",
       "      <td>0.899961</td>\n",
       "      <td>0.900338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.155400</td>\n",
       "      <td>0.310657</td>\n",
       "      <td>0.901596</td>\n",
       "      <td>0.901930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.103000</td>\n",
       "      <td>0.358620</td>\n",
       "      <td>0.898248</td>\n",
       "      <td>0.897451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.106500</td>\n",
       "      <td>0.352906</td>\n",
       "      <td>0.901596</td>\n",
       "      <td>0.901425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.106100</td>\n",
       "      <td>0.338523</td>\n",
       "      <td>0.901129</td>\n",
       "      <td>0.901443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.097800</td>\n",
       "      <td>0.369383</td>\n",
       "      <td>0.903464</td>\n",
       "      <td>0.903795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.066600</td>\n",
       "      <td>0.432715</td>\n",
       "      <td>0.901596</td>\n",
       "      <td>0.902442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.066900</td>\n",
       "      <td>0.410476</td>\n",
       "      <td>0.901752</td>\n",
       "      <td>0.901909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.082900</td>\n",
       "      <td>0.403331</td>\n",
       "      <td>0.905800</td>\n",
       "      <td>0.906273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.080400</td>\n",
       "      <td>0.398601</td>\n",
       "      <td>0.904710</td>\n",
       "      <td>0.905179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.049200</td>\n",
       "      <td>0.454908</td>\n",
       "      <td>0.905021</td>\n",
       "      <td>0.905625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.058900</td>\n",
       "      <td>0.438609</td>\n",
       "      <td>0.904788</td>\n",
       "      <td>0.905390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.420850</td>\n",
       "      <td>0.905333</td>\n",
       "      <td>0.905821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.053700</td>\n",
       "      <td>0.454221</td>\n",
       "      <td>0.904165</td>\n",
       "      <td>0.904667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.045200</td>\n",
       "      <td>0.456304</td>\n",
       "      <td>0.905411</td>\n",
       "      <td>0.906060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.039800</td>\n",
       "      <td>0.480757</td>\n",
       "      <td>0.902530</td>\n",
       "      <td>0.902990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.044700</td>\n",
       "      <td>0.481822</td>\n",
       "      <td>0.902919</td>\n",
       "      <td>0.903282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.041300</td>\n",
       "      <td>0.482065</td>\n",
       "      <td>0.905644</td>\n",
       "      <td>0.906086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.033000</td>\n",
       "      <td>0.489731</td>\n",
       "      <td>0.904632</td>\n",
       "      <td>0.904868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.032200</td>\n",
       "      <td>0.498216</td>\n",
       "      <td>0.906890</td>\n",
       "      <td>0.907006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.032900</td>\n",
       "      <td>0.505352</td>\n",
       "      <td>0.906189</td>\n",
       "      <td>0.906670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.030800</td>\n",
       "      <td>0.504769</td>\n",
       "      <td>0.906501</td>\n",
       "      <td>0.906803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/EgyBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/EgyBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51377 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12845 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6424' max='6424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6424/6424 11:16, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.966600</td>\n",
       "      <td>0.596272</td>\n",
       "      <td>0.833865</td>\n",
       "      <td>0.833613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.498700</td>\n",
       "      <td>0.398045</td>\n",
       "      <td>0.865395</td>\n",
       "      <td>0.866096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.387300</td>\n",
       "      <td>0.331822</td>\n",
       "      <td>0.882834</td>\n",
       "      <td>0.883987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.332200</td>\n",
       "      <td>0.315231</td>\n",
       "      <td>0.889529</td>\n",
       "      <td>0.890321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.252700</td>\n",
       "      <td>0.300685</td>\n",
       "      <td>0.895212</td>\n",
       "      <td>0.896349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.240200</td>\n",
       "      <td>0.320386</td>\n",
       "      <td>0.894511</td>\n",
       "      <td>0.895400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.242100</td>\n",
       "      <td>0.290442</td>\n",
       "      <td>0.901207</td>\n",
       "      <td>0.902103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.228700</td>\n",
       "      <td>0.292863</td>\n",
       "      <td>0.901440</td>\n",
       "      <td>0.902210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.168100</td>\n",
       "      <td>0.329820</td>\n",
       "      <td>0.901985</td>\n",
       "      <td>0.903579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.162800</td>\n",
       "      <td>0.307805</td>\n",
       "      <td>0.902141</td>\n",
       "      <td>0.903501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.162800</td>\n",
       "      <td>0.290743</td>\n",
       "      <td>0.907046</td>\n",
       "      <td>0.907574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.170500</td>\n",
       "      <td>0.275024</td>\n",
       "      <td>0.907746</td>\n",
       "      <td>0.908246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.115100</td>\n",
       "      <td>0.308524</td>\n",
       "      <td>0.905956</td>\n",
       "      <td>0.906478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.109000</td>\n",
       "      <td>0.329969</td>\n",
       "      <td>0.905489</td>\n",
       "      <td>0.905111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.115200</td>\n",
       "      <td>0.335729</td>\n",
       "      <td>0.903231</td>\n",
       "      <td>0.903735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.116000</td>\n",
       "      <td>0.316521</td>\n",
       "      <td>0.906656</td>\n",
       "      <td>0.906226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.076100</td>\n",
       "      <td>0.380773</td>\n",
       "      <td>0.905411</td>\n",
       "      <td>0.905794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.075300</td>\n",
       "      <td>0.378254</td>\n",
       "      <td>0.906267</td>\n",
       "      <td>0.907369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.080100</td>\n",
       "      <td>0.355563</td>\n",
       "      <td>0.904944</td>\n",
       "      <td>0.904764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.082600</td>\n",
       "      <td>0.380052</td>\n",
       "      <td>0.907357</td>\n",
       "      <td>0.907432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.060500</td>\n",
       "      <td>0.401698</td>\n",
       "      <td>0.906033</td>\n",
       "      <td>0.907200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.060800</td>\n",
       "      <td>0.423910</td>\n",
       "      <td>0.904165</td>\n",
       "      <td>0.904044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.059300</td>\n",
       "      <td>0.422828</td>\n",
       "      <td>0.905644</td>\n",
       "      <td>0.905579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.057800</td>\n",
       "      <td>0.416063</td>\n",
       "      <td>0.907591</td>\n",
       "      <td>0.907993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.042400</td>\n",
       "      <td>0.444857</td>\n",
       "      <td>0.907513</td>\n",
       "      <td>0.907835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.052200</td>\n",
       "      <td>0.430330</td>\n",
       "      <td>0.909381</td>\n",
       "      <td>0.909761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.035700</td>\n",
       "      <td>0.484702</td>\n",
       "      <td>0.907046</td>\n",
       "      <td>0.907655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.047300</td>\n",
       "      <td>0.447405</td>\n",
       "      <td>0.907513</td>\n",
       "      <td>0.907702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.037200</td>\n",
       "      <td>0.466311</td>\n",
       "      <td>0.907902</td>\n",
       "      <td>0.908365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.038200</td>\n",
       "      <td>0.473456</td>\n",
       "      <td>0.908135</td>\n",
       "      <td>0.908646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.034200</td>\n",
       "      <td>0.476906</td>\n",
       "      <td>0.908914</td>\n",
       "      <td>0.909322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.033900</td>\n",
       "      <td>0.480015</td>\n",
       "      <td>0.908525</td>\n",
       "      <td>0.909040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/EgyBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/EgyBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51377 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12845 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6424' max='6424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6424/6424 11:14, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.966600</td>\n",
       "      <td>0.596272</td>\n",
       "      <td>0.833865</td>\n",
       "      <td>0.833613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.498700</td>\n",
       "      <td>0.398045</td>\n",
       "      <td>0.865395</td>\n",
       "      <td>0.866096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.387300</td>\n",
       "      <td>0.331822</td>\n",
       "      <td>0.882834</td>\n",
       "      <td>0.883987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.332200</td>\n",
       "      <td>0.315231</td>\n",
       "      <td>0.889529</td>\n",
       "      <td>0.890321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.252700</td>\n",
       "      <td>0.300685</td>\n",
       "      <td>0.895212</td>\n",
       "      <td>0.896349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.240200</td>\n",
       "      <td>0.320386</td>\n",
       "      <td>0.894511</td>\n",
       "      <td>0.895400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.242100</td>\n",
       "      <td>0.290442</td>\n",
       "      <td>0.901207</td>\n",
       "      <td>0.902103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.228700</td>\n",
       "      <td>0.292863</td>\n",
       "      <td>0.901440</td>\n",
       "      <td>0.902210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.168100</td>\n",
       "      <td>0.329820</td>\n",
       "      <td>0.901985</td>\n",
       "      <td>0.903579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.162800</td>\n",
       "      <td>0.307805</td>\n",
       "      <td>0.902141</td>\n",
       "      <td>0.903501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.162800</td>\n",
       "      <td>0.290743</td>\n",
       "      <td>0.907046</td>\n",
       "      <td>0.907574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.170500</td>\n",
       "      <td>0.275024</td>\n",
       "      <td>0.907746</td>\n",
       "      <td>0.908246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.115100</td>\n",
       "      <td>0.308524</td>\n",
       "      <td>0.905956</td>\n",
       "      <td>0.906478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.109000</td>\n",
       "      <td>0.329969</td>\n",
       "      <td>0.905489</td>\n",
       "      <td>0.905111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.115200</td>\n",
       "      <td>0.335729</td>\n",
       "      <td>0.903231</td>\n",
       "      <td>0.903735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.116000</td>\n",
       "      <td>0.316521</td>\n",
       "      <td>0.906656</td>\n",
       "      <td>0.906226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.076100</td>\n",
       "      <td>0.380773</td>\n",
       "      <td>0.905411</td>\n",
       "      <td>0.905794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.075300</td>\n",
       "      <td>0.378254</td>\n",
       "      <td>0.906267</td>\n",
       "      <td>0.907369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.080100</td>\n",
       "      <td>0.355563</td>\n",
       "      <td>0.904944</td>\n",
       "      <td>0.904764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.082600</td>\n",
       "      <td>0.380052</td>\n",
       "      <td>0.907357</td>\n",
       "      <td>0.907432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.060500</td>\n",
       "      <td>0.401698</td>\n",
       "      <td>0.906033</td>\n",
       "      <td>0.907200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.060800</td>\n",
       "      <td>0.423910</td>\n",
       "      <td>0.904165</td>\n",
       "      <td>0.904044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.059300</td>\n",
       "      <td>0.422828</td>\n",
       "      <td>0.905644</td>\n",
       "      <td>0.905579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.057800</td>\n",
       "      <td>0.416063</td>\n",
       "      <td>0.907591</td>\n",
       "      <td>0.907993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.042400</td>\n",
       "      <td>0.444857</td>\n",
       "      <td>0.907513</td>\n",
       "      <td>0.907835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.052200</td>\n",
       "      <td>0.430330</td>\n",
       "      <td>0.909381</td>\n",
       "      <td>0.909761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.035700</td>\n",
       "      <td>0.484702</td>\n",
       "      <td>0.907046</td>\n",
       "      <td>0.907655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.047300</td>\n",
       "      <td>0.447405</td>\n",
       "      <td>0.907513</td>\n",
       "      <td>0.907702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.037200</td>\n",
       "      <td>0.466311</td>\n",
       "      <td>0.907902</td>\n",
       "      <td>0.908365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.038200</td>\n",
       "      <td>0.473456</td>\n",
       "      <td>0.908135</td>\n",
       "      <td>0.908646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.034200</td>\n",
       "      <td>0.476906</td>\n",
       "      <td>0.908914</td>\n",
       "      <td>0.909322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.033900</td>\n",
       "      <td>0.480015</td>\n",
       "      <td>0.908525</td>\n",
       "      <td>0.909040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/EgyBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/EgyBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51377 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12845 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6424' max='6424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6424/6424 11:17, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.966600</td>\n",
       "      <td>0.596272</td>\n",
       "      <td>0.833865</td>\n",
       "      <td>0.833613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.498700</td>\n",
       "      <td>0.398045</td>\n",
       "      <td>0.865395</td>\n",
       "      <td>0.866096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.387300</td>\n",
       "      <td>0.331822</td>\n",
       "      <td>0.882834</td>\n",
       "      <td>0.883987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.332200</td>\n",
       "      <td>0.315231</td>\n",
       "      <td>0.889529</td>\n",
       "      <td>0.890321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.252700</td>\n",
       "      <td>0.300685</td>\n",
       "      <td>0.895212</td>\n",
       "      <td>0.896349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.240200</td>\n",
       "      <td>0.320386</td>\n",
       "      <td>0.894511</td>\n",
       "      <td>0.895400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.242100</td>\n",
       "      <td>0.290442</td>\n",
       "      <td>0.901207</td>\n",
       "      <td>0.902103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.228700</td>\n",
       "      <td>0.292863</td>\n",
       "      <td>0.901440</td>\n",
       "      <td>0.902210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.168100</td>\n",
       "      <td>0.329820</td>\n",
       "      <td>0.901985</td>\n",
       "      <td>0.903579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.162800</td>\n",
       "      <td>0.307805</td>\n",
       "      <td>0.902141</td>\n",
       "      <td>0.903501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.162800</td>\n",
       "      <td>0.290743</td>\n",
       "      <td>0.907046</td>\n",
       "      <td>0.907574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.170500</td>\n",
       "      <td>0.275024</td>\n",
       "      <td>0.907746</td>\n",
       "      <td>0.908246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.115100</td>\n",
       "      <td>0.308524</td>\n",
       "      <td>0.905956</td>\n",
       "      <td>0.906478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.109000</td>\n",
       "      <td>0.329969</td>\n",
       "      <td>0.905489</td>\n",
       "      <td>0.905111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.115200</td>\n",
       "      <td>0.335729</td>\n",
       "      <td>0.903231</td>\n",
       "      <td>0.903735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.116000</td>\n",
       "      <td>0.316521</td>\n",
       "      <td>0.906656</td>\n",
       "      <td>0.906226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.076100</td>\n",
       "      <td>0.380773</td>\n",
       "      <td>0.905411</td>\n",
       "      <td>0.905794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.075300</td>\n",
       "      <td>0.378254</td>\n",
       "      <td>0.906267</td>\n",
       "      <td>0.907369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.080100</td>\n",
       "      <td>0.355563</td>\n",
       "      <td>0.904944</td>\n",
       "      <td>0.904764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.082600</td>\n",
       "      <td>0.380052</td>\n",
       "      <td>0.907357</td>\n",
       "      <td>0.907432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.060500</td>\n",
       "      <td>0.401698</td>\n",
       "      <td>0.906033</td>\n",
       "      <td>0.907200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.060800</td>\n",
       "      <td>0.423910</td>\n",
       "      <td>0.904165</td>\n",
       "      <td>0.904044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.059300</td>\n",
       "      <td>0.422828</td>\n",
       "      <td>0.905644</td>\n",
       "      <td>0.905579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.057800</td>\n",
       "      <td>0.416063</td>\n",
       "      <td>0.907591</td>\n",
       "      <td>0.907993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.042400</td>\n",
       "      <td>0.444857</td>\n",
       "      <td>0.907513</td>\n",
       "      <td>0.907835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.052200</td>\n",
       "      <td>0.430330</td>\n",
       "      <td>0.909381</td>\n",
       "      <td>0.909761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.035700</td>\n",
       "      <td>0.484702</td>\n",
       "      <td>0.907046</td>\n",
       "      <td>0.907655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.047300</td>\n",
       "      <td>0.447405</td>\n",
       "      <td>0.907513</td>\n",
       "      <td>0.907702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.037200</td>\n",
       "      <td>0.466311</td>\n",
       "      <td>0.907902</td>\n",
       "      <td>0.908365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.038200</td>\n",
       "      <td>0.473456</td>\n",
       "      <td>0.908135</td>\n",
       "      <td>0.908646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.034200</td>\n",
       "      <td>0.476906</td>\n",
       "      <td>0.908914</td>\n",
       "      <td>0.909322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.033900</td>\n",
       "      <td>0.480015</td>\n",
       "      <td>0.908525</td>\n",
       "      <td>0.909040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/EgyBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/EgyBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51377 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12845 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6424' max='6424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6424/6424 11:18, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.959800</td>\n",
       "      <td>0.594267</td>\n",
       "      <td>0.829350</td>\n",
       "      <td>0.829382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.503200</td>\n",
       "      <td>0.398995</td>\n",
       "      <td>0.865784</td>\n",
       "      <td>0.866786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.377000</td>\n",
       "      <td>0.341274</td>\n",
       "      <td>0.880732</td>\n",
       "      <td>0.881339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.337800</td>\n",
       "      <td>0.315869</td>\n",
       "      <td>0.890074</td>\n",
       "      <td>0.890821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.256400</td>\n",
       "      <td>0.306776</td>\n",
       "      <td>0.894979</td>\n",
       "      <td>0.895997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.236800</td>\n",
       "      <td>0.311265</td>\n",
       "      <td>0.895757</td>\n",
       "      <td>0.896914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.232600</td>\n",
       "      <td>0.307786</td>\n",
       "      <td>0.899105</td>\n",
       "      <td>0.899411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.226400</td>\n",
       "      <td>0.292487</td>\n",
       "      <td>0.902686</td>\n",
       "      <td>0.903284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.159800</td>\n",
       "      <td>0.323603</td>\n",
       "      <td>0.900350</td>\n",
       "      <td>0.900517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.153000</td>\n",
       "      <td>0.344875</td>\n",
       "      <td>0.899961</td>\n",
       "      <td>0.900224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.167600</td>\n",
       "      <td>0.306135</td>\n",
       "      <td>0.901985</td>\n",
       "      <td>0.903334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.154200</td>\n",
       "      <td>0.311431</td>\n",
       "      <td>0.906189</td>\n",
       "      <td>0.907213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.103500</td>\n",
       "      <td>0.379410</td>\n",
       "      <td>0.901051</td>\n",
       "      <td>0.902757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.102600</td>\n",
       "      <td>0.375250</td>\n",
       "      <td>0.902919</td>\n",
       "      <td>0.902991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.371006</td>\n",
       "      <td>0.906345</td>\n",
       "      <td>0.907203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.110300</td>\n",
       "      <td>0.350609</td>\n",
       "      <td>0.906812</td>\n",
       "      <td>0.907074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.075700</td>\n",
       "      <td>0.384578</td>\n",
       "      <td>0.906189</td>\n",
       "      <td>0.906596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.078300</td>\n",
       "      <td>0.377974</td>\n",
       "      <td>0.908135</td>\n",
       "      <td>0.908977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.079000</td>\n",
       "      <td>0.389252</td>\n",
       "      <td>0.907902</td>\n",
       "      <td>0.909496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.076800</td>\n",
       "      <td>0.375093</td>\n",
       "      <td>0.906968</td>\n",
       "      <td>0.908425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.416759</td>\n",
       "      <td>0.906423</td>\n",
       "      <td>0.907100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.056300</td>\n",
       "      <td>0.436327</td>\n",
       "      <td>0.909381</td>\n",
       "      <td>0.910202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.052600</td>\n",
       "      <td>0.450685</td>\n",
       "      <td>0.907046</td>\n",
       "      <td>0.907926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.055000</td>\n",
       "      <td>0.443288</td>\n",
       "      <td>0.908291</td>\n",
       "      <td>0.909358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.050700</td>\n",
       "      <td>0.470892</td>\n",
       "      <td>0.906578</td>\n",
       "      <td>0.907568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.034000</td>\n",
       "      <td>0.485695</td>\n",
       "      <td>0.907201</td>\n",
       "      <td>0.907990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.045100</td>\n",
       "      <td>0.484463</td>\n",
       "      <td>0.906734</td>\n",
       "      <td>0.907429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.042400</td>\n",
       "      <td>0.487070</td>\n",
       "      <td>0.907046</td>\n",
       "      <td>0.907825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.034200</td>\n",
       "      <td>0.497317</td>\n",
       "      <td>0.906423</td>\n",
       "      <td>0.907570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.034000</td>\n",
       "      <td>0.499519</td>\n",
       "      <td>0.907123</td>\n",
       "      <td>0.907922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.032400</td>\n",
       "      <td>0.498423</td>\n",
       "      <td>0.907668</td>\n",
       "      <td>0.908460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.033200</td>\n",
       "      <td>0.496863</td>\n",
       "      <td>0.908291</td>\n",
       "      <td>0.908967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/EgyBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/EgyBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51377 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12845 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6424' max='6424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6424/6424 11:17, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.959800</td>\n",
       "      <td>0.594267</td>\n",
       "      <td>0.829350</td>\n",
       "      <td>0.829382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.503200</td>\n",
       "      <td>0.398995</td>\n",
       "      <td>0.865784</td>\n",
       "      <td>0.866786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.377000</td>\n",
       "      <td>0.341274</td>\n",
       "      <td>0.880732</td>\n",
       "      <td>0.881339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.337800</td>\n",
       "      <td>0.315869</td>\n",
       "      <td>0.890074</td>\n",
       "      <td>0.890821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.256400</td>\n",
       "      <td>0.306776</td>\n",
       "      <td>0.894979</td>\n",
       "      <td>0.895997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.236800</td>\n",
       "      <td>0.311265</td>\n",
       "      <td>0.895757</td>\n",
       "      <td>0.896914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.232600</td>\n",
       "      <td>0.307786</td>\n",
       "      <td>0.899105</td>\n",
       "      <td>0.899411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.226400</td>\n",
       "      <td>0.292487</td>\n",
       "      <td>0.902686</td>\n",
       "      <td>0.903284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.159800</td>\n",
       "      <td>0.323603</td>\n",
       "      <td>0.900350</td>\n",
       "      <td>0.900517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.153000</td>\n",
       "      <td>0.344875</td>\n",
       "      <td>0.899961</td>\n",
       "      <td>0.900224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.167600</td>\n",
       "      <td>0.306135</td>\n",
       "      <td>0.901985</td>\n",
       "      <td>0.903334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.154200</td>\n",
       "      <td>0.311431</td>\n",
       "      <td>0.906189</td>\n",
       "      <td>0.907213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.103500</td>\n",
       "      <td>0.379410</td>\n",
       "      <td>0.901051</td>\n",
       "      <td>0.902757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.102600</td>\n",
       "      <td>0.375250</td>\n",
       "      <td>0.902919</td>\n",
       "      <td>0.902991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.371006</td>\n",
       "      <td>0.906345</td>\n",
       "      <td>0.907203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.110300</td>\n",
       "      <td>0.350609</td>\n",
       "      <td>0.906812</td>\n",
       "      <td>0.907074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.075700</td>\n",
       "      <td>0.384578</td>\n",
       "      <td>0.906189</td>\n",
       "      <td>0.906596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.078300</td>\n",
       "      <td>0.377974</td>\n",
       "      <td>0.908135</td>\n",
       "      <td>0.908977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.079000</td>\n",
       "      <td>0.389252</td>\n",
       "      <td>0.907902</td>\n",
       "      <td>0.909496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.076800</td>\n",
       "      <td>0.375093</td>\n",
       "      <td>0.906968</td>\n",
       "      <td>0.908425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.416759</td>\n",
       "      <td>0.906423</td>\n",
       "      <td>0.907100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.056300</td>\n",
       "      <td>0.436327</td>\n",
       "      <td>0.909381</td>\n",
       "      <td>0.910202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.052600</td>\n",
       "      <td>0.450685</td>\n",
       "      <td>0.907046</td>\n",
       "      <td>0.907926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.055000</td>\n",
       "      <td>0.443288</td>\n",
       "      <td>0.908291</td>\n",
       "      <td>0.909358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.050700</td>\n",
       "      <td>0.470892</td>\n",
       "      <td>0.906578</td>\n",
       "      <td>0.907568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.034000</td>\n",
       "      <td>0.485695</td>\n",
       "      <td>0.907201</td>\n",
       "      <td>0.907990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.045100</td>\n",
       "      <td>0.484463</td>\n",
       "      <td>0.906734</td>\n",
       "      <td>0.907429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.042400</td>\n",
       "      <td>0.487070</td>\n",
       "      <td>0.907046</td>\n",
       "      <td>0.907825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.034200</td>\n",
       "      <td>0.497317</td>\n",
       "      <td>0.906423</td>\n",
       "      <td>0.907570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.034000</td>\n",
       "      <td>0.499519</td>\n",
       "      <td>0.907123</td>\n",
       "      <td>0.907922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.032400</td>\n",
       "      <td>0.498423</td>\n",
       "      <td>0.907668</td>\n",
       "      <td>0.908460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.033200</td>\n",
       "      <td>0.496863</td>\n",
       "      <td>0.908291</td>\n",
       "      <td>0.908967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/EgyBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/EgyBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51377 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75b9400f2e954bda81858da8697fb659",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12845 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6424' max='6424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6424/6424 11:18, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.959800</td>\n",
       "      <td>0.594267</td>\n",
       "      <td>0.829350</td>\n",
       "      <td>0.829382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.503200</td>\n",
       "      <td>0.398995</td>\n",
       "      <td>0.865784</td>\n",
       "      <td>0.866786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.377000</td>\n",
       "      <td>0.341274</td>\n",
       "      <td>0.880732</td>\n",
       "      <td>0.881339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.337800</td>\n",
       "      <td>0.315869</td>\n",
       "      <td>0.890074</td>\n",
       "      <td>0.890821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.256400</td>\n",
       "      <td>0.306776</td>\n",
       "      <td>0.894979</td>\n",
       "      <td>0.895997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.236800</td>\n",
       "      <td>0.311265</td>\n",
       "      <td>0.895757</td>\n",
       "      <td>0.896914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.232600</td>\n",
       "      <td>0.307786</td>\n",
       "      <td>0.899105</td>\n",
       "      <td>0.899411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.226400</td>\n",
       "      <td>0.292487</td>\n",
       "      <td>0.902686</td>\n",
       "      <td>0.903284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.159800</td>\n",
       "      <td>0.323603</td>\n",
       "      <td>0.900350</td>\n",
       "      <td>0.900517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.153000</td>\n",
       "      <td>0.344875</td>\n",
       "      <td>0.899961</td>\n",
       "      <td>0.900224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.167600</td>\n",
       "      <td>0.306135</td>\n",
       "      <td>0.901985</td>\n",
       "      <td>0.903334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.154200</td>\n",
       "      <td>0.311431</td>\n",
       "      <td>0.906189</td>\n",
       "      <td>0.907213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.103500</td>\n",
       "      <td>0.379410</td>\n",
       "      <td>0.901051</td>\n",
       "      <td>0.902757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.102600</td>\n",
       "      <td>0.375250</td>\n",
       "      <td>0.902919</td>\n",
       "      <td>0.902991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.371006</td>\n",
       "      <td>0.906345</td>\n",
       "      <td>0.907203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.110300</td>\n",
       "      <td>0.350609</td>\n",
       "      <td>0.906812</td>\n",
       "      <td>0.907074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.075700</td>\n",
       "      <td>0.384578</td>\n",
       "      <td>0.906189</td>\n",
       "      <td>0.906596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.078300</td>\n",
       "      <td>0.377974</td>\n",
       "      <td>0.908135</td>\n",
       "      <td>0.908977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.079000</td>\n",
       "      <td>0.389252</td>\n",
       "      <td>0.907902</td>\n",
       "      <td>0.909496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.076800</td>\n",
       "      <td>0.375093</td>\n",
       "      <td>0.906968</td>\n",
       "      <td>0.908425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.416759</td>\n",
       "      <td>0.906423</td>\n",
       "      <td>0.907100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.056300</td>\n",
       "      <td>0.436327</td>\n",
       "      <td>0.909381</td>\n",
       "      <td>0.910202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.052600</td>\n",
       "      <td>0.450685</td>\n",
       "      <td>0.907046</td>\n",
       "      <td>0.907926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.055000</td>\n",
       "      <td>0.443288</td>\n",
       "      <td>0.908291</td>\n",
       "      <td>0.909358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.050700</td>\n",
       "      <td>0.470892</td>\n",
       "      <td>0.906578</td>\n",
       "      <td>0.907568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.034000</td>\n",
       "      <td>0.485695</td>\n",
       "      <td>0.907201</td>\n",
       "      <td>0.907990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.045100</td>\n",
       "      <td>0.484463</td>\n",
       "      <td>0.906734</td>\n",
       "      <td>0.907429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.042400</td>\n",
       "      <td>0.487070</td>\n",
       "      <td>0.907046</td>\n",
       "      <td>0.907825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.034200</td>\n",
       "      <td>0.497317</td>\n",
       "      <td>0.906423</td>\n",
       "      <td>0.907570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.034000</td>\n",
       "      <td>0.499519</td>\n",
       "      <td>0.907123</td>\n",
       "      <td>0.907922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.032400</td>\n",
       "      <td>0.498423</td>\n",
       "      <td>0.907668</td>\n",
       "      <td>0.908460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.033200</td>\n",
       "      <td>0.496863</td>\n",
       "      <td>0.908291</td>\n",
       "      <td>0.908967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 51377\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 12845\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bc8b8d6f8da4e81948a96c216cce03d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51377 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f84cf590fbe84c5d93e068038fd6d6d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12845 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6424' max='6424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6424/6424 11:16, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.501600</td>\n",
       "      <td>0.374039</td>\n",
       "      <td>0.867264</td>\n",
       "      <td>0.869755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.356100</td>\n",
       "      <td>0.322921</td>\n",
       "      <td>0.875905</td>\n",
       "      <td>0.875765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.316400</td>\n",
       "      <td>0.325393</td>\n",
       "      <td>0.884469</td>\n",
       "      <td>0.886109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.294300</td>\n",
       "      <td>0.291912</td>\n",
       "      <td>0.897548</td>\n",
       "      <td>0.899636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.184000</td>\n",
       "      <td>0.304302</td>\n",
       "      <td>0.905411</td>\n",
       "      <td>0.906498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.182000</td>\n",
       "      <td>0.296637</td>\n",
       "      <td>0.900662</td>\n",
       "      <td>0.900473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.157400</td>\n",
       "      <td>0.302153</td>\n",
       "      <td>0.903464</td>\n",
       "      <td>0.903855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.160900</td>\n",
       "      <td>0.303395</td>\n",
       "      <td>0.904243</td>\n",
       "      <td>0.904415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.089100</td>\n",
       "      <td>0.331693</td>\n",
       "      <td>0.909225</td>\n",
       "      <td>0.910190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.097100</td>\n",
       "      <td>0.345036</td>\n",
       "      <td>0.900350</td>\n",
       "      <td>0.899898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.096900</td>\n",
       "      <td>0.337072</td>\n",
       "      <td>0.904866</td>\n",
       "      <td>0.905489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.093500</td>\n",
       "      <td>0.343608</td>\n",
       "      <td>0.906501</td>\n",
       "      <td>0.907298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.054400</td>\n",
       "      <td>0.456015</td>\n",
       "      <td>0.905644</td>\n",
       "      <td>0.905926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.061700</td>\n",
       "      <td>0.437761</td>\n",
       "      <td>0.908758</td>\n",
       "      <td>0.908701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.061900</td>\n",
       "      <td>0.416047</td>\n",
       "      <td>0.906656</td>\n",
       "      <td>0.907563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.058400</td>\n",
       "      <td>0.423658</td>\n",
       "      <td>0.909381</td>\n",
       "      <td>0.909162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.034300</td>\n",
       "      <td>0.450883</td>\n",
       "      <td>0.907980</td>\n",
       "      <td>0.908712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.032600</td>\n",
       "      <td>0.487626</td>\n",
       "      <td>0.909070</td>\n",
       "      <td>0.909955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.037700</td>\n",
       "      <td>0.499252</td>\n",
       "      <td>0.910160</td>\n",
       "      <td>0.910747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.047600</td>\n",
       "      <td>0.463539</td>\n",
       "      <td>0.912962</td>\n",
       "      <td>0.913674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.022600</td>\n",
       "      <td>0.525635</td>\n",
       "      <td>0.909770</td>\n",
       "      <td>0.910531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.024300</td>\n",
       "      <td>0.523454</td>\n",
       "      <td>0.911639</td>\n",
       "      <td>0.911458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.030500</td>\n",
       "      <td>0.496300</td>\n",
       "      <td>0.912962</td>\n",
       "      <td>0.913536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.028600</td>\n",
       "      <td>0.503684</td>\n",
       "      <td>0.910315</td>\n",
       "      <td>0.910522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.019900</td>\n",
       "      <td>0.517842</td>\n",
       "      <td>0.910860</td>\n",
       "      <td>0.911236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.017200</td>\n",
       "      <td>0.545136</td>\n",
       "      <td>0.911250</td>\n",
       "      <td>0.911454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.020100</td>\n",
       "      <td>0.538743</td>\n",
       "      <td>0.911483</td>\n",
       "      <td>0.912276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.016600</td>\n",
       "      <td>0.548534</td>\n",
       "      <td>0.911639</td>\n",
       "      <td>0.912160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.015100</td>\n",
       "      <td>0.555358</td>\n",
       "      <td>0.912573</td>\n",
       "      <td>0.913121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.016600</td>\n",
       "      <td>0.568966</td>\n",
       "      <td>0.911717</td>\n",
       "      <td>0.912260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.013100</td>\n",
       "      <td>0.572751</td>\n",
       "      <td>0.911872</td>\n",
       "      <td>0.912353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>0.574794</td>\n",
       "      <td>0.911327</td>\n",
       "      <td>0.911974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9163c5f84e644a09a0acffe1c15ed286",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51377 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70e062dad9e348f5b1543c1f042ce805",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12845 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6424' max='6424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6424/6424 11:19, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.501600</td>\n",
       "      <td>0.374039</td>\n",
       "      <td>0.867264</td>\n",
       "      <td>0.869755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.356100</td>\n",
       "      <td>0.322921</td>\n",
       "      <td>0.875905</td>\n",
       "      <td>0.875765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.316400</td>\n",
       "      <td>0.325393</td>\n",
       "      <td>0.884469</td>\n",
       "      <td>0.886109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.294300</td>\n",
       "      <td>0.291912</td>\n",
       "      <td>0.897548</td>\n",
       "      <td>0.899636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.184000</td>\n",
       "      <td>0.304302</td>\n",
       "      <td>0.905411</td>\n",
       "      <td>0.906498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.182000</td>\n",
       "      <td>0.296637</td>\n",
       "      <td>0.900662</td>\n",
       "      <td>0.900473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.157400</td>\n",
       "      <td>0.302153</td>\n",
       "      <td>0.903464</td>\n",
       "      <td>0.903855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.160900</td>\n",
       "      <td>0.303395</td>\n",
       "      <td>0.904243</td>\n",
       "      <td>0.904415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.089100</td>\n",
       "      <td>0.331693</td>\n",
       "      <td>0.909225</td>\n",
       "      <td>0.910190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.097100</td>\n",
       "      <td>0.345036</td>\n",
       "      <td>0.900350</td>\n",
       "      <td>0.899898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.096900</td>\n",
       "      <td>0.337072</td>\n",
       "      <td>0.904866</td>\n",
       "      <td>0.905489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.093500</td>\n",
       "      <td>0.343608</td>\n",
       "      <td>0.906501</td>\n",
       "      <td>0.907298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.054400</td>\n",
       "      <td>0.456015</td>\n",
       "      <td>0.905644</td>\n",
       "      <td>0.905926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.061700</td>\n",
       "      <td>0.437761</td>\n",
       "      <td>0.908758</td>\n",
       "      <td>0.908701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.061900</td>\n",
       "      <td>0.416047</td>\n",
       "      <td>0.906656</td>\n",
       "      <td>0.907563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.058400</td>\n",
       "      <td>0.423658</td>\n",
       "      <td>0.909381</td>\n",
       "      <td>0.909162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.034300</td>\n",
       "      <td>0.450883</td>\n",
       "      <td>0.907980</td>\n",
       "      <td>0.908712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.032600</td>\n",
       "      <td>0.487626</td>\n",
       "      <td>0.909070</td>\n",
       "      <td>0.909955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.037700</td>\n",
       "      <td>0.499252</td>\n",
       "      <td>0.910160</td>\n",
       "      <td>0.910747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.047600</td>\n",
       "      <td>0.463539</td>\n",
       "      <td>0.912962</td>\n",
       "      <td>0.913674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.022600</td>\n",
       "      <td>0.525635</td>\n",
       "      <td>0.909770</td>\n",
       "      <td>0.910531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.024300</td>\n",
       "      <td>0.523454</td>\n",
       "      <td>0.911639</td>\n",
       "      <td>0.911458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.030500</td>\n",
       "      <td>0.496300</td>\n",
       "      <td>0.912962</td>\n",
       "      <td>0.913536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.028600</td>\n",
       "      <td>0.503684</td>\n",
       "      <td>0.910315</td>\n",
       "      <td>0.910522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.019900</td>\n",
       "      <td>0.517842</td>\n",
       "      <td>0.910860</td>\n",
       "      <td>0.911236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.017200</td>\n",
       "      <td>0.545136</td>\n",
       "      <td>0.911250</td>\n",
       "      <td>0.911454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.020100</td>\n",
       "      <td>0.538743</td>\n",
       "      <td>0.911483</td>\n",
       "      <td>0.912276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.016600</td>\n",
       "      <td>0.548534</td>\n",
       "      <td>0.911639</td>\n",
       "      <td>0.912160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.015100</td>\n",
       "      <td>0.555358</td>\n",
       "      <td>0.912573</td>\n",
       "      <td>0.913121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.016600</td>\n",
       "      <td>0.568966</td>\n",
       "      <td>0.911717</td>\n",
       "      <td>0.912260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.013100</td>\n",
       "      <td>0.572751</td>\n",
       "      <td>0.911872</td>\n",
       "      <td>0.912353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>0.574794</td>\n",
       "      <td>0.911327</td>\n",
       "      <td>0.911974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c3d209dd28c4c8ba71dd4b76463e32e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51377 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfb8152c58564037bd5e3c15167e0729",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12845 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6424' max='6424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6424/6424 11:17, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.501600</td>\n",
       "      <td>0.374039</td>\n",
       "      <td>0.867264</td>\n",
       "      <td>0.869755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.356100</td>\n",
       "      <td>0.322921</td>\n",
       "      <td>0.875905</td>\n",
       "      <td>0.875765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.316400</td>\n",
       "      <td>0.325393</td>\n",
       "      <td>0.884469</td>\n",
       "      <td>0.886109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.294300</td>\n",
       "      <td>0.291912</td>\n",
       "      <td>0.897548</td>\n",
       "      <td>0.899636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.184000</td>\n",
       "      <td>0.304302</td>\n",
       "      <td>0.905411</td>\n",
       "      <td>0.906498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.182000</td>\n",
       "      <td>0.296637</td>\n",
       "      <td>0.900662</td>\n",
       "      <td>0.900473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.157400</td>\n",
       "      <td>0.302153</td>\n",
       "      <td>0.903464</td>\n",
       "      <td>0.903855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.160900</td>\n",
       "      <td>0.303395</td>\n",
       "      <td>0.904243</td>\n",
       "      <td>0.904415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.089100</td>\n",
       "      <td>0.331693</td>\n",
       "      <td>0.909225</td>\n",
       "      <td>0.910190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.097100</td>\n",
       "      <td>0.345036</td>\n",
       "      <td>0.900350</td>\n",
       "      <td>0.899898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.096900</td>\n",
       "      <td>0.337072</td>\n",
       "      <td>0.904866</td>\n",
       "      <td>0.905489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.093500</td>\n",
       "      <td>0.343608</td>\n",
       "      <td>0.906501</td>\n",
       "      <td>0.907298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.054400</td>\n",
       "      <td>0.456015</td>\n",
       "      <td>0.905644</td>\n",
       "      <td>0.905926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.061700</td>\n",
       "      <td>0.437761</td>\n",
       "      <td>0.908758</td>\n",
       "      <td>0.908701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.061900</td>\n",
       "      <td>0.416047</td>\n",
       "      <td>0.906656</td>\n",
       "      <td>0.907563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.058400</td>\n",
       "      <td>0.423658</td>\n",
       "      <td>0.909381</td>\n",
       "      <td>0.909162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.034300</td>\n",
       "      <td>0.450883</td>\n",
       "      <td>0.907980</td>\n",
       "      <td>0.908712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.032600</td>\n",
       "      <td>0.487626</td>\n",
       "      <td>0.909070</td>\n",
       "      <td>0.909955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.037700</td>\n",
       "      <td>0.499252</td>\n",
       "      <td>0.910160</td>\n",
       "      <td>0.910747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.047600</td>\n",
       "      <td>0.463539</td>\n",
       "      <td>0.912962</td>\n",
       "      <td>0.913674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.022600</td>\n",
       "      <td>0.525635</td>\n",
       "      <td>0.909770</td>\n",
       "      <td>0.910531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.024300</td>\n",
       "      <td>0.523454</td>\n",
       "      <td>0.911639</td>\n",
       "      <td>0.911458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.030500</td>\n",
       "      <td>0.496300</td>\n",
       "      <td>0.912962</td>\n",
       "      <td>0.913536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.028600</td>\n",
       "      <td>0.503684</td>\n",
       "      <td>0.910315</td>\n",
       "      <td>0.910522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.019900</td>\n",
       "      <td>0.517842</td>\n",
       "      <td>0.910860</td>\n",
       "      <td>0.911236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.017200</td>\n",
       "      <td>0.545136</td>\n",
       "      <td>0.911250</td>\n",
       "      <td>0.911454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.020100</td>\n",
       "      <td>0.538743</td>\n",
       "      <td>0.911483</td>\n",
       "      <td>0.912276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.016600</td>\n",
       "      <td>0.548534</td>\n",
       "      <td>0.911639</td>\n",
       "      <td>0.912160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.015100</td>\n",
       "      <td>0.555358</td>\n",
       "      <td>0.912573</td>\n",
       "      <td>0.913121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.016600</td>\n",
       "      <td>0.568966</td>\n",
       "      <td>0.911717</td>\n",
       "      <td>0.912260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.013100</td>\n",
       "      <td>0.572751</td>\n",
       "      <td>0.911872</td>\n",
       "      <td>0.912353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>0.574794</td>\n",
       "      <td>0.911327</td>\n",
       "      <td>0.911974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5329c3fa58604174b7d2b25da40fe39e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51377 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "842d4be889a7463dba5c7640a27e27d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12845 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6424' max='6424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6424/6424 11:13, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.510600</td>\n",
       "      <td>0.387151</td>\n",
       "      <td>0.864149</td>\n",
       "      <td>0.866310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.357900</td>\n",
       "      <td>0.330889</td>\n",
       "      <td>0.884780</td>\n",
       "      <td>0.887877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.314900</td>\n",
       "      <td>0.292082</td>\n",
       "      <td>0.892799</td>\n",
       "      <td>0.895448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.290700</td>\n",
       "      <td>0.271643</td>\n",
       "      <td>0.904321</td>\n",
       "      <td>0.906536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.182300</td>\n",
       "      <td>0.293295</td>\n",
       "      <td>0.895913</td>\n",
       "      <td>0.899126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.176700</td>\n",
       "      <td>0.293718</td>\n",
       "      <td>0.904554</td>\n",
       "      <td>0.905404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.180900</td>\n",
       "      <td>0.265971</td>\n",
       "      <td>0.911950</td>\n",
       "      <td>0.913175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.172000</td>\n",
       "      <td>0.282743</td>\n",
       "      <td>0.911483</td>\n",
       "      <td>0.912508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.090100</td>\n",
       "      <td>0.369520</td>\n",
       "      <td>0.907668</td>\n",
       "      <td>0.909125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.096600</td>\n",
       "      <td>0.305794</td>\n",
       "      <td>0.911405</td>\n",
       "      <td>0.912550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.094600</td>\n",
       "      <td>0.307571</td>\n",
       "      <td>0.914519</td>\n",
       "      <td>0.915947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.108800</td>\n",
       "      <td>0.286388</td>\n",
       "      <td>0.914675</td>\n",
       "      <td>0.916311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.055200</td>\n",
       "      <td>0.398286</td>\n",
       "      <td>0.915765</td>\n",
       "      <td>0.917289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.059100</td>\n",
       "      <td>0.373704</td>\n",
       "      <td>0.912651</td>\n",
       "      <td>0.913628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.061000</td>\n",
       "      <td>0.403742</td>\n",
       "      <td>0.915453</td>\n",
       "      <td>0.916520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.058400</td>\n",
       "      <td>0.378019</td>\n",
       "      <td>0.914753</td>\n",
       "      <td>0.916307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.036000</td>\n",
       "      <td>0.472193</td>\n",
       "      <td>0.912339</td>\n",
       "      <td>0.914241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.034300</td>\n",
       "      <td>0.455787</td>\n",
       "      <td>0.916777</td>\n",
       "      <td>0.918337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.041200</td>\n",
       "      <td>0.439857</td>\n",
       "      <td>0.915453</td>\n",
       "      <td>0.916795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.034800</td>\n",
       "      <td>0.451963</td>\n",
       "      <td>0.913274</td>\n",
       "      <td>0.914801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.027000</td>\n",
       "      <td>0.494871</td>\n",
       "      <td>0.913585</td>\n",
       "      <td>0.914994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.025200</td>\n",
       "      <td>0.489963</td>\n",
       "      <td>0.916543</td>\n",
       "      <td>0.918362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.027900</td>\n",
       "      <td>0.513032</td>\n",
       "      <td>0.912807</td>\n",
       "      <td>0.914132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.024400</td>\n",
       "      <td>0.503476</td>\n",
       "      <td>0.915998</td>\n",
       "      <td>0.917813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.016600</td>\n",
       "      <td>0.524486</td>\n",
       "      <td>0.915298</td>\n",
       "      <td>0.917208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.019600</td>\n",
       "      <td>0.531683</td>\n",
       "      <td>0.917166</td>\n",
       "      <td>0.919038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.016800</td>\n",
       "      <td>0.534379</td>\n",
       "      <td>0.914519</td>\n",
       "      <td>0.916522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.016700</td>\n",
       "      <td>0.533465</td>\n",
       "      <td>0.914364</td>\n",
       "      <td>0.915580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.012400</td>\n",
       "      <td>0.543950</td>\n",
       "      <td>0.915998</td>\n",
       "      <td>0.917668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.012300</td>\n",
       "      <td>0.549301</td>\n",
       "      <td>0.917400</td>\n",
       "      <td>0.919200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.012100</td>\n",
       "      <td>0.544850</td>\n",
       "      <td>0.917088</td>\n",
       "      <td>0.918839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.011500</td>\n",
       "      <td>0.546008</td>\n",
       "      <td>0.917011</td>\n",
       "      <td>0.918700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a18ca2cc9dad487a8027251bb2851364",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51377 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bee70108fd1844b7a916afb1c09cc936",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12845 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6424' max='6424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6424/6424 11:18, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.510600</td>\n",
       "      <td>0.387151</td>\n",
       "      <td>0.864149</td>\n",
       "      <td>0.866310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.357900</td>\n",
       "      <td>0.330889</td>\n",
       "      <td>0.884780</td>\n",
       "      <td>0.887877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.314900</td>\n",
       "      <td>0.292082</td>\n",
       "      <td>0.892799</td>\n",
       "      <td>0.895448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.290700</td>\n",
       "      <td>0.271643</td>\n",
       "      <td>0.904321</td>\n",
       "      <td>0.906536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.182300</td>\n",
       "      <td>0.293295</td>\n",
       "      <td>0.895913</td>\n",
       "      <td>0.899126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.176700</td>\n",
       "      <td>0.293718</td>\n",
       "      <td>0.904554</td>\n",
       "      <td>0.905404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.180900</td>\n",
       "      <td>0.265971</td>\n",
       "      <td>0.911950</td>\n",
       "      <td>0.913175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.172000</td>\n",
       "      <td>0.282743</td>\n",
       "      <td>0.911483</td>\n",
       "      <td>0.912508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.090100</td>\n",
       "      <td>0.369520</td>\n",
       "      <td>0.907668</td>\n",
       "      <td>0.909125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.096600</td>\n",
       "      <td>0.305794</td>\n",
       "      <td>0.911405</td>\n",
       "      <td>0.912550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.094600</td>\n",
       "      <td>0.307571</td>\n",
       "      <td>0.914519</td>\n",
       "      <td>0.915947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.108800</td>\n",
       "      <td>0.286388</td>\n",
       "      <td>0.914675</td>\n",
       "      <td>0.916311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.055200</td>\n",
       "      <td>0.398286</td>\n",
       "      <td>0.915765</td>\n",
       "      <td>0.917289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.059100</td>\n",
       "      <td>0.373704</td>\n",
       "      <td>0.912651</td>\n",
       "      <td>0.913628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.061000</td>\n",
       "      <td>0.403742</td>\n",
       "      <td>0.915453</td>\n",
       "      <td>0.916520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.058400</td>\n",
       "      <td>0.378019</td>\n",
       "      <td>0.914753</td>\n",
       "      <td>0.916307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.036000</td>\n",
       "      <td>0.472193</td>\n",
       "      <td>0.912339</td>\n",
       "      <td>0.914241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.034300</td>\n",
       "      <td>0.455787</td>\n",
       "      <td>0.916777</td>\n",
       "      <td>0.918337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.041200</td>\n",
       "      <td>0.439857</td>\n",
       "      <td>0.915453</td>\n",
       "      <td>0.916795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.034800</td>\n",
       "      <td>0.451963</td>\n",
       "      <td>0.913274</td>\n",
       "      <td>0.914801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.027000</td>\n",
       "      <td>0.494871</td>\n",
       "      <td>0.913585</td>\n",
       "      <td>0.914994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.025200</td>\n",
       "      <td>0.489963</td>\n",
       "      <td>0.916543</td>\n",
       "      <td>0.918362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.027900</td>\n",
       "      <td>0.513032</td>\n",
       "      <td>0.912807</td>\n",
       "      <td>0.914132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.024400</td>\n",
       "      <td>0.503476</td>\n",
       "      <td>0.915998</td>\n",
       "      <td>0.917813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.016600</td>\n",
       "      <td>0.524486</td>\n",
       "      <td>0.915298</td>\n",
       "      <td>0.917208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.019600</td>\n",
       "      <td>0.531683</td>\n",
       "      <td>0.917166</td>\n",
       "      <td>0.919038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.016800</td>\n",
       "      <td>0.534379</td>\n",
       "      <td>0.914519</td>\n",
       "      <td>0.916522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.016700</td>\n",
       "      <td>0.533465</td>\n",
       "      <td>0.914364</td>\n",
       "      <td>0.915580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.012400</td>\n",
       "      <td>0.543950</td>\n",
       "      <td>0.915998</td>\n",
       "      <td>0.917668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.012300</td>\n",
       "      <td>0.549301</td>\n",
       "      <td>0.917400</td>\n",
       "      <td>0.919200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.012100</td>\n",
       "      <td>0.544850</td>\n",
       "      <td>0.917088</td>\n",
       "      <td>0.918839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.011500</td>\n",
       "      <td>0.546008</td>\n",
       "      <td>0.917011</td>\n",
       "      <td>0.918700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2025b0b46e0a41f7862e451337cf66e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51377 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af17955ecc364902901fec2681e04fb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12845 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6424' max='6424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6424/6424 11:20, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.510600</td>\n",
       "      <td>0.387151</td>\n",
       "      <td>0.864149</td>\n",
       "      <td>0.866310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.357900</td>\n",
       "      <td>0.330889</td>\n",
       "      <td>0.884780</td>\n",
       "      <td>0.887877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.314900</td>\n",
       "      <td>0.292082</td>\n",
       "      <td>0.892799</td>\n",
       "      <td>0.895448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.290700</td>\n",
       "      <td>0.271643</td>\n",
       "      <td>0.904321</td>\n",
       "      <td>0.906536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.182300</td>\n",
       "      <td>0.293295</td>\n",
       "      <td>0.895913</td>\n",
       "      <td>0.899126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.176700</td>\n",
       "      <td>0.293718</td>\n",
       "      <td>0.904554</td>\n",
       "      <td>0.905404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.180900</td>\n",
       "      <td>0.265971</td>\n",
       "      <td>0.911950</td>\n",
       "      <td>0.913175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.172000</td>\n",
       "      <td>0.282743</td>\n",
       "      <td>0.911483</td>\n",
       "      <td>0.912508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.090100</td>\n",
       "      <td>0.369520</td>\n",
       "      <td>0.907668</td>\n",
       "      <td>0.909125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.096600</td>\n",
       "      <td>0.305794</td>\n",
       "      <td>0.911405</td>\n",
       "      <td>0.912550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.094600</td>\n",
       "      <td>0.307571</td>\n",
       "      <td>0.914519</td>\n",
       "      <td>0.915947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.108800</td>\n",
       "      <td>0.286388</td>\n",
       "      <td>0.914675</td>\n",
       "      <td>0.916311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.055200</td>\n",
       "      <td>0.398286</td>\n",
       "      <td>0.915765</td>\n",
       "      <td>0.917289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.059100</td>\n",
       "      <td>0.373704</td>\n",
       "      <td>0.912651</td>\n",
       "      <td>0.913628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.061000</td>\n",
       "      <td>0.403742</td>\n",
       "      <td>0.915453</td>\n",
       "      <td>0.916520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.058400</td>\n",
       "      <td>0.378019</td>\n",
       "      <td>0.914753</td>\n",
       "      <td>0.916307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.036000</td>\n",
       "      <td>0.472193</td>\n",
       "      <td>0.912339</td>\n",
       "      <td>0.914241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.034300</td>\n",
       "      <td>0.455787</td>\n",
       "      <td>0.916777</td>\n",
       "      <td>0.918337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.041200</td>\n",
       "      <td>0.439857</td>\n",
       "      <td>0.915453</td>\n",
       "      <td>0.916795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.034800</td>\n",
       "      <td>0.451963</td>\n",
       "      <td>0.913274</td>\n",
       "      <td>0.914801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.027000</td>\n",
       "      <td>0.494871</td>\n",
       "      <td>0.913585</td>\n",
       "      <td>0.914994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.025200</td>\n",
       "      <td>0.489963</td>\n",
       "      <td>0.916543</td>\n",
       "      <td>0.918362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.027900</td>\n",
       "      <td>0.513032</td>\n",
       "      <td>0.912807</td>\n",
       "      <td>0.914132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.024400</td>\n",
       "      <td>0.503476</td>\n",
       "      <td>0.915998</td>\n",
       "      <td>0.917813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.016600</td>\n",
       "      <td>0.524486</td>\n",
       "      <td>0.915298</td>\n",
       "      <td>0.917208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.019600</td>\n",
       "      <td>0.531683</td>\n",
       "      <td>0.917166</td>\n",
       "      <td>0.919038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.016800</td>\n",
       "      <td>0.534379</td>\n",
       "      <td>0.914519</td>\n",
       "      <td>0.916522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.016700</td>\n",
       "      <td>0.533465</td>\n",
       "      <td>0.914364</td>\n",
       "      <td>0.915580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.012400</td>\n",
       "      <td>0.543950</td>\n",
       "      <td>0.915998</td>\n",
       "      <td>0.917668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.012300</td>\n",
       "      <td>0.549301</td>\n",
       "      <td>0.917400</td>\n",
       "      <td>0.919200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.012100</td>\n",
       "      <td>0.544850</td>\n",
       "      <td>0.917088</td>\n",
       "      <td>0.918839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.011500</td>\n",
       "      <td>0.546008</td>\n",
       "      <td>0.917011</td>\n",
       "      <td>0.918700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "710eef394de74ce4b2dddea8c352883c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51377 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21b446329cf94506a4926cf2a7cd4f3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12845 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6424' max='6424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6424/6424 11:18, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.504600</td>\n",
       "      <td>0.356733</td>\n",
       "      <td>0.873959</td>\n",
       "      <td>0.874654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.360900</td>\n",
       "      <td>0.305851</td>\n",
       "      <td>0.891164</td>\n",
       "      <td>0.892764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.305600</td>\n",
       "      <td>0.303690</td>\n",
       "      <td>0.893655</td>\n",
       "      <td>0.893825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.289300</td>\n",
       "      <td>0.270390</td>\n",
       "      <td>0.904632</td>\n",
       "      <td>0.904505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.179100</td>\n",
       "      <td>0.273043</td>\n",
       "      <td>0.903854</td>\n",
       "      <td>0.903936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.174000</td>\n",
       "      <td>0.281070</td>\n",
       "      <td>0.908603</td>\n",
       "      <td>0.909403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.169800</td>\n",
       "      <td>0.285310</td>\n",
       "      <td>0.908914</td>\n",
       "      <td>0.909651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.167400</td>\n",
       "      <td>0.284563</td>\n",
       "      <td>0.912884</td>\n",
       "      <td>0.913042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.095800</td>\n",
       "      <td>0.320047</td>\n",
       "      <td>0.909537</td>\n",
       "      <td>0.910286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.094900</td>\n",
       "      <td>0.328020</td>\n",
       "      <td>0.912962</td>\n",
       "      <td>0.913604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.098800</td>\n",
       "      <td>0.346566</td>\n",
       "      <td>0.911717</td>\n",
       "      <td>0.912275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.095700</td>\n",
       "      <td>0.344225</td>\n",
       "      <td>0.911327</td>\n",
       "      <td>0.911898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.057300</td>\n",
       "      <td>0.422967</td>\n",
       "      <td>0.911561</td>\n",
       "      <td>0.912122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.054200</td>\n",
       "      <td>0.467419</td>\n",
       "      <td>0.909770</td>\n",
       "      <td>0.911208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.060200</td>\n",
       "      <td>0.452069</td>\n",
       "      <td>0.907824</td>\n",
       "      <td>0.907366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.061400</td>\n",
       "      <td>0.439481</td>\n",
       "      <td>0.911717</td>\n",
       "      <td>0.912185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.037100</td>\n",
       "      <td>0.499939</td>\n",
       "      <td>0.912573</td>\n",
       "      <td>0.912642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.039800</td>\n",
       "      <td>0.480945</td>\n",
       "      <td>0.909148</td>\n",
       "      <td>0.909693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.036700</td>\n",
       "      <td>0.513282</td>\n",
       "      <td>0.910082</td>\n",
       "      <td>0.910420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.044600</td>\n",
       "      <td>0.466597</td>\n",
       "      <td>0.910004</td>\n",
       "      <td>0.910264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.028600</td>\n",
       "      <td>0.506574</td>\n",
       "      <td>0.912573</td>\n",
       "      <td>0.912869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.027400</td>\n",
       "      <td>0.522759</td>\n",
       "      <td>0.911561</td>\n",
       "      <td>0.912394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.020700</td>\n",
       "      <td>0.550088</td>\n",
       "      <td>0.913351</td>\n",
       "      <td>0.913873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.025400</td>\n",
       "      <td>0.532430</td>\n",
       "      <td>0.913896</td>\n",
       "      <td>0.914068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.022400</td>\n",
       "      <td>0.559808</td>\n",
       "      <td>0.914364</td>\n",
       "      <td>0.915067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.017700</td>\n",
       "      <td>0.563617</td>\n",
       "      <td>0.913585</td>\n",
       "      <td>0.914172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.020800</td>\n",
       "      <td>0.541680</td>\n",
       "      <td>0.914130</td>\n",
       "      <td>0.914888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.019200</td>\n",
       "      <td>0.544928</td>\n",
       "      <td>0.913896</td>\n",
       "      <td>0.914394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.013400</td>\n",
       "      <td>0.563631</td>\n",
       "      <td>0.915921</td>\n",
       "      <td>0.916402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.013400</td>\n",
       "      <td>0.564784</td>\n",
       "      <td>0.916232</td>\n",
       "      <td>0.916708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.010900</td>\n",
       "      <td>0.571144</td>\n",
       "      <td>0.915609</td>\n",
       "      <td>0.916138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.015400</td>\n",
       "      <td>0.572603</td>\n",
       "      <td>0.915609</td>\n",
       "      <td>0.916209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f6913106e1544718960d79e771bb095",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51377 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbf10ab0b3514bac9f2ed49501f25046",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12845 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6424' max='6424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6424/6424 11:18, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.504600</td>\n",
       "      <td>0.356733</td>\n",
       "      <td>0.873959</td>\n",
       "      <td>0.874654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.360900</td>\n",
       "      <td>0.305851</td>\n",
       "      <td>0.891164</td>\n",
       "      <td>0.892764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.305600</td>\n",
       "      <td>0.303690</td>\n",
       "      <td>0.893655</td>\n",
       "      <td>0.893825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.289300</td>\n",
       "      <td>0.270390</td>\n",
       "      <td>0.904632</td>\n",
       "      <td>0.904505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.179100</td>\n",
       "      <td>0.273043</td>\n",
       "      <td>0.903854</td>\n",
       "      <td>0.903936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.174000</td>\n",
       "      <td>0.281070</td>\n",
       "      <td>0.908603</td>\n",
       "      <td>0.909403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.169800</td>\n",
       "      <td>0.285310</td>\n",
       "      <td>0.908914</td>\n",
       "      <td>0.909651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.167400</td>\n",
       "      <td>0.284563</td>\n",
       "      <td>0.912884</td>\n",
       "      <td>0.913042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.095800</td>\n",
       "      <td>0.320047</td>\n",
       "      <td>0.909537</td>\n",
       "      <td>0.910286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.094900</td>\n",
       "      <td>0.328020</td>\n",
       "      <td>0.912962</td>\n",
       "      <td>0.913604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.098800</td>\n",
       "      <td>0.346566</td>\n",
       "      <td>0.911717</td>\n",
       "      <td>0.912275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.095700</td>\n",
       "      <td>0.344225</td>\n",
       "      <td>0.911327</td>\n",
       "      <td>0.911898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.057300</td>\n",
       "      <td>0.422967</td>\n",
       "      <td>0.911561</td>\n",
       "      <td>0.912122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.054200</td>\n",
       "      <td>0.467419</td>\n",
       "      <td>0.909770</td>\n",
       "      <td>0.911208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.060200</td>\n",
       "      <td>0.452069</td>\n",
       "      <td>0.907824</td>\n",
       "      <td>0.907366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.061400</td>\n",
       "      <td>0.439481</td>\n",
       "      <td>0.911717</td>\n",
       "      <td>0.912185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.037100</td>\n",
       "      <td>0.499939</td>\n",
       "      <td>0.912573</td>\n",
       "      <td>0.912642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.039800</td>\n",
       "      <td>0.480945</td>\n",
       "      <td>0.909148</td>\n",
       "      <td>0.909693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.036700</td>\n",
       "      <td>0.513282</td>\n",
       "      <td>0.910082</td>\n",
       "      <td>0.910420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.044600</td>\n",
       "      <td>0.466597</td>\n",
       "      <td>0.910004</td>\n",
       "      <td>0.910264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.028600</td>\n",
       "      <td>0.506574</td>\n",
       "      <td>0.912573</td>\n",
       "      <td>0.912869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.027400</td>\n",
       "      <td>0.522759</td>\n",
       "      <td>0.911561</td>\n",
       "      <td>0.912394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.020700</td>\n",
       "      <td>0.550088</td>\n",
       "      <td>0.913351</td>\n",
       "      <td>0.913873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.025400</td>\n",
       "      <td>0.532430</td>\n",
       "      <td>0.913896</td>\n",
       "      <td>0.914068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.022400</td>\n",
       "      <td>0.559808</td>\n",
       "      <td>0.914364</td>\n",
       "      <td>0.915067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.017700</td>\n",
       "      <td>0.563617</td>\n",
       "      <td>0.913585</td>\n",
       "      <td>0.914172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.020800</td>\n",
       "      <td>0.541680</td>\n",
       "      <td>0.914130</td>\n",
       "      <td>0.914888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.019200</td>\n",
       "      <td>0.544928</td>\n",
       "      <td>0.913896</td>\n",
       "      <td>0.914394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.013400</td>\n",
       "      <td>0.563631</td>\n",
       "      <td>0.915921</td>\n",
       "      <td>0.916402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.013400</td>\n",
       "      <td>0.564784</td>\n",
       "      <td>0.916232</td>\n",
       "      <td>0.916708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.010900</td>\n",
       "      <td>0.571144</td>\n",
       "      <td>0.915609</td>\n",
       "      <td>0.916138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.015400</td>\n",
       "      <td>0.572603</td>\n",
       "      <td>0.915609</td>\n",
       "      <td>0.916209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c73d5a5cc754ba5915eb1cf3c0f9c05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51377 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa4ade08aea04558866a90e440538665",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12845 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6424' max='6424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6424/6424 11:16, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.504600</td>\n",
       "      <td>0.356733</td>\n",
       "      <td>0.873959</td>\n",
       "      <td>0.874654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.360900</td>\n",
       "      <td>0.305851</td>\n",
       "      <td>0.891164</td>\n",
       "      <td>0.892764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.305600</td>\n",
       "      <td>0.303690</td>\n",
       "      <td>0.893655</td>\n",
       "      <td>0.893825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.289300</td>\n",
       "      <td>0.270390</td>\n",
       "      <td>0.904632</td>\n",
       "      <td>0.904505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.179100</td>\n",
       "      <td>0.273043</td>\n",
       "      <td>0.903854</td>\n",
       "      <td>0.903936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.174000</td>\n",
       "      <td>0.281070</td>\n",
       "      <td>0.908603</td>\n",
       "      <td>0.909403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.169800</td>\n",
       "      <td>0.285310</td>\n",
       "      <td>0.908914</td>\n",
       "      <td>0.909651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.167400</td>\n",
       "      <td>0.284563</td>\n",
       "      <td>0.912884</td>\n",
       "      <td>0.913042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.095800</td>\n",
       "      <td>0.320047</td>\n",
       "      <td>0.909537</td>\n",
       "      <td>0.910286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.094900</td>\n",
       "      <td>0.328020</td>\n",
       "      <td>0.912962</td>\n",
       "      <td>0.913604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.098800</td>\n",
       "      <td>0.346566</td>\n",
       "      <td>0.911717</td>\n",
       "      <td>0.912275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.095700</td>\n",
       "      <td>0.344225</td>\n",
       "      <td>0.911327</td>\n",
       "      <td>0.911898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.057300</td>\n",
       "      <td>0.422967</td>\n",
       "      <td>0.911561</td>\n",
       "      <td>0.912122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.054200</td>\n",
       "      <td>0.467419</td>\n",
       "      <td>0.909770</td>\n",
       "      <td>0.911208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.060200</td>\n",
       "      <td>0.452069</td>\n",
       "      <td>0.907824</td>\n",
       "      <td>0.907366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.061400</td>\n",
       "      <td>0.439481</td>\n",
       "      <td>0.911717</td>\n",
       "      <td>0.912185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.037100</td>\n",
       "      <td>0.499939</td>\n",
       "      <td>0.912573</td>\n",
       "      <td>0.912642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.039800</td>\n",
       "      <td>0.480945</td>\n",
       "      <td>0.909148</td>\n",
       "      <td>0.909693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.036700</td>\n",
       "      <td>0.513282</td>\n",
       "      <td>0.910082</td>\n",
       "      <td>0.910420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.044600</td>\n",
       "      <td>0.466597</td>\n",
       "      <td>0.910004</td>\n",
       "      <td>0.910264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.028600</td>\n",
       "      <td>0.506574</td>\n",
       "      <td>0.912573</td>\n",
       "      <td>0.912869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.027400</td>\n",
       "      <td>0.522759</td>\n",
       "      <td>0.911561</td>\n",
       "      <td>0.912394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.020700</td>\n",
       "      <td>0.550088</td>\n",
       "      <td>0.913351</td>\n",
       "      <td>0.913873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.025400</td>\n",
       "      <td>0.532430</td>\n",
       "      <td>0.913896</td>\n",
       "      <td>0.914068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.022400</td>\n",
       "      <td>0.559808</td>\n",
       "      <td>0.914364</td>\n",
       "      <td>0.915067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.017700</td>\n",
       "      <td>0.563617</td>\n",
       "      <td>0.913585</td>\n",
       "      <td>0.914172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.020800</td>\n",
       "      <td>0.541680</td>\n",
       "      <td>0.914130</td>\n",
       "      <td>0.914888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.019200</td>\n",
       "      <td>0.544928</td>\n",
       "      <td>0.913896</td>\n",
       "      <td>0.914394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.013400</td>\n",
       "      <td>0.563631</td>\n",
       "      <td>0.915921</td>\n",
       "      <td>0.916402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.013400</td>\n",
       "      <td>0.564784</td>\n",
       "      <td>0.916232</td>\n",
       "      <td>0.916708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.010900</td>\n",
       "      <td>0.571144</td>\n",
       "      <td>0.915609</td>\n",
       "      <td>0.916138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.015400</td>\n",
       "      <td>0.572603</td>\n",
       "      <td>0.915609</td>\n",
       "      <td>0.916209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 51377\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 12845\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunis-ai/TunBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tunis-ai/TunBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edc29ee6ce974e3e844b1cb1a49603a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51377 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeb10b77eb314a57bb70fb49c968fa82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12845 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6424' max='6424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6424/6424 10:53, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.242500</td>\n",
       "      <td>1.162016</td>\n",
       "      <td>0.471467</td>\n",
       "      <td>0.380133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.047200</td>\n",
       "      <td>1.066616</td>\n",
       "      <td>0.560763</td>\n",
       "      <td>0.542299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.972800</td>\n",
       "      <td>0.908349</td>\n",
       "      <td>0.620786</td>\n",
       "      <td>0.612173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.918200</td>\n",
       "      <td>0.848764</td>\n",
       "      <td>0.658466</td>\n",
       "      <td>0.656422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.861800</td>\n",
       "      <td>0.837657</td>\n",
       "      <td>0.667808</td>\n",
       "      <td>0.668258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.842700</td>\n",
       "      <td>0.820424</td>\n",
       "      <td>0.674192</td>\n",
       "      <td>0.675071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.805900</td>\n",
       "      <td>0.783589</td>\n",
       "      <td>0.686726</td>\n",
       "      <td>0.687241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.813100</td>\n",
       "      <td>0.784575</td>\n",
       "      <td>0.690775</td>\n",
       "      <td>0.691384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.772300</td>\n",
       "      <td>0.829990</td>\n",
       "      <td>0.666796</td>\n",
       "      <td>0.668717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.760200</td>\n",
       "      <td>0.790856</td>\n",
       "      <td>0.685325</td>\n",
       "      <td>0.687911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.761900</td>\n",
       "      <td>0.794238</td>\n",
       "      <td>0.677306</td>\n",
       "      <td>0.680272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.761100</td>\n",
       "      <td>0.758036</td>\n",
       "      <td>0.701362</td>\n",
       "      <td>0.702313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.706500</td>\n",
       "      <td>0.784464</td>\n",
       "      <td>0.680654</td>\n",
       "      <td>0.683711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.716700</td>\n",
       "      <td>0.765043</td>\n",
       "      <td>0.701985</td>\n",
       "      <td>0.702738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.710400</td>\n",
       "      <td>0.756119</td>\n",
       "      <td>0.699338</td>\n",
       "      <td>0.703993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.713800</td>\n",
       "      <td>0.754477</td>\n",
       "      <td>0.704009</td>\n",
       "      <td>0.706178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.678700</td>\n",
       "      <td>0.747033</td>\n",
       "      <td>0.709070</td>\n",
       "      <td>0.712802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.665200</td>\n",
       "      <td>0.739783</td>\n",
       "      <td>0.712417</td>\n",
       "      <td>0.716367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.675100</td>\n",
       "      <td>0.742868</td>\n",
       "      <td>0.713274</td>\n",
       "      <td>0.716314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.666900</td>\n",
       "      <td>0.747048</td>\n",
       "      <td>0.709459</td>\n",
       "      <td>0.713538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.623500</td>\n",
       "      <td>0.752191</td>\n",
       "      <td>0.712962</td>\n",
       "      <td>0.716967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.624800</td>\n",
       "      <td>0.743290</td>\n",
       "      <td>0.719035</td>\n",
       "      <td>0.721880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.630800</td>\n",
       "      <td>0.733496</td>\n",
       "      <td>0.718490</td>\n",
       "      <td>0.722596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>0.718460</td>\n",
       "      <td>0.719969</td>\n",
       "      <td>0.723900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.585600</td>\n",
       "      <td>0.729709</td>\n",
       "      <td>0.717322</td>\n",
       "      <td>0.721093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.569400</td>\n",
       "      <td>0.748391</td>\n",
       "      <td>0.720280</td>\n",
       "      <td>0.724369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.586000</td>\n",
       "      <td>0.742431</td>\n",
       "      <td>0.718801</td>\n",
       "      <td>0.723126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.594900</td>\n",
       "      <td>0.747873</td>\n",
       "      <td>0.718256</td>\n",
       "      <td>0.722225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.548800</td>\n",
       "      <td>0.742790</td>\n",
       "      <td>0.723706</td>\n",
       "      <td>0.727942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.544200</td>\n",
       "      <td>0.747701</td>\n",
       "      <td>0.723472</td>\n",
       "      <td>0.728097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.551300</td>\n",
       "      <td>0.741561</td>\n",
       "      <td>0.725730</td>\n",
       "      <td>0.730697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.547500</td>\n",
       "      <td>0.738955</td>\n",
       "      <td>0.725263</td>\n",
       "      <td>0.729987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunis-ai/TunBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tunis-ai/TunBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01f4febf3b7741b9977e8c8ce2714ba7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51377 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1079fc1f2f8f45ad9a062cf85ab38954",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12845 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6424' max='6424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6424/6424 10:51, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.242500</td>\n",
       "      <td>1.162016</td>\n",
       "      <td>0.471467</td>\n",
       "      <td>0.380133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.047200</td>\n",
       "      <td>1.066616</td>\n",
       "      <td>0.560763</td>\n",
       "      <td>0.542299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.972800</td>\n",
       "      <td>0.908349</td>\n",
       "      <td>0.620786</td>\n",
       "      <td>0.612173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.918200</td>\n",
       "      <td>0.848764</td>\n",
       "      <td>0.658466</td>\n",
       "      <td>0.656422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.861800</td>\n",
       "      <td>0.837657</td>\n",
       "      <td>0.667808</td>\n",
       "      <td>0.668258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.842700</td>\n",
       "      <td>0.820424</td>\n",
       "      <td>0.674192</td>\n",
       "      <td>0.675071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.805900</td>\n",
       "      <td>0.783589</td>\n",
       "      <td>0.686726</td>\n",
       "      <td>0.687241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.813100</td>\n",
       "      <td>0.784575</td>\n",
       "      <td>0.690775</td>\n",
       "      <td>0.691384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.772300</td>\n",
       "      <td>0.829990</td>\n",
       "      <td>0.666796</td>\n",
       "      <td>0.668717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.760200</td>\n",
       "      <td>0.790856</td>\n",
       "      <td>0.685325</td>\n",
       "      <td>0.687911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.761900</td>\n",
       "      <td>0.794238</td>\n",
       "      <td>0.677306</td>\n",
       "      <td>0.680272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.761100</td>\n",
       "      <td>0.758036</td>\n",
       "      <td>0.701362</td>\n",
       "      <td>0.702313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.706500</td>\n",
       "      <td>0.784464</td>\n",
       "      <td>0.680654</td>\n",
       "      <td>0.683711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.716700</td>\n",
       "      <td>0.765043</td>\n",
       "      <td>0.701985</td>\n",
       "      <td>0.702738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.710400</td>\n",
       "      <td>0.756119</td>\n",
       "      <td>0.699338</td>\n",
       "      <td>0.703993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.713800</td>\n",
       "      <td>0.754477</td>\n",
       "      <td>0.704009</td>\n",
       "      <td>0.706178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.678700</td>\n",
       "      <td>0.747033</td>\n",
       "      <td>0.709070</td>\n",
       "      <td>0.712802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.665200</td>\n",
       "      <td>0.739783</td>\n",
       "      <td>0.712417</td>\n",
       "      <td>0.716367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.675100</td>\n",
       "      <td>0.742868</td>\n",
       "      <td>0.713274</td>\n",
       "      <td>0.716314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.666900</td>\n",
       "      <td>0.747048</td>\n",
       "      <td>0.709459</td>\n",
       "      <td>0.713538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.623500</td>\n",
       "      <td>0.752191</td>\n",
       "      <td>0.712962</td>\n",
       "      <td>0.716967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.624800</td>\n",
       "      <td>0.743290</td>\n",
       "      <td>0.719035</td>\n",
       "      <td>0.721880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.630800</td>\n",
       "      <td>0.733496</td>\n",
       "      <td>0.718490</td>\n",
       "      <td>0.722596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>0.718460</td>\n",
       "      <td>0.719969</td>\n",
       "      <td>0.723900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.585600</td>\n",
       "      <td>0.729709</td>\n",
       "      <td>0.717322</td>\n",
       "      <td>0.721093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.569400</td>\n",
       "      <td>0.748391</td>\n",
       "      <td>0.720280</td>\n",
       "      <td>0.724369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.586000</td>\n",
       "      <td>0.742431</td>\n",
       "      <td>0.718801</td>\n",
       "      <td>0.723126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.594900</td>\n",
       "      <td>0.747873</td>\n",
       "      <td>0.718256</td>\n",
       "      <td>0.722225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.548800</td>\n",
       "      <td>0.742790</td>\n",
       "      <td>0.723706</td>\n",
       "      <td>0.727942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.544200</td>\n",
       "      <td>0.747701</td>\n",
       "      <td>0.723472</td>\n",
       "      <td>0.728097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.551300</td>\n",
       "      <td>0.741561</td>\n",
       "      <td>0.725730</td>\n",
       "      <td>0.730697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.547500</td>\n",
       "      <td>0.738955</td>\n",
       "      <td>0.725263</td>\n",
       "      <td>0.729987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunis-ai/TunBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tunis-ai/TunBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb73665eae9e4958872b3f8d85849c62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51377 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3fce556b6fb4c1aa14493b7a794126f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12845 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6424' max='6424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6424/6424 10:51, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.242500</td>\n",
       "      <td>1.162016</td>\n",
       "      <td>0.471467</td>\n",
       "      <td>0.380133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.047200</td>\n",
       "      <td>1.066616</td>\n",
       "      <td>0.560763</td>\n",
       "      <td>0.542299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.972800</td>\n",
       "      <td>0.908349</td>\n",
       "      <td>0.620786</td>\n",
       "      <td>0.612173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.918200</td>\n",
       "      <td>0.848764</td>\n",
       "      <td>0.658466</td>\n",
       "      <td>0.656422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.861800</td>\n",
       "      <td>0.837657</td>\n",
       "      <td>0.667808</td>\n",
       "      <td>0.668258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.842700</td>\n",
       "      <td>0.820424</td>\n",
       "      <td>0.674192</td>\n",
       "      <td>0.675071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.805900</td>\n",
       "      <td>0.783589</td>\n",
       "      <td>0.686726</td>\n",
       "      <td>0.687241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.813100</td>\n",
       "      <td>0.784575</td>\n",
       "      <td>0.690775</td>\n",
       "      <td>0.691384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.772300</td>\n",
       "      <td>0.829990</td>\n",
       "      <td>0.666796</td>\n",
       "      <td>0.668717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.760200</td>\n",
       "      <td>0.790856</td>\n",
       "      <td>0.685325</td>\n",
       "      <td>0.687911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.761900</td>\n",
       "      <td>0.794238</td>\n",
       "      <td>0.677306</td>\n",
       "      <td>0.680272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.761100</td>\n",
       "      <td>0.758036</td>\n",
       "      <td>0.701362</td>\n",
       "      <td>0.702313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.706500</td>\n",
       "      <td>0.784464</td>\n",
       "      <td>0.680654</td>\n",
       "      <td>0.683711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.716700</td>\n",
       "      <td>0.765043</td>\n",
       "      <td>0.701985</td>\n",
       "      <td>0.702738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.710400</td>\n",
       "      <td>0.756119</td>\n",
       "      <td>0.699338</td>\n",
       "      <td>0.703993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.713800</td>\n",
       "      <td>0.754477</td>\n",
       "      <td>0.704009</td>\n",
       "      <td>0.706178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.678700</td>\n",
       "      <td>0.747033</td>\n",
       "      <td>0.709070</td>\n",
       "      <td>0.712802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.665200</td>\n",
       "      <td>0.739783</td>\n",
       "      <td>0.712417</td>\n",
       "      <td>0.716367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.675100</td>\n",
       "      <td>0.742868</td>\n",
       "      <td>0.713274</td>\n",
       "      <td>0.716314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.666900</td>\n",
       "      <td>0.747048</td>\n",
       "      <td>0.709459</td>\n",
       "      <td>0.713538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.623500</td>\n",
       "      <td>0.752191</td>\n",
       "      <td>0.712962</td>\n",
       "      <td>0.716967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.624800</td>\n",
       "      <td>0.743290</td>\n",
       "      <td>0.719035</td>\n",
       "      <td>0.721880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.630800</td>\n",
       "      <td>0.733496</td>\n",
       "      <td>0.718490</td>\n",
       "      <td>0.722596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>0.718460</td>\n",
       "      <td>0.719969</td>\n",
       "      <td>0.723900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.585600</td>\n",
       "      <td>0.729709</td>\n",
       "      <td>0.717322</td>\n",
       "      <td>0.721093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.569400</td>\n",
       "      <td>0.748391</td>\n",
       "      <td>0.720280</td>\n",
       "      <td>0.724369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.586000</td>\n",
       "      <td>0.742431</td>\n",
       "      <td>0.718801</td>\n",
       "      <td>0.723126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.594900</td>\n",
       "      <td>0.747873</td>\n",
       "      <td>0.718256</td>\n",
       "      <td>0.722225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.548800</td>\n",
       "      <td>0.742790</td>\n",
       "      <td>0.723706</td>\n",
       "      <td>0.727942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.544200</td>\n",
       "      <td>0.747701</td>\n",
       "      <td>0.723472</td>\n",
       "      <td>0.728097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.551300</td>\n",
       "      <td>0.741561</td>\n",
       "      <td>0.725730</td>\n",
       "      <td>0.730697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.547500</td>\n",
       "      <td>0.738955</td>\n",
       "      <td>0.725263</td>\n",
       "      <td>0.729987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunis-ai/TunBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tunis-ai/TunBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2f660878c3c437f9c2a884cfd0270bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51377 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a06d998f75cc4c8aa3868616648fd66e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12845 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6424' max='6424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6424/6424 10:52, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.227600</td>\n",
       "      <td>1.125681</td>\n",
       "      <td>0.508447</td>\n",
       "      <td>0.431254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.039000</td>\n",
       "      <td>1.009173</td>\n",
       "      <td>0.558895</td>\n",
       "      <td>0.559881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.950800</td>\n",
       "      <td>0.896119</td>\n",
       "      <td>0.646866</td>\n",
       "      <td>0.641027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.888600</td>\n",
       "      <td>0.863300</td>\n",
       "      <td>0.651771</td>\n",
       "      <td>0.651053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.864700</td>\n",
       "      <td>0.859004</td>\n",
       "      <td>0.649046</td>\n",
       "      <td>0.639031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.828700</td>\n",
       "      <td>0.840516</td>\n",
       "      <td>0.663215</td>\n",
       "      <td>0.652981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.820500</td>\n",
       "      <td>0.806955</td>\n",
       "      <td>0.679564</td>\n",
       "      <td>0.682479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.794300</td>\n",
       "      <td>0.793702</td>\n",
       "      <td>0.682756</td>\n",
       "      <td>0.683701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.760500</td>\n",
       "      <td>0.803097</td>\n",
       "      <td>0.689840</td>\n",
       "      <td>0.692553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.755800</td>\n",
       "      <td>0.774907</td>\n",
       "      <td>0.690619</td>\n",
       "      <td>0.689612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.758400</td>\n",
       "      <td>0.786330</td>\n",
       "      <td>0.683301</td>\n",
       "      <td>0.687219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.749600</td>\n",
       "      <td>0.771445</td>\n",
       "      <td>0.691553</td>\n",
       "      <td>0.692448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.707000</td>\n",
       "      <td>0.756111</td>\n",
       "      <td>0.700895</td>\n",
       "      <td>0.701494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.715900</td>\n",
       "      <td>0.748365</td>\n",
       "      <td>0.707435</td>\n",
       "      <td>0.710537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.695200</td>\n",
       "      <td>0.735444</td>\n",
       "      <td>0.704243</td>\n",
       "      <td>0.707041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.699600</td>\n",
       "      <td>0.726162</td>\n",
       "      <td>0.710393</td>\n",
       "      <td>0.712120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.651100</td>\n",
       "      <td>0.740158</td>\n",
       "      <td>0.700740</td>\n",
       "      <td>0.704967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.661000</td>\n",
       "      <td>0.747417</td>\n",
       "      <td>0.703153</td>\n",
       "      <td>0.707985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.661000</td>\n",
       "      <td>0.725030</td>\n",
       "      <td>0.713429</td>\n",
       "      <td>0.717282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.644200</td>\n",
       "      <td>0.731356</td>\n",
       "      <td>0.707824</td>\n",
       "      <td>0.709603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.624800</td>\n",
       "      <td>0.761162</td>\n",
       "      <td>0.707980</td>\n",
       "      <td>0.713463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.604800</td>\n",
       "      <td>0.744571</td>\n",
       "      <td>0.711950</td>\n",
       "      <td>0.714233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.603300</td>\n",
       "      <td>0.730832</td>\n",
       "      <td>0.719035</td>\n",
       "      <td>0.723146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.603500</td>\n",
       "      <td>0.736109</td>\n",
       "      <td>0.712184</td>\n",
       "      <td>0.716086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.575900</td>\n",
       "      <td>0.730869</td>\n",
       "      <td>0.719657</td>\n",
       "      <td>0.724414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.576200</td>\n",
       "      <td>0.727975</td>\n",
       "      <td>0.724796</td>\n",
       "      <td>0.728906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.553700</td>\n",
       "      <td>0.743320</td>\n",
       "      <td>0.717166</td>\n",
       "      <td>0.722262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.556700</td>\n",
       "      <td>0.725758</td>\n",
       "      <td>0.720436</td>\n",
       "      <td>0.723841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.536400</td>\n",
       "      <td>0.741163</td>\n",
       "      <td>0.721993</td>\n",
       "      <td>0.725734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.527900</td>\n",
       "      <td>0.742365</td>\n",
       "      <td>0.724873</td>\n",
       "      <td>0.729869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.523500</td>\n",
       "      <td>0.734671</td>\n",
       "      <td>0.725107</td>\n",
       "      <td>0.729566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.521700</td>\n",
       "      <td>0.736911</td>\n",
       "      <td>0.724640</td>\n",
       "      <td>0.728993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunis-ai/TunBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tunis-ai/TunBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56f40fc301224318b3583b61a8327c6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51377 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9780b341e3b4e6aa9674e2e33a0f1d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12845 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6424' max='6424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6424/6424 10:51, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.227600</td>\n",
       "      <td>1.125681</td>\n",
       "      <td>0.508447</td>\n",
       "      <td>0.431254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.039000</td>\n",
       "      <td>1.009173</td>\n",
       "      <td>0.558895</td>\n",
       "      <td>0.559881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.950800</td>\n",
       "      <td>0.896119</td>\n",
       "      <td>0.646866</td>\n",
       "      <td>0.641027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.888600</td>\n",
       "      <td>0.863300</td>\n",
       "      <td>0.651771</td>\n",
       "      <td>0.651053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.864700</td>\n",
       "      <td>0.859004</td>\n",
       "      <td>0.649046</td>\n",
       "      <td>0.639031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.828700</td>\n",
       "      <td>0.840516</td>\n",
       "      <td>0.663215</td>\n",
       "      <td>0.652981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.820500</td>\n",
       "      <td>0.806955</td>\n",
       "      <td>0.679564</td>\n",
       "      <td>0.682479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.794300</td>\n",
       "      <td>0.793702</td>\n",
       "      <td>0.682756</td>\n",
       "      <td>0.683701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.760500</td>\n",
       "      <td>0.803097</td>\n",
       "      <td>0.689840</td>\n",
       "      <td>0.692553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.755800</td>\n",
       "      <td>0.774907</td>\n",
       "      <td>0.690619</td>\n",
       "      <td>0.689612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.758400</td>\n",
       "      <td>0.786330</td>\n",
       "      <td>0.683301</td>\n",
       "      <td>0.687219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.749600</td>\n",
       "      <td>0.771445</td>\n",
       "      <td>0.691553</td>\n",
       "      <td>0.692448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.707000</td>\n",
       "      <td>0.756111</td>\n",
       "      <td>0.700895</td>\n",
       "      <td>0.701494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.715900</td>\n",
       "      <td>0.748365</td>\n",
       "      <td>0.707435</td>\n",
       "      <td>0.710537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.695200</td>\n",
       "      <td>0.735444</td>\n",
       "      <td>0.704243</td>\n",
       "      <td>0.707041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.699600</td>\n",
       "      <td>0.726162</td>\n",
       "      <td>0.710393</td>\n",
       "      <td>0.712120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.651100</td>\n",
       "      <td>0.740158</td>\n",
       "      <td>0.700740</td>\n",
       "      <td>0.704967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.661000</td>\n",
       "      <td>0.747417</td>\n",
       "      <td>0.703153</td>\n",
       "      <td>0.707985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.661000</td>\n",
       "      <td>0.725030</td>\n",
       "      <td>0.713429</td>\n",
       "      <td>0.717282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.644200</td>\n",
       "      <td>0.731356</td>\n",
       "      <td>0.707824</td>\n",
       "      <td>0.709603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.624800</td>\n",
       "      <td>0.761162</td>\n",
       "      <td>0.707980</td>\n",
       "      <td>0.713463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.604800</td>\n",
       "      <td>0.744571</td>\n",
       "      <td>0.711950</td>\n",
       "      <td>0.714233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.603300</td>\n",
       "      <td>0.730832</td>\n",
       "      <td>0.719035</td>\n",
       "      <td>0.723146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.603500</td>\n",
       "      <td>0.736109</td>\n",
       "      <td>0.712184</td>\n",
       "      <td>0.716086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.575900</td>\n",
       "      <td>0.730869</td>\n",
       "      <td>0.719657</td>\n",
       "      <td>0.724414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.576200</td>\n",
       "      <td>0.727975</td>\n",
       "      <td>0.724796</td>\n",
       "      <td>0.728906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.553700</td>\n",
       "      <td>0.743320</td>\n",
       "      <td>0.717166</td>\n",
       "      <td>0.722262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.556700</td>\n",
       "      <td>0.725758</td>\n",
       "      <td>0.720436</td>\n",
       "      <td>0.723841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.536400</td>\n",
       "      <td>0.741163</td>\n",
       "      <td>0.721993</td>\n",
       "      <td>0.725734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.527900</td>\n",
       "      <td>0.742365</td>\n",
       "      <td>0.724873</td>\n",
       "      <td>0.729869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.523500</td>\n",
       "      <td>0.734671</td>\n",
       "      <td>0.725107</td>\n",
       "      <td>0.729566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.521700</td>\n",
       "      <td>0.736911</td>\n",
       "      <td>0.724640</td>\n",
       "      <td>0.728993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunis-ai/TunBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tunis-ai/TunBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f52495438ec43e58f2062e4a10cf4b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51377 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebd61e0c5d7b44d9bb56e6ec33433da9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12845 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6424' max='6424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6424/6424 10:51, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.227600</td>\n",
       "      <td>1.125681</td>\n",
       "      <td>0.508447</td>\n",
       "      <td>0.431254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.039000</td>\n",
       "      <td>1.009173</td>\n",
       "      <td>0.558895</td>\n",
       "      <td>0.559881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.950800</td>\n",
       "      <td>0.896119</td>\n",
       "      <td>0.646866</td>\n",
       "      <td>0.641027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.888600</td>\n",
       "      <td>0.863300</td>\n",
       "      <td>0.651771</td>\n",
       "      <td>0.651053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.864700</td>\n",
       "      <td>0.859004</td>\n",
       "      <td>0.649046</td>\n",
       "      <td>0.639031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.828700</td>\n",
       "      <td>0.840516</td>\n",
       "      <td>0.663215</td>\n",
       "      <td>0.652981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.820500</td>\n",
       "      <td>0.806955</td>\n",
       "      <td>0.679564</td>\n",
       "      <td>0.682479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.794300</td>\n",
       "      <td>0.793702</td>\n",
       "      <td>0.682756</td>\n",
       "      <td>0.683701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.760500</td>\n",
       "      <td>0.803097</td>\n",
       "      <td>0.689840</td>\n",
       "      <td>0.692553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.755800</td>\n",
       "      <td>0.774907</td>\n",
       "      <td>0.690619</td>\n",
       "      <td>0.689612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.758400</td>\n",
       "      <td>0.786330</td>\n",
       "      <td>0.683301</td>\n",
       "      <td>0.687219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.749600</td>\n",
       "      <td>0.771445</td>\n",
       "      <td>0.691553</td>\n",
       "      <td>0.692448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.707000</td>\n",
       "      <td>0.756111</td>\n",
       "      <td>0.700895</td>\n",
       "      <td>0.701494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.715900</td>\n",
       "      <td>0.748365</td>\n",
       "      <td>0.707435</td>\n",
       "      <td>0.710537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.695200</td>\n",
       "      <td>0.735444</td>\n",
       "      <td>0.704243</td>\n",
       "      <td>0.707041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.699600</td>\n",
       "      <td>0.726162</td>\n",
       "      <td>0.710393</td>\n",
       "      <td>0.712120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.651100</td>\n",
       "      <td>0.740158</td>\n",
       "      <td>0.700740</td>\n",
       "      <td>0.704967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.661000</td>\n",
       "      <td>0.747417</td>\n",
       "      <td>0.703153</td>\n",
       "      <td>0.707985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.661000</td>\n",
       "      <td>0.725030</td>\n",
       "      <td>0.713429</td>\n",
       "      <td>0.717282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.644200</td>\n",
       "      <td>0.731356</td>\n",
       "      <td>0.707824</td>\n",
       "      <td>0.709603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.624800</td>\n",
       "      <td>0.761162</td>\n",
       "      <td>0.707980</td>\n",
       "      <td>0.713463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.604800</td>\n",
       "      <td>0.744571</td>\n",
       "      <td>0.711950</td>\n",
       "      <td>0.714233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.603300</td>\n",
       "      <td>0.730832</td>\n",
       "      <td>0.719035</td>\n",
       "      <td>0.723146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.603500</td>\n",
       "      <td>0.736109</td>\n",
       "      <td>0.712184</td>\n",
       "      <td>0.716086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.575900</td>\n",
       "      <td>0.730869</td>\n",
       "      <td>0.719657</td>\n",
       "      <td>0.724414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.576200</td>\n",
       "      <td>0.727975</td>\n",
       "      <td>0.724796</td>\n",
       "      <td>0.728906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.553700</td>\n",
       "      <td>0.743320</td>\n",
       "      <td>0.717166</td>\n",
       "      <td>0.722262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.556700</td>\n",
       "      <td>0.725758</td>\n",
       "      <td>0.720436</td>\n",
       "      <td>0.723841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.536400</td>\n",
       "      <td>0.741163</td>\n",
       "      <td>0.721993</td>\n",
       "      <td>0.725734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.527900</td>\n",
       "      <td>0.742365</td>\n",
       "      <td>0.724873</td>\n",
       "      <td>0.729869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.523500</td>\n",
       "      <td>0.734671</td>\n",
       "      <td>0.725107</td>\n",
       "      <td>0.729566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.521700</td>\n",
       "      <td>0.736911</td>\n",
       "      <td>0.724640</td>\n",
       "      <td>0.728993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunis-ai/TunBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tunis-ai/TunBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae61578e242e46799023cfbcfd2eb5da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51377 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e92a7d4cb5c45068d3833be26172cc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12845 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6424' max='6424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6424/6424 10:51, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.226600</td>\n",
       "      <td>1.163268</td>\n",
       "      <td>0.491865</td>\n",
       "      <td>0.381331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.035000</td>\n",
       "      <td>1.016056</td>\n",
       "      <td>0.566913</td>\n",
       "      <td>0.560809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.938700</td>\n",
       "      <td>0.900506</td>\n",
       "      <td>0.644687</td>\n",
       "      <td>0.645455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.892100</td>\n",
       "      <td>0.900711</td>\n",
       "      <td>0.630985</td>\n",
       "      <td>0.628170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.848200</td>\n",
       "      <td>0.859045</td>\n",
       "      <td>0.648657</td>\n",
       "      <td>0.639753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.826200</td>\n",
       "      <td>0.872063</td>\n",
       "      <td>0.651538</td>\n",
       "      <td>0.648664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.809600</td>\n",
       "      <td>0.843801</td>\n",
       "      <td>0.653562</td>\n",
       "      <td>0.656607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.803400</td>\n",
       "      <td>0.827648</td>\n",
       "      <td>0.665006</td>\n",
       "      <td>0.662756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.758600</td>\n",
       "      <td>0.815908</td>\n",
       "      <td>0.674893</td>\n",
       "      <td>0.675445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.757700</td>\n",
       "      <td>0.776920</td>\n",
       "      <td>0.682834</td>\n",
       "      <td>0.683805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.765300</td>\n",
       "      <td>0.809488</td>\n",
       "      <td>0.676761</td>\n",
       "      <td>0.679359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.752000</td>\n",
       "      <td>0.805242</td>\n",
       "      <td>0.676761</td>\n",
       "      <td>0.677014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.714300</td>\n",
       "      <td>0.771439</td>\n",
       "      <td>0.691320</td>\n",
       "      <td>0.691633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.713900</td>\n",
       "      <td>0.758809</td>\n",
       "      <td>0.697937</td>\n",
       "      <td>0.698082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.693600</td>\n",
       "      <td>0.762034</td>\n",
       "      <td>0.692332</td>\n",
       "      <td>0.692984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.691200</td>\n",
       "      <td>0.748504</td>\n",
       "      <td>0.694823</td>\n",
       "      <td>0.698046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.669100</td>\n",
       "      <td>0.760627</td>\n",
       "      <td>0.693967</td>\n",
       "      <td>0.694622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.665000</td>\n",
       "      <td>0.771360</td>\n",
       "      <td>0.692176</td>\n",
       "      <td>0.697366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.666500</td>\n",
       "      <td>0.755122</td>\n",
       "      <td>0.696925</td>\n",
       "      <td>0.698218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.646600</td>\n",
       "      <td>0.746392</td>\n",
       "      <td>0.698638</td>\n",
       "      <td>0.702700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.615300</td>\n",
       "      <td>0.760508</td>\n",
       "      <td>0.703542</td>\n",
       "      <td>0.705487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.617400</td>\n",
       "      <td>0.745227</td>\n",
       "      <td>0.708836</td>\n",
       "      <td>0.712453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.613700</td>\n",
       "      <td>0.735532</td>\n",
       "      <td>0.705722</td>\n",
       "      <td>0.708183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.610400</td>\n",
       "      <td>0.748091</td>\n",
       "      <td>0.698871</td>\n",
       "      <td>0.702276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.588600</td>\n",
       "      <td>0.762842</td>\n",
       "      <td>0.707046</td>\n",
       "      <td>0.709658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.574500</td>\n",
       "      <td>0.757048</td>\n",
       "      <td>0.708680</td>\n",
       "      <td>0.711938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.575300</td>\n",
       "      <td>0.760386</td>\n",
       "      <td>0.707513</td>\n",
       "      <td>0.710829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.560900</td>\n",
       "      <td>0.750349</td>\n",
       "      <td>0.705177</td>\n",
       "      <td>0.707291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.543200</td>\n",
       "      <td>0.753750</td>\n",
       "      <td>0.712807</td>\n",
       "      <td>0.716599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.541800</td>\n",
       "      <td>0.762080</td>\n",
       "      <td>0.712262</td>\n",
       "      <td>0.715978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.530500</td>\n",
       "      <td>0.756717</td>\n",
       "      <td>0.712495</td>\n",
       "      <td>0.715370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.545100</td>\n",
       "      <td>0.750199</td>\n",
       "      <td>0.712184</td>\n",
       "      <td>0.715429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunis-ai/TunBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tunis-ai/TunBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eccb49b235d404396d7dbc37944bb33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51377 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb2284f2763e4bafae21eead1d5c7bc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12845 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6424' max='6424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6424/6424 10:52, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.226600</td>\n",
       "      <td>1.163268</td>\n",
       "      <td>0.491865</td>\n",
       "      <td>0.381331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.035000</td>\n",
       "      <td>1.016056</td>\n",
       "      <td>0.566913</td>\n",
       "      <td>0.560809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.938700</td>\n",
       "      <td>0.900506</td>\n",
       "      <td>0.644687</td>\n",
       "      <td>0.645455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.892100</td>\n",
       "      <td>0.900711</td>\n",
       "      <td>0.630985</td>\n",
       "      <td>0.628170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.848200</td>\n",
       "      <td>0.859045</td>\n",
       "      <td>0.648657</td>\n",
       "      <td>0.639753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.826200</td>\n",
       "      <td>0.872063</td>\n",
       "      <td>0.651538</td>\n",
       "      <td>0.648664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.809600</td>\n",
       "      <td>0.843801</td>\n",
       "      <td>0.653562</td>\n",
       "      <td>0.656607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.803400</td>\n",
       "      <td>0.827648</td>\n",
       "      <td>0.665006</td>\n",
       "      <td>0.662756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.758600</td>\n",
       "      <td>0.815908</td>\n",
       "      <td>0.674893</td>\n",
       "      <td>0.675445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.757700</td>\n",
       "      <td>0.776920</td>\n",
       "      <td>0.682834</td>\n",
       "      <td>0.683805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.765300</td>\n",
       "      <td>0.809488</td>\n",
       "      <td>0.676761</td>\n",
       "      <td>0.679359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.752000</td>\n",
       "      <td>0.805242</td>\n",
       "      <td>0.676761</td>\n",
       "      <td>0.677014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.714300</td>\n",
       "      <td>0.771439</td>\n",
       "      <td>0.691320</td>\n",
       "      <td>0.691633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.713900</td>\n",
       "      <td>0.758809</td>\n",
       "      <td>0.697937</td>\n",
       "      <td>0.698082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.693600</td>\n",
       "      <td>0.762034</td>\n",
       "      <td>0.692332</td>\n",
       "      <td>0.692984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.691200</td>\n",
       "      <td>0.748504</td>\n",
       "      <td>0.694823</td>\n",
       "      <td>0.698046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.669100</td>\n",
       "      <td>0.760627</td>\n",
       "      <td>0.693967</td>\n",
       "      <td>0.694622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.665000</td>\n",
       "      <td>0.771360</td>\n",
       "      <td>0.692176</td>\n",
       "      <td>0.697366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.666500</td>\n",
       "      <td>0.755122</td>\n",
       "      <td>0.696925</td>\n",
       "      <td>0.698218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.646600</td>\n",
       "      <td>0.746392</td>\n",
       "      <td>0.698638</td>\n",
       "      <td>0.702700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.615300</td>\n",
       "      <td>0.760508</td>\n",
       "      <td>0.703542</td>\n",
       "      <td>0.705487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.617400</td>\n",
       "      <td>0.745227</td>\n",
       "      <td>0.708836</td>\n",
       "      <td>0.712453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.613700</td>\n",
       "      <td>0.735532</td>\n",
       "      <td>0.705722</td>\n",
       "      <td>0.708183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.610400</td>\n",
       "      <td>0.748091</td>\n",
       "      <td>0.698871</td>\n",
       "      <td>0.702276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.588600</td>\n",
       "      <td>0.762842</td>\n",
       "      <td>0.707046</td>\n",
       "      <td>0.709658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.574500</td>\n",
       "      <td>0.757048</td>\n",
       "      <td>0.708680</td>\n",
       "      <td>0.711938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.575300</td>\n",
       "      <td>0.760386</td>\n",
       "      <td>0.707513</td>\n",
       "      <td>0.710829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.560900</td>\n",
       "      <td>0.750349</td>\n",
       "      <td>0.705177</td>\n",
       "      <td>0.707291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.543200</td>\n",
       "      <td>0.753750</td>\n",
       "      <td>0.712807</td>\n",
       "      <td>0.716599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.541800</td>\n",
       "      <td>0.762080</td>\n",
       "      <td>0.712262</td>\n",
       "      <td>0.715978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.530500</td>\n",
       "      <td>0.756717</td>\n",
       "      <td>0.712495</td>\n",
       "      <td>0.715370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.545100</td>\n",
       "      <td>0.750199</td>\n",
       "      <td>0.712184</td>\n",
       "      <td>0.715429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunis-ai/TunBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tunis-ai/TunBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75b54fdbeb484da79d6dd3c9de83bcf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51377 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17f5326973ca47ffa38fe59084ad8ed0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12845 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6424' max='6424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6424/6424 10:48, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.226600</td>\n",
       "      <td>1.163268</td>\n",
       "      <td>0.491865</td>\n",
       "      <td>0.381331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.035000</td>\n",
       "      <td>1.016056</td>\n",
       "      <td>0.566913</td>\n",
       "      <td>0.560809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.938700</td>\n",
       "      <td>0.900506</td>\n",
       "      <td>0.644687</td>\n",
       "      <td>0.645455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.892100</td>\n",
       "      <td>0.900711</td>\n",
       "      <td>0.630985</td>\n",
       "      <td>0.628170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.848200</td>\n",
       "      <td>0.859045</td>\n",
       "      <td>0.648657</td>\n",
       "      <td>0.639753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.826200</td>\n",
       "      <td>0.872063</td>\n",
       "      <td>0.651538</td>\n",
       "      <td>0.648664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.809600</td>\n",
       "      <td>0.843801</td>\n",
       "      <td>0.653562</td>\n",
       "      <td>0.656607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.803400</td>\n",
       "      <td>0.827648</td>\n",
       "      <td>0.665006</td>\n",
       "      <td>0.662756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.758600</td>\n",
       "      <td>0.815908</td>\n",
       "      <td>0.674893</td>\n",
       "      <td>0.675445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.757700</td>\n",
       "      <td>0.776920</td>\n",
       "      <td>0.682834</td>\n",
       "      <td>0.683805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.765300</td>\n",
       "      <td>0.809488</td>\n",
       "      <td>0.676761</td>\n",
       "      <td>0.679359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.752000</td>\n",
       "      <td>0.805242</td>\n",
       "      <td>0.676761</td>\n",
       "      <td>0.677014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.714300</td>\n",
       "      <td>0.771439</td>\n",
       "      <td>0.691320</td>\n",
       "      <td>0.691633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.713900</td>\n",
       "      <td>0.758809</td>\n",
       "      <td>0.697937</td>\n",
       "      <td>0.698082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.693600</td>\n",
       "      <td>0.762034</td>\n",
       "      <td>0.692332</td>\n",
       "      <td>0.692984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.691200</td>\n",
       "      <td>0.748504</td>\n",
       "      <td>0.694823</td>\n",
       "      <td>0.698046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.669100</td>\n",
       "      <td>0.760627</td>\n",
       "      <td>0.693967</td>\n",
       "      <td>0.694622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.665000</td>\n",
       "      <td>0.771360</td>\n",
       "      <td>0.692176</td>\n",
       "      <td>0.697366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.666500</td>\n",
       "      <td>0.755122</td>\n",
       "      <td>0.696925</td>\n",
       "      <td>0.698218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.646600</td>\n",
       "      <td>0.746392</td>\n",
       "      <td>0.698638</td>\n",
       "      <td>0.702700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.615300</td>\n",
       "      <td>0.760508</td>\n",
       "      <td>0.703542</td>\n",
       "      <td>0.705487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.617400</td>\n",
       "      <td>0.745227</td>\n",
       "      <td>0.708836</td>\n",
       "      <td>0.712453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.613700</td>\n",
       "      <td>0.735532</td>\n",
       "      <td>0.705722</td>\n",
       "      <td>0.708183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.610400</td>\n",
       "      <td>0.748091</td>\n",
       "      <td>0.698871</td>\n",
       "      <td>0.702276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.588600</td>\n",
       "      <td>0.762842</td>\n",
       "      <td>0.707046</td>\n",
       "      <td>0.709658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.574500</td>\n",
       "      <td>0.757048</td>\n",
       "      <td>0.708680</td>\n",
       "      <td>0.711938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.575300</td>\n",
       "      <td>0.760386</td>\n",
       "      <td>0.707513</td>\n",
       "      <td>0.710829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.560900</td>\n",
       "      <td>0.750349</td>\n",
       "      <td>0.705177</td>\n",
       "      <td>0.707291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.543200</td>\n",
       "      <td>0.753750</td>\n",
       "      <td>0.712807</td>\n",
       "      <td>0.716599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.541800</td>\n",
       "      <td>0.762080</td>\n",
       "      <td>0.712262</td>\n",
       "      <td>0.715978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.530500</td>\n",
       "      <td>0.756717</td>\n",
       "      <td>0.712495</td>\n",
       "      <td>0.715370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.545100</td>\n",
       "      <td>0.750199</td>\n",
       "      <td>0.712184</td>\n",
       "      <td>0.715429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 51377\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 12845\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alger-ia/dziribert, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3154a38af66c4f7780010587e576b433",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51377 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34ddb766bf924aa2b96a085b2cc9ce51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12845 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6424' max='6424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6424/6424 11:03, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.461300</td>\n",
       "      <td>0.358420</td>\n",
       "      <td>0.870455</td>\n",
       "      <td>0.872621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.309992</td>\n",
       "      <td>0.885792</td>\n",
       "      <td>0.884752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.310700</td>\n",
       "      <td>0.297902</td>\n",
       "      <td>0.891242</td>\n",
       "      <td>0.892883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.287400</td>\n",
       "      <td>0.286041</td>\n",
       "      <td>0.897392</td>\n",
       "      <td>0.898491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.154800</td>\n",
       "      <td>0.310673</td>\n",
       "      <td>0.902219</td>\n",
       "      <td>0.903613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.288846</td>\n",
       "      <td>0.902219</td>\n",
       "      <td>0.903333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.142800</td>\n",
       "      <td>0.310472</td>\n",
       "      <td>0.908058</td>\n",
       "      <td>0.908035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.139200</td>\n",
       "      <td>0.295400</td>\n",
       "      <td>0.908213</td>\n",
       "      <td>0.908042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.064600</td>\n",
       "      <td>0.438836</td>\n",
       "      <td>0.901285</td>\n",
       "      <td>0.903076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.078400</td>\n",
       "      <td>0.400521</td>\n",
       "      <td>0.906111</td>\n",
       "      <td>0.905874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.079700</td>\n",
       "      <td>0.415967</td>\n",
       "      <td>0.906189</td>\n",
       "      <td>0.906653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.076600</td>\n",
       "      <td>0.393121</td>\n",
       "      <td>0.907201</td>\n",
       "      <td>0.907465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.043900</td>\n",
       "      <td>0.518807</td>\n",
       "      <td>0.906656</td>\n",
       "      <td>0.906975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.046600</td>\n",
       "      <td>0.459377</td>\n",
       "      <td>0.906501</td>\n",
       "      <td>0.907258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>0.438239</td>\n",
       "      <td>0.907357</td>\n",
       "      <td>0.908313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.044600</td>\n",
       "      <td>0.449651</td>\n",
       "      <td>0.908680</td>\n",
       "      <td>0.908582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.028400</td>\n",
       "      <td>0.527843</td>\n",
       "      <td>0.906345</td>\n",
       "      <td>0.906925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.026900</td>\n",
       "      <td>0.550570</td>\n",
       "      <td>0.907435</td>\n",
       "      <td>0.908655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.032500</td>\n",
       "      <td>0.549315</td>\n",
       "      <td>0.908447</td>\n",
       "      <td>0.909093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.037300</td>\n",
       "      <td>0.526321</td>\n",
       "      <td>0.907046</td>\n",
       "      <td>0.907565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.016500</td>\n",
       "      <td>0.592336</td>\n",
       "      <td>0.905878</td>\n",
       "      <td>0.906238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.021900</td>\n",
       "      <td>0.599020</td>\n",
       "      <td>0.905021</td>\n",
       "      <td>0.905825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.028600</td>\n",
       "      <td>0.598586</td>\n",
       "      <td>0.907435</td>\n",
       "      <td>0.907859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>0.564565</td>\n",
       "      <td>0.909615</td>\n",
       "      <td>0.910075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.016500</td>\n",
       "      <td>0.571345</td>\n",
       "      <td>0.909926</td>\n",
       "      <td>0.910309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.015600</td>\n",
       "      <td>0.575791</td>\n",
       "      <td>0.911016</td>\n",
       "      <td>0.911787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.017900</td>\n",
       "      <td>0.585953</td>\n",
       "      <td>0.910393</td>\n",
       "      <td>0.910652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.014600</td>\n",
       "      <td>0.602387</td>\n",
       "      <td>0.910237</td>\n",
       "      <td>0.911059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.015700</td>\n",
       "      <td>0.597046</td>\n",
       "      <td>0.911094</td>\n",
       "      <td>0.911572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.013200</td>\n",
       "      <td>0.614476</td>\n",
       "      <td>0.910782</td>\n",
       "      <td>0.911449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.010700</td>\n",
       "      <td>0.612247</td>\n",
       "      <td>0.911483</td>\n",
       "      <td>0.911943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>0.614341</td>\n",
       "      <td>0.911172</td>\n",
       "      <td>0.911700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alger-ia/dziribert, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c282012a40547e996dd785b779eabef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51377 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2447401ee204c55a597b6a6320cf15f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12845 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6424' max='6424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6424/6424 11:05, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.461300</td>\n",
       "      <td>0.358420</td>\n",
       "      <td>0.870455</td>\n",
       "      <td>0.872621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.309992</td>\n",
       "      <td>0.885792</td>\n",
       "      <td>0.884752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.310700</td>\n",
       "      <td>0.297902</td>\n",
       "      <td>0.891242</td>\n",
       "      <td>0.892883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.287400</td>\n",
       "      <td>0.286041</td>\n",
       "      <td>0.897392</td>\n",
       "      <td>0.898491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.154800</td>\n",
       "      <td>0.310673</td>\n",
       "      <td>0.902219</td>\n",
       "      <td>0.903613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.288846</td>\n",
       "      <td>0.902219</td>\n",
       "      <td>0.903333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.142800</td>\n",
       "      <td>0.310472</td>\n",
       "      <td>0.908058</td>\n",
       "      <td>0.908035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.139200</td>\n",
       "      <td>0.295400</td>\n",
       "      <td>0.908213</td>\n",
       "      <td>0.908042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.064600</td>\n",
       "      <td>0.438836</td>\n",
       "      <td>0.901285</td>\n",
       "      <td>0.903076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.078400</td>\n",
       "      <td>0.400521</td>\n",
       "      <td>0.906111</td>\n",
       "      <td>0.905874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.079700</td>\n",
       "      <td>0.415967</td>\n",
       "      <td>0.906189</td>\n",
       "      <td>0.906653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.076600</td>\n",
       "      <td>0.393121</td>\n",
       "      <td>0.907201</td>\n",
       "      <td>0.907465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.043900</td>\n",
       "      <td>0.518807</td>\n",
       "      <td>0.906656</td>\n",
       "      <td>0.906975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.046600</td>\n",
       "      <td>0.459377</td>\n",
       "      <td>0.906501</td>\n",
       "      <td>0.907258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>0.438239</td>\n",
       "      <td>0.907357</td>\n",
       "      <td>0.908313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.044600</td>\n",
       "      <td>0.449651</td>\n",
       "      <td>0.908680</td>\n",
       "      <td>0.908582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.028400</td>\n",
       "      <td>0.527843</td>\n",
       "      <td>0.906345</td>\n",
       "      <td>0.906925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.026900</td>\n",
       "      <td>0.550570</td>\n",
       "      <td>0.907435</td>\n",
       "      <td>0.908655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.032500</td>\n",
       "      <td>0.549315</td>\n",
       "      <td>0.908447</td>\n",
       "      <td>0.909093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.037300</td>\n",
       "      <td>0.526321</td>\n",
       "      <td>0.907046</td>\n",
       "      <td>0.907565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.016500</td>\n",
       "      <td>0.592336</td>\n",
       "      <td>0.905878</td>\n",
       "      <td>0.906238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.021900</td>\n",
       "      <td>0.599020</td>\n",
       "      <td>0.905021</td>\n",
       "      <td>0.905825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.028600</td>\n",
       "      <td>0.598586</td>\n",
       "      <td>0.907435</td>\n",
       "      <td>0.907859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>0.564565</td>\n",
       "      <td>0.909615</td>\n",
       "      <td>0.910075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.016500</td>\n",
       "      <td>0.571345</td>\n",
       "      <td>0.909926</td>\n",
       "      <td>0.910309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.015600</td>\n",
       "      <td>0.575791</td>\n",
       "      <td>0.911016</td>\n",
       "      <td>0.911787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.017900</td>\n",
       "      <td>0.585953</td>\n",
       "      <td>0.910393</td>\n",
       "      <td>0.910652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.014600</td>\n",
       "      <td>0.602387</td>\n",
       "      <td>0.910237</td>\n",
       "      <td>0.911059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.015700</td>\n",
       "      <td>0.597046</td>\n",
       "      <td>0.911094</td>\n",
       "      <td>0.911572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.013200</td>\n",
       "      <td>0.614476</td>\n",
       "      <td>0.910782</td>\n",
       "      <td>0.911449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.010700</td>\n",
       "      <td>0.612247</td>\n",
       "      <td>0.911483</td>\n",
       "      <td>0.911943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>0.614341</td>\n",
       "      <td>0.911172</td>\n",
       "      <td>0.911700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alger-ia/dziribert, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c4e8ad7c7b640bfb7897a50dedbbfef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51377 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39bd7ff253fd47a79ccb150f9bac5af5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12845 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6424' max='6424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6424/6424 11:05, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.461300</td>\n",
       "      <td>0.358420</td>\n",
       "      <td>0.870455</td>\n",
       "      <td>0.872621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.309992</td>\n",
       "      <td>0.885792</td>\n",
       "      <td>0.884752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.310700</td>\n",
       "      <td>0.297902</td>\n",
       "      <td>0.891242</td>\n",
       "      <td>0.892883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.287400</td>\n",
       "      <td>0.286041</td>\n",
       "      <td>0.897392</td>\n",
       "      <td>0.898491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.154800</td>\n",
       "      <td>0.310673</td>\n",
       "      <td>0.902219</td>\n",
       "      <td>0.903613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.288846</td>\n",
       "      <td>0.902219</td>\n",
       "      <td>0.903333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.142800</td>\n",
       "      <td>0.310472</td>\n",
       "      <td>0.908058</td>\n",
       "      <td>0.908035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.139200</td>\n",
       "      <td>0.295400</td>\n",
       "      <td>0.908213</td>\n",
       "      <td>0.908042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.064600</td>\n",
       "      <td>0.438836</td>\n",
       "      <td>0.901285</td>\n",
       "      <td>0.903076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.078400</td>\n",
       "      <td>0.400521</td>\n",
       "      <td>0.906111</td>\n",
       "      <td>0.905874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.079700</td>\n",
       "      <td>0.415967</td>\n",
       "      <td>0.906189</td>\n",
       "      <td>0.906653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.076600</td>\n",
       "      <td>0.393121</td>\n",
       "      <td>0.907201</td>\n",
       "      <td>0.907465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.043900</td>\n",
       "      <td>0.518807</td>\n",
       "      <td>0.906656</td>\n",
       "      <td>0.906975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.046600</td>\n",
       "      <td>0.459377</td>\n",
       "      <td>0.906501</td>\n",
       "      <td>0.907258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>0.438239</td>\n",
       "      <td>0.907357</td>\n",
       "      <td>0.908313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.044600</td>\n",
       "      <td>0.449651</td>\n",
       "      <td>0.908680</td>\n",
       "      <td>0.908582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.028400</td>\n",
       "      <td>0.527843</td>\n",
       "      <td>0.906345</td>\n",
       "      <td>0.906925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.026900</td>\n",
       "      <td>0.550570</td>\n",
       "      <td>0.907435</td>\n",
       "      <td>0.908655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.032500</td>\n",
       "      <td>0.549315</td>\n",
       "      <td>0.908447</td>\n",
       "      <td>0.909093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.037300</td>\n",
       "      <td>0.526321</td>\n",
       "      <td>0.907046</td>\n",
       "      <td>0.907565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.016500</td>\n",
       "      <td>0.592336</td>\n",
       "      <td>0.905878</td>\n",
       "      <td>0.906238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.021900</td>\n",
       "      <td>0.599020</td>\n",
       "      <td>0.905021</td>\n",
       "      <td>0.905825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.028600</td>\n",
       "      <td>0.598586</td>\n",
       "      <td>0.907435</td>\n",
       "      <td>0.907859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>0.564565</td>\n",
       "      <td>0.909615</td>\n",
       "      <td>0.910075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.016500</td>\n",
       "      <td>0.571345</td>\n",
       "      <td>0.909926</td>\n",
       "      <td>0.910309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.015600</td>\n",
       "      <td>0.575791</td>\n",
       "      <td>0.911016</td>\n",
       "      <td>0.911787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.017900</td>\n",
       "      <td>0.585953</td>\n",
       "      <td>0.910393</td>\n",
       "      <td>0.910652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.014600</td>\n",
       "      <td>0.602387</td>\n",
       "      <td>0.910237</td>\n",
       "      <td>0.911059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.015700</td>\n",
       "      <td>0.597046</td>\n",
       "      <td>0.911094</td>\n",
       "      <td>0.911572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.013200</td>\n",
       "      <td>0.614476</td>\n",
       "      <td>0.910782</td>\n",
       "      <td>0.911449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.010700</td>\n",
       "      <td>0.612247</td>\n",
       "      <td>0.911483</td>\n",
       "      <td>0.911943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>0.614341</td>\n",
       "      <td>0.911172</td>\n",
       "      <td>0.911700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alger-ia/dziribert, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d01b32b6d6a4ba4aed337ca0be6f9a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51377 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90eb3e14179e499f89d6826378a05a62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12845 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6424' max='6424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6424/6424 11:03, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.490200</td>\n",
       "      <td>0.391245</td>\n",
       "      <td>0.855274</td>\n",
       "      <td>0.856077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.339400</td>\n",
       "      <td>0.299853</td>\n",
       "      <td>0.890152</td>\n",
       "      <td>0.891654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.312900</td>\n",
       "      <td>0.278274</td>\n",
       "      <td>0.894745</td>\n",
       "      <td>0.897568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.287600</td>\n",
       "      <td>0.270149</td>\n",
       "      <td>0.903931</td>\n",
       "      <td>0.905452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.154200</td>\n",
       "      <td>0.275382</td>\n",
       "      <td>0.906734</td>\n",
       "      <td>0.908257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.153200</td>\n",
       "      <td>0.299103</td>\n",
       "      <td>0.908992</td>\n",
       "      <td>0.910840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.159000</td>\n",
       "      <td>0.272687</td>\n",
       "      <td>0.910782</td>\n",
       "      <td>0.912365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.150900</td>\n",
       "      <td>0.290581</td>\n",
       "      <td>0.909615</td>\n",
       "      <td>0.911573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.070100</td>\n",
       "      <td>0.400458</td>\n",
       "      <td>0.904632</td>\n",
       "      <td>0.904987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.074800</td>\n",
       "      <td>0.395152</td>\n",
       "      <td>0.905956</td>\n",
       "      <td>0.907636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.077800</td>\n",
       "      <td>0.382139</td>\n",
       "      <td>0.910549</td>\n",
       "      <td>0.913061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.084700</td>\n",
       "      <td>0.341619</td>\n",
       "      <td>0.909303</td>\n",
       "      <td>0.911070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.046100</td>\n",
       "      <td>0.430568</td>\n",
       "      <td>0.910938</td>\n",
       "      <td>0.911394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.047800</td>\n",
       "      <td>0.409216</td>\n",
       "      <td>0.908603</td>\n",
       "      <td>0.909688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.044200</td>\n",
       "      <td>0.495937</td>\n",
       "      <td>0.908291</td>\n",
       "      <td>0.908540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.052900</td>\n",
       "      <td>0.427063</td>\n",
       "      <td>0.911250</td>\n",
       "      <td>0.912557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.026200</td>\n",
       "      <td>0.515139</td>\n",
       "      <td>0.909148</td>\n",
       "      <td>0.909850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.035800</td>\n",
       "      <td>0.492131</td>\n",
       "      <td>0.912184</td>\n",
       "      <td>0.913917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.027800</td>\n",
       "      <td>0.492492</td>\n",
       "      <td>0.911717</td>\n",
       "      <td>0.912944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.030200</td>\n",
       "      <td>0.517018</td>\n",
       "      <td>0.910782</td>\n",
       "      <td>0.912171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.019400</td>\n",
       "      <td>0.581988</td>\n",
       "      <td>0.910237</td>\n",
       "      <td>0.912280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.020100</td>\n",
       "      <td>0.562227</td>\n",
       "      <td>0.912962</td>\n",
       "      <td>0.914504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.021000</td>\n",
       "      <td>0.553631</td>\n",
       "      <td>0.912028</td>\n",
       "      <td>0.913269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.017600</td>\n",
       "      <td>0.580659</td>\n",
       "      <td>0.913896</td>\n",
       "      <td>0.914785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.013700</td>\n",
       "      <td>0.583367</td>\n",
       "      <td>0.914675</td>\n",
       "      <td>0.916346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.015400</td>\n",
       "      <td>0.583449</td>\n",
       "      <td>0.914597</td>\n",
       "      <td>0.916000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.012600</td>\n",
       "      <td>0.593339</td>\n",
       "      <td>0.914441</td>\n",
       "      <td>0.916103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.015900</td>\n",
       "      <td>0.588234</td>\n",
       "      <td>0.914519</td>\n",
       "      <td>0.916190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.011400</td>\n",
       "      <td>0.599289</td>\n",
       "      <td>0.914519</td>\n",
       "      <td>0.916125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.012200</td>\n",
       "      <td>0.607426</td>\n",
       "      <td>0.913585</td>\n",
       "      <td>0.915137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.011500</td>\n",
       "      <td>0.607620</td>\n",
       "      <td>0.913663</td>\n",
       "      <td>0.915375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.011600</td>\n",
       "      <td>0.606789</td>\n",
       "      <td>0.914208</td>\n",
       "      <td>0.915919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alger-ia/dziribert, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0425f21f78d47d0a62edf528f7a54a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51377 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "270dac69199b477f80c48f295b641583",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12845 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6424' max='6424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6424/6424 11:02, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.490200</td>\n",
       "      <td>0.391245</td>\n",
       "      <td>0.855274</td>\n",
       "      <td>0.856077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.339400</td>\n",
       "      <td>0.299853</td>\n",
       "      <td>0.890152</td>\n",
       "      <td>0.891654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.312900</td>\n",
       "      <td>0.278274</td>\n",
       "      <td>0.894745</td>\n",
       "      <td>0.897568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.287600</td>\n",
       "      <td>0.270149</td>\n",
       "      <td>0.903931</td>\n",
       "      <td>0.905452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.154200</td>\n",
       "      <td>0.275382</td>\n",
       "      <td>0.906734</td>\n",
       "      <td>0.908257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.153200</td>\n",
       "      <td>0.299103</td>\n",
       "      <td>0.908992</td>\n",
       "      <td>0.910840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.159000</td>\n",
       "      <td>0.272687</td>\n",
       "      <td>0.910782</td>\n",
       "      <td>0.912365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.150900</td>\n",
       "      <td>0.290581</td>\n",
       "      <td>0.909615</td>\n",
       "      <td>0.911573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.070100</td>\n",
       "      <td>0.400458</td>\n",
       "      <td>0.904632</td>\n",
       "      <td>0.904987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.074800</td>\n",
       "      <td>0.395152</td>\n",
       "      <td>0.905956</td>\n",
       "      <td>0.907636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.077800</td>\n",
       "      <td>0.382139</td>\n",
       "      <td>0.910549</td>\n",
       "      <td>0.913061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.084700</td>\n",
       "      <td>0.341619</td>\n",
       "      <td>0.909303</td>\n",
       "      <td>0.911070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.046100</td>\n",
       "      <td>0.430568</td>\n",
       "      <td>0.910938</td>\n",
       "      <td>0.911394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.047800</td>\n",
       "      <td>0.409216</td>\n",
       "      <td>0.908603</td>\n",
       "      <td>0.909688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.044200</td>\n",
       "      <td>0.495937</td>\n",
       "      <td>0.908291</td>\n",
       "      <td>0.908540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.052900</td>\n",
       "      <td>0.427063</td>\n",
       "      <td>0.911250</td>\n",
       "      <td>0.912557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.026200</td>\n",
       "      <td>0.515139</td>\n",
       "      <td>0.909148</td>\n",
       "      <td>0.909850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.035800</td>\n",
       "      <td>0.492131</td>\n",
       "      <td>0.912184</td>\n",
       "      <td>0.913917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.027800</td>\n",
       "      <td>0.492492</td>\n",
       "      <td>0.911717</td>\n",
       "      <td>0.912944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.030200</td>\n",
       "      <td>0.517018</td>\n",
       "      <td>0.910782</td>\n",
       "      <td>0.912171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.019400</td>\n",
       "      <td>0.581988</td>\n",
       "      <td>0.910237</td>\n",
       "      <td>0.912280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.020100</td>\n",
       "      <td>0.562227</td>\n",
       "      <td>0.912962</td>\n",
       "      <td>0.914504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.021000</td>\n",
       "      <td>0.553631</td>\n",
       "      <td>0.912028</td>\n",
       "      <td>0.913269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.017600</td>\n",
       "      <td>0.580659</td>\n",
       "      <td>0.913896</td>\n",
       "      <td>0.914785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.013700</td>\n",
       "      <td>0.583367</td>\n",
       "      <td>0.914675</td>\n",
       "      <td>0.916346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.015400</td>\n",
       "      <td>0.583449</td>\n",
       "      <td>0.914597</td>\n",
       "      <td>0.916000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.012600</td>\n",
       "      <td>0.593339</td>\n",
       "      <td>0.914441</td>\n",
       "      <td>0.916103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.015900</td>\n",
       "      <td>0.588234</td>\n",
       "      <td>0.914519</td>\n",
       "      <td>0.916190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.011400</td>\n",
       "      <td>0.599289</td>\n",
       "      <td>0.914519</td>\n",
       "      <td>0.916125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.012200</td>\n",
       "      <td>0.607426</td>\n",
       "      <td>0.913585</td>\n",
       "      <td>0.915137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.011500</td>\n",
       "      <td>0.607620</td>\n",
       "      <td>0.913663</td>\n",
       "      <td>0.915375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.011600</td>\n",
       "      <td>0.606789</td>\n",
       "      <td>0.914208</td>\n",
       "      <td>0.915919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alger-ia/dziribert, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f6d3112cca54ff68704317ff54269c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51377 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98b58afc5beb477d927f916fc6019bd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12845 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6424' max='6424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6424/6424 11:05, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.490200</td>\n",
       "      <td>0.391245</td>\n",
       "      <td>0.855274</td>\n",
       "      <td>0.856077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.339400</td>\n",
       "      <td>0.299853</td>\n",
       "      <td>0.890152</td>\n",
       "      <td>0.891654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.312900</td>\n",
       "      <td>0.278274</td>\n",
       "      <td>0.894745</td>\n",
       "      <td>0.897568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.287600</td>\n",
       "      <td>0.270149</td>\n",
       "      <td>0.903931</td>\n",
       "      <td>0.905452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.154200</td>\n",
       "      <td>0.275382</td>\n",
       "      <td>0.906734</td>\n",
       "      <td>0.908257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.153200</td>\n",
       "      <td>0.299103</td>\n",
       "      <td>0.908992</td>\n",
       "      <td>0.910840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.159000</td>\n",
       "      <td>0.272687</td>\n",
       "      <td>0.910782</td>\n",
       "      <td>0.912365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.150900</td>\n",
       "      <td>0.290581</td>\n",
       "      <td>0.909615</td>\n",
       "      <td>0.911573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.070100</td>\n",
       "      <td>0.400458</td>\n",
       "      <td>0.904632</td>\n",
       "      <td>0.904987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.074800</td>\n",
       "      <td>0.395152</td>\n",
       "      <td>0.905956</td>\n",
       "      <td>0.907636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.077800</td>\n",
       "      <td>0.382139</td>\n",
       "      <td>0.910549</td>\n",
       "      <td>0.913061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.084700</td>\n",
       "      <td>0.341619</td>\n",
       "      <td>0.909303</td>\n",
       "      <td>0.911070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.046100</td>\n",
       "      <td>0.430568</td>\n",
       "      <td>0.910938</td>\n",
       "      <td>0.911394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.047800</td>\n",
       "      <td>0.409216</td>\n",
       "      <td>0.908603</td>\n",
       "      <td>0.909688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.044200</td>\n",
       "      <td>0.495937</td>\n",
       "      <td>0.908291</td>\n",
       "      <td>0.908540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.052900</td>\n",
       "      <td>0.427063</td>\n",
       "      <td>0.911250</td>\n",
       "      <td>0.912557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.026200</td>\n",
       "      <td>0.515139</td>\n",
       "      <td>0.909148</td>\n",
       "      <td>0.909850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.035800</td>\n",
       "      <td>0.492131</td>\n",
       "      <td>0.912184</td>\n",
       "      <td>0.913917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.027800</td>\n",
       "      <td>0.492492</td>\n",
       "      <td>0.911717</td>\n",
       "      <td>0.912944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.030200</td>\n",
       "      <td>0.517018</td>\n",
       "      <td>0.910782</td>\n",
       "      <td>0.912171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.019400</td>\n",
       "      <td>0.581988</td>\n",
       "      <td>0.910237</td>\n",
       "      <td>0.912280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.020100</td>\n",
       "      <td>0.562227</td>\n",
       "      <td>0.912962</td>\n",
       "      <td>0.914504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.021000</td>\n",
       "      <td>0.553631</td>\n",
       "      <td>0.912028</td>\n",
       "      <td>0.913269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.017600</td>\n",
       "      <td>0.580659</td>\n",
       "      <td>0.913896</td>\n",
       "      <td>0.914785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.013700</td>\n",
       "      <td>0.583367</td>\n",
       "      <td>0.914675</td>\n",
       "      <td>0.916346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.015400</td>\n",
       "      <td>0.583449</td>\n",
       "      <td>0.914597</td>\n",
       "      <td>0.916000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.012600</td>\n",
       "      <td>0.593339</td>\n",
       "      <td>0.914441</td>\n",
       "      <td>0.916103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.015900</td>\n",
       "      <td>0.588234</td>\n",
       "      <td>0.914519</td>\n",
       "      <td>0.916190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.011400</td>\n",
       "      <td>0.599289</td>\n",
       "      <td>0.914519</td>\n",
       "      <td>0.916125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.012200</td>\n",
       "      <td>0.607426</td>\n",
       "      <td>0.913585</td>\n",
       "      <td>0.915137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.011500</td>\n",
       "      <td>0.607620</td>\n",
       "      <td>0.913663</td>\n",
       "      <td>0.915375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.011600</td>\n",
       "      <td>0.606789</td>\n",
       "      <td>0.914208</td>\n",
       "      <td>0.915919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alger-ia/dziribert, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ecf7049574a4d91b4aabd021d35f40e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51377 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c987507cdcbb4df69427151f24e6dc1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12845 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6424' max='6424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6424/6424 11:04, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.470500</td>\n",
       "      <td>0.360773</td>\n",
       "      <td>0.868120</td>\n",
       "      <td>0.869979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.349100</td>\n",
       "      <td>0.301704</td>\n",
       "      <td>0.889763</td>\n",
       "      <td>0.891234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.298400</td>\n",
       "      <td>0.280580</td>\n",
       "      <td>0.898482</td>\n",
       "      <td>0.898865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.282800</td>\n",
       "      <td>0.289164</td>\n",
       "      <td>0.899105</td>\n",
       "      <td>0.899826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.346199</td>\n",
       "      <td>0.896302</td>\n",
       "      <td>0.896387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.144000</td>\n",
       "      <td>0.299579</td>\n",
       "      <td>0.909225</td>\n",
       "      <td>0.909947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.149400</td>\n",
       "      <td>0.345643</td>\n",
       "      <td>0.899494</td>\n",
       "      <td>0.899366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.154400</td>\n",
       "      <td>0.300701</td>\n",
       "      <td>0.906501</td>\n",
       "      <td>0.906906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.076400</td>\n",
       "      <td>0.359567</td>\n",
       "      <td>0.905878</td>\n",
       "      <td>0.906095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.075100</td>\n",
       "      <td>0.392353</td>\n",
       "      <td>0.907591</td>\n",
       "      <td>0.908055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.080400</td>\n",
       "      <td>0.375369</td>\n",
       "      <td>0.905255</td>\n",
       "      <td>0.905155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.080600</td>\n",
       "      <td>0.377763</td>\n",
       "      <td>0.904476</td>\n",
       "      <td>0.905389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.048500</td>\n",
       "      <td>0.465705</td>\n",
       "      <td>0.908680</td>\n",
       "      <td>0.909165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.045900</td>\n",
       "      <td>0.488490</td>\n",
       "      <td>0.906734</td>\n",
       "      <td>0.906939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.049100</td>\n",
       "      <td>0.454842</td>\n",
       "      <td>0.905644</td>\n",
       "      <td>0.905724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.047400</td>\n",
       "      <td>0.471237</td>\n",
       "      <td>0.907357</td>\n",
       "      <td>0.907828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.029600</td>\n",
       "      <td>0.549522</td>\n",
       "      <td>0.906423</td>\n",
       "      <td>0.907328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.027900</td>\n",
       "      <td>0.565442</td>\n",
       "      <td>0.905722</td>\n",
       "      <td>0.906075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.031200</td>\n",
       "      <td>0.552028</td>\n",
       "      <td>0.906578</td>\n",
       "      <td>0.907166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.029600</td>\n",
       "      <td>0.535323</td>\n",
       "      <td>0.908058</td>\n",
       "      <td>0.908731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.022900</td>\n",
       "      <td>0.576745</td>\n",
       "      <td>0.906345</td>\n",
       "      <td>0.906365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.020400</td>\n",
       "      <td>0.619522</td>\n",
       "      <td>0.907046</td>\n",
       "      <td>0.907521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.018900</td>\n",
       "      <td>0.609368</td>\n",
       "      <td>0.908914</td>\n",
       "      <td>0.909133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.025300</td>\n",
       "      <td>0.603616</td>\n",
       "      <td>0.907902</td>\n",
       "      <td>0.908504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.019300</td>\n",
       "      <td>0.606813</td>\n",
       "      <td>0.908914</td>\n",
       "      <td>0.909588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.012700</td>\n",
       "      <td>0.624625</td>\n",
       "      <td>0.907746</td>\n",
       "      <td>0.908176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.017900</td>\n",
       "      <td>0.601087</td>\n",
       "      <td>0.908992</td>\n",
       "      <td>0.909379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.013500</td>\n",
       "      <td>0.610807</td>\n",
       "      <td>0.907591</td>\n",
       "      <td>0.907954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.011900</td>\n",
       "      <td>0.629575</td>\n",
       "      <td>0.907980</td>\n",
       "      <td>0.908671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.012200</td>\n",
       "      <td>0.637306</td>\n",
       "      <td>0.906968</td>\n",
       "      <td>0.907523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.011400</td>\n",
       "      <td>0.631842</td>\n",
       "      <td>0.907746</td>\n",
       "      <td>0.908061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.013800</td>\n",
       "      <td>0.628243</td>\n",
       "      <td>0.907824</td>\n",
       "      <td>0.908299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alger-ia/dziribert, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fd52aa9b1634c45a90a1acc33e7d9ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51377 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d72f0ae3a1a449dbca68b7614507ff5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12845 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6424' max='6424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6424/6424 11:04, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.470500</td>\n",
       "      <td>0.360773</td>\n",
       "      <td>0.868120</td>\n",
       "      <td>0.869979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.349100</td>\n",
       "      <td>0.301704</td>\n",
       "      <td>0.889763</td>\n",
       "      <td>0.891234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.298400</td>\n",
       "      <td>0.280580</td>\n",
       "      <td>0.898482</td>\n",
       "      <td>0.898865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.282800</td>\n",
       "      <td>0.289164</td>\n",
       "      <td>0.899105</td>\n",
       "      <td>0.899826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.346199</td>\n",
       "      <td>0.896302</td>\n",
       "      <td>0.896387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.144000</td>\n",
       "      <td>0.299579</td>\n",
       "      <td>0.909225</td>\n",
       "      <td>0.909947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.149400</td>\n",
       "      <td>0.345643</td>\n",
       "      <td>0.899494</td>\n",
       "      <td>0.899366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.154400</td>\n",
       "      <td>0.300701</td>\n",
       "      <td>0.906501</td>\n",
       "      <td>0.906906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.076400</td>\n",
       "      <td>0.359567</td>\n",
       "      <td>0.905878</td>\n",
       "      <td>0.906095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.075100</td>\n",
       "      <td>0.392353</td>\n",
       "      <td>0.907591</td>\n",
       "      <td>0.908055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.080400</td>\n",
       "      <td>0.375369</td>\n",
       "      <td>0.905255</td>\n",
       "      <td>0.905155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.080600</td>\n",
       "      <td>0.377763</td>\n",
       "      <td>0.904476</td>\n",
       "      <td>0.905389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.048500</td>\n",
       "      <td>0.465705</td>\n",
       "      <td>0.908680</td>\n",
       "      <td>0.909165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.045900</td>\n",
       "      <td>0.488490</td>\n",
       "      <td>0.906734</td>\n",
       "      <td>0.906939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.049100</td>\n",
       "      <td>0.454842</td>\n",
       "      <td>0.905644</td>\n",
       "      <td>0.905724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.047400</td>\n",
       "      <td>0.471237</td>\n",
       "      <td>0.907357</td>\n",
       "      <td>0.907828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.029600</td>\n",
       "      <td>0.549522</td>\n",
       "      <td>0.906423</td>\n",
       "      <td>0.907328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.027900</td>\n",
       "      <td>0.565442</td>\n",
       "      <td>0.905722</td>\n",
       "      <td>0.906075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.031200</td>\n",
       "      <td>0.552028</td>\n",
       "      <td>0.906578</td>\n",
       "      <td>0.907166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.029600</td>\n",
       "      <td>0.535323</td>\n",
       "      <td>0.908058</td>\n",
       "      <td>0.908731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.022900</td>\n",
       "      <td>0.576745</td>\n",
       "      <td>0.906345</td>\n",
       "      <td>0.906365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.020400</td>\n",
       "      <td>0.619522</td>\n",
       "      <td>0.907046</td>\n",
       "      <td>0.907521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.018900</td>\n",
       "      <td>0.609368</td>\n",
       "      <td>0.908914</td>\n",
       "      <td>0.909133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.025300</td>\n",
       "      <td>0.603616</td>\n",
       "      <td>0.907902</td>\n",
       "      <td>0.908504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.019300</td>\n",
       "      <td>0.606813</td>\n",
       "      <td>0.908914</td>\n",
       "      <td>0.909588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.012700</td>\n",
       "      <td>0.624625</td>\n",
       "      <td>0.907746</td>\n",
       "      <td>0.908176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.017900</td>\n",
       "      <td>0.601087</td>\n",
       "      <td>0.908992</td>\n",
       "      <td>0.909379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.013500</td>\n",
       "      <td>0.610807</td>\n",
       "      <td>0.907591</td>\n",
       "      <td>0.907954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.011900</td>\n",
       "      <td>0.629575</td>\n",
       "      <td>0.907980</td>\n",
       "      <td>0.908671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.012200</td>\n",
       "      <td>0.637306</td>\n",
       "      <td>0.906968</td>\n",
       "      <td>0.907523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.011400</td>\n",
       "      <td>0.631842</td>\n",
       "      <td>0.907746</td>\n",
       "      <td>0.908061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.013800</td>\n",
       "      <td>0.628243</td>\n",
       "      <td>0.907824</td>\n",
       "      <td>0.908299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alger-ia/dziribert, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6c89ee8a7cb495dbddeadc381ebfb8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51377 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4cea5388a5846a6b798f34c341df7da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12845 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6424' max='6424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6424/6424 11:04, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.470500</td>\n",
       "      <td>0.360773</td>\n",
       "      <td>0.868120</td>\n",
       "      <td>0.869979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.349100</td>\n",
       "      <td>0.301704</td>\n",
       "      <td>0.889763</td>\n",
       "      <td>0.891234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.298400</td>\n",
       "      <td>0.280580</td>\n",
       "      <td>0.898482</td>\n",
       "      <td>0.898865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.282800</td>\n",
       "      <td>0.289164</td>\n",
       "      <td>0.899105</td>\n",
       "      <td>0.899826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.346199</td>\n",
       "      <td>0.896302</td>\n",
       "      <td>0.896387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.144000</td>\n",
       "      <td>0.299579</td>\n",
       "      <td>0.909225</td>\n",
       "      <td>0.909947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.149400</td>\n",
       "      <td>0.345643</td>\n",
       "      <td>0.899494</td>\n",
       "      <td>0.899366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.154400</td>\n",
       "      <td>0.300701</td>\n",
       "      <td>0.906501</td>\n",
       "      <td>0.906906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.076400</td>\n",
       "      <td>0.359567</td>\n",
       "      <td>0.905878</td>\n",
       "      <td>0.906095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.075100</td>\n",
       "      <td>0.392353</td>\n",
       "      <td>0.907591</td>\n",
       "      <td>0.908055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.080400</td>\n",
       "      <td>0.375369</td>\n",
       "      <td>0.905255</td>\n",
       "      <td>0.905155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.080600</td>\n",
       "      <td>0.377763</td>\n",
       "      <td>0.904476</td>\n",
       "      <td>0.905389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.048500</td>\n",
       "      <td>0.465705</td>\n",
       "      <td>0.908680</td>\n",
       "      <td>0.909165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.045900</td>\n",
       "      <td>0.488490</td>\n",
       "      <td>0.906734</td>\n",
       "      <td>0.906939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.049100</td>\n",
       "      <td>0.454842</td>\n",
       "      <td>0.905644</td>\n",
       "      <td>0.905724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.047400</td>\n",
       "      <td>0.471237</td>\n",
       "      <td>0.907357</td>\n",
       "      <td>0.907828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.029600</td>\n",
       "      <td>0.549522</td>\n",
       "      <td>0.906423</td>\n",
       "      <td>0.907328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.027900</td>\n",
       "      <td>0.565442</td>\n",
       "      <td>0.905722</td>\n",
       "      <td>0.906075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.031200</td>\n",
       "      <td>0.552028</td>\n",
       "      <td>0.906578</td>\n",
       "      <td>0.907166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.029600</td>\n",
       "      <td>0.535323</td>\n",
       "      <td>0.908058</td>\n",
       "      <td>0.908731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.022900</td>\n",
       "      <td>0.576745</td>\n",
       "      <td>0.906345</td>\n",
       "      <td>0.906365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.020400</td>\n",
       "      <td>0.619522</td>\n",
       "      <td>0.907046</td>\n",
       "      <td>0.907521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.018900</td>\n",
       "      <td>0.609368</td>\n",
       "      <td>0.908914</td>\n",
       "      <td>0.909133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.025300</td>\n",
       "      <td>0.603616</td>\n",
       "      <td>0.907902</td>\n",
       "      <td>0.908504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.019300</td>\n",
       "      <td>0.606813</td>\n",
       "      <td>0.908914</td>\n",
       "      <td>0.909588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.012700</td>\n",
       "      <td>0.624625</td>\n",
       "      <td>0.907746</td>\n",
       "      <td>0.908176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.017900</td>\n",
       "      <td>0.601087</td>\n",
       "      <td>0.908992</td>\n",
       "      <td>0.909379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.013500</td>\n",
       "      <td>0.610807</td>\n",
       "      <td>0.907591</td>\n",
       "      <td>0.907954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.011900</td>\n",
       "      <td>0.629575</td>\n",
       "      <td>0.907980</td>\n",
       "      <td>0.908671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.012200</td>\n",
       "      <td>0.637306</td>\n",
       "      <td>0.906968</td>\n",
       "      <td>0.907523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.011400</td>\n",
       "      <td>0.631842</td>\n",
       "      <td>0.907746</td>\n",
       "      <td>0.908061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.013800</td>\n",
       "      <td>0.628243</td>\n",
       "      <td>0.907824</td>\n",
       "      <td>0.908299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 51377\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 12845\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SI2M-Lab/DarijaBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SI2M-Lab/DarijaBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e1fd4da3d7f4bd0ba60a98bf84f8da4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51377 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bdc651d48fc4897b1fbdeef3b967935",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12845 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6424' max='6424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6424/6424 11:22, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.401700</td>\n",
       "      <td>0.373332</td>\n",
       "      <td>0.859868</td>\n",
       "      <td>0.864811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.323800</td>\n",
       "      <td>0.279805</td>\n",
       "      <td>0.897236</td>\n",
       "      <td>0.896414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.283100</td>\n",
       "      <td>0.275952</td>\n",
       "      <td>0.900817</td>\n",
       "      <td>0.903100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.266300</td>\n",
       "      <td>0.273941</td>\n",
       "      <td>0.904788</td>\n",
       "      <td>0.907199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.173400</td>\n",
       "      <td>0.259128</td>\n",
       "      <td>0.915531</td>\n",
       "      <td>0.915838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.162100</td>\n",
       "      <td>0.279770</td>\n",
       "      <td>0.908369</td>\n",
       "      <td>0.909506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.145400</td>\n",
       "      <td>0.317324</td>\n",
       "      <td>0.903854</td>\n",
       "      <td>0.905730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.156800</td>\n",
       "      <td>0.251235</td>\n",
       "      <td>0.915843</td>\n",
       "      <td>0.916358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.083700</td>\n",
       "      <td>0.340259</td>\n",
       "      <td>0.911016</td>\n",
       "      <td>0.912248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.088300</td>\n",
       "      <td>0.370457</td>\n",
       "      <td>0.905177</td>\n",
       "      <td>0.905040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.099700</td>\n",
       "      <td>0.307570</td>\n",
       "      <td>0.915298</td>\n",
       "      <td>0.915158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.092200</td>\n",
       "      <td>0.328294</td>\n",
       "      <td>0.913351</td>\n",
       "      <td>0.913355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.048900</td>\n",
       "      <td>0.485034</td>\n",
       "      <td>0.909070</td>\n",
       "      <td>0.909399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.057200</td>\n",
       "      <td>0.373920</td>\n",
       "      <td>0.913741</td>\n",
       "      <td>0.913401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.056800</td>\n",
       "      <td>0.349377</td>\n",
       "      <td>0.915376</td>\n",
       "      <td>0.915201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.052800</td>\n",
       "      <td>0.386615</td>\n",
       "      <td>0.917166</td>\n",
       "      <td>0.916624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.031000</td>\n",
       "      <td>0.465880</td>\n",
       "      <td>0.916466</td>\n",
       "      <td>0.916401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.032900</td>\n",
       "      <td>0.464338</td>\n",
       "      <td>0.916933</td>\n",
       "      <td>0.917617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.037100</td>\n",
       "      <td>0.464776</td>\n",
       "      <td>0.917322</td>\n",
       "      <td>0.917887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.043500</td>\n",
       "      <td>0.405057</td>\n",
       "      <td>0.918256</td>\n",
       "      <td>0.918569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.021700</td>\n",
       "      <td>0.494857</td>\n",
       "      <td>0.918568</td>\n",
       "      <td>0.919002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.021200</td>\n",
       "      <td>0.484747</td>\n",
       "      <td>0.918334</td>\n",
       "      <td>0.918889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.020800</td>\n",
       "      <td>0.534358</td>\n",
       "      <td>0.917166</td>\n",
       "      <td>0.917634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.028500</td>\n",
       "      <td>0.476248</td>\n",
       "      <td>0.917478</td>\n",
       "      <td>0.917552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.016800</td>\n",
       "      <td>0.539072</td>\n",
       "      <td>0.917244</td>\n",
       "      <td>0.917872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.016700</td>\n",
       "      <td>0.514629</td>\n",
       "      <td>0.918412</td>\n",
       "      <td>0.918237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.020300</td>\n",
       "      <td>0.533552</td>\n",
       "      <td>0.918957</td>\n",
       "      <td>0.918893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.016600</td>\n",
       "      <td>0.533080</td>\n",
       "      <td>0.918957</td>\n",
       "      <td>0.919613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.013300</td>\n",
       "      <td>0.539204</td>\n",
       "      <td>0.918334</td>\n",
       "      <td>0.919030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.014300</td>\n",
       "      <td>0.537448</td>\n",
       "      <td>0.919969</td>\n",
       "      <td>0.920228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.013400</td>\n",
       "      <td>0.535107</td>\n",
       "      <td>0.920514</td>\n",
       "      <td>0.920908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.010800</td>\n",
       "      <td>0.538805</td>\n",
       "      <td>0.920670</td>\n",
       "      <td>0.920993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SI2M-Lab/DarijaBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SI2M-Lab/DarijaBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73641f3b34b5480f9f558d428637010e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51377 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1569f7a4670450e878b1aae1dea0772",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12845 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6424' max='6424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6424/6424 11:23, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.401700</td>\n",
       "      <td>0.373332</td>\n",
       "      <td>0.859868</td>\n",
       "      <td>0.864811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.323800</td>\n",
       "      <td>0.279805</td>\n",
       "      <td>0.897236</td>\n",
       "      <td>0.896414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.283100</td>\n",
       "      <td>0.275952</td>\n",
       "      <td>0.900817</td>\n",
       "      <td>0.903100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.266300</td>\n",
       "      <td>0.273941</td>\n",
       "      <td>0.904788</td>\n",
       "      <td>0.907199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.173400</td>\n",
       "      <td>0.259128</td>\n",
       "      <td>0.915531</td>\n",
       "      <td>0.915838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.162100</td>\n",
       "      <td>0.279770</td>\n",
       "      <td>0.908369</td>\n",
       "      <td>0.909506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.145400</td>\n",
       "      <td>0.317324</td>\n",
       "      <td>0.903854</td>\n",
       "      <td>0.905730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.156800</td>\n",
       "      <td>0.251235</td>\n",
       "      <td>0.915843</td>\n",
       "      <td>0.916358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.083700</td>\n",
       "      <td>0.340259</td>\n",
       "      <td>0.911016</td>\n",
       "      <td>0.912248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.088300</td>\n",
       "      <td>0.370457</td>\n",
       "      <td>0.905177</td>\n",
       "      <td>0.905040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.099700</td>\n",
       "      <td>0.307570</td>\n",
       "      <td>0.915298</td>\n",
       "      <td>0.915158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.092200</td>\n",
       "      <td>0.328294</td>\n",
       "      <td>0.913351</td>\n",
       "      <td>0.913355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.048900</td>\n",
       "      <td>0.485034</td>\n",
       "      <td>0.909070</td>\n",
       "      <td>0.909399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.057200</td>\n",
       "      <td>0.373920</td>\n",
       "      <td>0.913741</td>\n",
       "      <td>0.913401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.056800</td>\n",
       "      <td>0.349377</td>\n",
       "      <td>0.915376</td>\n",
       "      <td>0.915201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.052800</td>\n",
       "      <td>0.386615</td>\n",
       "      <td>0.917166</td>\n",
       "      <td>0.916624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.031000</td>\n",
       "      <td>0.465880</td>\n",
       "      <td>0.916466</td>\n",
       "      <td>0.916401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.032900</td>\n",
       "      <td>0.464338</td>\n",
       "      <td>0.916933</td>\n",
       "      <td>0.917617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.037100</td>\n",
       "      <td>0.464776</td>\n",
       "      <td>0.917322</td>\n",
       "      <td>0.917887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.043500</td>\n",
       "      <td>0.405057</td>\n",
       "      <td>0.918256</td>\n",
       "      <td>0.918569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.021700</td>\n",
       "      <td>0.494857</td>\n",
       "      <td>0.918568</td>\n",
       "      <td>0.919002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.021200</td>\n",
       "      <td>0.484747</td>\n",
       "      <td>0.918334</td>\n",
       "      <td>0.918889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.020800</td>\n",
       "      <td>0.534358</td>\n",
       "      <td>0.917166</td>\n",
       "      <td>0.917634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.028500</td>\n",
       "      <td>0.476248</td>\n",
       "      <td>0.917478</td>\n",
       "      <td>0.917552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.016800</td>\n",
       "      <td>0.539072</td>\n",
       "      <td>0.917244</td>\n",
       "      <td>0.917872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.016700</td>\n",
       "      <td>0.514629</td>\n",
       "      <td>0.918412</td>\n",
       "      <td>0.918237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.020300</td>\n",
       "      <td>0.533552</td>\n",
       "      <td>0.918957</td>\n",
       "      <td>0.918893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.016600</td>\n",
       "      <td>0.533080</td>\n",
       "      <td>0.918957</td>\n",
       "      <td>0.919613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.013300</td>\n",
       "      <td>0.539204</td>\n",
       "      <td>0.918334</td>\n",
       "      <td>0.919030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.014300</td>\n",
       "      <td>0.537448</td>\n",
       "      <td>0.919969</td>\n",
       "      <td>0.920228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.013400</td>\n",
       "      <td>0.535107</td>\n",
       "      <td>0.920514</td>\n",
       "      <td>0.920908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.010800</td>\n",
       "      <td>0.538805</td>\n",
       "      <td>0.920670</td>\n",
       "      <td>0.920993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SI2M-Lab/DarijaBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SI2M-Lab/DarijaBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "183f3f49a59a4bd88b6a81a52c890a64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51377 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e82b1201913f444399d23882328baab5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12845 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6424' max='6424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6424/6424 11:24, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.401700</td>\n",
       "      <td>0.373332</td>\n",
       "      <td>0.859868</td>\n",
       "      <td>0.864811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.323800</td>\n",
       "      <td>0.279805</td>\n",
       "      <td>0.897236</td>\n",
       "      <td>0.896414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.283100</td>\n",
       "      <td>0.275952</td>\n",
       "      <td>0.900817</td>\n",
       "      <td>0.903100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.266300</td>\n",
       "      <td>0.273941</td>\n",
       "      <td>0.904788</td>\n",
       "      <td>0.907199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.173400</td>\n",
       "      <td>0.259128</td>\n",
       "      <td>0.915531</td>\n",
       "      <td>0.915838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.162100</td>\n",
       "      <td>0.279770</td>\n",
       "      <td>0.908369</td>\n",
       "      <td>0.909506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.145400</td>\n",
       "      <td>0.317324</td>\n",
       "      <td>0.903854</td>\n",
       "      <td>0.905730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.156800</td>\n",
       "      <td>0.251235</td>\n",
       "      <td>0.915843</td>\n",
       "      <td>0.916358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.083700</td>\n",
       "      <td>0.340259</td>\n",
       "      <td>0.911016</td>\n",
       "      <td>0.912248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.088300</td>\n",
       "      <td>0.370457</td>\n",
       "      <td>0.905177</td>\n",
       "      <td>0.905040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.099700</td>\n",
       "      <td>0.307570</td>\n",
       "      <td>0.915298</td>\n",
       "      <td>0.915158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.092200</td>\n",
       "      <td>0.328294</td>\n",
       "      <td>0.913351</td>\n",
       "      <td>0.913355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.048900</td>\n",
       "      <td>0.485034</td>\n",
       "      <td>0.909070</td>\n",
       "      <td>0.909399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.057200</td>\n",
       "      <td>0.373920</td>\n",
       "      <td>0.913741</td>\n",
       "      <td>0.913401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.056800</td>\n",
       "      <td>0.349377</td>\n",
       "      <td>0.915376</td>\n",
       "      <td>0.915201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.052800</td>\n",
       "      <td>0.386615</td>\n",
       "      <td>0.917166</td>\n",
       "      <td>0.916624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.031000</td>\n",
       "      <td>0.465880</td>\n",
       "      <td>0.916466</td>\n",
       "      <td>0.916401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.032900</td>\n",
       "      <td>0.464338</td>\n",
       "      <td>0.916933</td>\n",
       "      <td>0.917617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.037100</td>\n",
       "      <td>0.464776</td>\n",
       "      <td>0.917322</td>\n",
       "      <td>0.917887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.043500</td>\n",
       "      <td>0.405057</td>\n",
       "      <td>0.918256</td>\n",
       "      <td>0.918569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.021700</td>\n",
       "      <td>0.494857</td>\n",
       "      <td>0.918568</td>\n",
       "      <td>0.919002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.021200</td>\n",
       "      <td>0.484747</td>\n",
       "      <td>0.918334</td>\n",
       "      <td>0.918889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.020800</td>\n",
       "      <td>0.534358</td>\n",
       "      <td>0.917166</td>\n",
       "      <td>0.917634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.028500</td>\n",
       "      <td>0.476248</td>\n",
       "      <td>0.917478</td>\n",
       "      <td>0.917552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.016800</td>\n",
       "      <td>0.539072</td>\n",
       "      <td>0.917244</td>\n",
       "      <td>0.917872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.016700</td>\n",
       "      <td>0.514629</td>\n",
       "      <td>0.918412</td>\n",
       "      <td>0.918237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.020300</td>\n",
       "      <td>0.533552</td>\n",
       "      <td>0.918957</td>\n",
       "      <td>0.918893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.016600</td>\n",
       "      <td>0.533080</td>\n",
       "      <td>0.918957</td>\n",
       "      <td>0.919613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.013300</td>\n",
       "      <td>0.539204</td>\n",
       "      <td>0.918334</td>\n",
       "      <td>0.919030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.014300</td>\n",
       "      <td>0.537448</td>\n",
       "      <td>0.919969</td>\n",
       "      <td>0.920228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.013400</td>\n",
       "      <td>0.535107</td>\n",
       "      <td>0.920514</td>\n",
       "      <td>0.920908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.010800</td>\n",
       "      <td>0.538805</td>\n",
       "      <td>0.920670</td>\n",
       "      <td>0.920993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SI2M-Lab/DarijaBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SI2M-Lab/DarijaBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae3450f5931942f8b741f36fd6745d07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51377 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc354587621943518dc35156603e46e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12845 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6424' max='6424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6424/6424 11:23, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.419700</td>\n",
       "      <td>0.336476</td>\n",
       "      <td>0.876995</td>\n",
       "      <td>0.880803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.311700</td>\n",
       "      <td>0.294284</td>\n",
       "      <td>0.894589</td>\n",
       "      <td>0.898005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.289000</td>\n",
       "      <td>0.308365</td>\n",
       "      <td>0.891475</td>\n",
       "      <td>0.894595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.266700</td>\n",
       "      <td>0.249540</td>\n",
       "      <td>0.909381</td>\n",
       "      <td>0.912742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.169400</td>\n",
       "      <td>0.276714</td>\n",
       "      <td>0.906968</td>\n",
       "      <td>0.908807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.160300</td>\n",
       "      <td>0.304705</td>\n",
       "      <td>0.911327</td>\n",
       "      <td>0.912482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.165700</td>\n",
       "      <td>0.271279</td>\n",
       "      <td>0.909692</td>\n",
       "      <td>0.911719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>0.259959</td>\n",
       "      <td>0.916232</td>\n",
       "      <td>0.917051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.077900</td>\n",
       "      <td>0.350842</td>\n",
       "      <td>0.910549</td>\n",
       "      <td>0.911133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.095800</td>\n",
       "      <td>0.312357</td>\n",
       "      <td>0.917711</td>\n",
       "      <td>0.919573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.088200</td>\n",
       "      <td>0.369374</td>\n",
       "      <td>0.916777</td>\n",
       "      <td>0.918029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.095200</td>\n",
       "      <td>0.286305</td>\n",
       "      <td>0.916621</td>\n",
       "      <td>0.918487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.052300</td>\n",
       "      <td>0.432159</td>\n",
       "      <td>0.916855</td>\n",
       "      <td>0.918157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.053200</td>\n",
       "      <td>0.370477</td>\n",
       "      <td>0.917555</td>\n",
       "      <td>0.918795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.059000</td>\n",
       "      <td>0.400626</td>\n",
       "      <td>0.916933</td>\n",
       "      <td>0.919083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.058500</td>\n",
       "      <td>0.366131</td>\n",
       "      <td>0.913429</td>\n",
       "      <td>0.915198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.031700</td>\n",
       "      <td>0.460559</td>\n",
       "      <td>0.914519</td>\n",
       "      <td>0.916464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.039600</td>\n",
       "      <td>0.484205</td>\n",
       "      <td>0.913585</td>\n",
       "      <td>0.914980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.034300</td>\n",
       "      <td>0.459401</td>\n",
       "      <td>0.916076</td>\n",
       "      <td>0.918080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.035400</td>\n",
       "      <td>0.456217</td>\n",
       "      <td>0.917088</td>\n",
       "      <td>0.919051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.022900</td>\n",
       "      <td>0.507801</td>\n",
       "      <td>0.917789</td>\n",
       "      <td>0.919596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>0.509583</td>\n",
       "      <td>0.916232</td>\n",
       "      <td>0.918362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.023500</td>\n",
       "      <td>0.525165</td>\n",
       "      <td>0.916777</td>\n",
       "      <td>0.917991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.021500</td>\n",
       "      <td>0.538505</td>\n",
       "      <td>0.917166</td>\n",
       "      <td>0.918591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.016900</td>\n",
       "      <td>0.549847</td>\n",
       "      <td>0.914597</td>\n",
       "      <td>0.916494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.018600</td>\n",
       "      <td>0.536291</td>\n",
       "      <td>0.918100</td>\n",
       "      <td>0.920521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.014000</td>\n",
       "      <td>0.556414</td>\n",
       "      <td>0.916310</td>\n",
       "      <td>0.918071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.016800</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.916621</td>\n",
       "      <td>0.918348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.013400</td>\n",
       "      <td>0.552079</td>\n",
       "      <td>0.918334</td>\n",
       "      <td>0.920308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.011900</td>\n",
       "      <td>0.558533</td>\n",
       "      <td>0.917789</td>\n",
       "      <td>0.920146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>0.561724</td>\n",
       "      <td>0.917400</td>\n",
       "      <td>0.919678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.011400</td>\n",
       "      <td>0.564677</td>\n",
       "      <td>0.916699</td>\n",
       "      <td>0.918713</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SI2M-Lab/DarijaBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SI2M-Lab/DarijaBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92556490e0d54845ace6d05bfdb58deb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51377 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c1fdcb26b3e492a844eccbed4257439",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12845 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6424' max='6424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6424/6424 11:23, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.419700</td>\n",
       "      <td>0.336476</td>\n",
       "      <td>0.876995</td>\n",
       "      <td>0.880803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.311700</td>\n",
       "      <td>0.294284</td>\n",
       "      <td>0.894589</td>\n",
       "      <td>0.898005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.289000</td>\n",
       "      <td>0.308365</td>\n",
       "      <td>0.891475</td>\n",
       "      <td>0.894595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.266700</td>\n",
       "      <td>0.249540</td>\n",
       "      <td>0.909381</td>\n",
       "      <td>0.912742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.169400</td>\n",
       "      <td>0.276714</td>\n",
       "      <td>0.906968</td>\n",
       "      <td>0.908807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.160300</td>\n",
       "      <td>0.304705</td>\n",
       "      <td>0.911327</td>\n",
       "      <td>0.912482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.165700</td>\n",
       "      <td>0.271279</td>\n",
       "      <td>0.909692</td>\n",
       "      <td>0.911719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>0.259959</td>\n",
       "      <td>0.916232</td>\n",
       "      <td>0.917051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.077900</td>\n",
       "      <td>0.350842</td>\n",
       "      <td>0.910549</td>\n",
       "      <td>0.911133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.095800</td>\n",
       "      <td>0.312357</td>\n",
       "      <td>0.917711</td>\n",
       "      <td>0.919573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.088200</td>\n",
       "      <td>0.369374</td>\n",
       "      <td>0.916777</td>\n",
       "      <td>0.918029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.095200</td>\n",
       "      <td>0.286305</td>\n",
       "      <td>0.916621</td>\n",
       "      <td>0.918487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.052300</td>\n",
       "      <td>0.432159</td>\n",
       "      <td>0.916855</td>\n",
       "      <td>0.918157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.053200</td>\n",
       "      <td>0.370477</td>\n",
       "      <td>0.917555</td>\n",
       "      <td>0.918795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.059000</td>\n",
       "      <td>0.400626</td>\n",
       "      <td>0.916933</td>\n",
       "      <td>0.919083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.058500</td>\n",
       "      <td>0.366131</td>\n",
       "      <td>0.913429</td>\n",
       "      <td>0.915198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.031700</td>\n",
       "      <td>0.460559</td>\n",
       "      <td>0.914519</td>\n",
       "      <td>0.916464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.039600</td>\n",
       "      <td>0.484205</td>\n",
       "      <td>0.913585</td>\n",
       "      <td>0.914980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.034300</td>\n",
       "      <td>0.459401</td>\n",
       "      <td>0.916076</td>\n",
       "      <td>0.918080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.035400</td>\n",
       "      <td>0.456217</td>\n",
       "      <td>0.917088</td>\n",
       "      <td>0.919051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.022900</td>\n",
       "      <td>0.507801</td>\n",
       "      <td>0.917789</td>\n",
       "      <td>0.919596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>0.509583</td>\n",
       "      <td>0.916232</td>\n",
       "      <td>0.918362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.023500</td>\n",
       "      <td>0.525165</td>\n",
       "      <td>0.916777</td>\n",
       "      <td>0.917991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.021500</td>\n",
       "      <td>0.538505</td>\n",
       "      <td>0.917166</td>\n",
       "      <td>0.918591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.016900</td>\n",
       "      <td>0.549847</td>\n",
       "      <td>0.914597</td>\n",
       "      <td>0.916494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.018600</td>\n",
       "      <td>0.536291</td>\n",
       "      <td>0.918100</td>\n",
       "      <td>0.920521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.014000</td>\n",
       "      <td>0.556414</td>\n",
       "      <td>0.916310</td>\n",
       "      <td>0.918071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.016800</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.916621</td>\n",
       "      <td>0.918348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.013400</td>\n",
       "      <td>0.552079</td>\n",
       "      <td>0.918334</td>\n",
       "      <td>0.920308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.011900</td>\n",
       "      <td>0.558533</td>\n",
       "      <td>0.917789</td>\n",
       "      <td>0.920146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>0.561724</td>\n",
       "      <td>0.917400</td>\n",
       "      <td>0.919678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.011400</td>\n",
       "      <td>0.564677</td>\n",
       "      <td>0.916699</td>\n",
       "      <td>0.918713</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SI2M-Lab/DarijaBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SI2M-Lab/DarijaBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5db1c927999e419baf1ed11e95aba45c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51377 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "485cd58cab2e4b8aa1dc7d3b5773d45c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12845 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6424' max='6424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6424/6424 11:23, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.419700</td>\n",
       "      <td>0.336476</td>\n",
       "      <td>0.876995</td>\n",
       "      <td>0.880803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.311700</td>\n",
       "      <td>0.294284</td>\n",
       "      <td>0.894589</td>\n",
       "      <td>0.898005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.289000</td>\n",
       "      <td>0.308365</td>\n",
       "      <td>0.891475</td>\n",
       "      <td>0.894595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.266700</td>\n",
       "      <td>0.249540</td>\n",
       "      <td>0.909381</td>\n",
       "      <td>0.912742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.169400</td>\n",
       "      <td>0.276714</td>\n",
       "      <td>0.906968</td>\n",
       "      <td>0.908807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.160300</td>\n",
       "      <td>0.304705</td>\n",
       "      <td>0.911327</td>\n",
       "      <td>0.912482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.165700</td>\n",
       "      <td>0.271279</td>\n",
       "      <td>0.909692</td>\n",
       "      <td>0.911719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>0.259959</td>\n",
       "      <td>0.916232</td>\n",
       "      <td>0.917051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.077900</td>\n",
       "      <td>0.350842</td>\n",
       "      <td>0.910549</td>\n",
       "      <td>0.911133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.095800</td>\n",
       "      <td>0.312357</td>\n",
       "      <td>0.917711</td>\n",
       "      <td>0.919573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.088200</td>\n",
       "      <td>0.369374</td>\n",
       "      <td>0.916777</td>\n",
       "      <td>0.918029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.095200</td>\n",
       "      <td>0.286305</td>\n",
       "      <td>0.916621</td>\n",
       "      <td>0.918487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.052300</td>\n",
       "      <td>0.432159</td>\n",
       "      <td>0.916855</td>\n",
       "      <td>0.918157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.053200</td>\n",
       "      <td>0.370477</td>\n",
       "      <td>0.917555</td>\n",
       "      <td>0.918795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.059000</td>\n",
       "      <td>0.400626</td>\n",
       "      <td>0.916933</td>\n",
       "      <td>0.919083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.058500</td>\n",
       "      <td>0.366131</td>\n",
       "      <td>0.913429</td>\n",
       "      <td>0.915198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.031700</td>\n",
       "      <td>0.460559</td>\n",
       "      <td>0.914519</td>\n",
       "      <td>0.916464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.039600</td>\n",
       "      <td>0.484205</td>\n",
       "      <td>0.913585</td>\n",
       "      <td>0.914980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.034300</td>\n",
       "      <td>0.459401</td>\n",
       "      <td>0.916076</td>\n",
       "      <td>0.918080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.035400</td>\n",
       "      <td>0.456217</td>\n",
       "      <td>0.917088</td>\n",
       "      <td>0.919051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.022900</td>\n",
       "      <td>0.507801</td>\n",
       "      <td>0.917789</td>\n",
       "      <td>0.919596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>0.509583</td>\n",
       "      <td>0.916232</td>\n",
       "      <td>0.918362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.023500</td>\n",
       "      <td>0.525165</td>\n",
       "      <td>0.916777</td>\n",
       "      <td>0.917991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.021500</td>\n",
       "      <td>0.538505</td>\n",
       "      <td>0.917166</td>\n",
       "      <td>0.918591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.016900</td>\n",
       "      <td>0.549847</td>\n",
       "      <td>0.914597</td>\n",
       "      <td>0.916494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.018600</td>\n",
       "      <td>0.536291</td>\n",
       "      <td>0.918100</td>\n",
       "      <td>0.920521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.014000</td>\n",
       "      <td>0.556414</td>\n",
       "      <td>0.916310</td>\n",
       "      <td>0.918071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.016800</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.916621</td>\n",
       "      <td>0.918348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.013400</td>\n",
       "      <td>0.552079</td>\n",
       "      <td>0.918334</td>\n",
       "      <td>0.920308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.011900</td>\n",
       "      <td>0.558533</td>\n",
       "      <td>0.917789</td>\n",
       "      <td>0.920146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>0.561724</td>\n",
       "      <td>0.917400</td>\n",
       "      <td>0.919678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.011400</td>\n",
       "      <td>0.564677</td>\n",
       "      <td>0.916699</td>\n",
       "      <td>0.918713</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SI2M-Lab/DarijaBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SI2M-Lab/DarijaBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dfe1ed63d724b71bf4cb20a95cb0961",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51377 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aa8ea7803494e0ea26e4c168cfb6c24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12845 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6424' max='6424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6424/6424 11:23, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.407400</td>\n",
       "      <td>0.356220</td>\n",
       "      <td>0.877228</td>\n",
       "      <td>0.878760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.315300</td>\n",
       "      <td>0.273217</td>\n",
       "      <td>0.902297</td>\n",
       "      <td>0.903345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.284200</td>\n",
       "      <td>0.262492</td>\n",
       "      <td>0.906345</td>\n",
       "      <td>0.906923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.268700</td>\n",
       "      <td>0.255684</td>\n",
       "      <td>0.911639</td>\n",
       "      <td>0.912852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.167300</td>\n",
       "      <td>0.267120</td>\n",
       "      <td>0.908603</td>\n",
       "      <td>0.908379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.156900</td>\n",
       "      <td>0.291287</td>\n",
       "      <td>0.907513</td>\n",
       "      <td>0.909072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.158400</td>\n",
       "      <td>0.291486</td>\n",
       "      <td>0.911639</td>\n",
       "      <td>0.912885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.163900</td>\n",
       "      <td>0.265218</td>\n",
       "      <td>0.914208</td>\n",
       "      <td>0.915185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.086000</td>\n",
       "      <td>0.365286</td>\n",
       "      <td>0.913896</td>\n",
       "      <td>0.914763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.086900</td>\n",
       "      <td>0.370700</td>\n",
       "      <td>0.913896</td>\n",
       "      <td>0.914256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.095700</td>\n",
       "      <td>0.310501</td>\n",
       "      <td>0.912884</td>\n",
       "      <td>0.913307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.089400</td>\n",
       "      <td>0.361233</td>\n",
       "      <td>0.912028</td>\n",
       "      <td>0.912378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.055300</td>\n",
       "      <td>0.433830</td>\n",
       "      <td>0.911172</td>\n",
       "      <td>0.912606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.055000</td>\n",
       "      <td>0.454931</td>\n",
       "      <td>0.913663</td>\n",
       "      <td>0.914467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.056100</td>\n",
       "      <td>0.410324</td>\n",
       "      <td>0.914753</td>\n",
       "      <td>0.915924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.054700</td>\n",
       "      <td>0.445212</td>\n",
       "      <td>0.914986</td>\n",
       "      <td>0.915131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.033600</td>\n",
       "      <td>0.510837</td>\n",
       "      <td>0.913585</td>\n",
       "      <td>0.914987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.036200</td>\n",
       "      <td>0.463858</td>\n",
       "      <td>0.913741</td>\n",
       "      <td>0.913973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.034200</td>\n",
       "      <td>0.481806</td>\n",
       "      <td>0.917166</td>\n",
       "      <td>0.917541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.038300</td>\n",
       "      <td>0.474566</td>\n",
       "      <td>0.914519</td>\n",
       "      <td>0.915448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.023600</td>\n",
       "      <td>0.496304</td>\n",
       "      <td>0.915453</td>\n",
       "      <td>0.915768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.023800</td>\n",
       "      <td>0.552298</td>\n",
       "      <td>0.916076</td>\n",
       "      <td>0.917366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.022000</td>\n",
       "      <td>0.540483</td>\n",
       "      <td>0.917088</td>\n",
       "      <td>0.918083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.027900</td>\n",
       "      <td>0.515656</td>\n",
       "      <td>0.916076</td>\n",
       "      <td>0.916811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.020100</td>\n",
       "      <td>0.552870</td>\n",
       "      <td>0.915687</td>\n",
       "      <td>0.916518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.015100</td>\n",
       "      <td>0.551083</td>\n",
       "      <td>0.916388</td>\n",
       "      <td>0.917203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.017800</td>\n",
       "      <td>0.552126</td>\n",
       "      <td>0.916777</td>\n",
       "      <td>0.917465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.015800</td>\n",
       "      <td>0.558698</td>\n",
       "      <td>0.917244</td>\n",
       "      <td>0.918051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.012800</td>\n",
       "      <td>0.558219</td>\n",
       "      <td>0.917478</td>\n",
       "      <td>0.918096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.014700</td>\n",
       "      <td>0.554497</td>\n",
       "      <td>0.918723</td>\n",
       "      <td>0.919480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.014600</td>\n",
       "      <td>0.555758</td>\n",
       "      <td>0.918490</td>\n",
       "      <td>0.919366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.014100</td>\n",
       "      <td>0.557756</td>\n",
       "      <td>0.918412</td>\n",
       "      <td>0.919234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SI2M-Lab/DarijaBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SI2M-Lab/DarijaBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a10a991a3918418390889645db307aeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51377 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9389293831104914bc1efb1ea338ff86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12845 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6424' max='6424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6424/6424 11:22, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.407400</td>\n",
       "      <td>0.356220</td>\n",
       "      <td>0.877228</td>\n",
       "      <td>0.878760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.315300</td>\n",
       "      <td>0.273217</td>\n",
       "      <td>0.902297</td>\n",
       "      <td>0.903345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.284200</td>\n",
       "      <td>0.262492</td>\n",
       "      <td>0.906345</td>\n",
       "      <td>0.906923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.268700</td>\n",
       "      <td>0.255684</td>\n",
       "      <td>0.911639</td>\n",
       "      <td>0.912852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.167300</td>\n",
       "      <td>0.267120</td>\n",
       "      <td>0.908603</td>\n",
       "      <td>0.908379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.156900</td>\n",
       "      <td>0.291287</td>\n",
       "      <td>0.907513</td>\n",
       "      <td>0.909072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.158400</td>\n",
       "      <td>0.291486</td>\n",
       "      <td>0.911639</td>\n",
       "      <td>0.912885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.163900</td>\n",
       "      <td>0.265218</td>\n",
       "      <td>0.914208</td>\n",
       "      <td>0.915185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.086000</td>\n",
       "      <td>0.365286</td>\n",
       "      <td>0.913896</td>\n",
       "      <td>0.914763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.086900</td>\n",
       "      <td>0.370700</td>\n",
       "      <td>0.913896</td>\n",
       "      <td>0.914256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.095700</td>\n",
       "      <td>0.310501</td>\n",
       "      <td>0.912884</td>\n",
       "      <td>0.913307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.089400</td>\n",
       "      <td>0.361233</td>\n",
       "      <td>0.912028</td>\n",
       "      <td>0.912378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.055300</td>\n",
       "      <td>0.433830</td>\n",
       "      <td>0.911172</td>\n",
       "      <td>0.912606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.055000</td>\n",
       "      <td>0.454931</td>\n",
       "      <td>0.913663</td>\n",
       "      <td>0.914467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.056100</td>\n",
       "      <td>0.410324</td>\n",
       "      <td>0.914753</td>\n",
       "      <td>0.915924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.054700</td>\n",
       "      <td>0.445212</td>\n",
       "      <td>0.914986</td>\n",
       "      <td>0.915131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.033600</td>\n",
       "      <td>0.510837</td>\n",
       "      <td>0.913585</td>\n",
       "      <td>0.914987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.036200</td>\n",
       "      <td>0.463858</td>\n",
       "      <td>0.913741</td>\n",
       "      <td>0.913973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.034200</td>\n",
       "      <td>0.481806</td>\n",
       "      <td>0.917166</td>\n",
       "      <td>0.917541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.038300</td>\n",
       "      <td>0.474566</td>\n",
       "      <td>0.914519</td>\n",
       "      <td>0.915448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.023600</td>\n",
       "      <td>0.496304</td>\n",
       "      <td>0.915453</td>\n",
       "      <td>0.915768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.023800</td>\n",
       "      <td>0.552298</td>\n",
       "      <td>0.916076</td>\n",
       "      <td>0.917366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.022000</td>\n",
       "      <td>0.540483</td>\n",
       "      <td>0.917088</td>\n",
       "      <td>0.918083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.027900</td>\n",
       "      <td>0.515656</td>\n",
       "      <td>0.916076</td>\n",
       "      <td>0.916811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.020100</td>\n",
       "      <td>0.552870</td>\n",
       "      <td>0.915687</td>\n",
       "      <td>0.916518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.015100</td>\n",
       "      <td>0.551083</td>\n",
       "      <td>0.916388</td>\n",
       "      <td>0.917203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.017800</td>\n",
       "      <td>0.552126</td>\n",
       "      <td>0.916777</td>\n",
       "      <td>0.917465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.015800</td>\n",
       "      <td>0.558698</td>\n",
       "      <td>0.917244</td>\n",
       "      <td>0.918051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.012800</td>\n",
       "      <td>0.558219</td>\n",
       "      <td>0.917478</td>\n",
       "      <td>0.918096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.014700</td>\n",
       "      <td>0.554497</td>\n",
       "      <td>0.918723</td>\n",
       "      <td>0.919480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.014600</td>\n",
       "      <td>0.555758</td>\n",
       "      <td>0.918490</td>\n",
       "      <td>0.919366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.014100</td>\n",
       "      <td>0.557756</td>\n",
       "      <td>0.918412</td>\n",
       "      <td>0.919234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SI2M-Lab/DarijaBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SI2M-Lab/DarijaBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "703a8b904f054a748bc427c6d563ce3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51377 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8370d733edb9402f91fdb732a55bb6f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12845 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6424' max='6424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6424/6424 11:23, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.407400</td>\n",
       "      <td>0.356220</td>\n",
       "      <td>0.877228</td>\n",
       "      <td>0.878760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.315300</td>\n",
       "      <td>0.273217</td>\n",
       "      <td>0.902297</td>\n",
       "      <td>0.903345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.284200</td>\n",
       "      <td>0.262492</td>\n",
       "      <td>0.906345</td>\n",
       "      <td>0.906923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.268700</td>\n",
       "      <td>0.255684</td>\n",
       "      <td>0.911639</td>\n",
       "      <td>0.912852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.167300</td>\n",
       "      <td>0.267120</td>\n",
       "      <td>0.908603</td>\n",
       "      <td>0.908379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.156900</td>\n",
       "      <td>0.291287</td>\n",
       "      <td>0.907513</td>\n",
       "      <td>0.909072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.158400</td>\n",
       "      <td>0.291486</td>\n",
       "      <td>0.911639</td>\n",
       "      <td>0.912885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.163900</td>\n",
       "      <td>0.265218</td>\n",
       "      <td>0.914208</td>\n",
       "      <td>0.915185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.086000</td>\n",
       "      <td>0.365286</td>\n",
       "      <td>0.913896</td>\n",
       "      <td>0.914763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.086900</td>\n",
       "      <td>0.370700</td>\n",
       "      <td>0.913896</td>\n",
       "      <td>0.914256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.095700</td>\n",
       "      <td>0.310501</td>\n",
       "      <td>0.912884</td>\n",
       "      <td>0.913307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.089400</td>\n",
       "      <td>0.361233</td>\n",
       "      <td>0.912028</td>\n",
       "      <td>0.912378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.055300</td>\n",
       "      <td>0.433830</td>\n",
       "      <td>0.911172</td>\n",
       "      <td>0.912606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.055000</td>\n",
       "      <td>0.454931</td>\n",
       "      <td>0.913663</td>\n",
       "      <td>0.914467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.056100</td>\n",
       "      <td>0.410324</td>\n",
       "      <td>0.914753</td>\n",
       "      <td>0.915924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.054700</td>\n",
       "      <td>0.445212</td>\n",
       "      <td>0.914986</td>\n",
       "      <td>0.915131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.033600</td>\n",
       "      <td>0.510837</td>\n",
       "      <td>0.913585</td>\n",
       "      <td>0.914987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.036200</td>\n",
       "      <td>0.463858</td>\n",
       "      <td>0.913741</td>\n",
       "      <td>0.913973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.034200</td>\n",
       "      <td>0.481806</td>\n",
       "      <td>0.917166</td>\n",
       "      <td>0.917541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.038300</td>\n",
       "      <td>0.474566</td>\n",
       "      <td>0.914519</td>\n",
       "      <td>0.915448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.023600</td>\n",
       "      <td>0.496304</td>\n",
       "      <td>0.915453</td>\n",
       "      <td>0.915768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.023800</td>\n",
       "      <td>0.552298</td>\n",
       "      <td>0.916076</td>\n",
       "      <td>0.917366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.022000</td>\n",
       "      <td>0.540483</td>\n",
       "      <td>0.917088</td>\n",
       "      <td>0.918083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.027900</td>\n",
       "      <td>0.515656</td>\n",
       "      <td>0.916076</td>\n",
       "      <td>0.916811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.020100</td>\n",
       "      <td>0.552870</td>\n",
       "      <td>0.915687</td>\n",
       "      <td>0.916518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.015100</td>\n",
       "      <td>0.551083</td>\n",
       "      <td>0.916388</td>\n",
       "      <td>0.917203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.017800</td>\n",
       "      <td>0.552126</td>\n",
       "      <td>0.916777</td>\n",
       "      <td>0.917465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.015800</td>\n",
       "      <td>0.558698</td>\n",
       "      <td>0.917244</td>\n",
       "      <td>0.918051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.012800</td>\n",
       "      <td>0.558219</td>\n",
       "      <td>0.917478</td>\n",
       "      <td>0.918096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.014700</td>\n",
       "      <td>0.554497</td>\n",
       "      <td>0.918723</td>\n",
       "      <td>0.919480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.014600</td>\n",
       "      <td>0.555758</td>\n",
       "      <td>0.918490</td>\n",
       "      <td>0.919366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.014100</td>\n",
       "      <td>0.557756</td>\n",
       "      <td>0.918412</td>\n",
       "      <td>0.919234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 51377\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 12845\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorRoBERTa, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at otmangi/MorRoBERTa and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14a4159ac4cd4116bb53a4f7841fc44a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51377 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37610b2e63034b16b6bee55f2d9ac8ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12845 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6424' max='6424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6424/6424 06:09, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.449200</td>\n",
       "      <td>0.381331</td>\n",
       "      <td>0.863060</td>\n",
       "      <td>0.864897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.349000</td>\n",
       "      <td>0.335805</td>\n",
       "      <td>0.875671</td>\n",
       "      <td>0.871118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.308700</td>\n",
       "      <td>0.296456</td>\n",
       "      <td>0.890308</td>\n",
       "      <td>0.889271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.294500</td>\n",
       "      <td>0.289893</td>\n",
       "      <td>0.895368</td>\n",
       "      <td>0.895978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.178400</td>\n",
       "      <td>0.318541</td>\n",
       "      <td>0.901985</td>\n",
       "      <td>0.902658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.176400</td>\n",
       "      <td>0.296424</td>\n",
       "      <td>0.901985</td>\n",
       "      <td>0.901243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.162000</td>\n",
       "      <td>0.315100</td>\n",
       "      <td>0.904165</td>\n",
       "      <td>0.903541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.169600</td>\n",
       "      <td>0.279239</td>\n",
       "      <td>0.906111</td>\n",
       "      <td>0.905810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.088500</td>\n",
       "      <td>0.407914</td>\n",
       "      <td>0.899572</td>\n",
       "      <td>0.898408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.087000</td>\n",
       "      <td>0.384672</td>\n",
       "      <td>0.902608</td>\n",
       "      <td>0.902209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.099700</td>\n",
       "      <td>0.392583</td>\n",
       "      <td>0.902452</td>\n",
       "      <td>0.901592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.096100</td>\n",
       "      <td>0.407050</td>\n",
       "      <td>0.902141</td>\n",
       "      <td>0.901904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.055400</td>\n",
       "      <td>0.492515</td>\n",
       "      <td>0.902530</td>\n",
       "      <td>0.903249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.054100</td>\n",
       "      <td>0.477575</td>\n",
       "      <td>0.902997</td>\n",
       "      <td>0.903215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.055700</td>\n",
       "      <td>0.480506</td>\n",
       "      <td>0.903387</td>\n",
       "      <td>0.903124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.049600</td>\n",
       "      <td>0.483279</td>\n",
       "      <td>0.903776</td>\n",
       "      <td>0.903604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.032700</td>\n",
       "      <td>0.532211</td>\n",
       "      <td>0.904710</td>\n",
       "      <td>0.904740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.028400</td>\n",
       "      <td>0.569697</td>\n",
       "      <td>0.904087</td>\n",
       "      <td>0.904000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.036800</td>\n",
       "      <td>0.581196</td>\n",
       "      <td>0.905722</td>\n",
       "      <td>0.905903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.042800</td>\n",
       "      <td>0.521853</td>\n",
       "      <td>0.905021</td>\n",
       "      <td>0.904801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.022200</td>\n",
       "      <td>0.581005</td>\n",
       "      <td>0.906189</td>\n",
       "      <td>0.906202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.022700</td>\n",
       "      <td>0.597939</td>\n",
       "      <td>0.905800</td>\n",
       "      <td>0.905704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.026000</td>\n",
       "      <td>0.612935</td>\n",
       "      <td>0.905956</td>\n",
       "      <td>0.905987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.022600</td>\n",
       "      <td>0.592642</td>\n",
       "      <td>0.905021</td>\n",
       "      <td>0.904933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.019600</td>\n",
       "      <td>0.600205</td>\n",
       "      <td>0.907513</td>\n",
       "      <td>0.906872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.015800</td>\n",
       "      <td>0.602844</td>\n",
       "      <td>0.905956</td>\n",
       "      <td>0.905797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.016800</td>\n",
       "      <td>0.620204</td>\n",
       "      <td>0.906267</td>\n",
       "      <td>0.905877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.017400</td>\n",
       "      <td>0.627750</td>\n",
       "      <td>0.906578</td>\n",
       "      <td>0.906429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.013600</td>\n",
       "      <td>0.626012</td>\n",
       "      <td>0.906501</td>\n",
       "      <td>0.906528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.015100</td>\n",
       "      <td>0.631474</td>\n",
       "      <td>0.906578</td>\n",
       "      <td>0.906246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.011700</td>\n",
       "      <td>0.631361</td>\n",
       "      <td>0.906578</td>\n",
       "      <td>0.906248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>0.633414</td>\n",
       "      <td>0.906423</td>\n",
       "      <td>0.906080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorRoBERTa, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at otmangi/MorRoBERTa and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b4788f0f0ca435384d271724213f324",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51377 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9f736566d7b493a9ad040da2165a5d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12845 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6424' max='6424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6424/6424 06:08, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.449200</td>\n",
       "      <td>0.381331</td>\n",
       "      <td>0.863060</td>\n",
       "      <td>0.864897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.349000</td>\n",
       "      <td>0.335805</td>\n",
       "      <td>0.875671</td>\n",
       "      <td>0.871118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.308700</td>\n",
       "      <td>0.296456</td>\n",
       "      <td>0.890308</td>\n",
       "      <td>0.889271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.294500</td>\n",
       "      <td>0.289893</td>\n",
       "      <td>0.895368</td>\n",
       "      <td>0.895978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.178400</td>\n",
       "      <td>0.318541</td>\n",
       "      <td>0.901985</td>\n",
       "      <td>0.902658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.176400</td>\n",
       "      <td>0.296424</td>\n",
       "      <td>0.901985</td>\n",
       "      <td>0.901243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.162000</td>\n",
       "      <td>0.315100</td>\n",
       "      <td>0.904165</td>\n",
       "      <td>0.903541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.169600</td>\n",
       "      <td>0.279239</td>\n",
       "      <td>0.906111</td>\n",
       "      <td>0.905810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.088500</td>\n",
       "      <td>0.407914</td>\n",
       "      <td>0.899572</td>\n",
       "      <td>0.898408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.087000</td>\n",
       "      <td>0.384672</td>\n",
       "      <td>0.902608</td>\n",
       "      <td>0.902209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.099700</td>\n",
       "      <td>0.392583</td>\n",
       "      <td>0.902452</td>\n",
       "      <td>0.901592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.096100</td>\n",
       "      <td>0.407050</td>\n",
       "      <td>0.902141</td>\n",
       "      <td>0.901904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.055400</td>\n",
       "      <td>0.492515</td>\n",
       "      <td>0.902530</td>\n",
       "      <td>0.903249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.054100</td>\n",
       "      <td>0.477575</td>\n",
       "      <td>0.902997</td>\n",
       "      <td>0.903215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.055700</td>\n",
       "      <td>0.480506</td>\n",
       "      <td>0.903387</td>\n",
       "      <td>0.903124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.049600</td>\n",
       "      <td>0.483279</td>\n",
       "      <td>0.903776</td>\n",
       "      <td>0.903604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.032700</td>\n",
       "      <td>0.532211</td>\n",
       "      <td>0.904710</td>\n",
       "      <td>0.904740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.028400</td>\n",
       "      <td>0.569697</td>\n",
       "      <td>0.904087</td>\n",
       "      <td>0.904000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.036800</td>\n",
       "      <td>0.581196</td>\n",
       "      <td>0.905722</td>\n",
       "      <td>0.905903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.042800</td>\n",
       "      <td>0.521853</td>\n",
       "      <td>0.905021</td>\n",
       "      <td>0.904801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.022200</td>\n",
       "      <td>0.581005</td>\n",
       "      <td>0.906189</td>\n",
       "      <td>0.906202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.022700</td>\n",
       "      <td>0.597939</td>\n",
       "      <td>0.905800</td>\n",
       "      <td>0.905704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.026000</td>\n",
       "      <td>0.612935</td>\n",
       "      <td>0.905956</td>\n",
       "      <td>0.905987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.022600</td>\n",
       "      <td>0.592642</td>\n",
       "      <td>0.905021</td>\n",
       "      <td>0.904933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.019600</td>\n",
       "      <td>0.600205</td>\n",
       "      <td>0.907513</td>\n",
       "      <td>0.906872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.015800</td>\n",
       "      <td>0.602844</td>\n",
       "      <td>0.905956</td>\n",
       "      <td>0.905797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.016800</td>\n",
       "      <td>0.620204</td>\n",
       "      <td>0.906267</td>\n",
       "      <td>0.905877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.017400</td>\n",
       "      <td>0.627750</td>\n",
       "      <td>0.906578</td>\n",
       "      <td>0.906429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.013600</td>\n",
       "      <td>0.626012</td>\n",
       "      <td>0.906501</td>\n",
       "      <td>0.906528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.015100</td>\n",
       "      <td>0.631474</td>\n",
       "      <td>0.906578</td>\n",
       "      <td>0.906246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.011700</td>\n",
       "      <td>0.631361</td>\n",
       "      <td>0.906578</td>\n",
       "      <td>0.906248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>0.633414</td>\n",
       "      <td>0.906423</td>\n",
       "      <td>0.906080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorRoBERTa, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at otmangi/MorRoBERTa and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44b46d3f1ab74ff5b904308f02ea5fa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51377 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b807ff24e864de896cc21d827a35dfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12845 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6424' max='6424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6424/6424 06:10, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.449200</td>\n",
       "      <td>0.381331</td>\n",
       "      <td>0.863060</td>\n",
       "      <td>0.864897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.349000</td>\n",
       "      <td>0.335805</td>\n",
       "      <td>0.875671</td>\n",
       "      <td>0.871118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.308700</td>\n",
       "      <td>0.296456</td>\n",
       "      <td>0.890308</td>\n",
       "      <td>0.889271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.294500</td>\n",
       "      <td>0.289893</td>\n",
       "      <td>0.895368</td>\n",
       "      <td>0.895978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.178400</td>\n",
       "      <td>0.318541</td>\n",
       "      <td>0.901985</td>\n",
       "      <td>0.902658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.176400</td>\n",
       "      <td>0.296424</td>\n",
       "      <td>0.901985</td>\n",
       "      <td>0.901243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.162000</td>\n",
       "      <td>0.315100</td>\n",
       "      <td>0.904165</td>\n",
       "      <td>0.903541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.169600</td>\n",
       "      <td>0.279239</td>\n",
       "      <td>0.906111</td>\n",
       "      <td>0.905810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.088500</td>\n",
       "      <td>0.407914</td>\n",
       "      <td>0.899572</td>\n",
       "      <td>0.898408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.087000</td>\n",
       "      <td>0.384672</td>\n",
       "      <td>0.902608</td>\n",
       "      <td>0.902209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.099700</td>\n",
       "      <td>0.392583</td>\n",
       "      <td>0.902452</td>\n",
       "      <td>0.901592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.096100</td>\n",
       "      <td>0.407050</td>\n",
       "      <td>0.902141</td>\n",
       "      <td>0.901904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.055400</td>\n",
       "      <td>0.492515</td>\n",
       "      <td>0.902530</td>\n",
       "      <td>0.903249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.054100</td>\n",
       "      <td>0.477575</td>\n",
       "      <td>0.902997</td>\n",
       "      <td>0.903215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.055700</td>\n",
       "      <td>0.480506</td>\n",
       "      <td>0.903387</td>\n",
       "      <td>0.903124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.049600</td>\n",
       "      <td>0.483279</td>\n",
       "      <td>0.903776</td>\n",
       "      <td>0.903604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.032700</td>\n",
       "      <td>0.532211</td>\n",
       "      <td>0.904710</td>\n",
       "      <td>0.904740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.028400</td>\n",
       "      <td>0.569697</td>\n",
       "      <td>0.904087</td>\n",
       "      <td>0.904000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.036800</td>\n",
       "      <td>0.581196</td>\n",
       "      <td>0.905722</td>\n",
       "      <td>0.905903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.042800</td>\n",
       "      <td>0.521853</td>\n",
       "      <td>0.905021</td>\n",
       "      <td>0.904801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.022200</td>\n",
       "      <td>0.581005</td>\n",
       "      <td>0.906189</td>\n",
       "      <td>0.906202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.022700</td>\n",
       "      <td>0.597939</td>\n",
       "      <td>0.905800</td>\n",
       "      <td>0.905704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.026000</td>\n",
       "      <td>0.612935</td>\n",
       "      <td>0.905956</td>\n",
       "      <td>0.905987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.022600</td>\n",
       "      <td>0.592642</td>\n",
       "      <td>0.905021</td>\n",
       "      <td>0.904933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.019600</td>\n",
       "      <td>0.600205</td>\n",
       "      <td>0.907513</td>\n",
       "      <td>0.906872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.015800</td>\n",
       "      <td>0.602844</td>\n",
       "      <td>0.905956</td>\n",
       "      <td>0.905797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.016800</td>\n",
       "      <td>0.620204</td>\n",
       "      <td>0.906267</td>\n",
       "      <td>0.905877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.017400</td>\n",
       "      <td>0.627750</td>\n",
       "      <td>0.906578</td>\n",
       "      <td>0.906429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.013600</td>\n",
       "      <td>0.626012</td>\n",
       "      <td>0.906501</td>\n",
       "      <td>0.906528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.015100</td>\n",
       "      <td>0.631474</td>\n",
       "      <td>0.906578</td>\n",
       "      <td>0.906246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.011700</td>\n",
       "      <td>0.631361</td>\n",
       "      <td>0.906578</td>\n",
       "      <td>0.906248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>0.633414</td>\n",
       "      <td>0.906423</td>\n",
       "      <td>0.906080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorRoBERTa, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at otmangi/MorRoBERTa and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e81182426af45a8b702aab85d0856b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51377 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8a13b14d1e743ec8ac4792bc892f47f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12845 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6424' max='6424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6424/6424 06:09, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.468700</td>\n",
       "      <td>0.358230</td>\n",
       "      <td>0.873414</td>\n",
       "      <td>0.874743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.339500</td>\n",
       "      <td>0.305986</td>\n",
       "      <td>0.892176</td>\n",
       "      <td>0.892832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.313600</td>\n",
       "      <td>0.292364</td>\n",
       "      <td>0.888906</td>\n",
       "      <td>0.891959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.291800</td>\n",
       "      <td>0.261497</td>\n",
       "      <td>0.906423</td>\n",
       "      <td>0.907150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.177100</td>\n",
       "      <td>0.275330</td>\n",
       "      <td>0.902919</td>\n",
       "      <td>0.903832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.172600</td>\n",
       "      <td>0.292116</td>\n",
       "      <td>0.905644</td>\n",
       "      <td>0.905420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.176900</td>\n",
       "      <td>0.286460</td>\n",
       "      <td>0.907513</td>\n",
       "      <td>0.908090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.172200</td>\n",
       "      <td>0.282158</td>\n",
       "      <td>0.906968</td>\n",
       "      <td>0.907706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.080200</td>\n",
       "      <td>0.369006</td>\n",
       "      <td>0.910393</td>\n",
       "      <td>0.911157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.086700</td>\n",
       "      <td>0.355608</td>\n",
       "      <td>0.906189</td>\n",
       "      <td>0.907431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.093600</td>\n",
       "      <td>0.347609</td>\n",
       "      <td>0.909848</td>\n",
       "      <td>0.910700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.103700</td>\n",
       "      <td>0.327377</td>\n",
       "      <td>0.907746</td>\n",
       "      <td>0.909010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.048900</td>\n",
       "      <td>0.449438</td>\n",
       "      <td>0.907668</td>\n",
       "      <td>0.909063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.047500</td>\n",
       "      <td>0.480869</td>\n",
       "      <td>0.907591</td>\n",
       "      <td>0.907772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.054600</td>\n",
       "      <td>0.465744</td>\n",
       "      <td>0.905333</td>\n",
       "      <td>0.905690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.058600</td>\n",
       "      <td>0.494646</td>\n",
       "      <td>0.904944</td>\n",
       "      <td>0.905281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.031700</td>\n",
       "      <td>0.552938</td>\n",
       "      <td>0.905956</td>\n",
       "      <td>0.906849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.031700</td>\n",
       "      <td>0.588008</td>\n",
       "      <td>0.905021</td>\n",
       "      <td>0.905838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.034000</td>\n",
       "      <td>0.505890</td>\n",
       "      <td>0.906423</td>\n",
       "      <td>0.907236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.037400</td>\n",
       "      <td>0.534895</td>\n",
       "      <td>0.907357</td>\n",
       "      <td>0.908372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.020500</td>\n",
       "      <td>0.585246</td>\n",
       "      <td>0.906501</td>\n",
       "      <td>0.907869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.020500</td>\n",
       "      <td>0.573998</td>\n",
       "      <td>0.909225</td>\n",
       "      <td>0.910244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.023500</td>\n",
       "      <td>0.583451</td>\n",
       "      <td>0.907435</td>\n",
       "      <td>0.907119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.022000</td>\n",
       "      <td>0.593805</td>\n",
       "      <td>0.909225</td>\n",
       "      <td>0.909172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.015300</td>\n",
       "      <td>0.610524</td>\n",
       "      <td>0.910782</td>\n",
       "      <td>0.911175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.015600</td>\n",
       "      <td>0.605517</td>\n",
       "      <td>0.910471</td>\n",
       "      <td>0.911035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.014600</td>\n",
       "      <td>0.614355</td>\n",
       "      <td>0.908135</td>\n",
       "      <td>0.908576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.014900</td>\n",
       "      <td>0.610635</td>\n",
       "      <td>0.909459</td>\n",
       "      <td>0.910286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>0.626595</td>\n",
       "      <td>0.909537</td>\n",
       "      <td>0.910342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.013300</td>\n",
       "      <td>0.627037</td>\n",
       "      <td>0.908525</td>\n",
       "      <td>0.909403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.012400</td>\n",
       "      <td>0.629618</td>\n",
       "      <td>0.909381</td>\n",
       "      <td>0.910199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.011100</td>\n",
       "      <td>0.628645</td>\n",
       "      <td>0.910160</td>\n",
       "      <td>0.910935</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorRoBERTa, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at otmangi/MorRoBERTa and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8b8e79c14d641499d9cbfda83d512e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51377 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c918a3dcef64ba1b8d58569f68aa2bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12845 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6424' max='6424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6424/6424 06:09, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.468700</td>\n",
       "      <td>0.358230</td>\n",
       "      <td>0.873414</td>\n",
       "      <td>0.874743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.339500</td>\n",
       "      <td>0.305986</td>\n",
       "      <td>0.892176</td>\n",
       "      <td>0.892832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.313600</td>\n",
       "      <td>0.292364</td>\n",
       "      <td>0.888906</td>\n",
       "      <td>0.891959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.291800</td>\n",
       "      <td>0.261497</td>\n",
       "      <td>0.906423</td>\n",
       "      <td>0.907150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.177100</td>\n",
       "      <td>0.275330</td>\n",
       "      <td>0.902919</td>\n",
       "      <td>0.903832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.172600</td>\n",
       "      <td>0.292116</td>\n",
       "      <td>0.905644</td>\n",
       "      <td>0.905420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.176900</td>\n",
       "      <td>0.286460</td>\n",
       "      <td>0.907513</td>\n",
       "      <td>0.908090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.172200</td>\n",
       "      <td>0.282158</td>\n",
       "      <td>0.906968</td>\n",
       "      <td>0.907706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.080200</td>\n",
       "      <td>0.369006</td>\n",
       "      <td>0.910393</td>\n",
       "      <td>0.911157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.086700</td>\n",
       "      <td>0.355608</td>\n",
       "      <td>0.906189</td>\n",
       "      <td>0.907431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.093600</td>\n",
       "      <td>0.347609</td>\n",
       "      <td>0.909848</td>\n",
       "      <td>0.910700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.103700</td>\n",
       "      <td>0.327377</td>\n",
       "      <td>0.907746</td>\n",
       "      <td>0.909010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.048900</td>\n",
       "      <td>0.449438</td>\n",
       "      <td>0.907668</td>\n",
       "      <td>0.909063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.047500</td>\n",
       "      <td>0.480869</td>\n",
       "      <td>0.907591</td>\n",
       "      <td>0.907772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.054600</td>\n",
       "      <td>0.465744</td>\n",
       "      <td>0.905333</td>\n",
       "      <td>0.905690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.058600</td>\n",
       "      <td>0.494646</td>\n",
       "      <td>0.904944</td>\n",
       "      <td>0.905281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.031700</td>\n",
       "      <td>0.552938</td>\n",
       "      <td>0.905956</td>\n",
       "      <td>0.906849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.031700</td>\n",
       "      <td>0.588008</td>\n",
       "      <td>0.905021</td>\n",
       "      <td>0.905838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.034000</td>\n",
       "      <td>0.505890</td>\n",
       "      <td>0.906423</td>\n",
       "      <td>0.907236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.037400</td>\n",
       "      <td>0.534895</td>\n",
       "      <td>0.907357</td>\n",
       "      <td>0.908372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.020500</td>\n",
       "      <td>0.585246</td>\n",
       "      <td>0.906501</td>\n",
       "      <td>0.907869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.020500</td>\n",
       "      <td>0.573998</td>\n",
       "      <td>0.909225</td>\n",
       "      <td>0.910244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.023500</td>\n",
       "      <td>0.583451</td>\n",
       "      <td>0.907435</td>\n",
       "      <td>0.907119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.022000</td>\n",
       "      <td>0.593805</td>\n",
       "      <td>0.909225</td>\n",
       "      <td>0.909172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.015300</td>\n",
       "      <td>0.610524</td>\n",
       "      <td>0.910782</td>\n",
       "      <td>0.911175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.015600</td>\n",
       "      <td>0.605517</td>\n",
       "      <td>0.910471</td>\n",
       "      <td>0.911035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.014600</td>\n",
       "      <td>0.614355</td>\n",
       "      <td>0.908135</td>\n",
       "      <td>0.908576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.014900</td>\n",
       "      <td>0.610635</td>\n",
       "      <td>0.909459</td>\n",
       "      <td>0.910286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>0.626595</td>\n",
       "      <td>0.909537</td>\n",
       "      <td>0.910342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.013300</td>\n",
       "      <td>0.627037</td>\n",
       "      <td>0.908525</td>\n",
       "      <td>0.909403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.012400</td>\n",
       "      <td>0.629618</td>\n",
       "      <td>0.909381</td>\n",
       "      <td>0.910199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.011100</td>\n",
       "      <td>0.628645</td>\n",
       "      <td>0.910160</td>\n",
       "      <td>0.910935</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorRoBERTa, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at otmangi/MorRoBERTa and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3759e72244834993b34ff1f2e2de453a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51377 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88ab285682d8460aac68c81ec17820c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12845 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6424' max='6424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6424/6424 06:08, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.468700</td>\n",
       "      <td>0.358230</td>\n",
       "      <td>0.873414</td>\n",
       "      <td>0.874743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.339500</td>\n",
       "      <td>0.305986</td>\n",
       "      <td>0.892176</td>\n",
       "      <td>0.892832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.313600</td>\n",
       "      <td>0.292364</td>\n",
       "      <td>0.888906</td>\n",
       "      <td>0.891959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.291800</td>\n",
       "      <td>0.261497</td>\n",
       "      <td>0.906423</td>\n",
       "      <td>0.907150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.177100</td>\n",
       "      <td>0.275330</td>\n",
       "      <td>0.902919</td>\n",
       "      <td>0.903832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.172600</td>\n",
       "      <td>0.292116</td>\n",
       "      <td>0.905644</td>\n",
       "      <td>0.905420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.176900</td>\n",
       "      <td>0.286460</td>\n",
       "      <td>0.907513</td>\n",
       "      <td>0.908090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.172200</td>\n",
       "      <td>0.282158</td>\n",
       "      <td>0.906968</td>\n",
       "      <td>0.907706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.080200</td>\n",
       "      <td>0.369006</td>\n",
       "      <td>0.910393</td>\n",
       "      <td>0.911157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.086700</td>\n",
       "      <td>0.355608</td>\n",
       "      <td>0.906189</td>\n",
       "      <td>0.907431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.093600</td>\n",
       "      <td>0.347609</td>\n",
       "      <td>0.909848</td>\n",
       "      <td>0.910700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.103700</td>\n",
       "      <td>0.327377</td>\n",
       "      <td>0.907746</td>\n",
       "      <td>0.909010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.048900</td>\n",
       "      <td>0.449438</td>\n",
       "      <td>0.907668</td>\n",
       "      <td>0.909063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.047500</td>\n",
       "      <td>0.480869</td>\n",
       "      <td>0.907591</td>\n",
       "      <td>0.907772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.054600</td>\n",
       "      <td>0.465744</td>\n",
       "      <td>0.905333</td>\n",
       "      <td>0.905690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.058600</td>\n",
       "      <td>0.494646</td>\n",
       "      <td>0.904944</td>\n",
       "      <td>0.905281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.031700</td>\n",
       "      <td>0.552938</td>\n",
       "      <td>0.905956</td>\n",
       "      <td>0.906849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.031700</td>\n",
       "      <td>0.588008</td>\n",
       "      <td>0.905021</td>\n",
       "      <td>0.905838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.034000</td>\n",
       "      <td>0.505890</td>\n",
       "      <td>0.906423</td>\n",
       "      <td>0.907236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.037400</td>\n",
       "      <td>0.534895</td>\n",
       "      <td>0.907357</td>\n",
       "      <td>0.908372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.020500</td>\n",
       "      <td>0.585246</td>\n",
       "      <td>0.906501</td>\n",
       "      <td>0.907869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.020500</td>\n",
       "      <td>0.573998</td>\n",
       "      <td>0.909225</td>\n",
       "      <td>0.910244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.023500</td>\n",
       "      <td>0.583451</td>\n",
       "      <td>0.907435</td>\n",
       "      <td>0.907119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.022000</td>\n",
       "      <td>0.593805</td>\n",
       "      <td>0.909225</td>\n",
       "      <td>0.909172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.015300</td>\n",
       "      <td>0.610524</td>\n",
       "      <td>0.910782</td>\n",
       "      <td>0.911175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.015600</td>\n",
       "      <td>0.605517</td>\n",
       "      <td>0.910471</td>\n",
       "      <td>0.911035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.014600</td>\n",
       "      <td>0.614355</td>\n",
       "      <td>0.908135</td>\n",
       "      <td>0.908576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.014900</td>\n",
       "      <td>0.610635</td>\n",
       "      <td>0.909459</td>\n",
       "      <td>0.910286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>0.626595</td>\n",
       "      <td>0.909537</td>\n",
       "      <td>0.910342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.013300</td>\n",
       "      <td>0.627037</td>\n",
       "      <td>0.908525</td>\n",
       "      <td>0.909403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.012400</td>\n",
       "      <td>0.629618</td>\n",
       "      <td>0.909381</td>\n",
       "      <td>0.910199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.011100</td>\n",
       "      <td>0.628645</td>\n",
       "      <td>0.910160</td>\n",
       "      <td>0.910935</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorRoBERTa, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at otmangi/MorRoBERTa and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b48f404ab00a4d6fbcfd5661eaeefa7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51377 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89438e993310446a8a6fe791e6dd0ba5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12845 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6424' max='6424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6424/6424 06:08, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.452000</td>\n",
       "      <td>0.362233</td>\n",
       "      <td>0.869132</td>\n",
       "      <td>0.868800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.353900</td>\n",
       "      <td>0.310882</td>\n",
       "      <td>0.888595</td>\n",
       "      <td>0.888821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.300100</td>\n",
       "      <td>0.291284</td>\n",
       "      <td>0.895446</td>\n",
       "      <td>0.894021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.286200</td>\n",
       "      <td>0.272319</td>\n",
       "      <td>0.902997</td>\n",
       "      <td>0.903442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.174400</td>\n",
       "      <td>0.316386</td>\n",
       "      <td>0.898015</td>\n",
       "      <td>0.896903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.165500</td>\n",
       "      <td>0.297206</td>\n",
       "      <td>0.902530</td>\n",
       "      <td>0.901812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.173000</td>\n",
       "      <td>0.298129</td>\n",
       "      <td>0.905255</td>\n",
       "      <td>0.905727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.170600</td>\n",
       "      <td>0.307524</td>\n",
       "      <td>0.905566</td>\n",
       "      <td>0.904342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.086500</td>\n",
       "      <td>0.415871</td>\n",
       "      <td>0.900117</td>\n",
       "      <td>0.901111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.086300</td>\n",
       "      <td>0.411729</td>\n",
       "      <td>0.901752</td>\n",
       "      <td>0.901802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.098000</td>\n",
       "      <td>0.364900</td>\n",
       "      <td>0.901285</td>\n",
       "      <td>0.901694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.091000</td>\n",
       "      <td>0.385780</td>\n",
       "      <td>0.902608</td>\n",
       "      <td>0.903255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.055300</td>\n",
       "      <td>0.483809</td>\n",
       "      <td>0.903231</td>\n",
       "      <td>0.903589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.055100</td>\n",
       "      <td>0.521487</td>\n",
       "      <td>0.900740</td>\n",
       "      <td>0.901274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.051100</td>\n",
       "      <td>0.476222</td>\n",
       "      <td>0.903387</td>\n",
       "      <td>0.903216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.052400</td>\n",
       "      <td>0.512421</td>\n",
       "      <td>0.904009</td>\n",
       "      <td>0.903748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.032200</td>\n",
       "      <td>0.550044</td>\n",
       "      <td>0.906812</td>\n",
       "      <td>0.906974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.031400</td>\n",
       "      <td>0.553151</td>\n",
       "      <td>0.905333</td>\n",
       "      <td>0.905667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.033200</td>\n",
       "      <td>0.571546</td>\n",
       "      <td>0.904866</td>\n",
       "      <td>0.904972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.032600</td>\n",
       "      <td>0.575086</td>\n",
       "      <td>0.903387</td>\n",
       "      <td>0.903369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.023900</td>\n",
       "      <td>0.605230</td>\n",
       "      <td>0.905800</td>\n",
       "      <td>0.905563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.022800</td>\n",
       "      <td>0.612544</td>\n",
       "      <td>0.905255</td>\n",
       "      <td>0.905590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.018600</td>\n",
       "      <td>0.622190</td>\n",
       "      <td>0.904788</td>\n",
       "      <td>0.904727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.022300</td>\n",
       "      <td>0.618053</td>\n",
       "      <td>0.906345</td>\n",
       "      <td>0.906330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.019100</td>\n",
       "      <td>0.644104</td>\n",
       "      <td>0.903620</td>\n",
       "      <td>0.904054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.015300</td>\n",
       "      <td>0.639092</td>\n",
       "      <td>0.905333</td>\n",
       "      <td>0.905332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.017700</td>\n",
       "      <td>0.633555</td>\n",
       "      <td>0.907201</td>\n",
       "      <td>0.907194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.015100</td>\n",
       "      <td>0.647092</td>\n",
       "      <td>0.906267</td>\n",
       "      <td>0.906337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.012400</td>\n",
       "      <td>0.648194</td>\n",
       "      <td>0.906267</td>\n",
       "      <td>0.906306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.013600</td>\n",
       "      <td>0.653652</td>\n",
       "      <td>0.906111</td>\n",
       "      <td>0.906092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>0.652734</td>\n",
       "      <td>0.905956</td>\n",
       "      <td>0.905806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.012300</td>\n",
       "      <td>0.653309</td>\n",
       "      <td>0.906345</td>\n",
       "      <td>0.906370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorRoBERTa, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at otmangi/MorRoBERTa and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7396cfc743b492888966150a9837d8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51377 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec8a15bc0cf6455fba135bd24d343173",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12845 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6424' max='6424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6424/6424 06:09, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.452000</td>\n",
       "      <td>0.362233</td>\n",
       "      <td>0.869132</td>\n",
       "      <td>0.868800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.353900</td>\n",
       "      <td>0.310882</td>\n",
       "      <td>0.888595</td>\n",
       "      <td>0.888821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.300100</td>\n",
       "      <td>0.291284</td>\n",
       "      <td>0.895446</td>\n",
       "      <td>0.894021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.286200</td>\n",
       "      <td>0.272319</td>\n",
       "      <td>0.902997</td>\n",
       "      <td>0.903442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.174400</td>\n",
       "      <td>0.316386</td>\n",
       "      <td>0.898015</td>\n",
       "      <td>0.896903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.165500</td>\n",
       "      <td>0.297206</td>\n",
       "      <td>0.902530</td>\n",
       "      <td>0.901812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.173000</td>\n",
       "      <td>0.298129</td>\n",
       "      <td>0.905255</td>\n",
       "      <td>0.905727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.170600</td>\n",
       "      <td>0.307524</td>\n",
       "      <td>0.905566</td>\n",
       "      <td>0.904342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.086500</td>\n",
       "      <td>0.415871</td>\n",
       "      <td>0.900117</td>\n",
       "      <td>0.901111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.086300</td>\n",
       "      <td>0.411729</td>\n",
       "      <td>0.901752</td>\n",
       "      <td>0.901802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.098000</td>\n",
       "      <td>0.364900</td>\n",
       "      <td>0.901285</td>\n",
       "      <td>0.901694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.091000</td>\n",
       "      <td>0.385780</td>\n",
       "      <td>0.902608</td>\n",
       "      <td>0.903255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.055300</td>\n",
       "      <td>0.483809</td>\n",
       "      <td>0.903231</td>\n",
       "      <td>0.903589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.055100</td>\n",
       "      <td>0.521487</td>\n",
       "      <td>0.900740</td>\n",
       "      <td>0.901274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.051100</td>\n",
       "      <td>0.476222</td>\n",
       "      <td>0.903387</td>\n",
       "      <td>0.903216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.052400</td>\n",
       "      <td>0.512421</td>\n",
       "      <td>0.904009</td>\n",
       "      <td>0.903748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.032200</td>\n",
       "      <td>0.550044</td>\n",
       "      <td>0.906812</td>\n",
       "      <td>0.906974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.031400</td>\n",
       "      <td>0.553151</td>\n",
       "      <td>0.905333</td>\n",
       "      <td>0.905667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.033200</td>\n",
       "      <td>0.571546</td>\n",
       "      <td>0.904866</td>\n",
       "      <td>0.904972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.032600</td>\n",
       "      <td>0.575086</td>\n",
       "      <td>0.903387</td>\n",
       "      <td>0.903369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.023900</td>\n",
       "      <td>0.605230</td>\n",
       "      <td>0.905800</td>\n",
       "      <td>0.905563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.022800</td>\n",
       "      <td>0.612544</td>\n",
       "      <td>0.905255</td>\n",
       "      <td>0.905590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.018600</td>\n",
       "      <td>0.622190</td>\n",
       "      <td>0.904788</td>\n",
       "      <td>0.904727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.022300</td>\n",
       "      <td>0.618053</td>\n",
       "      <td>0.906345</td>\n",
       "      <td>0.906330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.019100</td>\n",
       "      <td>0.644104</td>\n",
       "      <td>0.903620</td>\n",
       "      <td>0.904054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.015300</td>\n",
       "      <td>0.639092</td>\n",
       "      <td>0.905333</td>\n",
       "      <td>0.905332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.017700</td>\n",
       "      <td>0.633555</td>\n",
       "      <td>0.907201</td>\n",
       "      <td>0.907194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.015100</td>\n",
       "      <td>0.647092</td>\n",
       "      <td>0.906267</td>\n",
       "      <td>0.906337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.012400</td>\n",
       "      <td>0.648194</td>\n",
       "      <td>0.906267</td>\n",
       "      <td>0.906306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.013600</td>\n",
       "      <td>0.653652</td>\n",
       "      <td>0.906111</td>\n",
       "      <td>0.906092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>0.652734</td>\n",
       "      <td>0.905956</td>\n",
       "      <td>0.905806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.012300</td>\n",
       "      <td>0.653309</td>\n",
       "      <td>0.906345</td>\n",
       "      <td>0.906370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorRoBERTa, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at otmangi/MorRoBERTa and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20fde9a9eba648a5b49672b8d5bddbd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51377 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3087a17d2f3d4e689c9ec9c733c4b431",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12845 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6424' max='6424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6424/6424 06:08, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.452000</td>\n",
       "      <td>0.362233</td>\n",
       "      <td>0.869132</td>\n",
       "      <td>0.868800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.353900</td>\n",
       "      <td>0.310882</td>\n",
       "      <td>0.888595</td>\n",
       "      <td>0.888821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.300100</td>\n",
       "      <td>0.291284</td>\n",
       "      <td>0.895446</td>\n",
       "      <td>0.894021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.286200</td>\n",
       "      <td>0.272319</td>\n",
       "      <td>0.902997</td>\n",
       "      <td>0.903442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.174400</td>\n",
       "      <td>0.316386</td>\n",
       "      <td>0.898015</td>\n",
       "      <td>0.896903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.165500</td>\n",
       "      <td>0.297206</td>\n",
       "      <td>0.902530</td>\n",
       "      <td>0.901812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.173000</td>\n",
       "      <td>0.298129</td>\n",
       "      <td>0.905255</td>\n",
       "      <td>0.905727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.170600</td>\n",
       "      <td>0.307524</td>\n",
       "      <td>0.905566</td>\n",
       "      <td>0.904342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.086500</td>\n",
       "      <td>0.415871</td>\n",
       "      <td>0.900117</td>\n",
       "      <td>0.901111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.086300</td>\n",
       "      <td>0.411729</td>\n",
       "      <td>0.901752</td>\n",
       "      <td>0.901802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.098000</td>\n",
       "      <td>0.364900</td>\n",
       "      <td>0.901285</td>\n",
       "      <td>0.901694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.091000</td>\n",
       "      <td>0.385780</td>\n",
       "      <td>0.902608</td>\n",
       "      <td>0.903255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.055300</td>\n",
       "      <td>0.483809</td>\n",
       "      <td>0.903231</td>\n",
       "      <td>0.903589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.055100</td>\n",
       "      <td>0.521487</td>\n",
       "      <td>0.900740</td>\n",
       "      <td>0.901274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.051100</td>\n",
       "      <td>0.476222</td>\n",
       "      <td>0.903387</td>\n",
       "      <td>0.903216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.052400</td>\n",
       "      <td>0.512421</td>\n",
       "      <td>0.904009</td>\n",
       "      <td>0.903748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.032200</td>\n",
       "      <td>0.550044</td>\n",
       "      <td>0.906812</td>\n",
       "      <td>0.906974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.031400</td>\n",
       "      <td>0.553151</td>\n",
       "      <td>0.905333</td>\n",
       "      <td>0.905667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.033200</td>\n",
       "      <td>0.571546</td>\n",
       "      <td>0.904866</td>\n",
       "      <td>0.904972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.032600</td>\n",
       "      <td>0.575086</td>\n",
       "      <td>0.903387</td>\n",
       "      <td>0.903369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.023900</td>\n",
       "      <td>0.605230</td>\n",
       "      <td>0.905800</td>\n",
       "      <td>0.905563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.022800</td>\n",
       "      <td>0.612544</td>\n",
       "      <td>0.905255</td>\n",
       "      <td>0.905590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.018600</td>\n",
       "      <td>0.622190</td>\n",
       "      <td>0.904788</td>\n",
       "      <td>0.904727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.022300</td>\n",
       "      <td>0.618053</td>\n",
       "      <td>0.906345</td>\n",
       "      <td>0.906330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.019100</td>\n",
       "      <td>0.644104</td>\n",
       "      <td>0.903620</td>\n",
       "      <td>0.904054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.015300</td>\n",
       "      <td>0.639092</td>\n",
       "      <td>0.905333</td>\n",
       "      <td>0.905332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.017700</td>\n",
       "      <td>0.633555</td>\n",
       "      <td>0.907201</td>\n",
       "      <td>0.907194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.015100</td>\n",
       "      <td>0.647092</td>\n",
       "      <td>0.906267</td>\n",
       "      <td>0.906337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.012400</td>\n",
       "      <td>0.648194</td>\n",
       "      <td>0.906267</td>\n",
       "      <td>0.906306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.013600</td>\n",
       "      <td>0.653652</td>\n",
       "      <td>0.906111</td>\n",
       "      <td>0.906092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>0.652734</td>\n",
       "      <td>0.905956</td>\n",
       "      <td>0.905806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.012300</td>\n",
       "      <td>0.653309</td>\n",
       "      <td>0.906345</td>\n",
       "      <td>0.906370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 51377\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 12845\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorrBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at otmangi/MorrBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4aa1a34190e8402687c076153cfcb02e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51377 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f38425f612a4f11b4b80a9c76890ae7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12845 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6424' max='6424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6424/6424 11:02, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.354139</td>\n",
       "      <td>0.872324</td>\n",
       "      <td>0.874845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.347200</td>\n",
       "      <td>0.324865</td>\n",
       "      <td>0.880888</td>\n",
       "      <td>0.880941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.315000</td>\n",
       "      <td>0.296596</td>\n",
       "      <td>0.888906</td>\n",
       "      <td>0.890234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.308347</td>\n",
       "      <td>0.892721</td>\n",
       "      <td>0.895142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.170700</td>\n",
       "      <td>0.347716</td>\n",
       "      <td>0.890930</td>\n",
       "      <td>0.892301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.174300</td>\n",
       "      <td>0.333449</td>\n",
       "      <td>0.891865</td>\n",
       "      <td>0.892253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.168000</td>\n",
       "      <td>0.336878</td>\n",
       "      <td>0.895835</td>\n",
       "      <td>0.895771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.177400</td>\n",
       "      <td>0.313976</td>\n",
       "      <td>0.898015</td>\n",
       "      <td>0.897793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.089900</td>\n",
       "      <td>0.413524</td>\n",
       "      <td>0.894511</td>\n",
       "      <td>0.895071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.094500</td>\n",
       "      <td>0.426238</td>\n",
       "      <td>0.891787</td>\n",
       "      <td>0.892909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.105200</td>\n",
       "      <td>0.446480</td>\n",
       "      <td>0.893110</td>\n",
       "      <td>0.892207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.097900</td>\n",
       "      <td>0.404792</td>\n",
       "      <td>0.893889</td>\n",
       "      <td>0.893764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.061100</td>\n",
       "      <td>0.481279</td>\n",
       "      <td>0.895368</td>\n",
       "      <td>0.895854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.063300</td>\n",
       "      <td>0.521964</td>\n",
       "      <td>0.894356</td>\n",
       "      <td>0.894861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.065800</td>\n",
       "      <td>0.463645</td>\n",
       "      <td>0.895368</td>\n",
       "      <td>0.895601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.061400</td>\n",
       "      <td>0.509838</td>\n",
       "      <td>0.894823</td>\n",
       "      <td>0.894927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.039900</td>\n",
       "      <td>0.523495</td>\n",
       "      <td>0.894901</td>\n",
       "      <td>0.895152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.041700</td>\n",
       "      <td>0.565968</td>\n",
       "      <td>0.894278</td>\n",
       "      <td>0.895140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.047300</td>\n",
       "      <td>0.566300</td>\n",
       "      <td>0.895757</td>\n",
       "      <td>0.896652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.048600</td>\n",
       "      <td>0.559410</td>\n",
       "      <td>0.897781</td>\n",
       "      <td>0.898302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.028800</td>\n",
       "      <td>0.639080</td>\n",
       "      <td>0.898715</td>\n",
       "      <td>0.899148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.030600</td>\n",
       "      <td>0.669835</td>\n",
       "      <td>0.894589</td>\n",
       "      <td>0.896012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.036500</td>\n",
       "      <td>0.622254</td>\n",
       "      <td>0.897470</td>\n",
       "      <td>0.898046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.031500</td>\n",
       "      <td>0.633276</td>\n",
       "      <td>0.898482</td>\n",
       "      <td>0.899359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.025600</td>\n",
       "      <td>0.640093</td>\n",
       "      <td>0.898638</td>\n",
       "      <td>0.899025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.025700</td>\n",
       "      <td>0.648211</td>\n",
       "      <td>0.896224</td>\n",
       "      <td>0.897138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.028000</td>\n",
       "      <td>0.656782</td>\n",
       "      <td>0.898015</td>\n",
       "      <td>0.898657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.023900</td>\n",
       "      <td>0.684046</td>\n",
       "      <td>0.897470</td>\n",
       "      <td>0.898910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.023500</td>\n",
       "      <td>0.677916</td>\n",
       "      <td>0.897470</td>\n",
       "      <td>0.898812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.021100</td>\n",
       "      <td>0.683842</td>\n",
       "      <td>0.897781</td>\n",
       "      <td>0.898855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.021200</td>\n",
       "      <td>0.683560</td>\n",
       "      <td>0.898404</td>\n",
       "      <td>0.899425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.019200</td>\n",
       "      <td>0.685880</td>\n",
       "      <td>0.898404</td>\n",
       "      <td>0.899523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorrBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at otmangi/MorrBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28f0ff5342794acabbaecc8d8bf0f1a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51377 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50c5f777f7f6421b94fb36dacf263e72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12845 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6424' max='6424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6424/6424 11:05, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.354139</td>\n",
       "      <td>0.872324</td>\n",
       "      <td>0.874845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.347200</td>\n",
       "      <td>0.324865</td>\n",
       "      <td>0.880888</td>\n",
       "      <td>0.880941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.315000</td>\n",
       "      <td>0.296596</td>\n",
       "      <td>0.888906</td>\n",
       "      <td>0.890234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.308347</td>\n",
       "      <td>0.892721</td>\n",
       "      <td>0.895142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.170700</td>\n",
       "      <td>0.347716</td>\n",
       "      <td>0.890930</td>\n",
       "      <td>0.892301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.174300</td>\n",
       "      <td>0.333449</td>\n",
       "      <td>0.891865</td>\n",
       "      <td>0.892253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.168000</td>\n",
       "      <td>0.336878</td>\n",
       "      <td>0.895835</td>\n",
       "      <td>0.895771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.177400</td>\n",
       "      <td>0.313976</td>\n",
       "      <td>0.898015</td>\n",
       "      <td>0.897793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.089900</td>\n",
       "      <td>0.413524</td>\n",
       "      <td>0.894511</td>\n",
       "      <td>0.895071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.094500</td>\n",
       "      <td>0.426238</td>\n",
       "      <td>0.891787</td>\n",
       "      <td>0.892909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.105200</td>\n",
       "      <td>0.446480</td>\n",
       "      <td>0.893110</td>\n",
       "      <td>0.892207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.097900</td>\n",
       "      <td>0.404792</td>\n",
       "      <td>0.893889</td>\n",
       "      <td>0.893764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.061100</td>\n",
       "      <td>0.481279</td>\n",
       "      <td>0.895368</td>\n",
       "      <td>0.895854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.063300</td>\n",
       "      <td>0.521964</td>\n",
       "      <td>0.894356</td>\n",
       "      <td>0.894861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.065800</td>\n",
       "      <td>0.463645</td>\n",
       "      <td>0.895368</td>\n",
       "      <td>0.895601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.061400</td>\n",
       "      <td>0.509838</td>\n",
       "      <td>0.894823</td>\n",
       "      <td>0.894927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.039900</td>\n",
       "      <td>0.523495</td>\n",
       "      <td>0.894901</td>\n",
       "      <td>0.895152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.041700</td>\n",
       "      <td>0.565968</td>\n",
       "      <td>0.894278</td>\n",
       "      <td>0.895140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.047300</td>\n",
       "      <td>0.566300</td>\n",
       "      <td>0.895757</td>\n",
       "      <td>0.896652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.048600</td>\n",
       "      <td>0.559410</td>\n",
       "      <td>0.897781</td>\n",
       "      <td>0.898302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.028800</td>\n",
       "      <td>0.639080</td>\n",
       "      <td>0.898715</td>\n",
       "      <td>0.899148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.030600</td>\n",
       "      <td>0.669835</td>\n",
       "      <td>0.894589</td>\n",
       "      <td>0.896012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.036500</td>\n",
       "      <td>0.622254</td>\n",
       "      <td>0.897470</td>\n",
       "      <td>0.898046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.031500</td>\n",
       "      <td>0.633276</td>\n",
       "      <td>0.898482</td>\n",
       "      <td>0.899359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.025600</td>\n",
       "      <td>0.640093</td>\n",
       "      <td>0.898638</td>\n",
       "      <td>0.899025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.025700</td>\n",
       "      <td>0.648211</td>\n",
       "      <td>0.896224</td>\n",
       "      <td>0.897138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.028000</td>\n",
       "      <td>0.656782</td>\n",
       "      <td>0.898015</td>\n",
       "      <td>0.898657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.023900</td>\n",
       "      <td>0.684046</td>\n",
       "      <td>0.897470</td>\n",
       "      <td>0.898910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.023500</td>\n",
       "      <td>0.677916</td>\n",
       "      <td>0.897470</td>\n",
       "      <td>0.898812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.021100</td>\n",
       "      <td>0.683842</td>\n",
       "      <td>0.897781</td>\n",
       "      <td>0.898855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.021200</td>\n",
       "      <td>0.683560</td>\n",
       "      <td>0.898404</td>\n",
       "      <td>0.899425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.019200</td>\n",
       "      <td>0.685880</td>\n",
       "      <td>0.898404</td>\n",
       "      <td>0.899523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorrBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at otmangi/MorrBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a46add8181040e4ac49accf58dda2d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51377 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f8f46d50e914e3584f4be1fd9db1fe2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12845 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6424' max='6424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6424/6424 11:04, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.354139</td>\n",
       "      <td>0.872324</td>\n",
       "      <td>0.874845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.347200</td>\n",
       "      <td>0.324865</td>\n",
       "      <td>0.880888</td>\n",
       "      <td>0.880941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.315000</td>\n",
       "      <td>0.296596</td>\n",
       "      <td>0.888906</td>\n",
       "      <td>0.890234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.308347</td>\n",
       "      <td>0.892721</td>\n",
       "      <td>0.895142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.170700</td>\n",
       "      <td>0.347716</td>\n",
       "      <td>0.890930</td>\n",
       "      <td>0.892301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.174300</td>\n",
       "      <td>0.333449</td>\n",
       "      <td>0.891865</td>\n",
       "      <td>0.892253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.168000</td>\n",
       "      <td>0.336878</td>\n",
       "      <td>0.895835</td>\n",
       "      <td>0.895771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.177400</td>\n",
       "      <td>0.313976</td>\n",
       "      <td>0.898015</td>\n",
       "      <td>0.897793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.089900</td>\n",
       "      <td>0.413524</td>\n",
       "      <td>0.894511</td>\n",
       "      <td>0.895071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.094500</td>\n",
       "      <td>0.426238</td>\n",
       "      <td>0.891787</td>\n",
       "      <td>0.892909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.105200</td>\n",
       "      <td>0.446480</td>\n",
       "      <td>0.893110</td>\n",
       "      <td>0.892207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.097900</td>\n",
       "      <td>0.404792</td>\n",
       "      <td>0.893889</td>\n",
       "      <td>0.893764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.061100</td>\n",
       "      <td>0.481279</td>\n",
       "      <td>0.895368</td>\n",
       "      <td>0.895854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.063300</td>\n",
       "      <td>0.521964</td>\n",
       "      <td>0.894356</td>\n",
       "      <td>0.894861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.065800</td>\n",
       "      <td>0.463645</td>\n",
       "      <td>0.895368</td>\n",
       "      <td>0.895601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.061400</td>\n",
       "      <td>0.509838</td>\n",
       "      <td>0.894823</td>\n",
       "      <td>0.894927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.039900</td>\n",
       "      <td>0.523495</td>\n",
       "      <td>0.894901</td>\n",
       "      <td>0.895152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.041700</td>\n",
       "      <td>0.565968</td>\n",
       "      <td>0.894278</td>\n",
       "      <td>0.895140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.047300</td>\n",
       "      <td>0.566300</td>\n",
       "      <td>0.895757</td>\n",
       "      <td>0.896652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.048600</td>\n",
       "      <td>0.559410</td>\n",
       "      <td>0.897781</td>\n",
       "      <td>0.898302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.028800</td>\n",
       "      <td>0.639080</td>\n",
       "      <td>0.898715</td>\n",
       "      <td>0.899148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.030600</td>\n",
       "      <td>0.669835</td>\n",
       "      <td>0.894589</td>\n",
       "      <td>0.896012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.036500</td>\n",
       "      <td>0.622254</td>\n",
       "      <td>0.897470</td>\n",
       "      <td>0.898046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.031500</td>\n",
       "      <td>0.633276</td>\n",
       "      <td>0.898482</td>\n",
       "      <td>0.899359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.025600</td>\n",
       "      <td>0.640093</td>\n",
       "      <td>0.898638</td>\n",
       "      <td>0.899025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.025700</td>\n",
       "      <td>0.648211</td>\n",
       "      <td>0.896224</td>\n",
       "      <td>0.897138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.028000</td>\n",
       "      <td>0.656782</td>\n",
       "      <td>0.898015</td>\n",
       "      <td>0.898657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.023900</td>\n",
       "      <td>0.684046</td>\n",
       "      <td>0.897470</td>\n",
       "      <td>0.898910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.023500</td>\n",
       "      <td>0.677916</td>\n",
       "      <td>0.897470</td>\n",
       "      <td>0.898812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.021100</td>\n",
       "      <td>0.683842</td>\n",
       "      <td>0.897781</td>\n",
       "      <td>0.898855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.021200</td>\n",
       "      <td>0.683560</td>\n",
       "      <td>0.898404</td>\n",
       "      <td>0.899425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.019200</td>\n",
       "      <td>0.685880</td>\n",
       "      <td>0.898404</td>\n",
       "      <td>0.899523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorrBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at otmangi/MorrBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cab0d69a1cf54c7bb145651216a7c685",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51377 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d8b6504b15342bbbb306ea219b9af57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12845 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6424' max='6424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6424/6424 11:07, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.436400</td>\n",
       "      <td>0.346275</td>\n",
       "      <td>0.873803</td>\n",
       "      <td>0.875839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.336300</td>\n",
       "      <td>0.300309</td>\n",
       "      <td>0.892409</td>\n",
       "      <td>0.894643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.319000</td>\n",
       "      <td>0.299125</td>\n",
       "      <td>0.890152</td>\n",
       "      <td>0.893032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.302700</td>\n",
       "      <td>0.282584</td>\n",
       "      <td>0.893422</td>\n",
       "      <td>0.896292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.175800</td>\n",
       "      <td>0.317928</td>\n",
       "      <td>0.894200</td>\n",
       "      <td>0.895479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.173600</td>\n",
       "      <td>0.319565</td>\n",
       "      <td>0.894278</td>\n",
       "      <td>0.894376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.317738</td>\n",
       "      <td>0.902141</td>\n",
       "      <td>0.903876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.182200</td>\n",
       "      <td>0.286626</td>\n",
       "      <td>0.907201</td>\n",
       "      <td>0.908644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.091000</td>\n",
       "      <td>0.396008</td>\n",
       "      <td>0.897548</td>\n",
       "      <td>0.898855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.098800</td>\n",
       "      <td>0.366521</td>\n",
       "      <td>0.899338</td>\n",
       "      <td>0.900868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.095600</td>\n",
       "      <td>0.421587</td>\n",
       "      <td>0.901440</td>\n",
       "      <td>0.902747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.105800</td>\n",
       "      <td>0.352988</td>\n",
       "      <td>0.900117</td>\n",
       "      <td>0.902286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.057300</td>\n",
       "      <td>0.452039</td>\n",
       "      <td>0.901907</td>\n",
       "      <td>0.903164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.063400</td>\n",
       "      <td>0.503808</td>\n",
       "      <td>0.900350</td>\n",
       "      <td>0.901674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>0.475949</td>\n",
       "      <td>0.900039</td>\n",
       "      <td>0.901339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.064300</td>\n",
       "      <td>0.463258</td>\n",
       "      <td>0.898404</td>\n",
       "      <td>0.899637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.038900</td>\n",
       "      <td>0.511699</td>\n",
       "      <td>0.899728</td>\n",
       "      <td>0.901539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.048900</td>\n",
       "      <td>0.529941</td>\n",
       "      <td>0.900117</td>\n",
       "      <td>0.901118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.044800</td>\n",
       "      <td>0.525285</td>\n",
       "      <td>0.899338</td>\n",
       "      <td>0.901753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.045200</td>\n",
       "      <td>0.539386</td>\n",
       "      <td>0.900584</td>\n",
       "      <td>0.902373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.578020</td>\n",
       "      <td>0.901907</td>\n",
       "      <td>0.903309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.031800</td>\n",
       "      <td>0.572880</td>\n",
       "      <td>0.903464</td>\n",
       "      <td>0.905441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.028900</td>\n",
       "      <td>0.582538</td>\n",
       "      <td>0.902141</td>\n",
       "      <td>0.903882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.031700</td>\n",
       "      <td>0.572600</td>\n",
       "      <td>0.904087</td>\n",
       "      <td>0.906264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.026100</td>\n",
       "      <td>0.612891</td>\n",
       "      <td>0.902686</td>\n",
       "      <td>0.904633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.026500</td>\n",
       "      <td>0.621315</td>\n",
       "      <td>0.904476</td>\n",
       "      <td>0.906197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.022700</td>\n",
       "      <td>0.617634</td>\n",
       "      <td>0.904476</td>\n",
       "      <td>0.906231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.025900</td>\n",
       "      <td>0.619443</td>\n",
       "      <td>0.903854</td>\n",
       "      <td>0.905764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.019300</td>\n",
       "      <td>0.643000</td>\n",
       "      <td>0.903776</td>\n",
       "      <td>0.905629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.022100</td>\n",
       "      <td>0.643926</td>\n",
       "      <td>0.903309</td>\n",
       "      <td>0.905157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.021000</td>\n",
       "      <td>0.647392</td>\n",
       "      <td>0.903464</td>\n",
       "      <td>0.905219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.020400</td>\n",
       "      <td>0.648107</td>\n",
       "      <td>0.903464</td>\n",
       "      <td>0.905108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorrBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at otmangi/MorrBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5da6ce5e14a4ba0b05094f773fa9cd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51377 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26b9deb8a2ac4469bd270bd22110ac00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12845 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6424' max='6424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6424/6424 11:04, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.436400</td>\n",
       "      <td>0.346275</td>\n",
       "      <td>0.873803</td>\n",
       "      <td>0.875839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.336300</td>\n",
       "      <td>0.300309</td>\n",
       "      <td>0.892409</td>\n",
       "      <td>0.894643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.319000</td>\n",
       "      <td>0.299125</td>\n",
       "      <td>0.890152</td>\n",
       "      <td>0.893032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.302700</td>\n",
       "      <td>0.282584</td>\n",
       "      <td>0.893422</td>\n",
       "      <td>0.896292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.175800</td>\n",
       "      <td>0.317928</td>\n",
       "      <td>0.894200</td>\n",
       "      <td>0.895479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.173600</td>\n",
       "      <td>0.319565</td>\n",
       "      <td>0.894278</td>\n",
       "      <td>0.894376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.317738</td>\n",
       "      <td>0.902141</td>\n",
       "      <td>0.903876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.182200</td>\n",
       "      <td>0.286626</td>\n",
       "      <td>0.907201</td>\n",
       "      <td>0.908644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.091000</td>\n",
       "      <td>0.396008</td>\n",
       "      <td>0.897548</td>\n",
       "      <td>0.898855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.098800</td>\n",
       "      <td>0.366521</td>\n",
       "      <td>0.899338</td>\n",
       "      <td>0.900868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.095600</td>\n",
       "      <td>0.421587</td>\n",
       "      <td>0.901440</td>\n",
       "      <td>0.902747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.105800</td>\n",
       "      <td>0.352988</td>\n",
       "      <td>0.900117</td>\n",
       "      <td>0.902286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.057300</td>\n",
       "      <td>0.452039</td>\n",
       "      <td>0.901907</td>\n",
       "      <td>0.903164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.063400</td>\n",
       "      <td>0.503808</td>\n",
       "      <td>0.900350</td>\n",
       "      <td>0.901674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>0.475949</td>\n",
       "      <td>0.900039</td>\n",
       "      <td>0.901339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.064300</td>\n",
       "      <td>0.463258</td>\n",
       "      <td>0.898404</td>\n",
       "      <td>0.899637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.038900</td>\n",
       "      <td>0.511699</td>\n",
       "      <td>0.899728</td>\n",
       "      <td>0.901539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.048900</td>\n",
       "      <td>0.529941</td>\n",
       "      <td>0.900117</td>\n",
       "      <td>0.901118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.044800</td>\n",
       "      <td>0.525285</td>\n",
       "      <td>0.899338</td>\n",
       "      <td>0.901753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.045200</td>\n",
       "      <td>0.539386</td>\n",
       "      <td>0.900584</td>\n",
       "      <td>0.902373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.578020</td>\n",
       "      <td>0.901907</td>\n",
       "      <td>0.903309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.031800</td>\n",
       "      <td>0.572880</td>\n",
       "      <td>0.903464</td>\n",
       "      <td>0.905441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.028900</td>\n",
       "      <td>0.582538</td>\n",
       "      <td>0.902141</td>\n",
       "      <td>0.903882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.031700</td>\n",
       "      <td>0.572600</td>\n",
       "      <td>0.904087</td>\n",
       "      <td>0.906264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.026100</td>\n",
       "      <td>0.612891</td>\n",
       "      <td>0.902686</td>\n",
       "      <td>0.904633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.026500</td>\n",
       "      <td>0.621315</td>\n",
       "      <td>0.904476</td>\n",
       "      <td>0.906197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.022700</td>\n",
       "      <td>0.617634</td>\n",
       "      <td>0.904476</td>\n",
       "      <td>0.906231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.025900</td>\n",
       "      <td>0.619443</td>\n",
       "      <td>0.903854</td>\n",
       "      <td>0.905764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.019300</td>\n",
       "      <td>0.643000</td>\n",
       "      <td>0.903776</td>\n",
       "      <td>0.905629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.022100</td>\n",
       "      <td>0.643926</td>\n",
       "      <td>0.903309</td>\n",
       "      <td>0.905157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.021000</td>\n",
       "      <td>0.647392</td>\n",
       "      <td>0.903464</td>\n",
       "      <td>0.905219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.020400</td>\n",
       "      <td>0.648107</td>\n",
       "      <td>0.903464</td>\n",
       "      <td>0.905108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorrBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at otmangi/MorrBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeeda83c06354b76b3c8afa6234b6e9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51377 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dea484d3dfee4615a6f06f9b74eae1c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12845 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6424' max='6424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6424/6424 11:03, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.436400</td>\n",
       "      <td>0.346275</td>\n",
       "      <td>0.873803</td>\n",
       "      <td>0.875839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.336300</td>\n",
       "      <td>0.300309</td>\n",
       "      <td>0.892409</td>\n",
       "      <td>0.894643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.319000</td>\n",
       "      <td>0.299125</td>\n",
       "      <td>0.890152</td>\n",
       "      <td>0.893032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.302700</td>\n",
       "      <td>0.282584</td>\n",
       "      <td>0.893422</td>\n",
       "      <td>0.896292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.175800</td>\n",
       "      <td>0.317928</td>\n",
       "      <td>0.894200</td>\n",
       "      <td>0.895479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.173600</td>\n",
       "      <td>0.319565</td>\n",
       "      <td>0.894278</td>\n",
       "      <td>0.894376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.317738</td>\n",
       "      <td>0.902141</td>\n",
       "      <td>0.903876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.182200</td>\n",
       "      <td>0.286626</td>\n",
       "      <td>0.907201</td>\n",
       "      <td>0.908644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.091000</td>\n",
       "      <td>0.396008</td>\n",
       "      <td>0.897548</td>\n",
       "      <td>0.898855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.098800</td>\n",
       "      <td>0.366521</td>\n",
       "      <td>0.899338</td>\n",
       "      <td>0.900868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.095600</td>\n",
       "      <td>0.421587</td>\n",
       "      <td>0.901440</td>\n",
       "      <td>0.902747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.105800</td>\n",
       "      <td>0.352988</td>\n",
       "      <td>0.900117</td>\n",
       "      <td>0.902286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.057300</td>\n",
       "      <td>0.452039</td>\n",
       "      <td>0.901907</td>\n",
       "      <td>0.903164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.063400</td>\n",
       "      <td>0.503808</td>\n",
       "      <td>0.900350</td>\n",
       "      <td>0.901674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>0.475949</td>\n",
       "      <td>0.900039</td>\n",
       "      <td>0.901339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.064300</td>\n",
       "      <td>0.463258</td>\n",
       "      <td>0.898404</td>\n",
       "      <td>0.899637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.038900</td>\n",
       "      <td>0.511699</td>\n",
       "      <td>0.899728</td>\n",
       "      <td>0.901539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.048900</td>\n",
       "      <td>0.529941</td>\n",
       "      <td>0.900117</td>\n",
       "      <td>0.901118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.044800</td>\n",
       "      <td>0.525285</td>\n",
       "      <td>0.899338</td>\n",
       "      <td>0.901753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.045200</td>\n",
       "      <td>0.539386</td>\n",
       "      <td>0.900584</td>\n",
       "      <td>0.902373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.578020</td>\n",
       "      <td>0.901907</td>\n",
       "      <td>0.903309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.031800</td>\n",
       "      <td>0.572880</td>\n",
       "      <td>0.903464</td>\n",
       "      <td>0.905441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.028900</td>\n",
       "      <td>0.582538</td>\n",
       "      <td>0.902141</td>\n",
       "      <td>0.903882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.031700</td>\n",
       "      <td>0.572600</td>\n",
       "      <td>0.904087</td>\n",
       "      <td>0.906264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.026100</td>\n",
       "      <td>0.612891</td>\n",
       "      <td>0.902686</td>\n",
       "      <td>0.904633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.026500</td>\n",
       "      <td>0.621315</td>\n",
       "      <td>0.904476</td>\n",
       "      <td>0.906197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.022700</td>\n",
       "      <td>0.617634</td>\n",
       "      <td>0.904476</td>\n",
       "      <td>0.906231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.025900</td>\n",
       "      <td>0.619443</td>\n",
       "      <td>0.903854</td>\n",
       "      <td>0.905764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.019300</td>\n",
       "      <td>0.643000</td>\n",
       "      <td>0.903776</td>\n",
       "      <td>0.905629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.022100</td>\n",
       "      <td>0.643926</td>\n",
       "      <td>0.903309</td>\n",
       "      <td>0.905157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.021000</td>\n",
       "      <td>0.647392</td>\n",
       "      <td>0.903464</td>\n",
       "      <td>0.905219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.020400</td>\n",
       "      <td>0.648107</td>\n",
       "      <td>0.903464</td>\n",
       "      <td>0.905108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorrBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at otmangi/MorrBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b0317b8ad744d399fe2dc7cdf0ce7d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51377 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2395a2c794548b489be006102236b9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12845 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6424' max='6424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6424/6424 11:06, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.362100</td>\n",
       "      <td>0.863215</td>\n",
       "      <td>0.866219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.351100</td>\n",
       "      <td>0.324836</td>\n",
       "      <td>0.880498</td>\n",
       "      <td>0.880987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.311500</td>\n",
       "      <td>0.308628</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.885435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.296200</td>\n",
       "      <td>0.292053</td>\n",
       "      <td>0.892487</td>\n",
       "      <td>0.892592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.173100</td>\n",
       "      <td>0.320294</td>\n",
       "      <td>0.891086</td>\n",
       "      <td>0.892113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.322435</td>\n",
       "      <td>0.895134</td>\n",
       "      <td>0.895994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.177900</td>\n",
       "      <td>0.299787</td>\n",
       "      <td>0.897859</td>\n",
       "      <td>0.899401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.173600</td>\n",
       "      <td>0.316647</td>\n",
       "      <td>0.896380</td>\n",
       "      <td>0.896585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.096300</td>\n",
       "      <td>0.412877</td>\n",
       "      <td>0.898015</td>\n",
       "      <td>0.898244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.096600</td>\n",
       "      <td>0.389087</td>\n",
       "      <td>0.896069</td>\n",
       "      <td>0.897282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.101400</td>\n",
       "      <td>0.413449</td>\n",
       "      <td>0.897859</td>\n",
       "      <td>0.898223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.098500</td>\n",
       "      <td>0.404939</td>\n",
       "      <td>0.897314</td>\n",
       "      <td>0.899002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.063500</td>\n",
       "      <td>0.484771</td>\n",
       "      <td>0.892409</td>\n",
       "      <td>0.893362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.065900</td>\n",
       "      <td>0.504926</td>\n",
       "      <td>0.896536</td>\n",
       "      <td>0.896665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.064000</td>\n",
       "      <td>0.495516</td>\n",
       "      <td>0.896847</td>\n",
       "      <td>0.897117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.063100</td>\n",
       "      <td>0.482268</td>\n",
       "      <td>0.898715</td>\n",
       "      <td>0.899960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.042800</td>\n",
       "      <td>0.558179</td>\n",
       "      <td>0.899105</td>\n",
       "      <td>0.899553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.041200</td>\n",
       "      <td>0.589507</td>\n",
       "      <td>0.890230</td>\n",
       "      <td>0.889997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.047700</td>\n",
       "      <td>0.554919</td>\n",
       "      <td>0.892643</td>\n",
       "      <td>0.894889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.047600</td>\n",
       "      <td>0.537866</td>\n",
       "      <td>0.898793</td>\n",
       "      <td>0.898556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.032000</td>\n",
       "      <td>0.577552</td>\n",
       "      <td>0.900272</td>\n",
       "      <td>0.900512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.033300</td>\n",
       "      <td>0.592428</td>\n",
       "      <td>0.898793</td>\n",
       "      <td>0.899530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.033900</td>\n",
       "      <td>0.586335</td>\n",
       "      <td>0.899805</td>\n",
       "      <td>0.900377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.034200</td>\n",
       "      <td>0.583173</td>\n",
       "      <td>0.899027</td>\n",
       "      <td>0.899750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.028900</td>\n",
       "      <td>0.619103</td>\n",
       "      <td>0.899416</td>\n",
       "      <td>0.900217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.022900</td>\n",
       "      <td>0.646871</td>\n",
       "      <td>0.897314</td>\n",
       "      <td>0.898532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.024700</td>\n",
       "      <td>0.655591</td>\n",
       "      <td>0.899883</td>\n",
       "      <td>0.900643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.025900</td>\n",
       "      <td>0.631690</td>\n",
       "      <td>0.898638</td>\n",
       "      <td>0.899251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.021000</td>\n",
       "      <td>0.657575</td>\n",
       "      <td>0.899650</td>\n",
       "      <td>0.900454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.022900</td>\n",
       "      <td>0.648046</td>\n",
       "      <td>0.900584</td>\n",
       "      <td>0.901454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.021800</td>\n",
       "      <td>0.648929</td>\n",
       "      <td>0.900895</td>\n",
       "      <td>0.901764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.021900</td>\n",
       "      <td>0.650241</td>\n",
       "      <td>0.901051</td>\n",
       "      <td>0.901826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorrBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at otmangi/MorrBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbbd6ab69b774385a10d5efb76fcb9d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51377 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4958e00bd634c4f983dc1df55ace42f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12845 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6424' max='6424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6424/6424 11:06, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.362100</td>\n",
       "      <td>0.863215</td>\n",
       "      <td>0.866219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.351100</td>\n",
       "      <td>0.324836</td>\n",
       "      <td>0.880498</td>\n",
       "      <td>0.880987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.311500</td>\n",
       "      <td>0.308628</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.885435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.296200</td>\n",
       "      <td>0.292053</td>\n",
       "      <td>0.892487</td>\n",
       "      <td>0.892592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.173100</td>\n",
       "      <td>0.320294</td>\n",
       "      <td>0.891086</td>\n",
       "      <td>0.892113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.322435</td>\n",
       "      <td>0.895134</td>\n",
       "      <td>0.895994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.177900</td>\n",
       "      <td>0.299787</td>\n",
       "      <td>0.897859</td>\n",
       "      <td>0.899401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.173600</td>\n",
       "      <td>0.316647</td>\n",
       "      <td>0.896380</td>\n",
       "      <td>0.896585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.096300</td>\n",
       "      <td>0.412877</td>\n",
       "      <td>0.898015</td>\n",
       "      <td>0.898244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.096600</td>\n",
       "      <td>0.389087</td>\n",
       "      <td>0.896069</td>\n",
       "      <td>0.897282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.101400</td>\n",
       "      <td>0.413449</td>\n",
       "      <td>0.897859</td>\n",
       "      <td>0.898223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.098500</td>\n",
       "      <td>0.404939</td>\n",
       "      <td>0.897314</td>\n",
       "      <td>0.899002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.063500</td>\n",
       "      <td>0.484771</td>\n",
       "      <td>0.892409</td>\n",
       "      <td>0.893362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.065900</td>\n",
       "      <td>0.504926</td>\n",
       "      <td>0.896536</td>\n",
       "      <td>0.896665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.064000</td>\n",
       "      <td>0.495516</td>\n",
       "      <td>0.896847</td>\n",
       "      <td>0.897117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.063100</td>\n",
       "      <td>0.482268</td>\n",
       "      <td>0.898715</td>\n",
       "      <td>0.899960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.042800</td>\n",
       "      <td>0.558179</td>\n",
       "      <td>0.899105</td>\n",
       "      <td>0.899553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.041200</td>\n",
       "      <td>0.589507</td>\n",
       "      <td>0.890230</td>\n",
       "      <td>0.889997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.047700</td>\n",
       "      <td>0.554919</td>\n",
       "      <td>0.892643</td>\n",
       "      <td>0.894889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.047600</td>\n",
       "      <td>0.537866</td>\n",
       "      <td>0.898793</td>\n",
       "      <td>0.898556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.032000</td>\n",
       "      <td>0.577552</td>\n",
       "      <td>0.900272</td>\n",
       "      <td>0.900512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.033300</td>\n",
       "      <td>0.592428</td>\n",
       "      <td>0.898793</td>\n",
       "      <td>0.899530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.033900</td>\n",
       "      <td>0.586335</td>\n",
       "      <td>0.899805</td>\n",
       "      <td>0.900377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.034200</td>\n",
       "      <td>0.583173</td>\n",
       "      <td>0.899027</td>\n",
       "      <td>0.899750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.028900</td>\n",
       "      <td>0.619103</td>\n",
       "      <td>0.899416</td>\n",
       "      <td>0.900217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.022900</td>\n",
       "      <td>0.646871</td>\n",
       "      <td>0.897314</td>\n",
       "      <td>0.898532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.024700</td>\n",
       "      <td>0.655591</td>\n",
       "      <td>0.899883</td>\n",
       "      <td>0.900643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.025900</td>\n",
       "      <td>0.631690</td>\n",
       "      <td>0.898638</td>\n",
       "      <td>0.899251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.021000</td>\n",
       "      <td>0.657575</td>\n",
       "      <td>0.899650</td>\n",
       "      <td>0.900454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.022900</td>\n",
       "      <td>0.648046</td>\n",
       "      <td>0.900584</td>\n",
       "      <td>0.901454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.021800</td>\n",
       "      <td>0.648929</td>\n",
       "      <td>0.900895</td>\n",
       "      <td>0.901764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.021900</td>\n",
       "      <td>0.650241</td>\n",
       "      <td>0.901051</td>\n",
       "      <td>0.901826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorrBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at otmangi/MorrBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2f13cceb2b74a7288c583ac0d33b240",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51377 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f4b7f86e34c403ebd14fa691ad926ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12845 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6424' max='6424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6424/6424 11:02, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.362100</td>\n",
       "      <td>0.863215</td>\n",
       "      <td>0.866219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.351100</td>\n",
       "      <td>0.324836</td>\n",
       "      <td>0.880498</td>\n",
       "      <td>0.880987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.311500</td>\n",
       "      <td>0.308628</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.885435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.296200</td>\n",
       "      <td>0.292053</td>\n",
       "      <td>0.892487</td>\n",
       "      <td>0.892592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.173100</td>\n",
       "      <td>0.320294</td>\n",
       "      <td>0.891086</td>\n",
       "      <td>0.892113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.322435</td>\n",
       "      <td>0.895134</td>\n",
       "      <td>0.895994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.177900</td>\n",
       "      <td>0.299787</td>\n",
       "      <td>0.897859</td>\n",
       "      <td>0.899401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.173600</td>\n",
       "      <td>0.316647</td>\n",
       "      <td>0.896380</td>\n",
       "      <td>0.896585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.096300</td>\n",
       "      <td>0.412877</td>\n",
       "      <td>0.898015</td>\n",
       "      <td>0.898244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.096600</td>\n",
       "      <td>0.389087</td>\n",
       "      <td>0.896069</td>\n",
       "      <td>0.897282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.101400</td>\n",
       "      <td>0.413449</td>\n",
       "      <td>0.897859</td>\n",
       "      <td>0.898223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.098500</td>\n",
       "      <td>0.404939</td>\n",
       "      <td>0.897314</td>\n",
       "      <td>0.899002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.063500</td>\n",
       "      <td>0.484771</td>\n",
       "      <td>0.892409</td>\n",
       "      <td>0.893362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.065900</td>\n",
       "      <td>0.504926</td>\n",
       "      <td>0.896536</td>\n",
       "      <td>0.896665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.064000</td>\n",
       "      <td>0.495516</td>\n",
       "      <td>0.896847</td>\n",
       "      <td>0.897117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.063100</td>\n",
       "      <td>0.482268</td>\n",
       "      <td>0.898715</td>\n",
       "      <td>0.899960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.042800</td>\n",
       "      <td>0.558179</td>\n",
       "      <td>0.899105</td>\n",
       "      <td>0.899553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.041200</td>\n",
       "      <td>0.589507</td>\n",
       "      <td>0.890230</td>\n",
       "      <td>0.889997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.047700</td>\n",
       "      <td>0.554919</td>\n",
       "      <td>0.892643</td>\n",
       "      <td>0.894889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.047600</td>\n",
       "      <td>0.537866</td>\n",
       "      <td>0.898793</td>\n",
       "      <td>0.898556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.032000</td>\n",
       "      <td>0.577552</td>\n",
       "      <td>0.900272</td>\n",
       "      <td>0.900512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.033300</td>\n",
       "      <td>0.592428</td>\n",
       "      <td>0.898793</td>\n",
       "      <td>0.899530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.033900</td>\n",
       "      <td>0.586335</td>\n",
       "      <td>0.899805</td>\n",
       "      <td>0.900377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.034200</td>\n",
       "      <td>0.583173</td>\n",
       "      <td>0.899027</td>\n",
       "      <td>0.899750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.028900</td>\n",
       "      <td>0.619103</td>\n",
       "      <td>0.899416</td>\n",
       "      <td>0.900217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.022900</td>\n",
       "      <td>0.646871</td>\n",
       "      <td>0.897314</td>\n",
       "      <td>0.898532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.024700</td>\n",
       "      <td>0.655591</td>\n",
       "      <td>0.899883</td>\n",
       "      <td>0.900643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.025900</td>\n",
       "      <td>0.631690</td>\n",
       "      <td>0.898638</td>\n",
       "      <td>0.899251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.021000</td>\n",
       "      <td>0.657575</td>\n",
       "      <td>0.899650</td>\n",
       "      <td>0.900454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.022900</td>\n",
       "      <td>0.648046</td>\n",
       "      <td>0.900584</td>\n",
       "      <td>0.901454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.021800</td>\n",
       "      <td>0.648929</td>\n",
       "      <td>0.900895</td>\n",
       "      <td>0.901764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.021900</td>\n",
       "      <td>0.650241</td>\n",
       "      <td>0.901051</td>\n",
       "      <td>0.901826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SI2M-Lab/DarijaBERT</td>\n",
       "      <td>0.920670</td>\n",
       "      <td>0.920993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alger-ia/dziribert</td>\n",
       "      <td>0.914675</td>\n",
       "      <td>0.916346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>faisalq/EgyBERT</td>\n",
       "      <td>0.909381</td>\n",
       "      <td>0.910202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>faisalq/SaudiBERT</td>\n",
       "      <td>0.917400</td>\n",
       "      <td>0.919200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>otmangi/MorRoBERTa</td>\n",
       "      <td>0.910782</td>\n",
       "      <td>0.911175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>otmangi/MorrBERT</td>\n",
       "      <td>0.907201</td>\n",
       "      <td>0.908644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>tunis-ai/TunBERT</td>\n",
       "      <td>0.725730</td>\n",
       "      <td>0.730697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model  Accuracy        F1\n",
       "0   SI2M-Lab/DarijaBERT  0.920670  0.920993\n",
       "3    alger-ia/dziribert  0.914675  0.916346\n",
       "6       faisalq/EgyBERT  0.909381  0.910202\n",
       "9     faisalq/SaudiBERT  0.917400  0.919200\n",
       "12   otmangi/MorRoBERTa  0.910782  0.911175\n",
       "15     otmangi/MorrBERT  0.907201  0.908644\n",
       "18     tunis-ai/TunBERT  0.725730  0.730697"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\" \n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import pyarabic.araby as araby\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.initializers import TruncatedNormal\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from datasets import load_dataset, Dataset, concatenate_datasets\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', 1000)\n",
    "\n",
    "\n",
    "fname = 'MTCD_2'\n",
    "log_file = fname + '.txt'\n",
    "\n",
    "with open(log_file, 'w') as f:\n",
    "    f.write('Model,Accuracy,F1\\n')\n",
    "\n",
    "\n",
    "df = pd.read_csv('datasets/MTCD.csv', encoding='utf-8', engine='python') #, quotechar=\"'\"  , quoting=3\n",
    "\n",
    "\n",
    "      \n",
    "display(df.columns)\n",
    "display(df[:4])\n",
    "\n",
    "\n",
    "\n",
    "classes = set(df['labels'].values)\n",
    "display(classes)\n",
    "\n",
    "df['labels'] = df['labels'].astype('category')\n",
    "df['label'] = df['labels'].cat.codes\n",
    "\n",
    "df = df[['text', 'label']]\n",
    "classes_num = len(classes)\n",
    "display(classes_num)\n",
    "display(len(df))\n",
    "\n",
    "\n",
    "\n",
    "max_sequence_length = 128\n",
    "\n",
    "\n",
    "\n",
    "models = [ \n",
    "        'faisalq/EgyBERT',            \n",
    "    'faisalq/SaudiBERT',            \n",
    "    'tunis-ai/TunBERT',\n",
    "    'alger-ia/dziribert',\n",
    "    'SI2M-Lab/DarijaBERT',\n",
    "    'otmangi/MorRoBERTa',\n",
    "    'otmangi/MorrBERT'\n",
    "            \n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "seeds = [0, 1, 42]\n",
    "\n",
    "for model_name in models:\n",
    "    for seed in seeds:\n",
    "        ds = Dataset.from_pandas(df)\n",
    "        ds = ds.train_test_split(test_size=0.2, seed = seed)\n",
    "        if seed==0:\n",
    "            display(ds)\n",
    "            \n",
    "        for i in range(3):\n",
    "            print(f'{model_name}, try:{i}')\n",
    "                  \n",
    "            tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "            model = AutoModelForSequenceClassification.from_pretrained(model_name,\n",
    "                                                                  num_labels=classes_num).to('cuda')                                                 \n",
    "            dataset_train = ds['train']\n",
    "            dataset_validation = ds['test']                                                    \n",
    "            \n",
    "          \n",
    "    \n",
    "            def preprocess_function(examples):\n",
    "                return tokenizer(examples['text'], truncation=True, padding=\"max_length\",\n",
    "                                max_length=max_sequence_length)\n",
    "            \n",
    "            \n",
    "            dataset_train = dataset_train.map(preprocess_function, batched=True)\n",
    "            dataset_validation = dataset_validation.map(preprocess_function, batched=True)\n",
    "            \n",
    "           \n",
    "            \n",
    "            def compute_metrics(eval_pred):\n",
    "                logits, labels = eval_pred\n",
    "                predictions = np.argmax(logits, axis=-1)    \n",
    "                acc = accuracy_score(labels, predictions)        \n",
    "                f1 = f1_score(labels, predictions, average='macro')   \n",
    "                with open(log_file, 'a') as f:\n",
    "                    f.write(f'{model_name},{acc},{f1}\\n')\n",
    "                return {'accuracy': acc, 'f1_score': f1}\n",
    "    \n",
    "    \n",
    "            \n",
    "            \n",
    "            epochs = 8\n",
    "            save_steps = 10000 #save checkpoint every 10000 steps\n",
    "            batch_size = 64\n",
    "            \n",
    "            training_args = TrainingArguments(\n",
    "                output_dir = 'bert/',\n",
    "                overwrite_output_dir=True,\n",
    "                num_train_epochs = epochs,\n",
    "                per_device_train_batch_size = batch_size,\n",
    "                per_device_eval_batch_size = batch_size,\n",
    "                save_steps = save_steps,\n",
    "                save_total_limit = 1, #only save the last 5 checkpoints\n",
    "                fp16=True,\n",
    "                learning_rate = 5e-5,  # 5e-5 is the default\n",
    "                logging_steps = 200, #50_000\n",
    "                evaluation_strategy = 'steps',\n",
    "                # evaluate_during_training = True,\n",
    "                eval_steps = 200\n",
    "                \n",
    "            )\n",
    "            \n",
    "            trainer = Trainer(\n",
    "                model = model,\n",
    "                args = training_args,\n",
    "                # data_collator=data_collator,\n",
    "                train_dataset=dataset_train,\n",
    "                eval_dataset=dataset_validation,\n",
    "                compute_metrics = compute_metrics\n",
    "            )\n",
    "            \n",
    "            \n",
    "            trainer.train()\n",
    "\n",
    "\n",
    "results = pd.read_csv(log_file)\n",
    "\n",
    "best_results = results.groupby('Model', as_index=False)['F1'].max()\n",
    "\n",
    "best_results = pd.merge(best_results, results, on=['Model', 'F1'])\n",
    "best_results = best_results[['Model', 'Accuracy', 'F1']]\n",
    "best_results = best_results.drop_duplicates()\n",
    "best_results.to_csv(f'{fname}.csv')\n",
    "display(best_results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a213ac86-934f-4e82-a949-0bcdcae2188d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220784d6-b06d-4429-adb8-0026654f9d49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8647cf08-3aa6-44eb-846f-4bed97554042",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e203fa6b-c9d7-44a4-b501-a67bfd3e4ce4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8794b705-31a1-45d7-8e88-4017a9c282aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
