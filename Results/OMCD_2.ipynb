{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d804ae66-9435-44be-8aad-beacbdeec0f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-15 09:47:25.471467: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-15 09:47:25.495308: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-15 09:47:25.893930: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'comment', 'off'], dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'comment', 'off'], dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>comment</th>\n",
       "      <th>off</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2908</td>\n",
       "      <td>فنانين الكبت والفساد .عقلية جنسية لا غير. العفن وليس الفن. شعب فيه اغلبية مستعدة للجنس وعندها قابلية .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1055</td>\n",
       "      <td>الدعارة هربت منها في المحمدية و سكنت في بوزنيقة و هي بحال بحال موجودة في كل المدن و السبب ملكنا زامل و الناس فقراء بالزاف</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>181</td>\n",
       "      <td>كون غير خريتي و مدرتيش هادشي</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4313</td>\n",
       "      <td>لا حول ولا قوة الا بالله العلي العظيم لا حول ولا قوة الا بالله العلي العظيم. استغفرالله العظيم واتوب اليه. مساكن الوالدين هما اللي في الواجهة. شعب لا يرحم</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   \n",
       "0        2908  \\\n",
       "1        1055   \n",
       "2         181   \n",
       "3        4313   \n",
       "\n",
       "                                                                                                                                                      comment   \n",
       "0                                                      فنانين الكبت والفساد .عقلية جنسية لا غير. العفن وليس الفن. شعب فيه اغلبية مستعدة للجنس وعندها قابلية .  \\\n",
       "1                                   الدعارة هربت منها في المحمدية و سكنت في بوزنيقة و هي بحال بحال موجودة في كل المدن و السبب ملكنا زامل و الناس فقراء بالزاف   \n",
       "2                                                                                                                                كون غير خريتي و مدرتيش هادشي   \n",
       "3  لا حول ولا قوة الا بالله العلي العظيم لا حول ولا قوة الا بالله العلي العظيم. استغفرالله العظيم واتوب اليه. مساكن الوالدين هما اللي في الواجهة. شعب لا يرحم   \n",
       "\n",
       "   off  \n",
       "0    1  \n",
       "1    1  \n",
       "2    1  \n",
       "3    0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{0, 1}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "6419"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1605"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['comment', 'label'],\n",
       "    num_rows: 6419\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['comment', 'label'],\n",
       "    num_rows: 1605\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/EgyBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/EgyBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6419 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1605 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2020' max='2020' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2020/2020 03:08, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.659100</td>\n",
       "      <td>0.659846</td>\n",
       "      <td>0.656075</td>\n",
       "      <td>0.617952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.657100</td>\n",
       "      <td>0.627193</td>\n",
       "      <td>0.667913</td>\n",
       "      <td>0.633471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.530100</td>\n",
       "      <td>0.442871</td>\n",
       "      <td>0.801246</td>\n",
       "      <td>0.800700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.399000</td>\n",
       "      <td>0.439409</td>\n",
       "      <td>0.790031</td>\n",
       "      <td>0.789967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.319900</td>\n",
       "      <td>0.387068</td>\n",
       "      <td>0.824299</td>\n",
       "      <td>0.823227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.229700</td>\n",
       "      <td>0.434718</td>\n",
       "      <td>0.813707</td>\n",
       "      <td>0.813446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.219700</td>\n",
       "      <td>0.471307</td>\n",
       "      <td>0.832399</td>\n",
       "      <td>0.828231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.153900</td>\n",
       "      <td>0.570209</td>\n",
       "      <td>0.810592</td>\n",
       "      <td>0.810575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.109000</td>\n",
       "      <td>0.586505</td>\n",
       "      <td>0.830530</td>\n",
       "      <td>0.829174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.109000</td>\n",
       "      <td>0.577751</td>\n",
       "      <td>0.834891</td>\n",
       "      <td>0.833767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.097700</td>\n",
       "      <td>0.624572</td>\n",
       "      <td>0.828660</td>\n",
       "      <td>0.827632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.071500</td>\n",
       "      <td>0.705124</td>\n",
       "      <td>0.824299</td>\n",
       "      <td>0.823157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.062300</td>\n",
       "      <td>0.697805</td>\n",
       "      <td>0.832399</td>\n",
       "      <td>0.831392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.076400</td>\n",
       "      <td>0.656880</td>\n",
       "      <td>0.838006</td>\n",
       "      <td>0.836481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.052400</td>\n",
       "      <td>0.736259</td>\n",
       "      <td>0.831153</td>\n",
       "      <td>0.830521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.047600</td>\n",
       "      <td>0.753167</td>\n",
       "      <td>0.828660</td>\n",
       "      <td>0.828275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.046900</td>\n",
       "      <td>0.707240</td>\n",
       "      <td>0.835514</td>\n",
       "      <td>0.834478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.041500</td>\n",
       "      <td>0.784769</td>\n",
       "      <td>0.831153</td>\n",
       "      <td>0.830689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.034000</td>\n",
       "      <td>0.878573</td>\n",
       "      <td>0.826168</td>\n",
       "      <td>0.825971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.043800</td>\n",
       "      <td>0.801349</td>\n",
       "      <td>0.833022</td>\n",
       "      <td>0.832483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.036700</td>\n",
       "      <td>0.742945</td>\n",
       "      <td>0.842991</td>\n",
       "      <td>0.841551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.040100</td>\n",
       "      <td>0.826664</td>\n",
       "      <td>0.838629</td>\n",
       "      <td>0.837752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.031300</td>\n",
       "      <td>0.841765</td>\n",
       "      <td>0.836760</td>\n",
       "      <td>0.836058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.036200</td>\n",
       "      <td>0.807922</td>\n",
       "      <td>0.836137</td>\n",
       "      <td>0.835306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.025100</td>\n",
       "      <td>0.868214</td>\n",
       "      <td>0.828037</td>\n",
       "      <td>0.827641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.029400</td>\n",
       "      <td>0.852409</td>\n",
       "      <td>0.838629</td>\n",
       "      <td>0.837629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.018600</td>\n",
       "      <td>0.877183</td>\n",
       "      <td>0.835514</td>\n",
       "      <td>0.834445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.022800</td>\n",
       "      <td>0.910417</td>\n",
       "      <td>0.836137</td>\n",
       "      <td>0.835364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.021600</td>\n",
       "      <td>0.929946</td>\n",
       "      <td>0.833022</td>\n",
       "      <td>0.832358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.023400</td>\n",
       "      <td>0.945445</td>\n",
       "      <td>0.836137</td>\n",
       "      <td>0.835549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.021700</td>\n",
       "      <td>0.899919</td>\n",
       "      <td>0.842991</td>\n",
       "      <td>0.841434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.021600</td>\n",
       "      <td>0.929396</td>\n",
       "      <td>0.835514</td>\n",
       "      <td>0.834752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1980</td>\n",
       "      <td>0.022500</td>\n",
       "      <td>0.921046</td>\n",
       "      <td>0.836760</td>\n",
       "      <td>0.835918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/EgyBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/EgyBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6419 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1605 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2020' max='2020' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2020/2020 03:09, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.618700</td>\n",
       "      <td>0.488469</td>\n",
       "      <td>0.807477</td>\n",
       "      <td>0.802689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.443200</td>\n",
       "      <td>0.427887</td>\n",
       "      <td>0.816199</td>\n",
       "      <td>0.813697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.361400</td>\n",
       "      <td>0.395844</td>\n",
       "      <td>0.819938</td>\n",
       "      <td>0.819395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.270800</td>\n",
       "      <td>0.528337</td>\n",
       "      <td>0.807477</td>\n",
       "      <td>0.807409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.227100</td>\n",
       "      <td>0.432945</td>\n",
       "      <td>0.832399</td>\n",
       "      <td>0.831981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.176700</td>\n",
       "      <td>0.475713</td>\n",
       "      <td>0.821807</td>\n",
       "      <td>0.821679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.159700</td>\n",
       "      <td>0.481548</td>\n",
       "      <td>0.844237</td>\n",
       "      <td>0.841805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.123100</td>\n",
       "      <td>0.540584</td>\n",
       "      <td>0.839252</td>\n",
       "      <td>0.838638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.093700</td>\n",
       "      <td>0.578369</td>\n",
       "      <td>0.837383</td>\n",
       "      <td>0.834269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.096200</td>\n",
       "      <td>0.587478</td>\n",
       "      <td>0.834268</td>\n",
       "      <td>0.833156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.084400</td>\n",
       "      <td>0.632400</td>\n",
       "      <td>0.834268</td>\n",
       "      <td>0.832181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.067800</td>\n",
       "      <td>0.658015</td>\n",
       "      <td>0.841121</td>\n",
       "      <td>0.840575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.055300</td>\n",
       "      <td>0.715085</td>\n",
       "      <td>0.844237</td>\n",
       "      <td>0.843160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.069800</td>\n",
       "      <td>0.622549</td>\n",
       "      <td>0.849221</td>\n",
       "      <td>0.847727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.070200</td>\n",
       "      <td>0.637994</td>\n",
       "      <td>0.842368</td>\n",
       "      <td>0.841088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.046500</td>\n",
       "      <td>0.744158</td>\n",
       "      <td>0.835514</td>\n",
       "      <td>0.834911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.047500</td>\n",
       "      <td>0.762656</td>\n",
       "      <td>0.830530</td>\n",
       "      <td>0.830030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.045600</td>\n",
       "      <td>0.800413</td>\n",
       "      <td>0.829283</td>\n",
       "      <td>0.828631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.041800</td>\n",
       "      <td>0.773143</td>\n",
       "      <td>0.841745</td>\n",
       "      <td>0.840216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.039100</td>\n",
       "      <td>0.681332</td>\n",
       "      <td>0.841121</td>\n",
       "      <td>0.839361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.037200</td>\n",
       "      <td>0.801294</td>\n",
       "      <td>0.842368</td>\n",
       "      <td>0.841778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.029500</td>\n",
       "      <td>0.783685</td>\n",
       "      <td>0.847975</td>\n",
       "      <td>0.846544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.026600</td>\n",
       "      <td>0.840831</td>\n",
       "      <td>0.836760</td>\n",
       "      <td>0.836210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.026900</td>\n",
       "      <td>0.810410</td>\n",
       "      <td>0.841121</td>\n",
       "      <td>0.840316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.023400</td>\n",
       "      <td>0.878576</td>\n",
       "      <td>0.829907</td>\n",
       "      <td>0.829582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.019000</td>\n",
       "      <td>0.824056</td>\n",
       "      <td>0.838006</td>\n",
       "      <td>0.836710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.017700</td>\n",
       "      <td>0.874147</td>\n",
       "      <td>0.839875</td>\n",
       "      <td>0.839005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.018600</td>\n",
       "      <td>0.878844</td>\n",
       "      <td>0.838629</td>\n",
       "      <td>0.837752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.016600</td>\n",
       "      <td>0.900899</td>\n",
       "      <td>0.842368</td>\n",
       "      <td>0.841540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.013000</td>\n",
       "      <td>0.905727</td>\n",
       "      <td>0.841745</td>\n",
       "      <td>0.840984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.014200</td>\n",
       "      <td>0.906234</td>\n",
       "      <td>0.841121</td>\n",
       "      <td>0.840344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.020500</td>\n",
       "      <td>0.927358</td>\n",
       "      <td>0.836137</td>\n",
       "      <td>0.835597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1980</td>\n",
       "      <td>0.016600</td>\n",
       "      <td>0.912082</td>\n",
       "      <td>0.841121</td>\n",
       "      <td>0.840425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/EgyBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/EgyBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6419 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1605 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2020' max='2020' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2020/2020 03:09, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.618700</td>\n",
       "      <td>0.488469</td>\n",
       "      <td>0.807477</td>\n",
       "      <td>0.802689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.443200</td>\n",
       "      <td>0.427887</td>\n",
       "      <td>0.816199</td>\n",
       "      <td>0.813697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.361400</td>\n",
       "      <td>0.395844</td>\n",
       "      <td>0.819938</td>\n",
       "      <td>0.819395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.270800</td>\n",
       "      <td>0.528337</td>\n",
       "      <td>0.807477</td>\n",
       "      <td>0.807409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.227100</td>\n",
       "      <td>0.432945</td>\n",
       "      <td>0.832399</td>\n",
       "      <td>0.831981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.176700</td>\n",
       "      <td>0.475713</td>\n",
       "      <td>0.821807</td>\n",
       "      <td>0.821679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.159700</td>\n",
       "      <td>0.481548</td>\n",
       "      <td>0.844237</td>\n",
       "      <td>0.841805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.123100</td>\n",
       "      <td>0.540584</td>\n",
       "      <td>0.839252</td>\n",
       "      <td>0.838638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.093700</td>\n",
       "      <td>0.578369</td>\n",
       "      <td>0.837383</td>\n",
       "      <td>0.834269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.096200</td>\n",
       "      <td>0.587478</td>\n",
       "      <td>0.834268</td>\n",
       "      <td>0.833156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.084400</td>\n",
       "      <td>0.632400</td>\n",
       "      <td>0.834268</td>\n",
       "      <td>0.832181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.067800</td>\n",
       "      <td>0.658015</td>\n",
       "      <td>0.841121</td>\n",
       "      <td>0.840575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.055300</td>\n",
       "      <td>0.715085</td>\n",
       "      <td>0.844237</td>\n",
       "      <td>0.843160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.069800</td>\n",
       "      <td>0.622549</td>\n",
       "      <td>0.849221</td>\n",
       "      <td>0.847727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.070200</td>\n",
       "      <td>0.637994</td>\n",
       "      <td>0.842368</td>\n",
       "      <td>0.841088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.046500</td>\n",
       "      <td>0.744158</td>\n",
       "      <td>0.835514</td>\n",
       "      <td>0.834911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.047500</td>\n",
       "      <td>0.762656</td>\n",
       "      <td>0.830530</td>\n",
       "      <td>0.830030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.045600</td>\n",
       "      <td>0.800413</td>\n",
       "      <td>0.829283</td>\n",
       "      <td>0.828631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.041800</td>\n",
       "      <td>0.773143</td>\n",
       "      <td>0.841745</td>\n",
       "      <td>0.840216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.039100</td>\n",
       "      <td>0.681332</td>\n",
       "      <td>0.841121</td>\n",
       "      <td>0.839361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.037200</td>\n",
       "      <td>0.801294</td>\n",
       "      <td>0.842368</td>\n",
       "      <td>0.841778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.029500</td>\n",
       "      <td>0.783685</td>\n",
       "      <td>0.847975</td>\n",
       "      <td>0.846544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.026600</td>\n",
       "      <td>0.840831</td>\n",
       "      <td>0.836760</td>\n",
       "      <td>0.836210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.026900</td>\n",
       "      <td>0.810410</td>\n",
       "      <td>0.841121</td>\n",
       "      <td>0.840316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.023400</td>\n",
       "      <td>0.878576</td>\n",
       "      <td>0.829907</td>\n",
       "      <td>0.829582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.019000</td>\n",
       "      <td>0.824056</td>\n",
       "      <td>0.838006</td>\n",
       "      <td>0.836710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.017700</td>\n",
       "      <td>0.874147</td>\n",
       "      <td>0.839875</td>\n",
       "      <td>0.839005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.018600</td>\n",
       "      <td>0.878844</td>\n",
       "      <td>0.838629</td>\n",
       "      <td>0.837752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.016600</td>\n",
       "      <td>0.900899</td>\n",
       "      <td>0.842368</td>\n",
       "      <td>0.841540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.013000</td>\n",
       "      <td>0.905727</td>\n",
       "      <td>0.841745</td>\n",
       "      <td>0.840984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.014200</td>\n",
       "      <td>0.906234</td>\n",
       "      <td>0.841121</td>\n",
       "      <td>0.840344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.020500</td>\n",
       "      <td>0.927358</td>\n",
       "      <td>0.836137</td>\n",
       "      <td>0.835597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1980</td>\n",
       "      <td>0.016600</td>\n",
       "      <td>0.912082</td>\n",
       "      <td>0.841121</td>\n",
       "      <td>0.840425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6419 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1605 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2020' max='2020' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2020/2020 03:08, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.460600</td>\n",
       "      <td>0.377947</td>\n",
       "      <td>0.825545</td>\n",
       "      <td>0.821452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.324700</td>\n",
       "      <td>0.480740</td>\n",
       "      <td>0.844237</td>\n",
       "      <td>0.840583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.195200</td>\n",
       "      <td>0.386275</td>\n",
       "      <td>0.842991</td>\n",
       "      <td>0.841551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.137600</td>\n",
       "      <td>0.597552</td>\n",
       "      <td>0.821807</td>\n",
       "      <td>0.821477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.092600</td>\n",
       "      <td>0.489382</td>\n",
       "      <td>0.853583</td>\n",
       "      <td>0.851675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.055900</td>\n",
       "      <td>0.589073</td>\n",
       "      <td>0.849844</td>\n",
       "      <td>0.848626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.057600</td>\n",
       "      <td>0.653749</td>\n",
       "      <td>0.854829</td>\n",
       "      <td>0.853297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.044400</td>\n",
       "      <td>0.676381</td>\n",
       "      <td>0.847352</td>\n",
       "      <td>0.845620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.047200</td>\n",
       "      <td>0.721090</td>\n",
       "      <td>0.857944</td>\n",
       "      <td>0.854611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.033600</td>\n",
       "      <td>0.773018</td>\n",
       "      <td>0.848598</td>\n",
       "      <td>0.847909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.024600</td>\n",
       "      <td>0.721989</td>\n",
       "      <td>0.841121</td>\n",
       "      <td>0.840425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.026800</td>\n",
       "      <td>0.872121</td>\n",
       "      <td>0.845483</td>\n",
       "      <td>0.844657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.019000</td>\n",
       "      <td>0.798749</td>\n",
       "      <td>0.846729</td>\n",
       "      <td>0.843981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.015500</td>\n",
       "      <td>0.968675</td>\n",
       "      <td>0.850467</td>\n",
       "      <td>0.847888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.021700</td>\n",
       "      <td>0.822895</td>\n",
       "      <td>0.849844</td>\n",
       "      <td>0.848557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.014700</td>\n",
       "      <td>0.929539</td>\n",
       "      <td>0.848598</td>\n",
       "      <td>0.846062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.011300</td>\n",
       "      <td>1.049479</td>\n",
       "      <td>0.840498</td>\n",
       "      <td>0.839914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.013900</td>\n",
       "      <td>1.010195</td>\n",
       "      <td>0.853583</td>\n",
       "      <td>0.851546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.010800</td>\n",
       "      <td>0.995116</td>\n",
       "      <td>0.848598</td>\n",
       "      <td>0.846400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.008600</td>\n",
       "      <td>1.037805</td>\n",
       "      <td>0.851090</td>\n",
       "      <td>0.849480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.008200</td>\n",
       "      <td>1.104095</td>\n",
       "      <td>0.847352</td>\n",
       "      <td>0.846078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.007100</td>\n",
       "      <td>1.196490</td>\n",
       "      <td>0.836137</td>\n",
       "      <td>0.835620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>1.138845</td>\n",
       "      <td>0.852336</td>\n",
       "      <td>0.850701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.009200</td>\n",
       "      <td>1.143221</td>\n",
       "      <td>0.847352</td>\n",
       "      <td>0.846312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>1.127942</td>\n",
       "      <td>0.853583</td>\n",
       "      <td>0.851457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.009800</td>\n",
       "      <td>1.147150</td>\n",
       "      <td>0.849221</td>\n",
       "      <td>0.847910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>1.133402</td>\n",
       "      <td>0.854206</td>\n",
       "      <td>0.851976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.006100</td>\n",
       "      <td>1.149958</td>\n",
       "      <td>0.851713</td>\n",
       "      <td>0.850051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.005900</td>\n",
       "      <td>1.172850</td>\n",
       "      <td>0.847975</td>\n",
       "      <td>0.846956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>1.170123</td>\n",
       "      <td>0.851090</td>\n",
       "      <td>0.849670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>1.170151</td>\n",
       "      <td>0.850467</td>\n",
       "      <td>0.848831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>1.176533</td>\n",
       "      <td>0.851090</td>\n",
       "      <td>0.849558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1980</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>1.178978</td>\n",
       "      <td>0.851090</td>\n",
       "      <td>0.849558</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6419 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1605 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2020' max='2020' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2020/2020 03:08, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.460600</td>\n",
       "      <td>0.377947</td>\n",
       "      <td>0.825545</td>\n",
       "      <td>0.821452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.324700</td>\n",
       "      <td>0.480740</td>\n",
       "      <td>0.844237</td>\n",
       "      <td>0.840583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.195200</td>\n",
       "      <td>0.386275</td>\n",
       "      <td>0.842991</td>\n",
       "      <td>0.841551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.137600</td>\n",
       "      <td>0.597552</td>\n",
       "      <td>0.821807</td>\n",
       "      <td>0.821477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.092600</td>\n",
       "      <td>0.489382</td>\n",
       "      <td>0.853583</td>\n",
       "      <td>0.851675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.055900</td>\n",
       "      <td>0.589073</td>\n",
       "      <td>0.849844</td>\n",
       "      <td>0.848626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.057600</td>\n",
       "      <td>0.653749</td>\n",
       "      <td>0.854829</td>\n",
       "      <td>0.853297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.044400</td>\n",
       "      <td>0.676381</td>\n",
       "      <td>0.847352</td>\n",
       "      <td>0.845620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.047200</td>\n",
       "      <td>0.721090</td>\n",
       "      <td>0.857944</td>\n",
       "      <td>0.854611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.033600</td>\n",
       "      <td>0.773018</td>\n",
       "      <td>0.848598</td>\n",
       "      <td>0.847909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.024600</td>\n",
       "      <td>0.721989</td>\n",
       "      <td>0.841121</td>\n",
       "      <td>0.840425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.026800</td>\n",
       "      <td>0.872121</td>\n",
       "      <td>0.845483</td>\n",
       "      <td>0.844657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.019000</td>\n",
       "      <td>0.798749</td>\n",
       "      <td>0.846729</td>\n",
       "      <td>0.843981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.015500</td>\n",
       "      <td>0.968675</td>\n",
       "      <td>0.850467</td>\n",
       "      <td>0.847888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.021700</td>\n",
       "      <td>0.822895</td>\n",
       "      <td>0.849844</td>\n",
       "      <td>0.848557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.014700</td>\n",
       "      <td>0.929539</td>\n",
       "      <td>0.848598</td>\n",
       "      <td>0.846062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.011300</td>\n",
       "      <td>1.049479</td>\n",
       "      <td>0.840498</td>\n",
       "      <td>0.839914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.013900</td>\n",
       "      <td>1.010195</td>\n",
       "      <td>0.853583</td>\n",
       "      <td>0.851546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.010800</td>\n",
       "      <td>0.995116</td>\n",
       "      <td>0.848598</td>\n",
       "      <td>0.846400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.008600</td>\n",
       "      <td>1.037805</td>\n",
       "      <td>0.851090</td>\n",
       "      <td>0.849480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.008200</td>\n",
       "      <td>1.104095</td>\n",
       "      <td>0.847352</td>\n",
       "      <td>0.846078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.007100</td>\n",
       "      <td>1.196490</td>\n",
       "      <td>0.836137</td>\n",
       "      <td>0.835620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>1.138845</td>\n",
       "      <td>0.852336</td>\n",
       "      <td>0.850701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.009200</td>\n",
       "      <td>1.143221</td>\n",
       "      <td>0.847352</td>\n",
       "      <td>0.846312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>1.127942</td>\n",
       "      <td>0.853583</td>\n",
       "      <td>0.851457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.009800</td>\n",
       "      <td>1.147150</td>\n",
       "      <td>0.849221</td>\n",
       "      <td>0.847910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>1.133402</td>\n",
       "      <td>0.854206</td>\n",
       "      <td>0.851976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.006100</td>\n",
       "      <td>1.149958</td>\n",
       "      <td>0.851713</td>\n",
       "      <td>0.850051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.005900</td>\n",
       "      <td>1.172850</td>\n",
       "      <td>0.847975</td>\n",
       "      <td>0.846956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>1.170123</td>\n",
       "      <td>0.851090</td>\n",
       "      <td>0.849670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>1.170151</td>\n",
       "      <td>0.850467</td>\n",
       "      <td>0.848831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>1.176533</td>\n",
       "      <td>0.851090</td>\n",
       "      <td>0.849558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1980</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>1.178978</td>\n",
       "      <td>0.851090</td>\n",
       "      <td>0.849558</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6419 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1605 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2020' max='2020' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2020/2020 03:08, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.460600</td>\n",
       "      <td>0.377947</td>\n",
       "      <td>0.825545</td>\n",
       "      <td>0.821452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.324700</td>\n",
       "      <td>0.480740</td>\n",
       "      <td>0.844237</td>\n",
       "      <td>0.840583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.195200</td>\n",
       "      <td>0.386275</td>\n",
       "      <td>0.842991</td>\n",
       "      <td>0.841551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.137600</td>\n",
       "      <td>0.597552</td>\n",
       "      <td>0.821807</td>\n",
       "      <td>0.821477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.092600</td>\n",
       "      <td>0.489382</td>\n",
       "      <td>0.853583</td>\n",
       "      <td>0.851675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.055900</td>\n",
       "      <td>0.589073</td>\n",
       "      <td>0.849844</td>\n",
       "      <td>0.848626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.057600</td>\n",
       "      <td>0.653749</td>\n",
       "      <td>0.854829</td>\n",
       "      <td>0.853297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.044400</td>\n",
       "      <td>0.676381</td>\n",
       "      <td>0.847352</td>\n",
       "      <td>0.845620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.047200</td>\n",
       "      <td>0.721090</td>\n",
       "      <td>0.857944</td>\n",
       "      <td>0.854611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.033600</td>\n",
       "      <td>0.773018</td>\n",
       "      <td>0.848598</td>\n",
       "      <td>0.847909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.024600</td>\n",
       "      <td>0.721989</td>\n",
       "      <td>0.841121</td>\n",
       "      <td>0.840425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.026800</td>\n",
       "      <td>0.872121</td>\n",
       "      <td>0.845483</td>\n",
       "      <td>0.844657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.019000</td>\n",
       "      <td>0.798749</td>\n",
       "      <td>0.846729</td>\n",
       "      <td>0.843981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.015500</td>\n",
       "      <td>0.968675</td>\n",
       "      <td>0.850467</td>\n",
       "      <td>0.847888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.021700</td>\n",
       "      <td>0.822895</td>\n",
       "      <td>0.849844</td>\n",
       "      <td>0.848557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.014700</td>\n",
       "      <td>0.929539</td>\n",
       "      <td>0.848598</td>\n",
       "      <td>0.846062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.011300</td>\n",
       "      <td>1.049479</td>\n",
       "      <td>0.840498</td>\n",
       "      <td>0.839914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.013900</td>\n",
       "      <td>1.010195</td>\n",
       "      <td>0.853583</td>\n",
       "      <td>0.851546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.010800</td>\n",
       "      <td>0.995116</td>\n",
       "      <td>0.848598</td>\n",
       "      <td>0.846400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.008600</td>\n",
       "      <td>1.037805</td>\n",
       "      <td>0.851090</td>\n",
       "      <td>0.849480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.008200</td>\n",
       "      <td>1.104095</td>\n",
       "      <td>0.847352</td>\n",
       "      <td>0.846078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.007100</td>\n",
       "      <td>1.196490</td>\n",
       "      <td>0.836137</td>\n",
       "      <td>0.835620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>1.138845</td>\n",
       "      <td>0.852336</td>\n",
       "      <td>0.850701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.009200</td>\n",
       "      <td>1.143221</td>\n",
       "      <td>0.847352</td>\n",
       "      <td>0.846312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>1.127942</td>\n",
       "      <td>0.853583</td>\n",
       "      <td>0.851457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.009800</td>\n",
       "      <td>1.147150</td>\n",
       "      <td>0.849221</td>\n",
       "      <td>0.847910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>1.133402</td>\n",
       "      <td>0.854206</td>\n",
       "      <td>0.851976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.006100</td>\n",
       "      <td>1.149958</td>\n",
       "      <td>0.851713</td>\n",
       "      <td>0.850051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.005900</td>\n",
       "      <td>1.172850</td>\n",
       "      <td>0.847975</td>\n",
       "      <td>0.846956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>1.170123</td>\n",
       "      <td>0.851090</td>\n",
       "      <td>0.849670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>1.170151</td>\n",
       "      <td>0.850467</td>\n",
       "      <td>0.848831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>1.176533</td>\n",
       "      <td>0.851090</td>\n",
       "      <td>0.849558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1980</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>1.178978</td>\n",
       "      <td>0.851090</td>\n",
       "      <td>0.849558</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunis-ai/TunBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tunis-ai/TunBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6419 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1605 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2020' max='2020' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2020/2020 03:00, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.752600</td>\n",
       "      <td>0.705177</td>\n",
       "      <td>0.446729</td>\n",
       "      <td>0.308786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.706600</td>\n",
       "      <td>0.688228</td>\n",
       "      <td>0.553271</td>\n",
       "      <td>0.356197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.698800</td>\n",
       "      <td>0.687398</td>\n",
       "      <td>0.553271</td>\n",
       "      <td>0.356197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.698400</td>\n",
       "      <td>0.687863</td>\n",
       "      <td>0.553271</td>\n",
       "      <td>0.356197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.694900</td>\n",
       "      <td>0.692092</td>\n",
       "      <td>0.548287</td>\n",
       "      <td>0.533258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.702500</td>\n",
       "      <td>0.690436</td>\n",
       "      <td>0.553271</td>\n",
       "      <td>0.356197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.698500</td>\n",
       "      <td>0.679696</td>\n",
       "      <td>0.586293</td>\n",
       "      <td>0.585996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.674300</td>\n",
       "      <td>0.673915</td>\n",
       "      <td>0.610592</td>\n",
       "      <td>0.610396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.695800</td>\n",
       "      <td>0.677101</td>\n",
       "      <td>0.579439</td>\n",
       "      <td>0.443163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.660800</td>\n",
       "      <td>0.677828</td>\n",
       "      <td>0.626791</td>\n",
       "      <td>0.590800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.637200</td>\n",
       "      <td>0.652271</td>\n",
       "      <td>0.616822</td>\n",
       "      <td>0.603891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.643500</td>\n",
       "      <td>0.664462</td>\n",
       "      <td>0.620561</td>\n",
       "      <td>0.605659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.629300</td>\n",
       "      <td>0.671980</td>\n",
       "      <td>0.615576</td>\n",
       "      <td>0.602602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.625800</td>\n",
       "      <td>0.672079</td>\n",
       "      <td>0.619315</td>\n",
       "      <td>0.619182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.631500</td>\n",
       "      <td>0.645211</td>\n",
       "      <td>0.635514</td>\n",
       "      <td>0.630552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.596300</td>\n",
       "      <td>0.673503</td>\n",
       "      <td>0.628037</td>\n",
       "      <td>0.627329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.616500</td>\n",
       "      <td>0.663182</td>\n",
       "      <td>0.638006</td>\n",
       "      <td>0.627302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.598300</td>\n",
       "      <td>0.663389</td>\n",
       "      <td>0.636760</td>\n",
       "      <td>0.605168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.585500</td>\n",
       "      <td>0.671013</td>\n",
       "      <td>0.636137</td>\n",
       "      <td>0.621752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.592400</td>\n",
       "      <td>0.671542</td>\n",
       "      <td>0.636137</td>\n",
       "      <td>0.612678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.569800</td>\n",
       "      <td>0.647018</td>\n",
       "      <td>0.646729</td>\n",
       "      <td>0.635964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.567500</td>\n",
       "      <td>0.648851</td>\n",
       "      <td>0.635514</td>\n",
       "      <td>0.615057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.554100</td>\n",
       "      <td>0.671848</td>\n",
       "      <td>0.641121</td>\n",
       "      <td>0.637474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.556200</td>\n",
       "      <td>0.695312</td>\n",
       "      <td>0.644860</td>\n",
       "      <td>0.636101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.671067</td>\n",
       "      <td>0.648598</td>\n",
       "      <td>0.632989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.529700</td>\n",
       "      <td>0.679362</td>\n",
       "      <td>0.641121</td>\n",
       "      <td>0.637381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.540500</td>\n",
       "      <td>0.690344</td>\n",
       "      <td>0.629907</td>\n",
       "      <td>0.628192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.529300</td>\n",
       "      <td>0.696439</td>\n",
       "      <td>0.627414</td>\n",
       "      <td>0.626048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.509500</td>\n",
       "      <td>0.697231</td>\n",
       "      <td>0.652960</td>\n",
       "      <td>0.634575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.512200</td>\n",
       "      <td>0.704089</td>\n",
       "      <td>0.652336</td>\n",
       "      <td>0.645493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.512200</td>\n",
       "      <td>0.700370</td>\n",
       "      <td>0.634268</td>\n",
       "      <td>0.631045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.505700</td>\n",
       "      <td>0.711875</td>\n",
       "      <td>0.643614</td>\n",
       "      <td>0.639522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1980</td>\n",
       "      <td>0.502000</td>\n",
       "      <td>0.704941</td>\n",
       "      <td>0.644237</td>\n",
       "      <td>0.638962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunis-ai/TunBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tunis-ai/TunBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6419 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1605 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2020' max='2020' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2020/2020 02:59, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.752600</td>\n",
       "      <td>0.705177</td>\n",
       "      <td>0.446729</td>\n",
       "      <td>0.308786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.706600</td>\n",
       "      <td>0.688228</td>\n",
       "      <td>0.553271</td>\n",
       "      <td>0.356197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.698800</td>\n",
       "      <td>0.687398</td>\n",
       "      <td>0.553271</td>\n",
       "      <td>0.356197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.698400</td>\n",
       "      <td>0.687863</td>\n",
       "      <td>0.553271</td>\n",
       "      <td>0.356197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.694900</td>\n",
       "      <td>0.692092</td>\n",
       "      <td>0.548287</td>\n",
       "      <td>0.533258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.702500</td>\n",
       "      <td>0.690436</td>\n",
       "      <td>0.553271</td>\n",
       "      <td>0.356197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.698500</td>\n",
       "      <td>0.679696</td>\n",
       "      <td>0.586293</td>\n",
       "      <td>0.585996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.674300</td>\n",
       "      <td>0.673915</td>\n",
       "      <td>0.610592</td>\n",
       "      <td>0.610396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.695800</td>\n",
       "      <td>0.677101</td>\n",
       "      <td>0.579439</td>\n",
       "      <td>0.443163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.660800</td>\n",
       "      <td>0.677828</td>\n",
       "      <td>0.626791</td>\n",
       "      <td>0.590800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.637200</td>\n",
       "      <td>0.652271</td>\n",
       "      <td>0.616822</td>\n",
       "      <td>0.603891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.643500</td>\n",
       "      <td>0.664462</td>\n",
       "      <td>0.620561</td>\n",
       "      <td>0.605659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.629300</td>\n",
       "      <td>0.671980</td>\n",
       "      <td>0.615576</td>\n",
       "      <td>0.602602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.625800</td>\n",
       "      <td>0.672079</td>\n",
       "      <td>0.619315</td>\n",
       "      <td>0.619182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.631500</td>\n",
       "      <td>0.645211</td>\n",
       "      <td>0.635514</td>\n",
       "      <td>0.630552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.596300</td>\n",
       "      <td>0.673503</td>\n",
       "      <td>0.628037</td>\n",
       "      <td>0.627329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.616500</td>\n",
       "      <td>0.663182</td>\n",
       "      <td>0.638006</td>\n",
       "      <td>0.627302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.598300</td>\n",
       "      <td>0.663389</td>\n",
       "      <td>0.636760</td>\n",
       "      <td>0.605168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.585500</td>\n",
       "      <td>0.671013</td>\n",
       "      <td>0.636137</td>\n",
       "      <td>0.621752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.592400</td>\n",
       "      <td>0.671542</td>\n",
       "      <td>0.636137</td>\n",
       "      <td>0.612678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.569800</td>\n",
       "      <td>0.647018</td>\n",
       "      <td>0.646729</td>\n",
       "      <td>0.635964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.567500</td>\n",
       "      <td>0.648851</td>\n",
       "      <td>0.635514</td>\n",
       "      <td>0.615057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.554100</td>\n",
       "      <td>0.671848</td>\n",
       "      <td>0.641121</td>\n",
       "      <td>0.637474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.556200</td>\n",
       "      <td>0.695312</td>\n",
       "      <td>0.644860</td>\n",
       "      <td>0.636101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.671067</td>\n",
       "      <td>0.648598</td>\n",
       "      <td>0.632989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.529700</td>\n",
       "      <td>0.679362</td>\n",
       "      <td>0.641121</td>\n",
       "      <td>0.637381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.540500</td>\n",
       "      <td>0.690344</td>\n",
       "      <td>0.629907</td>\n",
       "      <td>0.628192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.529300</td>\n",
       "      <td>0.696439</td>\n",
       "      <td>0.627414</td>\n",
       "      <td>0.626048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.509500</td>\n",
       "      <td>0.697231</td>\n",
       "      <td>0.652960</td>\n",
       "      <td>0.634575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.512200</td>\n",
       "      <td>0.704089</td>\n",
       "      <td>0.652336</td>\n",
       "      <td>0.645493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.512200</td>\n",
       "      <td>0.700370</td>\n",
       "      <td>0.634268</td>\n",
       "      <td>0.631045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.505700</td>\n",
       "      <td>0.711875</td>\n",
       "      <td>0.643614</td>\n",
       "      <td>0.639522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1980</td>\n",
       "      <td>0.502000</td>\n",
       "      <td>0.704941</td>\n",
       "      <td>0.644237</td>\n",
       "      <td>0.638962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunis-ai/TunBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tunis-ai/TunBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52cee11b788e48159beb4e690e15573e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6419 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44db0451f5d444259863647df9ce0655",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1605 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2020' max='2020' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2020/2020 02:57, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.752600</td>\n",
       "      <td>0.705177</td>\n",
       "      <td>0.446729</td>\n",
       "      <td>0.308786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.706600</td>\n",
       "      <td>0.688228</td>\n",
       "      <td>0.553271</td>\n",
       "      <td>0.356197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.698800</td>\n",
       "      <td>0.687398</td>\n",
       "      <td>0.553271</td>\n",
       "      <td>0.356197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.698400</td>\n",
       "      <td>0.687863</td>\n",
       "      <td>0.553271</td>\n",
       "      <td>0.356197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.694900</td>\n",
       "      <td>0.692092</td>\n",
       "      <td>0.548287</td>\n",
       "      <td>0.533258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.702500</td>\n",
       "      <td>0.690436</td>\n",
       "      <td>0.553271</td>\n",
       "      <td>0.356197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.698500</td>\n",
       "      <td>0.679696</td>\n",
       "      <td>0.586293</td>\n",
       "      <td>0.585996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.674300</td>\n",
       "      <td>0.673915</td>\n",
       "      <td>0.610592</td>\n",
       "      <td>0.610396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.695800</td>\n",
       "      <td>0.677101</td>\n",
       "      <td>0.579439</td>\n",
       "      <td>0.443163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.660800</td>\n",
       "      <td>0.677828</td>\n",
       "      <td>0.626791</td>\n",
       "      <td>0.590800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.637200</td>\n",
       "      <td>0.652271</td>\n",
       "      <td>0.616822</td>\n",
       "      <td>0.603891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.643500</td>\n",
       "      <td>0.664462</td>\n",
       "      <td>0.620561</td>\n",
       "      <td>0.605659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.629300</td>\n",
       "      <td>0.671980</td>\n",
       "      <td>0.615576</td>\n",
       "      <td>0.602602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.625800</td>\n",
       "      <td>0.672079</td>\n",
       "      <td>0.619315</td>\n",
       "      <td>0.619182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.631500</td>\n",
       "      <td>0.645211</td>\n",
       "      <td>0.635514</td>\n",
       "      <td>0.630552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.596300</td>\n",
       "      <td>0.673503</td>\n",
       "      <td>0.628037</td>\n",
       "      <td>0.627329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.616500</td>\n",
       "      <td>0.663182</td>\n",
       "      <td>0.638006</td>\n",
       "      <td>0.627302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.598300</td>\n",
       "      <td>0.663389</td>\n",
       "      <td>0.636760</td>\n",
       "      <td>0.605168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.585500</td>\n",
       "      <td>0.671013</td>\n",
       "      <td>0.636137</td>\n",
       "      <td>0.621752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.592400</td>\n",
       "      <td>0.671542</td>\n",
       "      <td>0.636137</td>\n",
       "      <td>0.612678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.569800</td>\n",
       "      <td>0.647018</td>\n",
       "      <td>0.646729</td>\n",
       "      <td>0.635964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.567500</td>\n",
       "      <td>0.648851</td>\n",
       "      <td>0.635514</td>\n",
       "      <td>0.615057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.554100</td>\n",
       "      <td>0.671848</td>\n",
       "      <td>0.641121</td>\n",
       "      <td>0.637474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.556200</td>\n",
       "      <td>0.695312</td>\n",
       "      <td>0.644860</td>\n",
       "      <td>0.636101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.671067</td>\n",
       "      <td>0.648598</td>\n",
       "      <td>0.632989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.529700</td>\n",
       "      <td>0.679362</td>\n",
       "      <td>0.641121</td>\n",
       "      <td>0.637381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.540500</td>\n",
       "      <td>0.690344</td>\n",
       "      <td>0.629907</td>\n",
       "      <td>0.628192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.529300</td>\n",
       "      <td>0.696439</td>\n",
       "      <td>0.627414</td>\n",
       "      <td>0.626048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.509500</td>\n",
       "      <td>0.697231</td>\n",
       "      <td>0.652960</td>\n",
       "      <td>0.634575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.512200</td>\n",
       "      <td>0.704089</td>\n",
       "      <td>0.652336</td>\n",
       "      <td>0.645493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.512200</td>\n",
       "      <td>0.700370</td>\n",
       "      <td>0.634268</td>\n",
       "      <td>0.631045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.505700</td>\n",
       "      <td>0.711875</td>\n",
       "      <td>0.643614</td>\n",
       "      <td>0.639522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1980</td>\n",
       "      <td>0.502000</td>\n",
       "      <td>0.704941</td>\n",
       "      <td>0.644237</td>\n",
       "      <td>0.638962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alger-ia/dziribert, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dc9c339793a4a529c0ac7b38eee87d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6419 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa8f4b7d5f62472485e40cf6747d37d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1605 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2020' max='2020' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2020/2020 03:01, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.447500</td>\n",
       "      <td>0.403901</td>\n",
       "      <td>0.812461</td>\n",
       "      <td>0.812461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.318700</td>\n",
       "      <td>0.482401</td>\n",
       "      <td>0.844237</td>\n",
       "      <td>0.841903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.200200</td>\n",
       "      <td>0.491229</td>\n",
       "      <td>0.845483</td>\n",
       "      <td>0.844103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.133600</td>\n",
       "      <td>0.633008</td>\n",
       "      <td>0.842991</td>\n",
       "      <td>0.841314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.097300</td>\n",
       "      <td>0.561921</td>\n",
       "      <td>0.837383</td>\n",
       "      <td>0.834327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.062700</td>\n",
       "      <td>0.648115</td>\n",
       "      <td>0.836137</td>\n",
       "      <td>0.833553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.048300</td>\n",
       "      <td>0.811073</td>\n",
       "      <td>0.836760</td>\n",
       "      <td>0.834704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.046000</td>\n",
       "      <td>0.870627</td>\n",
       "      <td>0.836760</td>\n",
       "      <td>0.836440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.044800</td>\n",
       "      <td>0.821329</td>\n",
       "      <td>0.839252</td>\n",
       "      <td>0.838174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.037300</td>\n",
       "      <td>0.771362</td>\n",
       "      <td>0.840498</td>\n",
       "      <td>0.838059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.022700</td>\n",
       "      <td>0.877914</td>\n",
       "      <td>0.840498</td>\n",
       "      <td>0.838667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.024900</td>\n",
       "      <td>0.834745</td>\n",
       "      <td>0.843614</td>\n",
       "      <td>0.842581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.014000</td>\n",
       "      <td>0.864527</td>\n",
       "      <td>0.847352</td>\n",
       "      <td>0.846375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.021000</td>\n",
       "      <td>0.982189</td>\n",
       "      <td>0.844237</td>\n",
       "      <td>0.842613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.014600</td>\n",
       "      <td>1.018736</td>\n",
       "      <td>0.830530</td>\n",
       "      <td>0.826419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.013600</td>\n",
       "      <td>1.010308</td>\n",
       "      <td>0.845483</td>\n",
       "      <td>0.844066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.008500</td>\n",
       "      <td>0.985062</td>\n",
       "      <td>0.843614</td>\n",
       "      <td>0.842764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.006300</td>\n",
       "      <td>1.125388</td>\n",
       "      <td>0.841745</td>\n",
       "      <td>0.840176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.004900</td>\n",
       "      <td>1.135428</td>\n",
       "      <td>0.840498</td>\n",
       "      <td>0.839556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.007400</td>\n",
       "      <td>1.126551</td>\n",
       "      <td>0.844860</td>\n",
       "      <td>0.843636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>1.177798</td>\n",
       "      <td>0.841745</td>\n",
       "      <td>0.839970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>1.198331</td>\n",
       "      <td>0.842368</td>\n",
       "      <td>0.840493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>1.220460</td>\n",
       "      <td>0.838006</td>\n",
       "      <td>0.835966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.007200</td>\n",
       "      <td>1.214323</td>\n",
       "      <td>0.842991</td>\n",
       "      <td>0.841474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>1.226686</td>\n",
       "      <td>0.839252</td>\n",
       "      <td>0.837535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.006200</td>\n",
       "      <td>1.232514</td>\n",
       "      <td>0.840498</td>\n",
       "      <td>0.839149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>1.223488</td>\n",
       "      <td>0.844237</td>\n",
       "      <td>0.843094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.007100</td>\n",
       "      <td>1.248319</td>\n",
       "      <td>0.841121</td>\n",
       "      <td>0.839006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>1.221496</td>\n",
       "      <td>0.844237</td>\n",
       "      <td>0.842532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>1.229772</td>\n",
       "      <td>0.844860</td>\n",
       "      <td>0.843100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>1.236919</td>\n",
       "      <td>0.845483</td>\n",
       "      <td>0.843709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>1.237341</td>\n",
       "      <td>0.846106</td>\n",
       "      <td>0.844442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1980</td>\n",
       "      <td>0.005700</td>\n",
       "      <td>1.242880</td>\n",
       "      <td>0.846106</td>\n",
       "      <td>0.844360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alger-ia/dziribert, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94ae01c3556b4f7398f4d6789c7084d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6419 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c6551c065c04fe487bf99d186f78963",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1605 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2020' max='2020' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2020/2020 03:00, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.447500</td>\n",
       "      <td>0.403901</td>\n",
       "      <td>0.812461</td>\n",
       "      <td>0.812461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.318700</td>\n",
       "      <td>0.482401</td>\n",
       "      <td>0.844237</td>\n",
       "      <td>0.841903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.200200</td>\n",
       "      <td>0.491229</td>\n",
       "      <td>0.845483</td>\n",
       "      <td>0.844103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.133600</td>\n",
       "      <td>0.633008</td>\n",
       "      <td>0.842991</td>\n",
       "      <td>0.841314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.097300</td>\n",
       "      <td>0.561921</td>\n",
       "      <td>0.837383</td>\n",
       "      <td>0.834327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.062700</td>\n",
       "      <td>0.648115</td>\n",
       "      <td>0.836137</td>\n",
       "      <td>0.833553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.048300</td>\n",
       "      <td>0.811073</td>\n",
       "      <td>0.836760</td>\n",
       "      <td>0.834704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.046000</td>\n",
       "      <td>0.870627</td>\n",
       "      <td>0.836760</td>\n",
       "      <td>0.836440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.044800</td>\n",
       "      <td>0.821329</td>\n",
       "      <td>0.839252</td>\n",
       "      <td>0.838174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.037300</td>\n",
       "      <td>0.771362</td>\n",
       "      <td>0.840498</td>\n",
       "      <td>0.838059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.022700</td>\n",
       "      <td>0.877914</td>\n",
       "      <td>0.840498</td>\n",
       "      <td>0.838667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.024900</td>\n",
       "      <td>0.834745</td>\n",
       "      <td>0.843614</td>\n",
       "      <td>0.842581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.014000</td>\n",
       "      <td>0.864527</td>\n",
       "      <td>0.847352</td>\n",
       "      <td>0.846375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.021000</td>\n",
       "      <td>0.982189</td>\n",
       "      <td>0.844237</td>\n",
       "      <td>0.842613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.014600</td>\n",
       "      <td>1.018736</td>\n",
       "      <td>0.830530</td>\n",
       "      <td>0.826419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.013600</td>\n",
       "      <td>1.010308</td>\n",
       "      <td>0.845483</td>\n",
       "      <td>0.844066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.008500</td>\n",
       "      <td>0.985062</td>\n",
       "      <td>0.843614</td>\n",
       "      <td>0.842764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.006300</td>\n",
       "      <td>1.125388</td>\n",
       "      <td>0.841745</td>\n",
       "      <td>0.840176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.004900</td>\n",
       "      <td>1.135428</td>\n",
       "      <td>0.840498</td>\n",
       "      <td>0.839556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.007400</td>\n",
       "      <td>1.126551</td>\n",
       "      <td>0.844860</td>\n",
       "      <td>0.843636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>1.177798</td>\n",
       "      <td>0.841745</td>\n",
       "      <td>0.839970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>1.198331</td>\n",
       "      <td>0.842368</td>\n",
       "      <td>0.840493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>1.220460</td>\n",
       "      <td>0.838006</td>\n",
       "      <td>0.835966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.007200</td>\n",
       "      <td>1.214323</td>\n",
       "      <td>0.842991</td>\n",
       "      <td>0.841474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>1.226686</td>\n",
       "      <td>0.839252</td>\n",
       "      <td>0.837535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.006200</td>\n",
       "      <td>1.232514</td>\n",
       "      <td>0.840498</td>\n",
       "      <td>0.839149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>1.223488</td>\n",
       "      <td>0.844237</td>\n",
       "      <td>0.843094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.007100</td>\n",
       "      <td>1.248319</td>\n",
       "      <td>0.841121</td>\n",
       "      <td>0.839006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>1.221496</td>\n",
       "      <td>0.844237</td>\n",
       "      <td>0.842532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>1.229772</td>\n",
       "      <td>0.844860</td>\n",
       "      <td>0.843100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>1.236919</td>\n",
       "      <td>0.845483</td>\n",
       "      <td>0.843709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>1.237341</td>\n",
       "      <td>0.846106</td>\n",
       "      <td>0.844442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1980</td>\n",
       "      <td>0.005700</td>\n",
       "      <td>1.242880</td>\n",
       "      <td>0.846106</td>\n",
       "      <td>0.844360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alger-ia/dziribert, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "932b2ce33bfe412f84d9884225f8cfa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6419 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cb014d053bf48c288680621af9b1898",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1605 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2020' max='2020' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2020/2020 03:00, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.447500</td>\n",
       "      <td>0.403901</td>\n",
       "      <td>0.812461</td>\n",
       "      <td>0.812461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.318700</td>\n",
       "      <td>0.482401</td>\n",
       "      <td>0.844237</td>\n",
       "      <td>0.841903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.200200</td>\n",
       "      <td>0.491229</td>\n",
       "      <td>0.845483</td>\n",
       "      <td>0.844103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.133600</td>\n",
       "      <td>0.633008</td>\n",
       "      <td>0.842991</td>\n",
       "      <td>0.841314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.097300</td>\n",
       "      <td>0.561921</td>\n",
       "      <td>0.837383</td>\n",
       "      <td>0.834327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.062700</td>\n",
       "      <td>0.648115</td>\n",
       "      <td>0.836137</td>\n",
       "      <td>0.833553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.048300</td>\n",
       "      <td>0.811073</td>\n",
       "      <td>0.836760</td>\n",
       "      <td>0.834704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.046000</td>\n",
       "      <td>0.870627</td>\n",
       "      <td>0.836760</td>\n",
       "      <td>0.836440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.044800</td>\n",
       "      <td>0.821329</td>\n",
       "      <td>0.839252</td>\n",
       "      <td>0.838174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.037300</td>\n",
       "      <td>0.771362</td>\n",
       "      <td>0.840498</td>\n",
       "      <td>0.838059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.022700</td>\n",
       "      <td>0.877914</td>\n",
       "      <td>0.840498</td>\n",
       "      <td>0.838667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.024900</td>\n",
       "      <td>0.834745</td>\n",
       "      <td>0.843614</td>\n",
       "      <td>0.842581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.014000</td>\n",
       "      <td>0.864527</td>\n",
       "      <td>0.847352</td>\n",
       "      <td>0.846375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.021000</td>\n",
       "      <td>0.982189</td>\n",
       "      <td>0.844237</td>\n",
       "      <td>0.842613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.014600</td>\n",
       "      <td>1.018736</td>\n",
       "      <td>0.830530</td>\n",
       "      <td>0.826419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.013600</td>\n",
       "      <td>1.010308</td>\n",
       "      <td>0.845483</td>\n",
       "      <td>0.844066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.008500</td>\n",
       "      <td>0.985062</td>\n",
       "      <td>0.843614</td>\n",
       "      <td>0.842764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.006300</td>\n",
       "      <td>1.125388</td>\n",
       "      <td>0.841745</td>\n",
       "      <td>0.840176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.004900</td>\n",
       "      <td>1.135428</td>\n",
       "      <td>0.840498</td>\n",
       "      <td>0.839556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.007400</td>\n",
       "      <td>1.126551</td>\n",
       "      <td>0.844860</td>\n",
       "      <td>0.843636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>1.177798</td>\n",
       "      <td>0.841745</td>\n",
       "      <td>0.839970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>1.198331</td>\n",
       "      <td>0.842368</td>\n",
       "      <td>0.840493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>1.220460</td>\n",
       "      <td>0.838006</td>\n",
       "      <td>0.835966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.007200</td>\n",
       "      <td>1.214323</td>\n",
       "      <td>0.842991</td>\n",
       "      <td>0.841474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>1.226686</td>\n",
       "      <td>0.839252</td>\n",
       "      <td>0.837535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.006200</td>\n",
       "      <td>1.232514</td>\n",
       "      <td>0.840498</td>\n",
       "      <td>0.839149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>1.223488</td>\n",
       "      <td>0.844237</td>\n",
       "      <td>0.843094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.007100</td>\n",
       "      <td>1.248319</td>\n",
       "      <td>0.841121</td>\n",
       "      <td>0.839006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>1.221496</td>\n",
       "      <td>0.844237</td>\n",
       "      <td>0.842532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>1.229772</td>\n",
       "      <td>0.844860</td>\n",
       "      <td>0.843100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>1.236919</td>\n",
       "      <td>0.845483</td>\n",
       "      <td>0.843709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>1.237341</td>\n",
       "      <td>0.846106</td>\n",
       "      <td>0.844442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1980</td>\n",
       "      <td>0.005700</td>\n",
       "      <td>1.242880</td>\n",
       "      <td>0.846106</td>\n",
       "      <td>0.844360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SI2M-Lab/DarijaBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SI2M-Lab/DarijaBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d80666b260694ecf8e993c7612219ae4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6419 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f63eee741eb946959853e1e4897e49a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1605 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2020' max='2020' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2020/2020 03:07, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.442100</td>\n",
       "      <td>0.351074</td>\n",
       "      <td>0.836137</td>\n",
       "      <td>0.834097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.320200</td>\n",
       "      <td>0.379140</td>\n",
       "      <td>0.853583</td>\n",
       "      <td>0.852361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.215900</td>\n",
       "      <td>0.384887</td>\n",
       "      <td>0.849221</td>\n",
       "      <td>0.847531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.149300</td>\n",
       "      <td>0.513538</td>\n",
       "      <td>0.847352</td>\n",
       "      <td>0.844264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.105200</td>\n",
       "      <td>0.600918</td>\n",
       "      <td>0.848598</td>\n",
       "      <td>0.847960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.068700</td>\n",
       "      <td>0.593445</td>\n",
       "      <td>0.842368</td>\n",
       "      <td>0.838575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.058400</td>\n",
       "      <td>0.736695</td>\n",
       "      <td>0.855452</td>\n",
       "      <td>0.854295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.062100</td>\n",
       "      <td>0.747734</td>\n",
       "      <td>0.834268</td>\n",
       "      <td>0.834260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.042200</td>\n",
       "      <td>0.752437</td>\n",
       "      <td>0.846106</td>\n",
       "      <td>0.844750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.033600</td>\n",
       "      <td>0.693587</td>\n",
       "      <td>0.849844</td>\n",
       "      <td>0.848141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.027700</td>\n",
       "      <td>0.828919</td>\n",
       "      <td>0.852336</td>\n",
       "      <td>0.851104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.019100</td>\n",
       "      <td>0.905891</td>\n",
       "      <td>0.858567</td>\n",
       "      <td>0.857287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.021300</td>\n",
       "      <td>0.825938</td>\n",
       "      <td>0.849844</td>\n",
       "      <td>0.848017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.015600</td>\n",
       "      <td>0.969531</td>\n",
       "      <td>0.847975</td>\n",
       "      <td>0.846793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.016900</td>\n",
       "      <td>1.001103</td>\n",
       "      <td>0.843614</td>\n",
       "      <td>0.840729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.014000</td>\n",
       "      <td>1.043639</td>\n",
       "      <td>0.839875</td>\n",
       "      <td>0.837696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.011800</td>\n",
       "      <td>0.943498</td>\n",
       "      <td>0.849844</td>\n",
       "      <td>0.849056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.014700</td>\n",
       "      <td>0.968935</td>\n",
       "      <td>0.856075</td>\n",
       "      <td>0.854630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.007600</td>\n",
       "      <td>1.087033</td>\n",
       "      <td>0.847352</td>\n",
       "      <td>0.844536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.011000</td>\n",
       "      <td>1.053036</td>\n",
       "      <td>0.854206</td>\n",
       "      <td>0.852833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.007400</td>\n",
       "      <td>1.105505</td>\n",
       "      <td>0.847975</td>\n",
       "      <td>0.847547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.009900</td>\n",
       "      <td>1.098118</td>\n",
       "      <td>0.849844</td>\n",
       "      <td>0.848141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.007100</td>\n",
       "      <td>1.102411</td>\n",
       "      <td>0.851090</td>\n",
       "      <td>0.849360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.006600</td>\n",
       "      <td>1.154693</td>\n",
       "      <td>0.854206</td>\n",
       "      <td>0.853228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>1.183628</td>\n",
       "      <td>0.852960</td>\n",
       "      <td>0.852033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.010500</td>\n",
       "      <td>1.167363</td>\n",
       "      <td>0.849844</td>\n",
       "      <td>0.848260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>1.201780</td>\n",
       "      <td>0.849221</td>\n",
       "      <td>0.848301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.006300</td>\n",
       "      <td>1.251832</td>\n",
       "      <td>0.846729</td>\n",
       "      <td>0.846256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.004900</td>\n",
       "      <td>1.208746</td>\n",
       "      <td>0.849844</td>\n",
       "      <td>0.848337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>1.229717</td>\n",
       "      <td>0.844237</td>\n",
       "      <td>0.843346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.007700</td>\n",
       "      <td>1.222558</td>\n",
       "      <td>0.849221</td>\n",
       "      <td>0.847611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>1.226922</td>\n",
       "      <td>0.848598</td>\n",
       "      <td>0.847718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1980</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>1.240407</td>\n",
       "      <td>0.848598</td>\n",
       "      <td>0.847884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SI2M-Lab/DarijaBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SI2M-Lab/DarijaBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "747befc3480541bc9f25375d99b96952",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6419 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "663fae38628d4d698b7bea447755f743",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1605 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2020' max='2020' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2020/2020 03:07, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.442100</td>\n",
       "      <td>0.351074</td>\n",
       "      <td>0.836137</td>\n",
       "      <td>0.834097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.320200</td>\n",
       "      <td>0.379140</td>\n",
       "      <td>0.853583</td>\n",
       "      <td>0.852361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.215900</td>\n",
       "      <td>0.384887</td>\n",
       "      <td>0.849221</td>\n",
       "      <td>0.847531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.149300</td>\n",
       "      <td>0.513538</td>\n",
       "      <td>0.847352</td>\n",
       "      <td>0.844264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.105200</td>\n",
       "      <td>0.600918</td>\n",
       "      <td>0.848598</td>\n",
       "      <td>0.847960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.068700</td>\n",
       "      <td>0.593445</td>\n",
       "      <td>0.842368</td>\n",
       "      <td>0.838575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.058400</td>\n",
       "      <td>0.736695</td>\n",
       "      <td>0.855452</td>\n",
       "      <td>0.854295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.062100</td>\n",
       "      <td>0.747734</td>\n",
       "      <td>0.834268</td>\n",
       "      <td>0.834260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.042200</td>\n",
       "      <td>0.752437</td>\n",
       "      <td>0.846106</td>\n",
       "      <td>0.844750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.033600</td>\n",
       "      <td>0.693587</td>\n",
       "      <td>0.849844</td>\n",
       "      <td>0.848141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.027700</td>\n",
       "      <td>0.828919</td>\n",
       "      <td>0.852336</td>\n",
       "      <td>0.851104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.019100</td>\n",
       "      <td>0.905891</td>\n",
       "      <td>0.858567</td>\n",
       "      <td>0.857287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.021300</td>\n",
       "      <td>0.825938</td>\n",
       "      <td>0.849844</td>\n",
       "      <td>0.848017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.015600</td>\n",
       "      <td>0.969531</td>\n",
       "      <td>0.847975</td>\n",
       "      <td>0.846793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.016900</td>\n",
       "      <td>1.001103</td>\n",
       "      <td>0.843614</td>\n",
       "      <td>0.840729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.014000</td>\n",
       "      <td>1.043639</td>\n",
       "      <td>0.839875</td>\n",
       "      <td>0.837696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.011800</td>\n",
       "      <td>0.943498</td>\n",
       "      <td>0.849844</td>\n",
       "      <td>0.849056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.014700</td>\n",
       "      <td>0.968935</td>\n",
       "      <td>0.856075</td>\n",
       "      <td>0.854630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.007600</td>\n",
       "      <td>1.087033</td>\n",
       "      <td>0.847352</td>\n",
       "      <td>0.844536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.011000</td>\n",
       "      <td>1.053036</td>\n",
       "      <td>0.854206</td>\n",
       "      <td>0.852833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.007400</td>\n",
       "      <td>1.105505</td>\n",
       "      <td>0.847975</td>\n",
       "      <td>0.847547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.009900</td>\n",
       "      <td>1.098118</td>\n",
       "      <td>0.849844</td>\n",
       "      <td>0.848141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.007100</td>\n",
       "      <td>1.102411</td>\n",
       "      <td>0.851090</td>\n",
       "      <td>0.849360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.006600</td>\n",
       "      <td>1.154693</td>\n",
       "      <td>0.854206</td>\n",
       "      <td>0.853228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>1.183628</td>\n",
       "      <td>0.852960</td>\n",
       "      <td>0.852033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.010500</td>\n",
       "      <td>1.167363</td>\n",
       "      <td>0.849844</td>\n",
       "      <td>0.848260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>1.201780</td>\n",
       "      <td>0.849221</td>\n",
       "      <td>0.848301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.006300</td>\n",
       "      <td>1.251832</td>\n",
       "      <td>0.846729</td>\n",
       "      <td>0.846256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.004900</td>\n",
       "      <td>1.208746</td>\n",
       "      <td>0.849844</td>\n",
       "      <td>0.848337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>1.229717</td>\n",
       "      <td>0.844237</td>\n",
       "      <td>0.843346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.007700</td>\n",
       "      <td>1.222558</td>\n",
       "      <td>0.849221</td>\n",
       "      <td>0.847611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>1.226922</td>\n",
       "      <td>0.848598</td>\n",
       "      <td>0.847718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1980</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>1.240407</td>\n",
       "      <td>0.848598</td>\n",
       "      <td>0.847884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SI2M-Lab/DarijaBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SI2M-Lab/DarijaBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86834fec0d2f470094175e9ce1f0c44e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6419 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc2450f97162400f8fd35471dd76ce57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1605 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2020' max='2020' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2020/2020 03:07, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.442100</td>\n",
       "      <td>0.351074</td>\n",
       "      <td>0.836137</td>\n",
       "      <td>0.834097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.320200</td>\n",
       "      <td>0.379140</td>\n",
       "      <td>0.853583</td>\n",
       "      <td>0.852361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.215900</td>\n",
       "      <td>0.384887</td>\n",
       "      <td>0.849221</td>\n",
       "      <td>0.847531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.149300</td>\n",
       "      <td>0.513538</td>\n",
       "      <td>0.847352</td>\n",
       "      <td>0.844264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.105200</td>\n",
       "      <td>0.600918</td>\n",
       "      <td>0.848598</td>\n",
       "      <td>0.847960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.068700</td>\n",
       "      <td>0.593445</td>\n",
       "      <td>0.842368</td>\n",
       "      <td>0.838575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.058400</td>\n",
       "      <td>0.736695</td>\n",
       "      <td>0.855452</td>\n",
       "      <td>0.854295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.062100</td>\n",
       "      <td>0.747734</td>\n",
       "      <td>0.834268</td>\n",
       "      <td>0.834260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.042200</td>\n",
       "      <td>0.752437</td>\n",
       "      <td>0.846106</td>\n",
       "      <td>0.844750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.033600</td>\n",
       "      <td>0.693587</td>\n",
       "      <td>0.849844</td>\n",
       "      <td>0.848141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.027700</td>\n",
       "      <td>0.828919</td>\n",
       "      <td>0.852336</td>\n",
       "      <td>0.851104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.019100</td>\n",
       "      <td>0.905891</td>\n",
       "      <td>0.858567</td>\n",
       "      <td>0.857287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.021300</td>\n",
       "      <td>0.825938</td>\n",
       "      <td>0.849844</td>\n",
       "      <td>0.848017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.015600</td>\n",
       "      <td>0.969531</td>\n",
       "      <td>0.847975</td>\n",
       "      <td>0.846793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.016900</td>\n",
       "      <td>1.001103</td>\n",
       "      <td>0.843614</td>\n",
       "      <td>0.840729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.014000</td>\n",
       "      <td>1.043639</td>\n",
       "      <td>0.839875</td>\n",
       "      <td>0.837696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.011800</td>\n",
       "      <td>0.943498</td>\n",
       "      <td>0.849844</td>\n",
       "      <td>0.849056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.014700</td>\n",
       "      <td>0.968935</td>\n",
       "      <td>0.856075</td>\n",
       "      <td>0.854630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.007600</td>\n",
       "      <td>1.087033</td>\n",
       "      <td>0.847352</td>\n",
       "      <td>0.844536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.011000</td>\n",
       "      <td>1.053036</td>\n",
       "      <td>0.854206</td>\n",
       "      <td>0.852833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.007400</td>\n",
       "      <td>1.105505</td>\n",
       "      <td>0.847975</td>\n",
       "      <td>0.847547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.009900</td>\n",
       "      <td>1.098118</td>\n",
       "      <td>0.849844</td>\n",
       "      <td>0.848141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.007100</td>\n",
       "      <td>1.102411</td>\n",
       "      <td>0.851090</td>\n",
       "      <td>0.849360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.006600</td>\n",
       "      <td>1.154693</td>\n",
       "      <td>0.854206</td>\n",
       "      <td>0.853228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>1.183628</td>\n",
       "      <td>0.852960</td>\n",
       "      <td>0.852033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.010500</td>\n",
       "      <td>1.167363</td>\n",
       "      <td>0.849844</td>\n",
       "      <td>0.848260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>1.201780</td>\n",
       "      <td>0.849221</td>\n",
       "      <td>0.848301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.006300</td>\n",
       "      <td>1.251832</td>\n",
       "      <td>0.846729</td>\n",
       "      <td>0.846256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.004900</td>\n",
       "      <td>1.208746</td>\n",
       "      <td>0.849844</td>\n",
       "      <td>0.848337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>1.229717</td>\n",
       "      <td>0.844237</td>\n",
       "      <td>0.843346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.007700</td>\n",
       "      <td>1.222558</td>\n",
       "      <td>0.849221</td>\n",
       "      <td>0.847611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>1.226922</td>\n",
       "      <td>0.848598</td>\n",
       "      <td>0.847718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1980</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>1.240407</td>\n",
       "      <td>0.848598</td>\n",
       "      <td>0.847884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorRoBERTa, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at otmangi/MorRoBERTa and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d91212c36a784e919bbe978553a4018f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6419 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39fccded90894ccb80537524f45da1a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1605 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2020' max='2020' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2020/2020 01:40, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.467700</td>\n",
       "      <td>0.407187</td>\n",
       "      <td>0.804984</td>\n",
       "      <td>0.804523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.348000</td>\n",
       "      <td>0.494636</td>\n",
       "      <td>0.822430</td>\n",
       "      <td>0.819337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.241100</td>\n",
       "      <td>0.417619</td>\n",
       "      <td>0.824299</td>\n",
       "      <td>0.821667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.176400</td>\n",
       "      <td>0.633845</td>\n",
       "      <td>0.808100</td>\n",
       "      <td>0.801104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.128600</td>\n",
       "      <td>0.605240</td>\n",
       "      <td>0.833645</td>\n",
       "      <td>0.831230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.063300</td>\n",
       "      <td>0.816005</td>\n",
       "      <td>0.819938</td>\n",
       "      <td>0.818785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.064400</td>\n",
       "      <td>0.868636</td>\n",
       "      <td>0.818692</td>\n",
       "      <td>0.816330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>0.905689</td>\n",
       "      <td>0.795639</td>\n",
       "      <td>0.795625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.043200</td>\n",
       "      <td>0.884077</td>\n",
       "      <td>0.809346</td>\n",
       "      <td>0.805241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.045200</td>\n",
       "      <td>0.908662</td>\n",
       "      <td>0.804361</td>\n",
       "      <td>0.803488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.031600</td>\n",
       "      <td>0.828895</td>\n",
       "      <td>0.824299</td>\n",
       "      <td>0.822329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.025500</td>\n",
       "      <td>1.039113</td>\n",
       "      <td>0.823053</td>\n",
       "      <td>0.822292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.022200</td>\n",
       "      <td>0.800098</td>\n",
       "      <td>0.821184</td>\n",
       "      <td>0.819891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.018000</td>\n",
       "      <td>1.173756</td>\n",
       "      <td>0.816822</td>\n",
       "      <td>0.814913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.016700</td>\n",
       "      <td>1.150326</td>\n",
       "      <td>0.821184</td>\n",
       "      <td>0.817632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.013200</td>\n",
       "      <td>1.210828</td>\n",
       "      <td>0.818069</td>\n",
       "      <td>0.814288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.014000</td>\n",
       "      <td>1.203748</td>\n",
       "      <td>0.819315</td>\n",
       "      <td>0.818212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.008300</td>\n",
       "      <td>1.260839</td>\n",
       "      <td>0.823676</td>\n",
       "      <td>0.822080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.008900</td>\n",
       "      <td>1.276962</td>\n",
       "      <td>0.825545</td>\n",
       "      <td>0.824029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.007900</td>\n",
       "      <td>1.310364</td>\n",
       "      <td>0.823676</td>\n",
       "      <td>0.820951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.007600</td>\n",
       "      <td>1.373066</td>\n",
       "      <td>0.824299</td>\n",
       "      <td>0.823628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.005900</td>\n",
       "      <td>1.297607</td>\n",
       "      <td>0.817445</td>\n",
       "      <td>0.816125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.006200</td>\n",
       "      <td>1.335914</td>\n",
       "      <td>0.820561</td>\n",
       "      <td>0.819205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>1.335121</td>\n",
       "      <td>0.827414</td>\n",
       "      <td>0.824231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>1.356426</td>\n",
       "      <td>0.818692</td>\n",
       "      <td>0.817494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>1.371306</td>\n",
       "      <td>0.821184</td>\n",
       "      <td>0.818750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>1.385814</td>\n",
       "      <td>0.824922</td>\n",
       "      <td>0.821990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.005700</td>\n",
       "      <td>1.391747</td>\n",
       "      <td>0.823676</td>\n",
       "      <td>0.821579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>1.416253</td>\n",
       "      <td>0.819938</td>\n",
       "      <td>0.818711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>1.414776</td>\n",
       "      <td>0.822430</td>\n",
       "      <td>0.819686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.005700</td>\n",
       "      <td>1.420679</td>\n",
       "      <td>0.822430</td>\n",
       "      <td>0.820117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>1.428475</td>\n",
       "      <td>0.823676</td>\n",
       "      <td>0.821861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1980</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>1.429347</td>\n",
       "      <td>0.822430</td>\n",
       "      <td>0.820602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorRoBERTa, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at otmangi/MorRoBERTa and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e3d7684578742a0b35c53aa4d05f89a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6419 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8972bc148106496783e7e7bb6b016e62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1605 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2020' max='2020' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2020/2020 01:40, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.467700</td>\n",
       "      <td>0.407187</td>\n",
       "      <td>0.804984</td>\n",
       "      <td>0.804523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.348000</td>\n",
       "      <td>0.494636</td>\n",
       "      <td>0.822430</td>\n",
       "      <td>0.819337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.241100</td>\n",
       "      <td>0.417619</td>\n",
       "      <td>0.824299</td>\n",
       "      <td>0.821667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.176400</td>\n",
       "      <td>0.633845</td>\n",
       "      <td>0.808100</td>\n",
       "      <td>0.801104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.128600</td>\n",
       "      <td>0.605240</td>\n",
       "      <td>0.833645</td>\n",
       "      <td>0.831230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.063300</td>\n",
       "      <td>0.816005</td>\n",
       "      <td>0.819938</td>\n",
       "      <td>0.818785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.064400</td>\n",
       "      <td>0.868636</td>\n",
       "      <td>0.818692</td>\n",
       "      <td>0.816330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>0.905689</td>\n",
       "      <td>0.795639</td>\n",
       "      <td>0.795625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.043200</td>\n",
       "      <td>0.884077</td>\n",
       "      <td>0.809346</td>\n",
       "      <td>0.805241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.045200</td>\n",
       "      <td>0.908662</td>\n",
       "      <td>0.804361</td>\n",
       "      <td>0.803488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.031600</td>\n",
       "      <td>0.828895</td>\n",
       "      <td>0.824299</td>\n",
       "      <td>0.822329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.025500</td>\n",
       "      <td>1.039113</td>\n",
       "      <td>0.823053</td>\n",
       "      <td>0.822292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.022200</td>\n",
       "      <td>0.800098</td>\n",
       "      <td>0.821184</td>\n",
       "      <td>0.819891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.018000</td>\n",
       "      <td>1.173756</td>\n",
       "      <td>0.816822</td>\n",
       "      <td>0.814913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.016700</td>\n",
       "      <td>1.150326</td>\n",
       "      <td>0.821184</td>\n",
       "      <td>0.817632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.013200</td>\n",
       "      <td>1.210828</td>\n",
       "      <td>0.818069</td>\n",
       "      <td>0.814288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.014000</td>\n",
       "      <td>1.203748</td>\n",
       "      <td>0.819315</td>\n",
       "      <td>0.818212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.008300</td>\n",
       "      <td>1.260839</td>\n",
       "      <td>0.823676</td>\n",
       "      <td>0.822080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.008900</td>\n",
       "      <td>1.276962</td>\n",
       "      <td>0.825545</td>\n",
       "      <td>0.824029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.007900</td>\n",
       "      <td>1.310364</td>\n",
       "      <td>0.823676</td>\n",
       "      <td>0.820951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.007600</td>\n",
       "      <td>1.373066</td>\n",
       "      <td>0.824299</td>\n",
       "      <td>0.823628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.005900</td>\n",
       "      <td>1.297607</td>\n",
       "      <td>0.817445</td>\n",
       "      <td>0.816125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.006200</td>\n",
       "      <td>1.335914</td>\n",
       "      <td>0.820561</td>\n",
       "      <td>0.819205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>1.335121</td>\n",
       "      <td>0.827414</td>\n",
       "      <td>0.824231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>1.356426</td>\n",
       "      <td>0.818692</td>\n",
       "      <td>0.817494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>1.371306</td>\n",
       "      <td>0.821184</td>\n",
       "      <td>0.818750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>1.385814</td>\n",
       "      <td>0.824922</td>\n",
       "      <td>0.821990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.005700</td>\n",
       "      <td>1.391747</td>\n",
       "      <td>0.823676</td>\n",
       "      <td>0.821579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>1.416253</td>\n",
       "      <td>0.819938</td>\n",
       "      <td>0.818711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>1.414776</td>\n",
       "      <td>0.822430</td>\n",
       "      <td>0.819686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.005700</td>\n",
       "      <td>1.420679</td>\n",
       "      <td>0.822430</td>\n",
       "      <td>0.820117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>1.428475</td>\n",
       "      <td>0.823676</td>\n",
       "      <td>0.821861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1980</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>1.429347</td>\n",
       "      <td>0.822430</td>\n",
       "      <td>0.820602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorRoBERTa, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at otmangi/MorRoBERTa and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10260d552ce2437282794788f6bc6573",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6419 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a639a1bafadc4db982742caa65a483a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1605 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2020' max='2020' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2020/2020 01:40, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.467700</td>\n",
       "      <td>0.407187</td>\n",
       "      <td>0.804984</td>\n",
       "      <td>0.804523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.348000</td>\n",
       "      <td>0.494636</td>\n",
       "      <td>0.822430</td>\n",
       "      <td>0.819337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.241100</td>\n",
       "      <td>0.417619</td>\n",
       "      <td>0.824299</td>\n",
       "      <td>0.821667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.176400</td>\n",
       "      <td>0.633845</td>\n",
       "      <td>0.808100</td>\n",
       "      <td>0.801104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.128600</td>\n",
       "      <td>0.605240</td>\n",
       "      <td>0.833645</td>\n",
       "      <td>0.831230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.063300</td>\n",
       "      <td>0.816005</td>\n",
       "      <td>0.819938</td>\n",
       "      <td>0.818785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.064400</td>\n",
       "      <td>0.868636</td>\n",
       "      <td>0.818692</td>\n",
       "      <td>0.816330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>0.905689</td>\n",
       "      <td>0.795639</td>\n",
       "      <td>0.795625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.043200</td>\n",
       "      <td>0.884077</td>\n",
       "      <td>0.809346</td>\n",
       "      <td>0.805241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.045200</td>\n",
       "      <td>0.908662</td>\n",
       "      <td>0.804361</td>\n",
       "      <td>0.803488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.031600</td>\n",
       "      <td>0.828895</td>\n",
       "      <td>0.824299</td>\n",
       "      <td>0.822329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.025500</td>\n",
       "      <td>1.039113</td>\n",
       "      <td>0.823053</td>\n",
       "      <td>0.822292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.022200</td>\n",
       "      <td>0.800098</td>\n",
       "      <td>0.821184</td>\n",
       "      <td>0.819891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.018000</td>\n",
       "      <td>1.173756</td>\n",
       "      <td>0.816822</td>\n",
       "      <td>0.814913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.016700</td>\n",
       "      <td>1.150326</td>\n",
       "      <td>0.821184</td>\n",
       "      <td>0.817632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.013200</td>\n",
       "      <td>1.210828</td>\n",
       "      <td>0.818069</td>\n",
       "      <td>0.814288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.014000</td>\n",
       "      <td>1.203748</td>\n",
       "      <td>0.819315</td>\n",
       "      <td>0.818212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.008300</td>\n",
       "      <td>1.260839</td>\n",
       "      <td>0.823676</td>\n",
       "      <td>0.822080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.008900</td>\n",
       "      <td>1.276962</td>\n",
       "      <td>0.825545</td>\n",
       "      <td>0.824029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.007900</td>\n",
       "      <td>1.310364</td>\n",
       "      <td>0.823676</td>\n",
       "      <td>0.820951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.007600</td>\n",
       "      <td>1.373066</td>\n",
       "      <td>0.824299</td>\n",
       "      <td>0.823628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.005900</td>\n",
       "      <td>1.297607</td>\n",
       "      <td>0.817445</td>\n",
       "      <td>0.816125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.006200</td>\n",
       "      <td>1.335914</td>\n",
       "      <td>0.820561</td>\n",
       "      <td>0.819205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>1.335121</td>\n",
       "      <td>0.827414</td>\n",
       "      <td>0.824231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>1.356426</td>\n",
       "      <td>0.818692</td>\n",
       "      <td>0.817494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>1.371306</td>\n",
       "      <td>0.821184</td>\n",
       "      <td>0.818750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>1.385814</td>\n",
       "      <td>0.824922</td>\n",
       "      <td>0.821990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.005700</td>\n",
       "      <td>1.391747</td>\n",
       "      <td>0.823676</td>\n",
       "      <td>0.821579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>1.416253</td>\n",
       "      <td>0.819938</td>\n",
       "      <td>0.818711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>1.414776</td>\n",
       "      <td>0.822430</td>\n",
       "      <td>0.819686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.005700</td>\n",
       "      <td>1.420679</td>\n",
       "      <td>0.822430</td>\n",
       "      <td>0.820117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>1.428475</td>\n",
       "      <td>0.823676</td>\n",
       "      <td>0.821861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1980</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>1.429347</td>\n",
       "      <td>0.822430</td>\n",
       "      <td>0.820602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorrBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at otmangi/MorrBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed5b06faf6514a37927a42fe4f9fad1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6419 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6c9316938644fa7b4c4dba0490a3b1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1605 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2020' max='2020' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2020/2020 03:02, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.419800</td>\n",
       "      <td>0.378933</td>\n",
       "      <td>0.821184</td>\n",
       "      <td>0.819773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.332100</td>\n",
       "      <td>0.521284</td>\n",
       "      <td>0.819315</td>\n",
       "      <td>0.815004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.204800</td>\n",
       "      <td>0.410218</td>\n",
       "      <td>0.829283</td>\n",
       "      <td>0.828631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.140100</td>\n",
       "      <td>0.664158</td>\n",
       "      <td>0.811838</td>\n",
       "      <td>0.805975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.107200</td>\n",
       "      <td>0.601107</td>\n",
       "      <td>0.822430</td>\n",
       "      <td>0.820736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.067400</td>\n",
       "      <td>0.760767</td>\n",
       "      <td>0.814330</td>\n",
       "      <td>0.811065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.062000</td>\n",
       "      <td>0.754349</td>\n",
       "      <td>0.823053</td>\n",
       "      <td>0.820060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.869627</td>\n",
       "      <td>0.818069</td>\n",
       "      <td>0.816444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.039700</td>\n",
       "      <td>0.926285</td>\n",
       "      <td>0.824922</td>\n",
       "      <td>0.822047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.029200</td>\n",
       "      <td>0.866614</td>\n",
       "      <td>0.826791</td>\n",
       "      <td>0.823062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.019000</td>\n",
       "      <td>1.039395</td>\n",
       "      <td>0.829283</td>\n",
       "      <td>0.827759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.021900</td>\n",
       "      <td>1.120148</td>\n",
       "      <td>0.816199</td>\n",
       "      <td>0.815363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.020500</td>\n",
       "      <td>1.146435</td>\n",
       "      <td>0.819938</td>\n",
       "      <td>0.818785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.009800</td>\n",
       "      <td>1.247512</td>\n",
       "      <td>0.815576</td>\n",
       "      <td>0.814557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.019200</td>\n",
       "      <td>1.089592</td>\n",
       "      <td>0.821184</td>\n",
       "      <td>0.819297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>1.245649</td>\n",
       "      <td>0.818069</td>\n",
       "      <td>0.814869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>1.199076</td>\n",
       "      <td>0.821807</td>\n",
       "      <td>0.820537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.010700</td>\n",
       "      <td>1.299800</td>\n",
       "      <td>0.819938</td>\n",
       "      <td>0.819119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.008100</td>\n",
       "      <td>1.301710</td>\n",
       "      <td>0.821184</td>\n",
       "      <td>0.820003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.010900</td>\n",
       "      <td>1.317099</td>\n",
       "      <td>0.822430</td>\n",
       "      <td>0.821497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.009100</td>\n",
       "      <td>1.280203</td>\n",
       "      <td>0.829283</td>\n",
       "      <td>0.827718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.008700</td>\n",
       "      <td>1.298917</td>\n",
       "      <td>0.828037</td>\n",
       "      <td>0.826155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.011000</td>\n",
       "      <td>1.292566</td>\n",
       "      <td>0.829283</td>\n",
       "      <td>0.828208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.008700</td>\n",
       "      <td>1.321050</td>\n",
       "      <td>0.829907</td>\n",
       "      <td>0.828918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.006900</td>\n",
       "      <td>1.323057</td>\n",
       "      <td>0.829907</td>\n",
       "      <td>0.827836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.007700</td>\n",
       "      <td>1.336059</td>\n",
       "      <td>0.829907</td>\n",
       "      <td>0.827788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.008600</td>\n",
       "      <td>1.320352</td>\n",
       "      <td>0.833022</td>\n",
       "      <td>0.831367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>1.357012</td>\n",
       "      <td>0.823053</td>\n",
       "      <td>0.819758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.006200</td>\n",
       "      <td>1.346777</td>\n",
       "      <td>0.828660</td>\n",
       "      <td>0.826670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.006300</td>\n",
       "      <td>1.351622</td>\n",
       "      <td>0.833022</td>\n",
       "      <td>0.831609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.009100</td>\n",
       "      <td>1.371797</td>\n",
       "      <td>0.829907</td>\n",
       "      <td>0.828783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.009800</td>\n",
       "      <td>1.361989</td>\n",
       "      <td>0.826168</td>\n",
       "      <td>0.823954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1980</td>\n",
       "      <td>0.008200</td>\n",
       "      <td>1.352147</td>\n",
       "      <td>0.829907</td>\n",
       "      <td>0.827930</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorrBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at otmangi/MorrBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d54d865f64641bab9b9076fde2c301e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6419 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e05c5e8098334f99b8363fc8d00b7919",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1605 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2020' max='2020' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2020/2020 03:01, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.419800</td>\n",
       "      <td>0.378933</td>\n",
       "      <td>0.821184</td>\n",
       "      <td>0.819773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.332100</td>\n",
       "      <td>0.521284</td>\n",
       "      <td>0.819315</td>\n",
       "      <td>0.815004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.204800</td>\n",
       "      <td>0.410218</td>\n",
       "      <td>0.829283</td>\n",
       "      <td>0.828631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.140100</td>\n",
       "      <td>0.664158</td>\n",
       "      <td>0.811838</td>\n",
       "      <td>0.805975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.107200</td>\n",
       "      <td>0.601107</td>\n",
       "      <td>0.822430</td>\n",
       "      <td>0.820736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.067400</td>\n",
       "      <td>0.760767</td>\n",
       "      <td>0.814330</td>\n",
       "      <td>0.811065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.062000</td>\n",
       "      <td>0.754349</td>\n",
       "      <td>0.823053</td>\n",
       "      <td>0.820060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.869627</td>\n",
       "      <td>0.818069</td>\n",
       "      <td>0.816444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.039700</td>\n",
       "      <td>0.926285</td>\n",
       "      <td>0.824922</td>\n",
       "      <td>0.822047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.029200</td>\n",
       "      <td>0.866614</td>\n",
       "      <td>0.826791</td>\n",
       "      <td>0.823062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.019000</td>\n",
       "      <td>1.039395</td>\n",
       "      <td>0.829283</td>\n",
       "      <td>0.827759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.021900</td>\n",
       "      <td>1.120148</td>\n",
       "      <td>0.816199</td>\n",
       "      <td>0.815363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.020500</td>\n",
       "      <td>1.146435</td>\n",
       "      <td>0.819938</td>\n",
       "      <td>0.818785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.009800</td>\n",
       "      <td>1.247512</td>\n",
       "      <td>0.815576</td>\n",
       "      <td>0.814557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.019200</td>\n",
       "      <td>1.089592</td>\n",
       "      <td>0.821184</td>\n",
       "      <td>0.819297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>1.245649</td>\n",
       "      <td>0.818069</td>\n",
       "      <td>0.814869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>1.199076</td>\n",
       "      <td>0.821807</td>\n",
       "      <td>0.820537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.010700</td>\n",
       "      <td>1.299800</td>\n",
       "      <td>0.819938</td>\n",
       "      <td>0.819119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.008100</td>\n",
       "      <td>1.301710</td>\n",
       "      <td>0.821184</td>\n",
       "      <td>0.820003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.010900</td>\n",
       "      <td>1.317099</td>\n",
       "      <td>0.822430</td>\n",
       "      <td>0.821497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.009100</td>\n",
       "      <td>1.280203</td>\n",
       "      <td>0.829283</td>\n",
       "      <td>0.827718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.008700</td>\n",
       "      <td>1.298917</td>\n",
       "      <td>0.828037</td>\n",
       "      <td>0.826155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.011000</td>\n",
       "      <td>1.292566</td>\n",
       "      <td>0.829283</td>\n",
       "      <td>0.828208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.008700</td>\n",
       "      <td>1.321050</td>\n",
       "      <td>0.829907</td>\n",
       "      <td>0.828918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.006900</td>\n",
       "      <td>1.323057</td>\n",
       "      <td>0.829907</td>\n",
       "      <td>0.827836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.007700</td>\n",
       "      <td>1.336059</td>\n",
       "      <td>0.829907</td>\n",
       "      <td>0.827788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.008600</td>\n",
       "      <td>1.320352</td>\n",
       "      <td>0.833022</td>\n",
       "      <td>0.831367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>1.357012</td>\n",
       "      <td>0.823053</td>\n",
       "      <td>0.819758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.006200</td>\n",
       "      <td>1.346777</td>\n",
       "      <td>0.828660</td>\n",
       "      <td>0.826670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.006300</td>\n",
       "      <td>1.351622</td>\n",
       "      <td>0.833022</td>\n",
       "      <td>0.831609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.009100</td>\n",
       "      <td>1.371797</td>\n",
       "      <td>0.829907</td>\n",
       "      <td>0.828783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.009800</td>\n",
       "      <td>1.361989</td>\n",
       "      <td>0.826168</td>\n",
       "      <td>0.823954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1980</td>\n",
       "      <td>0.008200</td>\n",
       "      <td>1.352147</td>\n",
       "      <td>0.829907</td>\n",
       "      <td>0.827930</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorrBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at otmangi/MorrBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99962da5889a4ef88dbcfb361abaa732",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6419 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abc8bc349efd4e498d1b9698d1a42ee9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1605 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2020' max='2020' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2020/2020 03:01, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.419800</td>\n",
       "      <td>0.378933</td>\n",
       "      <td>0.821184</td>\n",
       "      <td>0.819773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.332100</td>\n",
       "      <td>0.521284</td>\n",
       "      <td>0.819315</td>\n",
       "      <td>0.815004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.204800</td>\n",
       "      <td>0.410218</td>\n",
       "      <td>0.829283</td>\n",
       "      <td>0.828631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.140100</td>\n",
       "      <td>0.664158</td>\n",
       "      <td>0.811838</td>\n",
       "      <td>0.805975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.107200</td>\n",
       "      <td>0.601107</td>\n",
       "      <td>0.822430</td>\n",
       "      <td>0.820736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.067400</td>\n",
       "      <td>0.760767</td>\n",
       "      <td>0.814330</td>\n",
       "      <td>0.811065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.062000</td>\n",
       "      <td>0.754349</td>\n",
       "      <td>0.823053</td>\n",
       "      <td>0.820060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.869627</td>\n",
       "      <td>0.818069</td>\n",
       "      <td>0.816444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.039700</td>\n",
       "      <td>0.926285</td>\n",
       "      <td>0.824922</td>\n",
       "      <td>0.822047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.029200</td>\n",
       "      <td>0.866614</td>\n",
       "      <td>0.826791</td>\n",
       "      <td>0.823062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.019000</td>\n",
       "      <td>1.039395</td>\n",
       "      <td>0.829283</td>\n",
       "      <td>0.827759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.021900</td>\n",
       "      <td>1.120148</td>\n",
       "      <td>0.816199</td>\n",
       "      <td>0.815363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.020500</td>\n",
       "      <td>1.146435</td>\n",
       "      <td>0.819938</td>\n",
       "      <td>0.818785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.009800</td>\n",
       "      <td>1.247512</td>\n",
       "      <td>0.815576</td>\n",
       "      <td>0.814557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.019200</td>\n",
       "      <td>1.089592</td>\n",
       "      <td>0.821184</td>\n",
       "      <td>0.819297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>1.245649</td>\n",
       "      <td>0.818069</td>\n",
       "      <td>0.814869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>1.199076</td>\n",
       "      <td>0.821807</td>\n",
       "      <td>0.820537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.010700</td>\n",
       "      <td>1.299800</td>\n",
       "      <td>0.819938</td>\n",
       "      <td>0.819119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.008100</td>\n",
       "      <td>1.301710</td>\n",
       "      <td>0.821184</td>\n",
       "      <td>0.820003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.010900</td>\n",
       "      <td>1.317099</td>\n",
       "      <td>0.822430</td>\n",
       "      <td>0.821497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.009100</td>\n",
       "      <td>1.280203</td>\n",
       "      <td>0.829283</td>\n",
       "      <td>0.827718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.008700</td>\n",
       "      <td>1.298917</td>\n",
       "      <td>0.828037</td>\n",
       "      <td>0.826155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.011000</td>\n",
       "      <td>1.292566</td>\n",
       "      <td>0.829283</td>\n",
       "      <td>0.828208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.008700</td>\n",
       "      <td>1.321050</td>\n",
       "      <td>0.829907</td>\n",
       "      <td>0.828918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.006900</td>\n",
       "      <td>1.323057</td>\n",
       "      <td>0.829907</td>\n",
       "      <td>0.827836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.007700</td>\n",
       "      <td>1.336059</td>\n",
       "      <td>0.829907</td>\n",
       "      <td>0.827788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.008600</td>\n",
       "      <td>1.320352</td>\n",
       "      <td>0.833022</td>\n",
       "      <td>0.831367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>1.357012</td>\n",
       "      <td>0.823053</td>\n",
       "      <td>0.819758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.006200</td>\n",
       "      <td>1.346777</td>\n",
       "      <td>0.828660</td>\n",
       "      <td>0.826670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.006300</td>\n",
       "      <td>1.351622</td>\n",
       "      <td>0.833022</td>\n",
       "      <td>0.831609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.009100</td>\n",
       "      <td>1.371797</td>\n",
       "      <td>0.829907</td>\n",
       "      <td>0.828783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.009800</td>\n",
       "      <td>1.361989</td>\n",
       "      <td>0.826168</td>\n",
       "      <td>0.823954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1980</td>\n",
       "      <td>0.008200</td>\n",
       "      <td>1.352147</td>\n",
       "      <td>0.829907</td>\n",
       "      <td>0.827930</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SI2M-Lab/DarijaBERT</td>\n",
       "      <td>0.858567</td>\n",
       "      <td>0.857287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alger-ia/dziribert</td>\n",
       "      <td>0.847352</td>\n",
       "      <td>0.846375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>faisalq/EgyBERT</td>\n",
       "      <td>0.849221</td>\n",
       "      <td>0.847727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>faisalq/SaudiBERT</td>\n",
       "      <td>0.857944</td>\n",
       "      <td>0.854611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>otmangi/MorRoBERTa</td>\n",
       "      <td>0.833645</td>\n",
       "      <td>0.831230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>otmangi/MorrBERT</td>\n",
       "      <td>0.833022</td>\n",
       "      <td>0.831609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>tunis-ai/TunBERT</td>\n",
       "      <td>0.652336</td>\n",
       "      <td>0.645493</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model  Accuracy        F1\n",
       "0   SI2M-Lab/DarijaBERT  0.858567  0.857287\n",
       "3    alger-ia/dziribert  0.847352  0.846375\n",
       "6       faisalq/EgyBERT  0.849221  0.847727\n",
       "8     faisalq/SaudiBERT  0.857944  0.854611\n",
       "11   otmangi/MorRoBERTa  0.833645  0.831230\n",
       "14     otmangi/MorrBERT  0.833022  0.831609\n",
       "17     tunis-ai/TunBERT  0.652336  0.645493"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" \n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import pyarabic.araby as araby\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.initializers import TruncatedNormal\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from datasets import load_dataset, Dataset, concatenate_datasets\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', 1000)\n",
    "\n",
    "fname = 'OMCD_2'\n",
    "log_file = fname + '.txt'\n",
    "\n",
    "with open(log_file, 'w') as f:\n",
    "    f.write('Model,Accuracy,F1\\n')\n",
    "\n",
    "\n",
    "df = pd.read_csv('datasets/OMCD/train.csv', encoding='utf-8', engine='python') #, quotechar=\"'\"  , quoting=3\n",
    "df_test = pd.read_csv('datasets/OMCD/test.csv', encoding='utf-8', engine='python') #, quotechar=\"'\"  , quoting=3\n",
    "\n",
    "\n",
    "      \n",
    "display(df.columns)\n",
    "display(df_test.columns)\n",
    "display(df[:4])\n",
    "\n",
    "\n",
    "\n",
    "classes = set(df['off'].values)\n",
    "display(classes)\n",
    "\n",
    "df['off'] = df['off'].astype('category')\n",
    "df['label'] = df['off'].cat.codes\n",
    "\n",
    "\n",
    "df_test['off'] = df_test['off'].astype('category')\n",
    "df_test['label'] = df_test['off'].cat.codes\n",
    "\n",
    "df = df[['comment', 'label']]\n",
    "df_test = df_test[['comment', 'label']]\n",
    "classes_num = len(classes)\n",
    "display(classes_num)\n",
    "display(len(df))\n",
    "display(len(df_test))\n",
    "\n",
    "\n",
    "ds_t = Dataset.from_pandas(df)\n",
    "ds_v = Dataset.from_pandas(df_test)\n",
    "\n",
    "display(ds_t)\n",
    "display(ds_v)\n",
    "\n",
    "max_sequence_length = 128\n",
    "\n",
    "\n",
    "models = [ \n",
    "        'faisalq/EgyBERT',            \n",
    "    'faisalq/SaudiBERT',            \n",
    "    'tunis-ai/TunBERT',\n",
    "    'alger-ia/dziribert',\n",
    "    'SI2M-Lab/DarijaBERT',\n",
    "    'otmangi/MorRoBERTa',\n",
    "    'otmangi/MorrBERT'\n",
    "            \n",
    "]\n",
    "\n",
    "\n",
    "for model_name in models:\n",
    "    for i in range(3):\n",
    "        print(f'{model_name}, try:{i}')\n",
    "              \n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(model_name,\n",
    "                                                              num_labels=classes_num).to('cuda')                                                 \n",
    "        dataset_train = ds_t\n",
    "        dataset_validation = ds_v                                                     \n",
    "        \n",
    "      \n",
    "\n",
    "        def preprocess_function(examples):\n",
    "            return tokenizer(examples['comment'], truncation=True, padding=\"max_length\",\n",
    "                            max_length=max_sequence_length)\n",
    "        \n",
    "        \n",
    "        dataset_train = dataset_train.map(preprocess_function, batched=True)\n",
    "        dataset_validation = dataset_validation.map(preprocess_function, batched=True)\n",
    "        \n",
    "       \n",
    "        \n",
    "        def compute_metrics(eval_pred):\n",
    "            logits, labels = eval_pred\n",
    "            predictions = np.argmax(logits, axis=-1)    \n",
    "            acc = accuracy_score(labels, predictions)        \n",
    "            f1 = f1_score(labels, predictions, average='macro')   \n",
    "            with open(log_file, 'a') as f:\n",
    "                f.write(f'{model_name},{acc},{f1}\\n')\n",
    "            return {'accuracy': acc, 'f1_score': f1}\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        epochs = 20\n",
    "        save_steps = 10000 #save checkpoint every 10000 steps\n",
    "        batch_size = 64\n",
    "        \n",
    "        training_args = TrainingArguments(\n",
    "            output_dir = 'bert/',\n",
    "            overwrite_output_dir=True,\n",
    "            num_train_epochs = epochs,\n",
    "            per_device_train_batch_size = batch_size,\n",
    "            per_device_eval_batch_size = batch_size,\n",
    "            save_steps = save_steps,\n",
    "            save_total_limit = 1, #only save the last 5 checkpoints\n",
    "            fp16=True,\n",
    "            learning_rate = 5e-5,  # 5e-5 is the default\n",
    "            logging_steps = 60, #50_000\n",
    "            evaluation_strategy = 'steps',\n",
    "            # evaluate_during_training = True,\n",
    "            eval_steps = 60\n",
    "            \n",
    "        )\n",
    "        \n",
    "        trainer = Trainer(\n",
    "            model = model,\n",
    "            args = training_args,\n",
    "            # data_collator=data_collator,\n",
    "            train_dataset=dataset_train,\n",
    "            eval_dataset=dataset_validation,\n",
    "            compute_metrics = compute_metrics\n",
    "        )\n",
    "        \n",
    "        \n",
    "        trainer.train()\n",
    "\n",
    "\n",
    "results = pd.read_csv(log_file)\n",
    "\n",
    "best_results = results.groupby('Model', as_index=False)['F1'].max()\n",
    "\n",
    "best_results = pd.merge(best_results, results, on=['Model', 'F1'])\n",
    "best_results = best_results[['Model', 'Accuracy', 'F1']]\n",
    "best_results = best_results.drop_duplicates()\n",
    "best_results.to_csv(f'{fname}.csv')\n",
    "display(best_results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a213ac86-934f-4e82-a949-0bcdcae2188d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220784d6-b06d-4429-adb8-0026654f9d49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8647cf08-3aa6-44eb-846f-4bed97554042",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e203fa6b-c9d7-44a4-b501-a67bfd3e4ce4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8794b705-31a1-45d7-8e88-4017a9c282aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
