{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d804ae66-9435-44be-8aad-beacbdeec0f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-18 20:11:13.035247: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-18 20:11:13.058838: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-18 20:11:13.442265: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2399"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['Tweet', 'Topic'], dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>برا وخيط: أمل بنكيران... مصممة تبتكر الزي المغربي التقليدي بلمسة عالمية</td>\n",
       "      <td>ميديا</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ربورتاج: قافلة توجيه مُتنقّلة تُطلع تلاميذ العيون على مختلف الآفاق الدراسية</td>\n",
       "      <td>مجتمع</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ساعة الفطور: طريقة تحضير «وراب» بالخضر وصلصة «تزاتزيكي »</td>\n",
       "      <td>ميديا</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ربورتاج: مائدة إفطار رمضانية تجمع الديانات الثلاث بالدار البيضاء</td>\n",
       "      <td>ثقافة</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                         Tweet   \n",
       "0      برا وخيط: أمل بنكيران... مصممة تبتكر الزي المغربي التقليدي بلمسة عالمية  \\\n",
       "1  ربورتاج: قافلة توجيه مُتنقّلة تُطلع تلاميذ العيون على مختلف الآفاق الدراسية   \n",
       "2                     ساعة الفطور: طريقة تحضير «وراب» بالخضر وصلصة «تزاتزيكي »   \n",
       "3             ربورتاج: مائدة إفطار رمضانية تجمع الديانات الثلاث بالدار البيضاء   \n",
       "\n",
       "   Topic  \n",
       "0  ميديا  \n",
       "1  مجتمع  \n",
       "2  ميديا  \n",
       "3  ثقافة  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Topic\n",
       "مجتمع     357\n",
       "رياضة     354\n",
       "ميديا     353\n",
       "دولي      348\n",
       "اقتصاد    344\n",
       "سياسة     333\n",
       "ثقافة     310\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'اقتصاد', 'ثقافة', 'دولي', 'رياضة', 'سياسة', 'مجتمع', 'ميديا'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2399"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Tweet', 'label'],\n",
       "        num_rows: 1919\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Tweet', 'label'],\n",
       "        num_rows: 480\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/EgyBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/EgyBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1919 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 00:56, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.925800</td>\n",
       "      <td>1.881989</td>\n",
       "      <td>0.587500</td>\n",
       "      <td>0.563767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.811400</td>\n",
       "      <td>1.727480</td>\n",
       "      <td>0.620833</td>\n",
       "      <td>0.599088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>1.637000</td>\n",
       "      <td>1.564990</td>\n",
       "      <td>0.689583</td>\n",
       "      <td>0.686443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.469600</td>\n",
       "      <td>1.437649</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.722898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>1.304200</td>\n",
       "      <td>1.318660</td>\n",
       "      <td>0.743750</td>\n",
       "      <td>0.745346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.170300</td>\n",
       "      <td>1.212885</td>\n",
       "      <td>0.772917</td>\n",
       "      <td>0.773906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>1.033000</td>\n",
       "      <td>1.126774</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.776824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.977600</td>\n",
       "      <td>1.146692</td>\n",
       "      <td>0.735417</td>\n",
       "      <td>0.734942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>1.006500</td>\n",
       "      <td>1.135166</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.726750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.930200</td>\n",
       "      <td>1.102590</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.973400</td>\n",
       "      <td>1.258616</td>\n",
       "      <td>0.639583</td>\n",
       "      <td>0.647307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.929500</td>\n",
       "      <td>1.067107</td>\n",
       "      <td>0.762500</td>\n",
       "      <td>0.762652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.817300</td>\n",
       "      <td>1.047000</td>\n",
       "      <td>0.754167</td>\n",
       "      <td>0.754815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.748600</td>\n",
       "      <td>0.995984</td>\n",
       "      <td>0.779167</td>\n",
       "      <td>0.781115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.714600</td>\n",
       "      <td>0.954077</td>\n",
       "      <td>0.787500</td>\n",
       "      <td>0.789543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.640800</td>\n",
       "      <td>0.928499</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.793222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.608000</td>\n",
       "      <td>0.876930</td>\n",
       "      <td>0.797917</td>\n",
       "      <td>0.800139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.540800</td>\n",
       "      <td>0.866377</td>\n",
       "      <td>0.787500</td>\n",
       "      <td>0.789366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.500700</td>\n",
       "      <td>0.844325</td>\n",
       "      <td>0.785417</td>\n",
       "      <td>0.787435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.470700</td>\n",
       "      <td>0.836393</td>\n",
       "      <td>0.795833</td>\n",
       "      <td>0.797203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.426700</td>\n",
       "      <td>0.838933</td>\n",
       "      <td>0.785417</td>\n",
       "      <td>0.786265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.412100</td>\n",
       "      <td>0.820053</td>\n",
       "      <td>0.793750</td>\n",
       "      <td>0.795492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.398500</td>\n",
       "      <td>0.816685</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.793072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.389500</td>\n",
       "      <td>0.815457</td>\n",
       "      <td>0.795833</td>\n",
       "      <td>0.797116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/EgyBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/EgyBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1919 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 00:57, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.927200</td>\n",
       "      <td>1.884115</td>\n",
       "      <td>0.629167</td>\n",
       "      <td>0.611806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.816800</td>\n",
       "      <td>1.738224</td>\n",
       "      <td>0.662500</td>\n",
       "      <td>0.648219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>1.643200</td>\n",
       "      <td>1.567737</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.733134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.455800</td>\n",
       "      <td>1.408400</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.783507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>1.260800</td>\n",
       "      <td>1.261198</td>\n",
       "      <td>0.785417</td>\n",
       "      <td>0.786499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.091600</td>\n",
       "      <td>1.137491</td>\n",
       "      <td>0.793750</td>\n",
       "      <td>0.795078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.933300</td>\n",
       "      <td>1.029167</td>\n",
       "      <td>0.814583</td>\n",
       "      <td>0.816468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.802700</td>\n",
       "      <td>0.957799</td>\n",
       "      <td>0.797917</td>\n",
       "      <td>0.798048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.685300</td>\n",
       "      <td>0.888444</td>\n",
       "      <td>0.814583</td>\n",
       "      <td>0.817979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.570200</td>\n",
       "      <td>0.836712</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.802127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.475800</td>\n",
       "      <td>0.795925</td>\n",
       "      <td>0.810417</td>\n",
       "      <td>0.811735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.406500</td>\n",
       "      <td>0.774990</td>\n",
       "      <td>0.808333</td>\n",
       "      <td>0.810427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.341500</td>\n",
       "      <td>0.756705</td>\n",
       "      <td>0.795833</td>\n",
       "      <td>0.796512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.286300</td>\n",
       "      <td>0.739645</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.813640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.245600</td>\n",
       "      <td>0.730607</td>\n",
       "      <td>0.820833</td>\n",
       "      <td>0.821820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.214500</td>\n",
       "      <td>0.721200</td>\n",
       "      <td>0.820833</td>\n",
       "      <td>0.822180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.206200</td>\n",
       "      <td>0.744521</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.175100</td>\n",
       "      <td>0.738767</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.817882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.166800</td>\n",
       "      <td>0.756598</td>\n",
       "      <td>0.804167</td>\n",
       "      <td>0.804980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.155200</td>\n",
       "      <td>0.749655</td>\n",
       "      <td>0.806250</td>\n",
       "      <td>0.808040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.145600</td>\n",
       "      <td>0.772764</td>\n",
       "      <td>0.806250</td>\n",
       "      <td>0.806724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.136200</td>\n",
       "      <td>0.752459</td>\n",
       "      <td>0.806250</td>\n",
       "      <td>0.806729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.136900</td>\n",
       "      <td>0.743120</td>\n",
       "      <td>0.818750</td>\n",
       "      <td>0.819832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.135900</td>\n",
       "      <td>0.742181</td>\n",
       "      <td>0.822917</td>\n",
       "      <td>0.823959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/EgyBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/EgyBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1919 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 00:57, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.927200</td>\n",
       "      <td>1.884115</td>\n",
       "      <td>0.629167</td>\n",
       "      <td>0.611806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.816800</td>\n",
       "      <td>1.738224</td>\n",
       "      <td>0.662500</td>\n",
       "      <td>0.648219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>1.643200</td>\n",
       "      <td>1.567737</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.733134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.455800</td>\n",
       "      <td>1.408400</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.783507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>1.260800</td>\n",
       "      <td>1.261198</td>\n",
       "      <td>0.785417</td>\n",
       "      <td>0.786499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.091600</td>\n",
       "      <td>1.137491</td>\n",
       "      <td>0.793750</td>\n",
       "      <td>0.795078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.933300</td>\n",
       "      <td>1.029167</td>\n",
       "      <td>0.814583</td>\n",
       "      <td>0.816468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.802700</td>\n",
       "      <td>0.957799</td>\n",
       "      <td>0.797917</td>\n",
       "      <td>0.798048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.685300</td>\n",
       "      <td>0.888444</td>\n",
       "      <td>0.814583</td>\n",
       "      <td>0.817979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.570200</td>\n",
       "      <td>0.836712</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.802127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.475800</td>\n",
       "      <td>0.795925</td>\n",
       "      <td>0.810417</td>\n",
       "      <td>0.811735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.406500</td>\n",
       "      <td>0.774990</td>\n",
       "      <td>0.808333</td>\n",
       "      <td>0.810427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.341500</td>\n",
       "      <td>0.756705</td>\n",
       "      <td>0.795833</td>\n",
       "      <td>0.796512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.286300</td>\n",
       "      <td>0.739645</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.813640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.245600</td>\n",
       "      <td>0.730607</td>\n",
       "      <td>0.820833</td>\n",
       "      <td>0.821820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.214500</td>\n",
       "      <td>0.721200</td>\n",
       "      <td>0.820833</td>\n",
       "      <td>0.822180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.206200</td>\n",
       "      <td>0.744521</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.175100</td>\n",
       "      <td>0.738767</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.817882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.166800</td>\n",
       "      <td>0.756598</td>\n",
       "      <td>0.804167</td>\n",
       "      <td>0.804980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.155200</td>\n",
       "      <td>0.749655</td>\n",
       "      <td>0.806250</td>\n",
       "      <td>0.808040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.145600</td>\n",
       "      <td>0.772764</td>\n",
       "      <td>0.806250</td>\n",
       "      <td>0.806724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.136200</td>\n",
       "      <td>0.752459</td>\n",
       "      <td>0.806250</td>\n",
       "      <td>0.806729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.136900</td>\n",
       "      <td>0.743120</td>\n",
       "      <td>0.818750</td>\n",
       "      <td>0.819832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.135900</td>\n",
       "      <td>0.742181</td>\n",
       "      <td>0.822917</td>\n",
       "      <td>0.823959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/EgyBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/EgyBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1919 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 00:57, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.924600</td>\n",
       "      <td>1.875118</td>\n",
       "      <td>0.604167</td>\n",
       "      <td>0.575431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.814600</td>\n",
       "      <td>1.724536</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.666085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>1.634500</td>\n",
       "      <td>1.548578</td>\n",
       "      <td>0.737500</td>\n",
       "      <td>0.732003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.459500</td>\n",
       "      <td>1.404138</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.745263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>1.291800</td>\n",
       "      <td>1.274400</td>\n",
       "      <td>0.787500</td>\n",
       "      <td>0.784326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.121100</td>\n",
       "      <td>1.136107</td>\n",
       "      <td>0.802083</td>\n",
       "      <td>0.800196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.962500</td>\n",
       "      <td>1.044891</td>\n",
       "      <td>0.793750</td>\n",
       "      <td>0.792819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.828500</td>\n",
       "      <td>0.954754</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.790923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.689400</td>\n",
       "      <td>0.891586</td>\n",
       "      <td>0.802083</td>\n",
       "      <td>0.801597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.596300</td>\n",
       "      <td>0.830267</td>\n",
       "      <td>0.795833</td>\n",
       "      <td>0.796548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.493300</td>\n",
       "      <td>0.798365</td>\n",
       "      <td>0.797917</td>\n",
       "      <td>0.797008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.409000</td>\n",
       "      <td>0.792219</td>\n",
       "      <td>0.779167</td>\n",
       "      <td>0.779030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.337500</td>\n",
       "      <td>0.760667</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.791780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.284000</td>\n",
       "      <td>0.739517</td>\n",
       "      <td>0.804167</td>\n",
       "      <td>0.803960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.255400</td>\n",
       "      <td>0.747111</td>\n",
       "      <td>0.797917</td>\n",
       "      <td>0.797023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.219300</td>\n",
       "      <td>0.753289</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.791179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.207100</td>\n",
       "      <td>0.739434</td>\n",
       "      <td>0.795833</td>\n",
       "      <td>0.795345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.178700</td>\n",
       "      <td>0.770809</td>\n",
       "      <td>0.793750</td>\n",
       "      <td>0.795574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.172000</td>\n",
       "      <td>0.744602</td>\n",
       "      <td>0.804167</td>\n",
       "      <td>0.803462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.164200</td>\n",
       "      <td>0.766407</td>\n",
       "      <td>0.797917</td>\n",
       "      <td>0.798264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.142600</td>\n",
       "      <td>0.768603</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.798046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.142100</td>\n",
       "      <td>0.775484</td>\n",
       "      <td>0.797917</td>\n",
       "      <td>0.796658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.135900</td>\n",
       "      <td>0.780515</td>\n",
       "      <td>0.797917</td>\n",
       "      <td>0.796583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.138100</td>\n",
       "      <td>0.780719</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.798511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/EgyBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/EgyBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1919 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 00:56, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.924600</td>\n",
       "      <td>1.875118</td>\n",
       "      <td>0.604167</td>\n",
       "      <td>0.575431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.814600</td>\n",
       "      <td>1.724536</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.666085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>1.634500</td>\n",
       "      <td>1.548578</td>\n",
       "      <td>0.737500</td>\n",
       "      <td>0.732003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.459500</td>\n",
       "      <td>1.404138</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.745263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>1.291800</td>\n",
       "      <td>1.274400</td>\n",
       "      <td>0.787500</td>\n",
       "      <td>0.784326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.121100</td>\n",
       "      <td>1.136107</td>\n",
       "      <td>0.802083</td>\n",
       "      <td>0.800196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.962500</td>\n",
       "      <td>1.044891</td>\n",
       "      <td>0.793750</td>\n",
       "      <td>0.792819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.828500</td>\n",
       "      <td>0.954754</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.790923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.689400</td>\n",
       "      <td>0.891586</td>\n",
       "      <td>0.802083</td>\n",
       "      <td>0.801597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.596300</td>\n",
       "      <td>0.830267</td>\n",
       "      <td>0.795833</td>\n",
       "      <td>0.796548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.493300</td>\n",
       "      <td>0.798365</td>\n",
       "      <td>0.797917</td>\n",
       "      <td>0.797008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.409000</td>\n",
       "      <td>0.792219</td>\n",
       "      <td>0.779167</td>\n",
       "      <td>0.779030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.337500</td>\n",
       "      <td>0.760667</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.791780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.284000</td>\n",
       "      <td>0.739517</td>\n",
       "      <td>0.804167</td>\n",
       "      <td>0.803960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.255400</td>\n",
       "      <td>0.747111</td>\n",
       "      <td>0.797917</td>\n",
       "      <td>0.797023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.219300</td>\n",
       "      <td>0.753289</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.791179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.207100</td>\n",
       "      <td>0.739434</td>\n",
       "      <td>0.795833</td>\n",
       "      <td>0.795345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.178700</td>\n",
       "      <td>0.770809</td>\n",
       "      <td>0.793750</td>\n",
       "      <td>0.795574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.172000</td>\n",
       "      <td>0.744602</td>\n",
       "      <td>0.804167</td>\n",
       "      <td>0.803462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.164200</td>\n",
       "      <td>0.766407</td>\n",
       "      <td>0.797917</td>\n",
       "      <td>0.798264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.142600</td>\n",
       "      <td>0.768603</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.798046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.142100</td>\n",
       "      <td>0.775484</td>\n",
       "      <td>0.797917</td>\n",
       "      <td>0.796658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.135900</td>\n",
       "      <td>0.780515</td>\n",
       "      <td>0.797917</td>\n",
       "      <td>0.796583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.138100</td>\n",
       "      <td>0.780719</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.798511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/EgyBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/EgyBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1919 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 00:56, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.924600</td>\n",
       "      <td>1.875118</td>\n",
       "      <td>0.604167</td>\n",
       "      <td>0.575431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.814600</td>\n",
       "      <td>1.724536</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.666085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>1.634500</td>\n",
       "      <td>1.548578</td>\n",
       "      <td>0.737500</td>\n",
       "      <td>0.732003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.459500</td>\n",
       "      <td>1.404138</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.745263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>1.291800</td>\n",
       "      <td>1.274400</td>\n",
       "      <td>0.787500</td>\n",
       "      <td>0.784326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.121100</td>\n",
       "      <td>1.136107</td>\n",
       "      <td>0.802083</td>\n",
       "      <td>0.800196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.962500</td>\n",
       "      <td>1.044891</td>\n",
       "      <td>0.793750</td>\n",
       "      <td>0.792819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.828500</td>\n",
       "      <td>0.954754</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.790923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.689400</td>\n",
       "      <td>0.891586</td>\n",
       "      <td>0.802083</td>\n",
       "      <td>0.801597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.596300</td>\n",
       "      <td>0.830267</td>\n",
       "      <td>0.795833</td>\n",
       "      <td>0.796548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.493300</td>\n",
       "      <td>0.798365</td>\n",
       "      <td>0.797917</td>\n",
       "      <td>0.797008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.409000</td>\n",
       "      <td>0.792219</td>\n",
       "      <td>0.779167</td>\n",
       "      <td>0.779030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.337500</td>\n",
       "      <td>0.760667</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.791780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.284000</td>\n",
       "      <td>0.739517</td>\n",
       "      <td>0.804167</td>\n",
       "      <td>0.803960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.255400</td>\n",
       "      <td>0.747111</td>\n",
       "      <td>0.797917</td>\n",
       "      <td>0.797023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.219300</td>\n",
       "      <td>0.753289</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.791179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.207100</td>\n",
       "      <td>0.739434</td>\n",
       "      <td>0.795833</td>\n",
       "      <td>0.795345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.178700</td>\n",
       "      <td>0.770809</td>\n",
       "      <td>0.793750</td>\n",
       "      <td>0.795574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.172000</td>\n",
       "      <td>0.744602</td>\n",
       "      <td>0.804167</td>\n",
       "      <td>0.803462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.164200</td>\n",
       "      <td>0.766407</td>\n",
       "      <td>0.797917</td>\n",
       "      <td>0.798264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.142600</td>\n",
       "      <td>0.768603</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.798046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.142100</td>\n",
       "      <td>0.775484</td>\n",
       "      <td>0.797917</td>\n",
       "      <td>0.796658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.135900</td>\n",
       "      <td>0.780515</td>\n",
       "      <td>0.797917</td>\n",
       "      <td>0.796583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.138100</td>\n",
       "      <td>0.780719</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.798511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/EgyBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/EgyBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1919 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 00:56, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.927500</td>\n",
       "      <td>1.881628</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.670868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.817900</td>\n",
       "      <td>1.733034</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.679777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>1.645200</td>\n",
       "      <td>1.573261</td>\n",
       "      <td>0.714583</td>\n",
       "      <td>0.715108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.451600</td>\n",
       "      <td>1.405772</td>\n",
       "      <td>0.743750</td>\n",
       "      <td>0.746564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>1.272300</td>\n",
       "      <td>1.282484</td>\n",
       "      <td>0.764583</td>\n",
       "      <td>0.767075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.098600</td>\n",
       "      <td>1.151927</td>\n",
       "      <td>0.802083</td>\n",
       "      <td>0.806143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.944800</td>\n",
       "      <td>1.053997</td>\n",
       "      <td>0.787500</td>\n",
       "      <td>0.790027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.814100</td>\n",
       "      <td>0.984882</td>\n",
       "      <td>0.785417</td>\n",
       "      <td>0.782946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.690100</td>\n",
       "      <td>0.905348</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.801868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.582000</td>\n",
       "      <td>0.876862</td>\n",
       "      <td>0.789583</td>\n",
       "      <td>0.791549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.503400</td>\n",
       "      <td>0.850435</td>\n",
       "      <td>0.789583</td>\n",
       "      <td>0.790867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.422700</td>\n",
       "      <td>0.849535</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.774025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.366300</td>\n",
       "      <td>0.836516</td>\n",
       "      <td>0.777083</td>\n",
       "      <td>0.781559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.310300</td>\n",
       "      <td>0.807302</td>\n",
       "      <td>0.777083</td>\n",
       "      <td>0.777934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.267000</td>\n",
       "      <td>0.799302</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.786309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.239400</td>\n",
       "      <td>0.816312</td>\n",
       "      <td>0.777083</td>\n",
       "      <td>0.778182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.203900</td>\n",
       "      <td>0.813549</td>\n",
       "      <td>0.785417</td>\n",
       "      <td>0.788776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.196200</td>\n",
       "      <td>0.825871</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>0.783200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.171200</td>\n",
       "      <td>0.836946</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.787115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.865595</td>\n",
       "      <td>0.760417</td>\n",
       "      <td>0.762952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.865769</td>\n",
       "      <td>0.772917</td>\n",
       "      <td>0.774140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.145300</td>\n",
       "      <td>0.837328</td>\n",
       "      <td>0.785417</td>\n",
       "      <td>0.787774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.140300</td>\n",
       "      <td>0.830602</td>\n",
       "      <td>0.787500</td>\n",
       "      <td>0.790632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.134800</td>\n",
       "      <td>0.830397</td>\n",
       "      <td>0.785417</td>\n",
       "      <td>0.789221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/EgyBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/EgyBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1919 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 00:57, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.927500</td>\n",
       "      <td>1.881628</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.670868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.817900</td>\n",
       "      <td>1.733034</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.679777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>1.645200</td>\n",
       "      <td>1.573261</td>\n",
       "      <td>0.714583</td>\n",
       "      <td>0.715108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.451600</td>\n",
       "      <td>1.405772</td>\n",
       "      <td>0.743750</td>\n",
       "      <td>0.746564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>1.272300</td>\n",
       "      <td>1.282484</td>\n",
       "      <td>0.764583</td>\n",
       "      <td>0.767075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.098600</td>\n",
       "      <td>1.151927</td>\n",
       "      <td>0.802083</td>\n",
       "      <td>0.806143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.944800</td>\n",
       "      <td>1.053997</td>\n",
       "      <td>0.787500</td>\n",
       "      <td>0.790027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.814100</td>\n",
       "      <td>0.984882</td>\n",
       "      <td>0.785417</td>\n",
       "      <td>0.782946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.690100</td>\n",
       "      <td>0.905348</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.801868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.582000</td>\n",
       "      <td>0.876862</td>\n",
       "      <td>0.789583</td>\n",
       "      <td>0.791549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.503400</td>\n",
       "      <td>0.850435</td>\n",
       "      <td>0.789583</td>\n",
       "      <td>0.790867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.422700</td>\n",
       "      <td>0.849535</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.774025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.366300</td>\n",
       "      <td>0.836516</td>\n",
       "      <td>0.777083</td>\n",
       "      <td>0.781559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.310300</td>\n",
       "      <td>0.807302</td>\n",
       "      <td>0.777083</td>\n",
       "      <td>0.777934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.267000</td>\n",
       "      <td>0.799302</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.786309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.239400</td>\n",
       "      <td>0.816312</td>\n",
       "      <td>0.777083</td>\n",
       "      <td>0.778182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.203900</td>\n",
       "      <td>0.813549</td>\n",
       "      <td>0.785417</td>\n",
       "      <td>0.788776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.196200</td>\n",
       "      <td>0.825871</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>0.783200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.171200</td>\n",
       "      <td>0.836946</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.787115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.865595</td>\n",
       "      <td>0.760417</td>\n",
       "      <td>0.762952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.865769</td>\n",
       "      <td>0.772917</td>\n",
       "      <td>0.774140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.145300</td>\n",
       "      <td>0.837328</td>\n",
       "      <td>0.785417</td>\n",
       "      <td>0.787774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.140300</td>\n",
       "      <td>0.830602</td>\n",
       "      <td>0.787500</td>\n",
       "      <td>0.790632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.134800</td>\n",
       "      <td>0.830397</td>\n",
       "      <td>0.785417</td>\n",
       "      <td>0.789221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/EgyBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/EgyBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3227b7370374f1898c7ce791751d023",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1919 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60f7c9fcde7047e380a943b84606e488",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 00:56, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.927500</td>\n",
       "      <td>1.881628</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.670868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.817900</td>\n",
       "      <td>1.733034</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.679777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>1.645200</td>\n",
       "      <td>1.573261</td>\n",
       "      <td>0.714583</td>\n",
       "      <td>0.715108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.451600</td>\n",
       "      <td>1.405772</td>\n",
       "      <td>0.743750</td>\n",
       "      <td>0.746564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>1.272300</td>\n",
       "      <td>1.282484</td>\n",
       "      <td>0.764583</td>\n",
       "      <td>0.767075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.098600</td>\n",
       "      <td>1.151927</td>\n",
       "      <td>0.802083</td>\n",
       "      <td>0.806143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.944800</td>\n",
       "      <td>1.053997</td>\n",
       "      <td>0.787500</td>\n",
       "      <td>0.790027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.814100</td>\n",
       "      <td>0.984882</td>\n",
       "      <td>0.785417</td>\n",
       "      <td>0.782946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.690100</td>\n",
       "      <td>0.905348</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.801868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.582000</td>\n",
       "      <td>0.876862</td>\n",
       "      <td>0.789583</td>\n",
       "      <td>0.791549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.503400</td>\n",
       "      <td>0.850435</td>\n",
       "      <td>0.789583</td>\n",
       "      <td>0.790867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.422700</td>\n",
       "      <td>0.849535</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.774025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.366300</td>\n",
       "      <td>0.836516</td>\n",
       "      <td>0.777083</td>\n",
       "      <td>0.781559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.310300</td>\n",
       "      <td>0.807302</td>\n",
       "      <td>0.777083</td>\n",
       "      <td>0.777934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.267000</td>\n",
       "      <td>0.799302</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.786309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.239400</td>\n",
       "      <td>0.816312</td>\n",
       "      <td>0.777083</td>\n",
       "      <td>0.778182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.203900</td>\n",
       "      <td>0.813549</td>\n",
       "      <td>0.785417</td>\n",
       "      <td>0.788776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.196200</td>\n",
       "      <td>0.825871</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>0.783200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.171200</td>\n",
       "      <td>0.836946</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.787115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.865595</td>\n",
       "      <td>0.760417</td>\n",
       "      <td>0.762952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.865769</td>\n",
       "      <td>0.772917</td>\n",
       "      <td>0.774140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.145300</td>\n",
       "      <td>0.837328</td>\n",
       "      <td>0.785417</td>\n",
       "      <td>0.787774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.140300</td>\n",
       "      <td>0.830602</td>\n",
       "      <td>0.787500</td>\n",
       "      <td>0.790632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.134800</td>\n",
       "      <td>0.830397</td>\n",
       "      <td>0.785417</td>\n",
       "      <td>0.789221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Tweet', 'label'],\n",
       "        num_rows: 1919\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Tweet', 'label'],\n",
       "        num_rows: 480\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66fbea0007df4bd3b5c11cacdfed6726",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1919 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e339b0e31124a03b22a2a76d7736778",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 00:56, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.277200</td>\n",
       "      <td>0.789792</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>0.740925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.520300</td>\n",
       "      <td>0.652472</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.804480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.309800</td>\n",
       "      <td>0.698779</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.786507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.166400</td>\n",
       "      <td>0.743144</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>0.780418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.107900</td>\n",
       "      <td>0.792529</td>\n",
       "      <td>0.789583</td>\n",
       "      <td>0.791088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.045200</td>\n",
       "      <td>0.939097</td>\n",
       "      <td>0.785417</td>\n",
       "      <td>0.786656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.038000</td>\n",
       "      <td>0.953261</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.801241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.020700</td>\n",
       "      <td>1.054096</td>\n",
       "      <td>0.789583</td>\n",
       "      <td>0.790077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.015600</td>\n",
       "      <td>1.059727</td>\n",
       "      <td>0.793750</td>\n",
       "      <td>0.795547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.013400</td>\n",
       "      <td>1.118329</td>\n",
       "      <td>0.795833</td>\n",
       "      <td>0.800460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.014900</td>\n",
       "      <td>1.182540</td>\n",
       "      <td>0.779167</td>\n",
       "      <td>0.778558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.007300</td>\n",
       "      <td>1.108539</td>\n",
       "      <td>0.808333</td>\n",
       "      <td>0.811924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.006500</td>\n",
       "      <td>1.188970</td>\n",
       "      <td>0.795833</td>\n",
       "      <td>0.795190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.151284</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.801331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>1.164921</td>\n",
       "      <td>0.808333</td>\n",
       "      <td>0.809340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>1.179023</td>\n",
       "      <td>0.806250</td>\n",
       "      <td>0.807400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.182545</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>1.182125</td>\n",
       "      <td>0.804167</td>\n",
       "      <td>0.805099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>1.188959</td>\n",
       "      <td>0.804167</td>\n",
       "      <td>0.805281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.185859</td>\n",
       "      <td>0.808333</td>\n",
       "      <td>0.809747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>1.197662</td>\n",
       "      <td>0.808333</td>\n",
       "      <td>0.809240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>1.201835</td>\n",
       "      <td>0.806250</td>\n",
       "      <td>0.807267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>1.204443</td>\n",
       "      <td>0.802083</td>\n",
       "      <td>0.803275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>1.205297</td>\n",
       "      <td>0.802083</td>\n",
       "      <td>0.803275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18e4a60dc93c463cb391a166a6759495",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1919 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "303ebd41ff884450859cb08b94543779",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 00:56, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.277200</td>\n",
       "      <td>0.789792</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>0.740925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.520300</td>\n",
       "      <td>0.652472</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.804480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.309800</td>\n",
       "      <td>0.698779</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.786507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.166400</td>\n",
       "      <td>0.743144</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>0.780418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.107900</td>\n",
       "      <td>0.792529</td>\n",
       "      <td>0.789583</td>\n",
       "      <td>0.791088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.045200</td>\n",
       "      <td>0.939097</td>\n",
       "      <td>0.785417</td>\n",
       "      <td>0.786656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.038000</td>\n",
       "      <td>0.953261</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.801241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.020700</td>\n",
       "      <td>1.054096</td>\n",
       "      <td>0.789583</td>\n",
       "      <td>0.790077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.015600</td>\n",
       "      <td>1.059727</td>\n",
       "      <td>0.793750</td>\n",
       "      <td>0.795547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.013400</td>\n",
       "      <td>1.118329</td>\n",
       "      <td>0.795833</td>\n",
       "      <td>0.800460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.014900</td>\n",
       "      <td>1.182540</td>\n",
       "      <td>0.779167</td>\n",
       "      <td>0.778558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.007300</td>\n",
       "      <td>1.108539</td>\n",
       "      <td>0.808333</td>\n",
       "      <td>0.811924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.006500</td>\n",
       "      <td>1.188970</td>\n",
       "      <td>0.795833</td>\n",
       "      <td>0.795190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.151284</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.801331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>1.164921</td>\n",
       "      <td>0.808333</td>\n",
       "      <td>0.809340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>1.179023</td>\n",
       "      <td>0.806250</td>\n",
       "      <td>0.807400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.182545</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>1.182125</td>\n",
       "      <td>0.804167</td>\n",
       "      <td>0.805099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>1.188959</td>\n",
       "      <td>0.804167</td>\n",
       "      <td>0.805281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.185859</td>\n",
       "      <td>0.808333</td>\n",
       "      <td>0.809747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>1.197662</td>\n",
       "      <td>0.808333</td>\n",
       "      <td>0.809240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>1.201835</td>\n",
       "      <td>0.806250</td>\n",
       "      <td>0.807267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>1.204443</td>\n",
       "      <td>0.802083</td>\n",
       "      <td>0.803275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>1.205297</td>\n",
       "      <td>0.802083</td>\n",
       "      <td>0.803275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a46c0aaaca064f3b84f02d48696477c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1919 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff182e11424045d18d1205f087bc5900",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 00:56, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.277200</td>\n",
       "      <td>0.789792</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>0.740925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.520300</td>\n",
       "      <td>0.652472</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.804480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.309800</td>\n",
       "      <td>0.698779</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.786507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.166400</td>\n",
       "      <td>0.743144</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>0.780418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.107900</td>\n",
       "      <td>0.792529</td>\n",
       "      <td>0.789583</td>\n",
       "      <td>0.791088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.045200</td>\n",
       "      <td>0.939097</td>\n",
       "      <td>0.785417</td>\n",
       "      <td>0.786656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.038000</td>\n",
       "      <td>0.953261</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.801241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.020700</td>\n",
       "      <td>1.054096</td>\n",
       "      <td>0.789583</td>\n",
       "      <td>0.790077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.015600</td>\n",
       "      <td>1.059727</td>\n",
       "      <td>0.793750</td>\n",
       "      <td>0.795547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.013400</td>\n",
       "      <td>1.118329</td>\n",
       "      <td>0.795833</td>\n",
       "      <td>0.800460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.014900</td>\n",
       "      <td>1.182540</td>\n",
       "      <td>0.779167</td>\n",
       "      <td>0.778558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.007300</td>\n",
       "      <td>1.108539</td>\n",
       "      <td>0.808333</td>\n",
       "      <td>0.811924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.006500</td>\n",
       "      <td>1.188970</td>\n",
       "      <td>0.795833</td>\n",
       "      <td>0.795190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.151284</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.801331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>1.164921</td>\n",
       "      <td>0.808333</td>\n",
       "      <td>0.809340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>1.179023</td>\n",
       "      <td>0.806250</td>\n",
       "      <td>0.807400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.182545</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>1.182125</td>\n",
       "      <td>0.804167</td>\n",
       "      <td>0.805099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>1.188959</td>\n",
       "      <td>0.804167</td>\n",
       "      <td>0.805281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.185859</td>\n",
       "      <td>0.808333</td>\n",
       "      <td>0.809747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>1.197662</td>\n",
       "      <td>0.808333</td>\n",
       "      <td>0.809240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>1.201835</td>\n",
       "      <td>0.806250</td>\n",
       "      <td>0.807267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>1.204443</td>\n",
       "      <td>0.802083</td>\n",
       "      <td>0.803275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>1.205297</td>\n",
       "      <td>0.802083</td>\n",
       "      <td>0.803275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df1341be23254b59950db2e79b1562da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1919 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64a8203a3239497da3faa05de52ecf3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 00:56, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.322500</td>\n",
       "      <td>0.807567</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>0.730532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.614400</td>\n",
       "      <td>0.587967</td>\n",
       "      <td>0.797917</td>\n",
       "      <td>0.795685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.313500</td>\n",
       "      <td>0.601423</td>\n",
       "      <td>0.818750</td>\n",
       "      <td>0.818793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.202800</td>\n",
       "      <td>0.596602</td>\n",
       "      <td>0.827083</td>\n",
       "      <td>0.826289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.116400</td>\n",
       "      <td>0.660253</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.816386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.061600</td>\n",
       "      <td>0.787425</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.812607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.035100</td>\n",
       "      <td>0.848969</td>\n",
       "      <td>0.808333</td>\n",
       "      <td>0.805090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.027500</td>\n",
       "      <td>0.805845</td>\n",
       "      <td>0.835417</td>\n",
       "      <td>0.834487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.018000</td>\n",
       "      <td>0.921561</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.811506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.016300</td>\n",
       "      <td>1.016644</td>\n",
       "      <td>0.802083</td>\n",
       "      <td>0.798480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.010400</td>\n",
       "      <td>0.914860</td>\n",
       "      <td>0.827083</td>\n",
       "      <td>0.824234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.007200</td>\n",
       "      <td>1.034791</td>\n",
       "      <td>0.806250</td>\n",
       "      <td>0.806419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.010400</td>\n",
       "      <td>1.017941</td>\n",
       "      <td>0.827083</td>\n",
       "      <td>0.822880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>1.004770</td>\n",
       "      <td>0.820833</td>\n",
       "      <td>0.817732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>1.054105</td>\n",
       "      <td>0.814583</td>\n",
       "      <td>0.812296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>1.039051</td>\n",
       "      <td>0.820833</td>\n",
       "      <td>0.818004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>1.051416</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>0.821775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>1.080598</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.813611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>1.086568</td>\n",
       "      <td>0.818750</td>\n",
       "      <td>0.815835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>1.098721</td>\n",
       "      <td>0.820833</td>\n",
       "      <td>0.817917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.079935</td>\n",
       "      <td>0.822917</td>\n",
       "      <td>0.820494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>1.073906</td>\n",
       "      <td>0.822917</td>\n",
       "      <td>0.820160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>1.073781</td>\n",
       "      <td>0.820833</td>\n",
       "      <td>0.817862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>1.074285</td>\n",
       "      <td>0.820833</td>\n",
       "      <td>0.817862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20b05af0806a4783b8ce020ca0259b41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1919 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e447455014b458382aacead58d9b6dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 00:56, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.322500</td>\n",
       "      <td>0.807567</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>0.730532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.614400</td>\n",
       "      <td>0.587967</td>\n",
       "      <td>0.797917</td>\n",
       "      <td>0.795685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.313500</td>\n",
       "      <td>0.601423</td>\n",
       "      <td>0.818750</td>\n",
       "      <td>0.818793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.202800</td>\n",
       "      <td>0.596602</td>\n",
       "      <td>0.827083</td>\n",
       "      <td>0.826289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.116400</td>\n",
       "      <td>0.660253</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.816386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.061600</td>\n",
       "      <td>0.787425</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.812607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.035100</td>\n",
       "      <td>0.848969</td>\n",
       "      <td>0.808333</td>\n",
       "      <td>0.805090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.027500</td>\n",
       "      <td>0.805845</td>\n",
       "      <td>0.835417</td>\n",
       "      <td>0.834487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.018000</td>\n",
       "      <td>0.921561</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.811506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.016300</td>\n",
       "      <td>1.016644</td>\n",
       "      <td>0.802083</td>\n",
       "      <td>0.798480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.010400</td>\n",
       "      <td>0.914860</td>\n",
       "      <td>0.827083</td>\n",
       "      <td>0.824234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.007200</td>\n",
       "      <td>1.034791</td>\n",
       "      <td>0.806250</td>\n",
       "      <td>0.806419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.010400</td>\n",
       "      <td>1.017941</td>\n",
       "      <td>0.827083</td>\n",
       "      <td>0.822880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>1.004770</td>\n",
       "      <td>0.820833</td>\n",
       "      <td>0.817732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>1.054105</td>\n",
       "      <td>0.814583</td>\n",
       "      <td>0.812296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>1.039051</td>\n",
       "      <td>0.820833</td>\n",
       "      <td>0.818004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>1.051416</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>0.821775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>1.080598</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.813611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>1.086568</td>\n",
       "      <td>0.818750</td>\n",
       "      <td>0.815835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>1.098721</td>\n",
       "      <td>0.820833</td>\n",
       "      <td>0.817917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.079935</td>\n",
       "      <td>0.822917</td>\n",
       "      <td>0.820494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>1.073906</td>\n",
       "      <td>0.822917</td>\n",
       "      <td>0.820160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>1.073781</td>\n",
       "      <td>0.820833</td>\n",
       "      <td>0.817862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>1.074285</td>\n",
       "      <td>0.820833</td>\n",
       "      <td>0.817862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4abd6a351622427fb67c788acee2697e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1919 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a113d46747a54336845296d5cff63a8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 00:56, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.322500</td>\n",
       "      <td>0.807567</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>0.730532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.614400</td>\n",
       "      <td>0.587967</td>\n",
       "      <td>0.797917</td>\n",
       "      <td>0.795685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.313500</td>\n",
       "      <td>0.601423</td>\n",
       "      <td>0.818750</td>\n",
       "      <td>0.818793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.202800</td>\n",
       "      <td>0.596602</td>\n",
       "      <td>0.827083</td>\n",
       "      <td>0.826289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.116400</td>\n",
       "      <td>0.660253</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.816386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.061600</td>\n",
       "      <td>0.787425</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.812607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.035100</td>\n",
       "      <td>0.848969</td>\n",
       "      <td>0.808333</td>\n",
       "      <td>0.805090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.027500</td>\n",
       "      <td>0.805845</td>\n",
       "      <td>0.835417</td>\n",
       "      <td>0.834487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.018000</td>\n",
       "      <td>0.921561</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.811506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.016300</td>\n",
       "      <td>1.016644</td>\n",
       "      <td>0.802083</td>\n",
       "      <td>0.798480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.010400</td>\n",
       "      <td>0.914860</td>\n",
       "      <td>0.827083</td>\n",
       "      <td>0.824234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.007200</td>\n",
       "      <td>1.034791</td>\n",
       "      <td>0.806250</td>\n",
       "      <td>0.806419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.010400</td>\n",
       "      <td>1.017941</td>\n",
       "      <td>0.827083</td>\n",
       "      <td>0.822880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>1.004770</td>\n",
       "      <td>0.820833</td>\n",
       "      <td>0.817732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>1.054105</td>\n",
       "      <td>0.814583</td>\n",
       "      <td>0.812296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>1.039051</td>\n",
       "      <td>0.820833</td>\n",
       "      <td>0.818004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>1.051416</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>0.821775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>1.080598</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.813611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>1.086568</td>\n",
       "      <td>0.818750</td>\n",
       "      <td>0.815835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>1.098721</td>\n",
       "      <td>0.820833</td>\n",
       "      <td>0.817917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.079935</td>\n",
       "      <td>0.822917</td>\n",
       "      <td>0.820494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>1.073906</td>\n",
       "      <td>0.822917</td>\n",
       "      <td>0.820160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>1.073781</td>\n",
       "      <td>0.820833</td>\n",
       "      <td>0.817862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>1.074285</td>\n",
       "      <td>0.820833</td>\n",
       "      <td>0.817862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83a795aeb966436e809d5cea0bf26bd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1919 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a84246c768224587bc9267a06684bfb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 00:57, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.281100</td>\n",
       "      <td>0.771552</td>\n",
       "      <td>0.762500</td>\n",
       "      <td>0.762593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.539100</td>\n",
       "      <td>0.668558</td>\n",
       "      <td>0.787500</td>\n",
       "      <td>0.789392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.298600</td>\n",
       "      <td>0.647695</td>\n",
       "      <td>0.808333</td>\n",
       "      <td>0.810272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.172200</td>\n",
       "      <td>0.701630</td>\n",
       "      <td>0.810417</td>\n",
       "      <td>0.814004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.103200</td>\n",
       "      <td>0.771657</td>\n",
       "      <td>0.806250</td>\n",
       "      <td>0.810470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.072400</td>\n",
       "      <td>0.817346</td>\n",
       "      <td>0.797917</td>\n",
       "      <td>0.801422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.032500</td>\n",
       "      <td>0.887113</td>\n",
       "      <td>0.802083</td>\n",
       "      <td>0.804850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.041800</td>\n",
       "      <td>0.978635</td>\n",
       "      <td>0.804167</td>\n",
       "      <td>0.807657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.016200</td>\n",
       "      <td>0.999167</td>\n",
       "      <td>0.806250</td>\n",
       "      <td>0.810232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.016500</td>\n",
       "      <td>1.045380</td>\n",
       "      <td>0.806250</td>\n",
       "      <td>0.808574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.022800</td>\n",
       "      <td>1.062552</td>\n",
       "      <td>0.808333</td>\n",
       "      <td>0.813730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.013200</td>\n",
       "      <td>0.971804</td>\n",
       "      <td>0.818750</td>\n",
       "      <td>0.821052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>1.096818</td>\n",
       "      <td>0.795833</td>\n",
       "      <td>0.796040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.012100</td>\n",
       "      <td>1.102762</td>\n",
       "      <td>0.814583</td>\n",
       "      <td>0.818334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>1.040715</td>\n",
       "      <td>0.820833</td>\n",
       "      <td>0.823856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.004900</td>\n",
       "      <td>1.040631</td>\n",
       "      <td>0.802083</td>\n",
       "      <td>0.804948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>1.056047</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.815450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>1.108506</td>\n",
       "      <td>0.808333</td>\n",
       "      <td>0.811717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>1.116448</td>\n",
       "      <td>0.806250</td>\n",
       "      <td>0.809530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.121017</td>\n",
       "      <td>0.802083</td>\n",
       "      <td>0.806085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.132343</td>\n",
       "      <td>0.804167</td>\n",
       "      <td>0.807215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>1.134097</td>\n",
       "      <td>0.802083</td>\n",
       "      <td>0.805359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>1.133567</td>\n",
       "      <td>0.802083</td>\n",
       "      <td>0.805359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>1.131696</td>\n",
       "      <td>0.806250</td>\n",
       "      <td>0.809530</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eab56618fd8a4ce88bce8742648f27f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1919 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3203d9beb054a03bc3f3f4ff74aeebd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 00:57, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.281100</td>\n",
       "      <td>0.771552</td>\n",
       "      <td>0.762500</td>\n",
       "      <td>0.762593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.539100</td>\n",
       "      <td>0.668558</td>\n",
       "      <td>0.787500</td>\n",
       "      <td>0.789392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.298600</td>\n",
       "      <td>0.647695</td>\n",
       "      <td>0.808333</td>\n",
       "      <td>0.810272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.172200</td>\n",
       "      <td>0.701630</td>\n",
       "      <td>0.810417</td>\n",
       "      <td>0.814004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.103200</td>\n",
       "      <td>0.771657</td>\n",
       "      <td>0.806250</td>\n",
       "      <td>0.810470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.072400</td>\n",
       "      <td>0.817346</td>\n",
       "      <td>0.797917</td>\n",
       "      <td>0.801422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.032500</td>\n",
       "      <td>0.887113</td>\n",
       "      <td>0.802083</td>\n",
       "      <td>0.804850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.041800</td>\n",
       "      <td>0.978635</td>\n",
       "      <td>0.804167</td>\n",
       "      <td>0.807657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.016200</td>\n",
       "      <td>0.999167</td>\n",
       "      <td>0.806250</td>\n",
       "      <td>0.810232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.016500</td>\n",
       "      <td>1.045380</td>\n",
       "      <td>0.806250</td>\n",
       "      <td>0.808574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.022800</td>\n",
       "      <td>1.062552</td>\n",
       "      <td>0.808333</td>\n",
       "      <td>0.813730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.013200</td>\n",
       "      <td>0.971804</td>\n",
       "      <td>0.818750</td>\n",
       "      <td>0.821052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>1.096818</td>\n",
       "      <td>0.795833</td>\n",
       "      <td>0.796040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.012100</td>\n",
       "      <td>1.102762</td>\n",
       "      <td>0.814583</td>\n",
       "      <td>0.818334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>1.040715</td>\n",
       "      <td>0.820833</td>\n",
       "      <td>0.823856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.004900</td>\n",
       "      <td>1.040631</td>\n",
       "      <td>0.802083</td>\n",
       "      <td>0.804948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>1.056047</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.815450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>1.108506</td>\n",
       "      <td>0.808333</td>\n",
       "      <td>0.811717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>1.116448</td>\n",
       "      <td>0.806250</td>\n",
       "      <td>0.809530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.121017</td>\n",
       "      <td>0.802083</td>\n",
       "      <td>0.806085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.132343</td>\n",
       "      <td>0.804167</td>\n",
       "      <td>0.807215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>1.134097</td>\n",
       "      <td>0.802083</td>\n",
       "      <td>0.805359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>1.133567</td>\n",
       "      <td>0.802083</td>\n",
       "      <td>0.805359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>1.131696</td>\n",
       "      <td>0.806250</td>\n",
       "      <td>0.809530</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f78f3009cd641eb86f07bdb678c1585",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1919 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40713275bb4945e983c1981b5b7809cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 00:57, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.281100</td>\n",
       "      <td>0.771552</td>\n",
       "      <td>0.762500</td>\n",
       "      <td>0.762593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.539100</td>\n",
       "      <td>0.668558</td>\n",
       "      <td>0.787500</td>\n",
       "      <td>0.789392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.298600</td>\n",
       "      <td>0.647695</td>\n",
       "      <td>0.808333</td>\n",
       "      <td>0.810272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.172200</td>\n",
       "      <td>0.701630</td>\n",
       "      <td>0.810417</td>\n",
       "      <td>0.814004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.103200</td>\n",
       "      <td>0.771657</td>\n",
       "      <td>0.806250</td>\n",
       "      <td>0.810470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.072400</td>\n",
       "      <td>0.817346</td>\n",
       "      <td>0.797917</td>\n",
       "      <td>0.801422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.032500</td>\n",
       "      <td>0.887113</td>\n",
       "      <td>0.802083</td>\n",
       "      <td>0.804850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.041800</td>\n",
       "      <td>0.978635</td>\n",
       "      <td>0.804167</td>\n",
       "      <td>0.807657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.016200</td>\n",
       "      <td>0.999167</td>\n",
       "      <td>0.806250</td>\n",
       "      <td>0.810232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.016500</td>\n",
       "      <td>1.045380</td>\n",
       "      <td>0.806250</td>\n",
       "      <td>0.808574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.022800</td>\n",
       "      <td>1.062552</td>\n",
       "      <td>0.808333</td>\n",
       "      <td>0.813730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.013200</td>\n",
       "      <td>0.971804</td>\n",
       "      <td>0.818750</td>\n",
       "      <td>0.821052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>1.096818</td>\n",
       "      <td>0.795833</td>\n",
       "      <td>0.796040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.012100</td>\n",
       "      <td>1.102762</td>\n",
       "      <td>0.814583</td>\n",
       "      <td>0.818334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>1.040715</td>\n",
       "      <td>0.820833</td>\n",
       "      <td>0.823856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.004900</td>\n",
       "      <td>1.040631</td>\n",
       "      <td>0.802083</td>\n",
       "      <td>0.804948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>1.056047</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.815450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>1.108506</td>\n",
       "      <td>0.808333</td>\n",
       "      <td>0.811717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>1.116448</td>\n",
       "      <td>0.806250</td>\n",
       "      <td>0.809530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.121017</td>\n",
       "      <td>0.802083</td>\n",
       "      <td>0.806085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.132343</td>\n",
       "      <td>0.804167</td>\n",
       "      <td>0.807215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>1.134097</td>\n",
       "      <td>0.802083</td>\n",
       "      <td>0.805359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>1.133567</td>\n",
       "      <td>0.802083</td>\n",
       "      <td>0.805359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>1.131696</td>\n",
       "      <td>0.806250</td>\n",
       "      <td>0.809530</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Tweet', 'label'],\n",
       "        num_rows: 1919\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Tweet', 'label'],\n",
       "        num_rows: 480\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunis-ai/TunBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tunis-ai/TunBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2494d4a243b14c32888b08de4655f18a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1919 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "328fe4e72a3247bcb4b2f7e306af87ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 00:54, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>2.034000</td>\n",
       "      <td>1.969181</td>\n",
       "      <td>0.131250</td>\n",
       "      <td>0.033149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.969100</td>\n",
       "      <td>1.966663</td>\n",
       "      <td>0.145833</td>\n",
       "      <td>0.036364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>1.967000</td>\n",
       "      <td>1.951666</td>\n",
       "      <td>0.158333</td>\n",
       "      <td>0.039054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.959200</td>\n",
       "      <td>1.954454</td>\n",
       "      <td>0.131250</td>\n",
       "      <td>0.033149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>1.965800</td>\n",
       "      <td>1.966113</td>\n",
       "      <td>0.154167</td>\n",
       "      <td>0.038164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.965200</td>\n",
       "      <td>1.949532</td>\n",
       "      <td>0.158333</td>\n",
       "      <td>0.039054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>1.949400</td>\n",
       "      <td>1.952034</td>\n",
       "      <td>0.168750</td>\n",
       "      <td>0.065493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.931800</td>\n",
       "      <td>1.878046</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>0.140684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>1.848600</td>\n",
       "      <td>1.816481</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>0.210898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.829200</td>\n",
       "      <td>1.829102</td>\n",
       "      <td>0.258333</td>\n",
       "      <td>0.198476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>1.774000</td>\n",
       "      <td>1.801717</td>\n",
       "      <td>0.262500</td>\n",
       "      <td>0.193560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.757400</td>\n",
       "      <td>1.739840</td>\n",
       "      <td>0.277083</td>\n",
       "      <td>0.220846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>1.728600</td>\n",
       "      <td>1.732126</td>\n",
       "      <td>0.295833</td>\n",
       "      <td>0.276029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.685800</td>\n",
       "      <td>1.690796</td>\n",
       "      <td>0.341667</td>\n",
       "      <td>0.339763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>1.627300</td>\n",
       "      <td>1.685195</td>\n",
       "      <td>0.345833</td>\n",
       "      <td>0.334882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.592300</td>\n",
       "      <td>1.731298</td>\n",
       "      <td>0.358333</td>\n",
       "      <td>0.339765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>1.559300</td>\n",
       "      <td>1.706126</td>\n",
       "      <td>0.337500</td>\n",
       "      <td>0.327674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>1.525500</td>\n",
       "      <td>1.678651</td>\n",
       "      <td>0.381250</td>\n",
       "      <td>0.382597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>1.472100</td>\n",
       "      <td>1.683543</td>\n",
       "      <td>0.368750</td>\n",
       "      <td>0.362096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.456100</td>\n",
       "      <td>1.679068</td>\n",
       "      <td>0.414583</td>\n",
       "      <td>0.415796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>1.391100</td>\n",
       "      <td>1.650288</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.403685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>1.364200</td>\n",
       "      <td>1.672305</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.401930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>1.346500</td>\n",
       "      <td>1.657754</td>\n",
       "      <td>0.397917</td>\n",
       "      <td>0.400657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.329200</td>\n",
       "      <td>1.658604</td>\n",
       "      <td>0.410417</td>\n",
       "      <td>0.414887</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunis-ai/TunBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tunis-ai/TunBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "384431156f594a448c63c13eb3cba671",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1919 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "291b5036c4984128ab3081794333a7e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 00:54, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>2.034000</td>\n",
       "      <td>1.969181</td>\n",
       "      <td>0.131250</td>\n",
       "      <td>0.033149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.969100</td>\n",
       "      <td>1.966663</td>\n",
       "      <td>0.145833</td>\n",
       "      <td>0.036364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>1.967000</td>\n",
       "      <td>1.951666</td>\n",
       "      <td>0.158333</td>\n",
       "      <td>0.039054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.959200</td>\n",
       "      <td>1.954454</td>\n",
       "      <td>0.131250</td>\n",
       "      <td>0.033149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>1.965800</td>\n",
       "      <td>1.966113</td>\n",
       "      <td>0.154167</td>\n",
       "      <td>0.038164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.965200</td>\n",
       "      <td>1.949532</td>\n",
       "      <td>0.158333</td>\n",
       "      <td>0.039054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>1.949400</td>\n",
       "      <td>1.952034</td>\n",
       "      <td>0.168750</td>\n",
       "      <td>0.065493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.931800</td>\n",
       "      <td>1.878046</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>0.140684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>1.848600</td>\n",
       "      <td>1.816481</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>0.210898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.829200</td>\n",
       "      <td>1.829102</td>\n",
       "      <td>0.258333</td>\n",
       "      <td>0.198476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>1.774000</td>\n",
       "      <td>1.801717</td>\n",
       "      <td>0.262500</td>\n",
       "      <td>0.193560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.757400</td>\n",
       "      <td>1.739840</td>\n",
       "      <td>0.277083</td>\n",
       "      <td>0.220846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>1.728600</td>\n",
       "      <td>1.732126</td>\n",
       "      <td>0.295833</td>\n",
       "      <td>0.276029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.685800</td>\n",
       "      <td>1.690796</td>\n",
       "      <td>0.341667</td>\n",
       "      <td>0.339763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>1.627300</td>\n",
       "      <td>1.685195</td>\n",
       "      <td>0.345833</td>\n",
       "      <td>0.334882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.592300</td>\n",
       "      <td>1.731298</td>\n",
       "      <td>0.358333</td>\n",
       "      <td>0.339765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>1.559300</td>\n",
       "      <td>1.706126</td>\n",
       "      <td>0.337500</td>\n",
       "      <td>0.327674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>1.525500</td>\n",
       "      <td>1.678651</td>\n",
       "      <td>0.381250</td>\n",
       "      <td>0.382597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>1.472100</td>\n",
       "      <td>1.683543</td>\n",
       "      <td>0.368750</td>\n",
       "      <td>0.362096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.456100</td>\n",
       "      <td>1.679068</td>\n",
       "      <td>0.414583</td>\n",
       "      <td>0.415796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>1.391100</td>\n",
       "      <td>1.650288</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.403685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>1.364200</td>\n",
       "      <td>1.672305</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.401930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>1.346500</td>\n",
       "      <td>1.657754</td>\n",
       "      <td>0.397917</td>\n",
       "      <td>0.400657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.329200</td>\n",
       "      <td>1.658604</td>\n",
       "      <td>0.410417</td>\n",
       "      <td>0.414887</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunis-ai/TunBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tunis-ai/TunBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98388609c67b4259a8ce8fc34f5481c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1919 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0649c14dea024845a697155fd36c8cf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 01:13, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>2.034000</td>\n",
       "      <td>1.969181</td>\n",
       "      <td>0.131250</td>\n",
       "      <td>0.033149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.969100</td>\n",
       "      <td>1.966663</td>\n",
       "      <td>0.145833</td>\n",
       "      <td>0.036364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>1.967000</td>\n",
       "      <td>1.951666</td>\n",
       "      <td>0.158333</td>\n",
       "      <td>0.039054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.959200</td>\n",
       "      <td>1.954454</td>\n",
       "      <td>0.131250</td>\n",
       "      <td>0.033149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>1.965800</td>\n",
       "      <td>1.966113</td>\n",
       "      <td>0.154167</td>\n",
       "      <td>0.038164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.965200</td>\n",
       "      <td>1.949532</td>\n",
       "      <td>0.158333</td>\n",
       "      <td>0.039054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>1.949400</td>\n",
       "      <td>1.952034</td>\n",
       "      <td>0.168750</td>\n",
       "      <td>0.065493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.931800</td>\n",
       "      <td>1.878046</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>0.140684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>1.848600</td>\n",
       "      <td>1.816481</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>0.210898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.829200</td>\n",
       "      <td>1.829102</td>\n",
       "      <td>0.258333</td>\n",
       "      <td>0.198476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>1.774000</td>\n",
       "      <td>1.801717</td>\n",
       "      <td>0.262500</td>\n",
       "      <td>0.193560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.757400</td>\n",
       "      <td>1.739840</td>\n",
       "      <td>0.277083</td>\n",
       "      <td>0.220846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>1.728600</td>\n",
       "      <td>1.732126</td>\n",
       "      <td>0.295833</td>\n",
       "      <td>0.276029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.685800</td>\n",
       "      <td>1.690796</td>\n",
       "      <td>0.341667</td>\n",
       "      <td>0.339763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>1.627300</td>\n",
       "      <td>1.685195</td>\n",
       "      <td>0.345833</td>\n",
       "      <td>0.334882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.592300</td>\n",
       "      <td>1.731298</td>\n",
       "      <td>0.358333</td>\n",
       "      <td>0.339765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>1.559300</td>\n",
       "      <td>1.706126</td>\n",
       "      <td>0.337500</td>\n",
       "      <td>0.327674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>1.525500</td>\n",
       "      <td>1.678651</td>\n",
       "      <td>0.381250</td>\n",
       "      <td>0.382597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>1.472100</td>\n",
       "      <td>1.683543</td>\n",
       "      <td>0.368750</td>\n",
       "      <td>0.362096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.456100</td>\n",
       "      <td>1.679068</td>\n",
       "      <td>0.414583</td>\n",
       "      <td>0.415796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>1.391100</td>\n",
       "      <td>1.650288</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.403685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>1.364200</td>\n",
       "      <td>1.672305</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.401930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>1.346500</td>\n",
       "      <td>1.657754</td>\n",
       "      <td>0.397917</td>\n",
       "      <td>0.400657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.329200</td>\n",
       "      <td>1.658604</td>\n",
       "      <td>0.410417</td>\n",
       "      <td>0.414887</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunis-ai/TunBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tunis-ai/TunBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9aa041f55d564350bcf40dbe26f6d755",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1919 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e35c4fbf013f4aa99165332e4d6eca9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 01:42, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>2.041300</td>\n",
       "      <td>1.947970</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.037267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.972400</td>\n",
       "      <td>1.960099</td>\n",
       "      <td>0.135417</td>\n",
       "      <td>0.034076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>1.966200</td>\n",
       "      <td>1.957088</td>\n",
       "      <td>0.162500</td>\n",
       "      <td>0.039939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.984600</td>\n",
       "      <td>1.969649</td>\n",
       "      <td>0.145833</td>\n",
       "      <td>0.036364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>1.966900</td>\n",
       "      <td>1.950071</td>\n",
       "      <td>0.135417</td>\n",
       "      <td>0.034076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.969200</td>\n",
       "      <td>1.956401</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.037267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>1.960700</td>\n",
       "      <td>1.953265</td>\n",
       "      <td>0.137500</td>\n",
       "      <td>0.034537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.966700</td>\n",
       "      <td>1.971525</td>\n",
       "      <td>0.137500</td>\n",
       "      <td>0.034537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>1.958000</td>\n",
       "      <td>1.954722</td>\n",
       "      <td>0.160417</td>\n",
       "      <td>0.073739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.946200</td>\n",
       "      <td>1.907465</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.090814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>1.962100</td>\n",
       "      <td>1.949129</td>\n",
       "      <td>0.170833</td>\n",
       "      <td>0.099630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.944200</td>\n",
       "      <td>1.906561</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>0.113292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>1.889900</td>\n",
       "      <td>1.908470</td>\n",
       "      <td>0.222917</td>\n",
       "      <td>0.125070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.904000</td>\n",
       "      <td>1.873674</td>\n",
       "      <td>0.206250</td>\n",
       "      <td>0.113773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>1.862100</td>\n",
       "      <td>1.824489</td>\n",
       "      <td>0.256250</td>\n",
       "      <td>0.194904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.865700</td>\n",
       "      <td>1.844429</td>\n",
       "      <td>0.222917</td>\n",
       "      <td>0.146387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>1.839400</td>\n",
       "      <td>1.837842</td>\n",
       "      <td>0.239583</td>\n",
       "      <td>0.167400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>1.837100</td>\n",
       "      <td>1.813794</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>0.200399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>1.821900</td>\n",
       "      <td>1.827983</td>\n",
       "      <td>0.227083</td>\n",
       "      <td>0.191377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.807700</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.209531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>1.779400</td>\n",
       "      <td>1.770362</td>\n",
       "      <td>0.293750</td>\n",
       "      <td>0.271103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>1.763800</td>\n",
       "      <td>1.771531</td>\n",
       "      <td>0.268750</td>\n",
       "      <td>0.241467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>1.742800</td>\n",
       "      <td>1.745179</td>\n",
       "      <td>0.297917</td>\n",
       "      <td>0.266019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.731200</td>\n",
       "      <td>1.740184</td>\n",
       "      <td>0.285417</td>\n",
       "      <td>0.263111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunis-ai/TunBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tunis-ai/TunBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa07145fd03745ceb7a1a932ed70d9d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1919 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44258611483941d2b7f2682da629cd70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 01:41, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>2.041300</td>\n",
       "      <td>1.947970</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.037267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.972400</td>\n",
       "      <td>1.960099</td>\n",
       "      <td>0.135417</td>\n",
       "      <td>0.034076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>1.966200</td>\n",
       "      <td>1.957088</td>\n",
       "      <td>0.162500</td>\n",
       "      <td>0.039939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.984600</td>\n",
       "      <td>1.969649</td>\n",
       "      <td>0.145833</td>\n",
       "      <td>0.036364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>1.966900</td>\n",
       "      <td>1.950071</td>\n",
       "      <td>0.135417</td>\n",
       "      <td>0.034076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.969200</td>\n",
       "      <td>1.956401</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.037267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>1.960700</td>\n",
       "      <td>1.953265</td>\n",
       "      <td>0.137500</td>\n",
       "      <td>0.034537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.966700</td>\n",
       "      <td>1.971525</td>\n",
       "      <td>0.137500</td>\n",
       "      <td>0.034537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>1.958000</td>\n",
       "      <td>1.954722</td>\n",
       "      <td>0.160417</td>\n",
       "      <td>0.073739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.946200</td>\n",
       "      <td>1.907465</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.090814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>1.962100</td>\n",
       "      <td>1.949129</td>\n",
       "      <td>0.170833</td>\n",
       "      <td>0.099630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.944200</td>\n",
       "      <td>1.906561</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>0.113292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>1.889900</td>\n",
       "      <td>1.908470</td>\n",
       "      <td>0.222917</td>\n",
       "      <td>0.125070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.904000</td>\n",
       "      <td>1.873674</td>\n",
       "      <td>0.206250</td>\n",
       "      <td>0.113773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>1.862100</td>\n",
       "      <td>1.824489</td>\n",
       "      <td>0.256250</td>\n",
       "      <td>0.194904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.865700</td>\n",
       "      <td>1.844429</td>\n",
       "      <td>0.222917</td>\n",
       "      <td>0.146387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>1.839400</td>\n",
       "      <td>1.837842</td>\n",
       "      <td>0.239583</td>\n",
       "      <td>0.167400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>1.837100</td>\n",
       "      <td>1.813794</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>0.200399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>1.821900</td>\n",
       "      <td>1.827983</td>\n",
       "      <td>0.227083</td>\n",
       "      <td>0.191377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.807700</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.209531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>1.779400</td>\n",
       "      <td>1.770362</td>\n",
       "      <td>0.293750</td>\n",
       "      <td>0.271103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>1.763800</td>\n",
       "      <td>1.771531</td>\n",
       "      <td>0.268750</td>\n",
       "      <td>0.241467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>1.742800</td>\n",
       "      <td>1.745179</td>\n",
       "      <td>0.297917</td>\n",
       "      <td>0.266019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.731200</td>\n",
       "      <td>1.740184</td>\n",
       "      <td>0.285417</td>\n",
       "      <td>0.263111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunis-ai/TunBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tunis-ai/TunBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b027770f098b4851a011caa07281cf33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1919 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7af76c22a6344b35904421f1eb874214",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 01:42, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>2.041300</td>\n",
       "      <td>1.947970</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.037267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.972400</td>\n",
       "      <td>1.960099</td>\n",
       "      <td>0.135417</td>\n",
       "      <td>0.034076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>1.966200</td>\n",
       "      <td>1.957088</td>\n",
       "      <td>0.162500</td>\n",
       "      <td>0.039939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.984600</td>\n",
       "      <td>1.969649</td>\n",
       "      <td>0.145833</td>\n",
       "      <td>0.036364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>1.966900</td>\n",
       "      <td>1.950071</td>\n",
       "      <td>0.135417</td>\n",
       "      <td>0.034076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.969200</td>\n",
       "      <td>1.956401</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.037267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>1.960700</td>\n",
       "      <td>1.953265</td>\n",
       "      <td>0.137500</td>\n",
       "      <td>0.034537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.966700</td>\n",
       "      <td>1.971525</td>\n",
       "      <td>0.137500</td>\n",
       "      <td>0.034537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>1.958000</td>\n",
       "      <td>1.954722</td>\n",
       "      <td>0.160417</td>\n",
       "      <td>0.073739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.946200</td>\n",
       "      <td>1.907465</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.090814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>1.962100</td>\n",
       "      <td>1.949129</td>\n",
       "      <td>0.170833</td>\n",
       "      <td>0.099630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.944200</td>\n",
       "      <td>1.906561</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>0.113292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>1.889900</td>\n",
       "      <td>1.908470</td>\n",
       "      <td>0.222917</td>\n",
       "      <td>0.125070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.904000</td>\n",
       "      <td>1.873674</td>\n",
       "      <td>0.206250</td>\n",
       "      <td>0.113773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>1.862100</td>\n",
       "      <td>1.824489</td>\n",
       "      <td>0.256250</td>\n",
       "      <td>0.194904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.865700</td>\n",
       "      <td>1.844429</td>\n",
       "      <td>0.222917</td>\n",
       "      <td>0.146387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>1.839400</td>\n",
       "      <td>1.837842</td>\n",
       "      <td>0.239583</td>\n",
       "      <td>0.167400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>1.837100</td>\n",
       "      <td>1.813794</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>0.200399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>1.821900</td>\n",
       "      <td>1.827983</td>\n",
       "      <td>0.227083</td>\n",
       "      <td>0.191377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.807700</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.209531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>1.779400</td>\n",
       "      <td>1.770362</td>\n",
       "      <td>0.293750</td>\n",
       "      <td>0.271103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>1.763800</td>\n",
       "      <td>1.771531</td>\n",
       "      <td>0.268750</td>\n",
       "      <td>0.241467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>1.742800</td>\n",
       "      <td>1.745179</td>\n",
       "      <td>0.297917</td>\n",
       "      <td>0.266019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.731200</td>\n",
       "      <td>1.740184</td>\n",
       "      <td>0.285417</td>\n",
       "      <td>0.263111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunis-ai/TunBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tunis-ai/TunBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eb1d58b18b44606937651a63e751317",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1919 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4f86b925aea4be2a415b97e0241853a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 01:44, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>2.036800</td>\n",
       "      <td>1.954506</td>\n",
       "      <td>0.181250</td>\n",
       "      <td>0.043840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.977800</td>\n",
       "      <td>2.014264</td>\n",
       "      <td>0.145833</td>\n",
       "      <td>0.036364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>1.966800</td>\n",
       "      <td>1.989754</td>\n",
       "      <td>0.145833</td>\n",
       "      <td>0.036364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.971200</td>\n",
       "      <td>1.970622</td>\n",
       "      <td>0.143750</td>\n",
       "      <td>0.035909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>1.966900</td>\n",
       "      <td>1.947315</td>\n",
       "      <td>0.145833</td>\n",
       "      <td>0.036364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.954600</td>\n",
       "      <td>1.883940</td>\n",
       "      <td>0.220833</td>\n",
       "      <td>0.104834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>1.872700</td>\n",
       "      <td>1.879016</td>\n",
       "      <td>0.204167</td>\n",
       "      <td>0.151837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.831300</td>\n",
       "      <td>1.849543</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.125737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>1.783800</td>\n",
       "      <td>1.829150</td>\n",
       "      <td>0.264583</td>\n",
       "      <td>0.228431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.724300</td>\n",
       "      <td>1.799717</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.206518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>1.657800</td>\n",
       "      <td>1.883822</td>\n",
       "      <td>0.218750</td>\n",
       "      <td>0.198088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.611100</td>\n",
       "      <td>1.782878</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.289022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>1.555200</td>\n",
       "      <td>1.742874</td>\n",
       "      <td>0.337500</td>\n",
       "      <td>0.305283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.534700</td>\n",
       "      <td>1.717484</td>\n",
       "      <td>0.314583</td>\n",
       "      <td>0.323668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>1.479500</td>\n",
       "      <td>1.719344</td>\n",
       "      <td>0.337500</td>\n",
       "      <td>0.329036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.416500</td>\n",
       "      <td>1.709772</td>\n",
       "      <td>0.345833</td>\n",
       "      <td>0.337303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>1.394200</td>\n",
       "      <td>1.692321</td>\n",
       "      <td>0.356250</td>\n",
       "      <td>0.366049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>1.360800</td>\n",
       "      <td>1.755870</td>\n",
       "      <td>0.354167</td>\n",
       "      <td>0.349236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>1.303700</td>\n",
       "      <td>1.780740</td>\n",
       "      <td>0.337500</td>\n",
       "      <td>0.351115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.317900</td>\n",
       "      <td>1.746296</td>\n",
       "      <td>0.358333</td>\n",
       "      <td>0.354405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>1.231700</td>\n",
       "      <td>1.709288</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0.384454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>1.201800</td>\n",
       "      <td>1.733994</td>\n",
       "      <td>0.377083</td>\n",
       "      <td>0.379336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>1.213900</td>\n",
       "      <td>1.734960</td>\n",
       "      <td>0.368750</td>\n",
       "      <td>0.371219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.172700</td>\n",
       "      <td>1.741192</td>\n",
       "      <td>0.368750</td>\n",
       "      <td>0.371392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunis-ai/TunBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tunis-ai/TunBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "499b1f679d884dcd929970bec0110942",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1919 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "672cfbc1006544a7a696aa7e4684bd0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 01:42, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>2.036800</td>\n",
       "      <td>1.954506</td>\n",
       "      <td>0.181250</td>\n",
       "      <td>0.043840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.977800</td>\n",
       "      <td>2.014264</td>\n",
       "      <td>0.145833</td>\n",
       "      <td>0.036364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>1.966800</td>\n",
       "      <td>1.989754</td>\n",
       "      <td>0.145833</td>\n",
       "      <td>0.036364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.971200</td>\n",
       "      <td>1.970622</td>\n",
       "      <td>0.143750</td>\n",
       "      <td>0.035909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>1.966900</td>\n",
       "      <td>1.947315</td>\n",
       "      <td>0.145833</td>\n",
       "      <td>0.036364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.954600</td>\n",
       "      <td>1.883940</td>\n",
       "      <td>0.220833</td>\n",
       "      <td>0.104834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>1.872700</td>\n",
       "      <td>1.879016</td>\n",
       "      <td>0.204167</td>\n",
       "      <td>0.151837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.831300</td>\n",
       "      <td>1.849543</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.125737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>1.783800</td>\n",
       "      <td>1.829150</td>\n",
       "      <td>0.264583</td>\n",
       "      <td>0.228431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.724300</td>\n",
       "      <td>1.799717</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.206518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>1.657800</td>\n",
       "      <td>1.883822</td>\n",
       "      <td>0.218750</td>\n",
       "      <td>0.198088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.611100</td>\n",
       "      <td>1.782878</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.289022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>1.555200</td>\n",
       "      <td>1.742874</td>\n",
       "      <td>0.337500</td>\n",
       "      <td>0.305283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.534700</td>\n",
       "      <td>1.717484</td>\n",
       "      <td>0.314583</td>\n",
       "      <td>0.323668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>1.479500</td>\n",
       "      <td>1.719344</td>\n",
       "      <td>0.337500</td>\n",
       "      <td>0.329036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.416500</td>\n",
       "      <td>1.709772</td>\n",
       "      <td>0.345833</td>\n",
       "      <td>0.337303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>1.394200</td>\n",
       "      <td>1.692321</td>\n",
       "      <td>0.356250</td>\n",
       "      <td>0.366049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>1.360800</td>\n",
       "      <td>1.755870</td>\n",
       "      <td>0.354167</td>\n",
       "      <td>0.349236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>1.303700</td>\n",
       "      <td>1.780740</td>\n",
       "      <td>0.337500</td>\n",
       "      <td>0.351115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.317900</td>\n",
       "      <td>1.746296</td>\n",
       "      <td>0.358333</td>\n",
       "      <td>0.354405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>1.231700</td>\n",
       "      <td>1.709288</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0.384454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>1.201800</td>\n",
       "      <td>1.733994</td>\n",
       "      <td>0.377083</td>\n",
       "      <td>0.379336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>1.213900</td>\n",
       "      <td>1.734960</td>\n",
       "      <td>0.368750</td>\n",
       "      <td>0.371219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.172700</td>\n",
       "      <td>1.741192</td>\n",
       "      <td>0.368750</td>\n",
       "      <td>0.371392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunis-ai/TunBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tunis-ai/TunBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a162fd676ee49cfb33b9b453423a0c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1919 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39b6a48babec41708903ecce3bbb883d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 01:39, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>2.036800</td>\n",
       "      <td>1.954506</td>\n",
       "      <td>0.181250</td>\n",
       "      <td>0.043840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.977800</td>\n",
       "      <td>2.014264</td>\n",
       "      <td>0.145833</td>\n",
       "      <td>0.036364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>1.966800</td>\n",
       "      <td>1.989754</td>\n",
       "      <td>0.145833</td>\n",
       "      <td>0.036364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.971200</td>\n",
       "      <td>1.970622</td>\n",
       "      <td>0.143750</td>\n",
       "      <td>0.035909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>1.966900</td>\n",
       "      <td>1.947315</td>\n",
       "      <td>0.145833</td>\n",
       "      <td>0.036364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.954600</td>\n",
       "      <td>1.883940</td>\n",
       "      <td>0.220833</td>\n",
       "      <td>0.104834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>1.872700</td>\n",
       "      <td>1.879016</td>\n",
       "      <td>0.204167</td>\n",
       "      <td>0.151837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.831300</td>\n",
       "      <td>1.849543</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.125737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>1.783800</td>\n",
       "      <td>1.829150</td>\n",
       "      <td>0.264583</td>\n",
       "      <td>0.228431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.724300</td>\n",
       "      <td>1.799717</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.206518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>1.657800</td>\n",
       "      <td>1.883822</td>\n",
       "      <td>0.218750</td>\n",
       "      <td>0.198088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.611100</td>\n",
       "      <td>1.782878</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.289022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>1.555200</td>\n",
       "      <td>1.742874</td>\n",
       "      <td>0.337500</td>\n",
       "      <td>0.305283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.534700</td>\n",
       "      <td>1.717484</td>\n",
       "      <td>0.314583</td>\n",
       "      <td>0.323668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>1.479500</td>\n",
       "      <td>1.719344</td>\n",
       "      <td>0.337500</td>\n",
       "      <td>0.329036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.416500</td>\n",
       "      <td>1.709772</td>\n",
       "      <td>0.345833</td>\n",
       "      <td>0.337303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>1.394200</td>\n",
       "      <td>1.692321</td>\n",
       "      <td>0.356250</td>\n",
       "      <td>0.366049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>1.360800</td>\n",
       "      <td>1.755870</td>\n",
       "      <td>0.354167</td>\n",
       "      <td>0.349236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>1.303700</td>\n",
       "      <td>1.780740</td>\n",
       "      <td>0.337500</td>\n",
       "      <td>0.351115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.317900</td>\n",
       "      <td>1.746296</td>\n",
       "      <td>0.358333</td>\n",
       "      <td>0.354405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>1.231700</td>\n",
       "      <td>1.709288</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0.384454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>1.201800</td>\n",
       "      <td>1.733994</td>\n",
       "      <td>0.377083</td>\n",
       "      <td>0.379336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>1.213900</td>\n",
       "      <td>1.734960</td>\n",
       "      <td>0.368750</td>\n",
       "      <td>0.371219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.172700</td>\n",
       "      <td>1.741192</td>\n",
       "      <td>0.368750</td>\n",
       "      <td>0.371392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Tweet', 'label'],\n",
       "        num_rows: 1919\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Tweet', 'label'],\n",
       "        num_rows: 480\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alger-ia/dziribert, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecd8920f644c44efa39ff0d7a592671a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1919 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b9f24fd983e4394895f4c38c0f5bbed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 01:39, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.388600</td>\n",
       "      <td>0.898182</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.702479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.701400</td>\n",
       "      <td>0.731329</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.767101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.382300</td>\n",
       "      <td>0.710537</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.766025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.181000</td>\n",
       "      <td>0.721491</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.769948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.082400</td>\n",
       "      <td>0.773198</td>\n",
       "      <td>0.785417</td>\n",
       "      <td>0.784778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.043500</td>\n",
       "      <td>0.887003</td>\n",
       "      <td>0.789583</td>\n",
       "      <td>0.789380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.016900</td>\n",
       "      <td>0.961218</td>\n",
       "      <td>0.795833</td>\n",
       "      <td>0.795368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.013800</td>\n",
       "      <td>1.040312</td>\n",
       "      <td>0.789583</td>\n",
       "      <td>0.789597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.010700</td>\n",
       "      <td>1.019923</td>\n",
       "      <td>0.806250</td>\n",
       "      <td>0.806102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.007900</td>\n",
       "      <td>1.035478</td>\n",
       "      <td>0.810417</td>\n",
       "      <td>0.810724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.006200</td>\n",
       "      <td>1.019297</td>\n",
       "      <td>0.806250</td>\n",
       "      <td>0.805906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>1.047588</td>\n",
       "      <td>0.802083</td>\n",
       "      <td>0.802272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>1.030076</td>\n",
       "      <td>0.810417</td>\n",
       "      <td>0.811180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.052091</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.816713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>1.067967</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.817066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>1.082863</td>\n",
       "      <td>0.810417</td>\n",
       "      <td>0.810993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.093579</td>\n",
       "      <td>0.806250</td>\n",
       "      <td>0.806770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.084669</td>\n",
       "      <td>0.808333</td>\n",
       "      <td>0.808667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>1.088982</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.813434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>1.093782</td>\n",
       "      <td>0.814583</td>\n",
       "      <td>0.815224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>1.100346</td>\n",
       "      <td>0.810417</td>\n",
       "      <td>0.811094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>1.100279</td>\n",
       "      <td>0.814583</td>\n",
       "      <td>0.815350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>1.101447</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.817497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>1.102415</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.817497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alger-ia/dziribert, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46932ac57a7f46b1b2ed3db906f47fdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1919 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3af4e392517748efa86d40d00f87e519",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 01:40, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.388600</td>\n",
       "      <td>0.898182</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.702479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.701400</td>\n",
       "      <td>0.731329</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.767101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.382300</td>\n",
       "      <td>0.710537</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.766025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.181000</td>\n",
       "      <td>0.721491</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.769948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.082400</td>\n",
       "      <td>0.773198</td>\n",
       "      <td>0.785417</td>\n",
       "      <td>0.784778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.043500</td>\n",
       "      <td>0.887003</td>\n",
       "      <td>0.789583</td>\n",
       "      <td>0.789380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.016900</td>\n",
       "      <td>0.961218</td>\n",
       "      <td>0.795833</td>\n",
       "      <td>0.795368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.013800</td>\n",
       "      <td>1.040312</td>\n",
       "      <td>0.789583</td>\n",
       "      <td>0.789597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.010700</td>\n",
       "      <td>1.019923</td>\n",
       "      <td>0.806250</td>\n",
       "      <td>0.806102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.007900</td>\n",
       "      <td>1.035478</td>\n",
       "      <td>0.810417</td>\n",
       "      <td>0.810724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.006200</td>\n",
       "      <td>1.019297</td>\n",
       "      <td>0.806250</td>\n",
       "      <td>0.805906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>1.047588</td>\n",
       "      <td>0.802083</td>\n",
       "      <td>0.802272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>1.030076</td>\n",
       "      <td>0.810417</td>\n",
       "      <td>0.811180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.052091</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.816713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>1.067967</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.817066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>1.082863</td>\n",
       "      <td>0.810417</td>\n",
       "      <td>0.810993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.093579</td>\n",
       "      <td>0.806250</td>\n",
       "      <td>0.806770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.084669</td>\n",
       "      <td>0.808333</td>\n",
       "      <td>0.808667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>1.088982</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.813434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>1.093782</td>\n",
       "      <td>0.814583</td>\n",
       "      <td>0.815224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>1.100346</td>\n",
       "      <td>0.810417</td>\n",
       "      <td>0.811094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>1.100279</td>\n",
       "      <td>0.814583</td>\n",
       "      <td>0.815350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>1.101447</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.817497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>1.102415</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.817497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alger-ia/dziribert, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af159857f17d492c859114c387bd2930",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1919 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca86484b5c944c8db8daf69205def23c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 01:40, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.388600</td>\n",
       "      <td>0.898182</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.702479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.701400</td>\n",
       "      <td>0.731329</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.767101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.382300</td>\n",
       "      <td>0.710537</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.766025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.181000</td>\n",
       "      <td>0.721491</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.769948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.082400</td>\n",
       "      <td>0.773198</td>\n",
       "      <td>0.785417</td>\n",
       "      <td>0.784778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.043500</td>\n",
       "      <td>0.887003</td>\n",
       "      <td>0.789583</td>\n",
       "      <td>0.789380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.016900</td>\n",
       "      <td>0.961218</td>\n",
       "      <td>0.795833</td>\n",
       "      <td>0.795368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.013800</td>\n",
       "      <td>1.040312</td>\n",
       "      <td>0.789583</td>\n",
       "      <td>0.789597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.010700</td>\n",
       "      <td>1.019923</td>\n",
       "      <td>0.806250</td>\n",
       "      <td>0.806102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.007900</td>\n",
       "      <td>1.035478</td>\n",
       "      <td>0.810417</td>\n",
       "      <td>0.810724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.006200</td>\n",
       "      <td>1.019297</td>\n",
       "      <td>0.806250</td>\n",
       "      <td>0.805906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>1.047588</td>\n",
       "      <td>0.802083</td>\n",
       "      <td>0.802272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>1.030076</td>\n",
       "      <td>0.810417</td>\n",
       "      <td>0.811180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.052091</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.816713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>1.067967</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.817066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>1.082863</td>\n",
       "      <td>0.810417</td>\n",
       "      <td>0.810993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.093579</td>\n",
       "      <td>0.806250</td>\n",
       "      <td>0.806770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.084669</td>\n",
       "      <td>0.808333</td>\n",
       "      <td>0.808667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>1.088982</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.813434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>1.093782</td>\n",
       "      <td>0.814583</td>\n",
       "      <td>0.815224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>1.100346</td>\n",
       "      <td>0.810417</td>\n",
       "      <td>0.811094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>1.100279</td>\n",
       "      <td>0.814583</td>\n",
       "      <td>0.815350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>1.101447</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.817497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>1.102415</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.817497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alger-ia/dziribert, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39fbbec08f5840e5b8d335d1d740678a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1919 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "402b7e0e68aa4128abc8ec93d52d2ef5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 01:40, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.419300</td>\n",
       "      <td>0.899823</td>\n",
       "      <td>0.710417</td>\n",
       "      <td>0.704427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.705900</td>\n",
       "      <td>0.718820</td>\n",
       "      <td>0.756250</td>\n",
       "      <td>0.756550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.367100</td>\n",
       "      <td>0.741376</td>\n",
       "      <td>0.737500</td>\n",
       "      <td>0.736683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.206600</td>\n",
       "      <td>0.730282</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.791146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.082300</td>\n",
       "      <td>0.818778</td>\n",
       "      <td>0.802083</td>\n",
       "      <td>0.801412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.038600</td>\n",
       "      <td>0.971719</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.772376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.024200</td>\n",
       "      <td>1.186690</td>\n",
       "      <td>0.760417</td>\n",
       "      <td>0.756006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.026000</td>\n",
       "      <td>1.178724</td>\n",
       "      <td>0.762500</td>\n",
       "      <td>0.761724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.010600</td>\n",
       "      <td>1.025190</td>\n",
       "      <td>0.797917</td>\n",
       "      <td>0.797083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.012400</td>\n",
       "      <td>1.057452</td>\n",
       "      <td>0.789583</td>\n",
       "      <td>0.789569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.007400</td>\n",
       "      <td>1.084550</td>\n",
       "      <td>0.802083</td>\n",
       "      <td>0.799436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.005900</td>\n",
       "      <td>1.065896</td>\n",
       "      <td>0.808333</td>\n",
       "      <td>0.807738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.193064</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.783103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>1.122834</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.799324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.006300</td>\n",
       "      <td>1.077934</td>\n",
       "      <td>0.810417</td>\n",
       "      <td>0.809346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>1.112042</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.799170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>1.149402</td>\n",
       "      <td>0.804167</td>\n",
       "      <td>0.802585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.176776</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.798983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>1.175744</td>\n",
       "      <td>0.795833</td>\n",
       "      <td>0.794959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>1.165088</td>\n",
       "      <td>0.795833</td>\n",
       "      <td>0.795013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.187774</td>\n",
       "      <td>0.795833</td>\n",
       "      <td>0.795521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>1.190679</td>\n",
       "      <td>0.793750</td>\n",
       "      <td>0.793158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>1.183475</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.799065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>1.181956</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.798975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alger-ia/dziribert, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09d1896fcd6f43198979b1af5827732e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1919 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19bbc3bd614a4a8eb9eb3fd592b75897",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 01:39, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.419300</td>\n",
       "      <td>0.899823</td>\n",
       "      <td>0.710417</td>\n",
       "      <td>0.704427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.705900</td>\n",
       "      <td>0.718820</td>\n",
       "      <td>0.756250</td>\n",
       "      <td>0.756550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.367100</td>\n",
       "      <td>0.741376</td>\n",
       "      <td>0.737500</td>\n",
       "      <td>0.736683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.206600</td>\n",
       "      <td>0.730282</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.791146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.082300</td>\n",
       "      <td>0.818778</td>\n",
       "      <td>0.802083</td>\n",
       "      <td>0.801412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.038600</td>\n",
       "      <td>0.971719</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.772376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.024200</td>\n",
       "      <td>1.186690</td>\n",
       "      <td>0.760417</td>\n",
       "      <td>0.756006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.026000</td>\n",
       "      <td>1.178724</td>\n",
       "      <td>0.762500</td>\n",
       "      <td>0.761724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.010600</td>\n",
       "      <td>1.025190</td>\n",
       "      <td>0.797917</td>\n",
       "      <td>0.797083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.012400</td>\n",
       "      <td>1.057452</td>\n",
       "      <td>0.789583</td>\n",
       "      <td>0.789569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.007400</td>\n",
       "      <td>1.084550</td>\n",
       "      <td>0.802083</td>\n",
       "      <td>0.799436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.005900</td>\n",
       "      <td>1.065896</td>\n",
       "      <td>0.808333</td>\n",
       "      <td>0.807738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.193064</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.783103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>1.122834</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.799324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.006300</td>\n",
       "      <td>1.077934</td>\n",
       "      <td>0.810417</td>\n",
       "      <td>0.809346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>1.112042</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.799170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>1.149402</td>\n",
       "      <td>0.804167</td>\n",
       "      <td>0.802585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.176776</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.798983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>1.175744</td>\n",
       "      <td>0.795833</td>\n",
       "      <td>0.794959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>1.165088</td>\n",
       "      <td>0.795833</td>\n",
       "      <td>0.795013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.187774</td>\n",
       "      <td>0.795833</td>\n",
       "      <td>0.795521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>1.190679</td>\n",
       "      <td>0.793750</td>\n",
       "      <td>0.793158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>1.183475</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.799065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>1.181956</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.798975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alger-ia/dziribert, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45a5999a9bbe42228a18c2369b64fc8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1919 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e81a43d534354fd5ab554d054d999921",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 01:39, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.419300</td>\n",
       "      <td>0.899823</td>\n",
       "      <td>0.710417</td>\n",
       "      <td>0.704427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.705900</td>\n",
       "      <td>0.718820</td>\n",
       "      <td>0.756250</td>\n",
       "      <td>0.756550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.367100</td>\n",
       "      <td>0.741376</td>\n",
       "      <td>0.737500</td>\n",
       "      <td>0.736683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.206600</td>\n",
       "      <td>0.730282</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.791146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.082300</td>\n",
       "      <td>0.818778</td>\n",
       "      <td>0.802083</td>\n",
       "      <td>0.801412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.038600</td>\n",
       "      <td>0.971719</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.772376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.024200</td>\n",
       "      <td>1.186690</td>\n",
       "      <td>0.760417</td>\n",
       "      <td>0.756006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.026000</td>\n",
       "      <td>1.178724</td>\n",
       "      <td>0.762500</td>\n",
       "      <td>0.761724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.010600</td>\n",
       "      <td>1.025190</td>\n",
       "      <td>0.797917</td>\n",
       "      <td>0.797083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.012400</td>\n",
       "      <td>1.057452</td>\n",
       "      <td>0.789583</td>\n",
       "      <td>0.789569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.007400</td>\n",
       "      <td>1.084550</td>\n",
       "      <td>0.802083</td>\n",
       "      <td>0.799436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.005900</td>\n",
       "      <td>1.065896</td>\n",
       "      <td>0.808333</td>\n",
       "      <td>0.807738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.193064</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.783103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>1.122834</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.799324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.006300</td>\n",
       "      <td>1.077934</td>\n",
       "      <td>0.810417</td>\n",
       "      <td>0.809346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>1.112042</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.799170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>1.149402</td>\n",
       "      <td>0.804167</td>\n",
       "      <td>0.802585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.176776</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.798983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>1.175744</td>\n",
       "      <td>0.795833</td>\n",
       "      <td>0.794959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>1.165088</td>\n",
       "      <td>0.795833</td>\n",
       "      <td>0.795013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.187774</td>\n",
       "      <td>0.795833</td>\n",
       "      <td>0.795521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>1.190679</td>\n",
       "      <td>0.793750</td>\n",
       "      <td>0.793158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>1.183475</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.799065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>1.181956</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.798975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alger-ia/dziribert, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad6f34572f4b4088807ce1f55e1dd557",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1919 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0fe50113bf74ddaaa97b045c8b310c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 01:38, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>0.939757</td>\n",
       "      <td>0.691667</td>\n",
       "      <td>0.691085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.637600</td>\n",
       "      <td>0.807879</td>\n",
       "      <td>0.735417</td>\n",
       "      <td>0.737532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.369900</td>\n",
       "      <td>0.777808</td>\n",
       "      <td>0.756250</td>\n",
       "      <td>0.760976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.170100</td>\n",
       "      <td>0.862941</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.752794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.072200</td>\n",
       "      <td>0.892245</td>\n",
       "      <td>0.777083</td>\n",
       "      <td>0.781730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.052100</td>\n",
       "      <td>1.030017</td>\n",
       "      <td>0.762500</td>\n",
       "      <td>0.759135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.022000</td>\n",
       "      <td>1.105217</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.765829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.020400</td>\n",
       "      <td>1.158355</td>\n",
       "      <td>0.760417</td>\n",
       "      <td>0.765424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.015400</td>\n",
       "      <td>1.217930</td>\n",
       "      <td>0.764583</td>\n",
       "      <td>0.765493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.012700</td>\n",
       "      <td>1.241812</td>\n",
       "      <td>0.768750</td>\n",
       "      <td>0.771924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.011100</td>\n",
       "      <td>1.300799</td>\n",
       "      <td>0.752083</td>\n",
       "      <td>0.757741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>1.368933</td>\n",
       "      <td>0.737500</td>\n",
       "      <td>0.741772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>1.274969</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.778810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.007900</td>\n",
       "      <td>1.300143</td>\n",
       "      <td>0.777083</td>\n",
       "      <td>0.779227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>1.327700</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.774511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>1.346146</td>\n",
       "      <td>0.762500</td>\n",
       "      <td>0.764914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.005700</td>\n",
       "      <td>1.360457</td>\n",
       "      <td>0.764583</td>\n",
       "      <td>0.768342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>1.343524</td>\n",
       "      <td>0.772917</td>\n",
       "      <td>0.778029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.341810</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.775082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.345457</td>\n",
       "      <td>0.772917</td>\n",
       "      <td>0.777057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>1.343415</td>\n",
       "      <td>0.772917</td>\n",
       "      <td>0.776928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>1.344257</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.775010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.348589</td>\n",
       "      <td>0.768750</td>\n",
       "      <td>0.772897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>1.350347</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.771122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alger-ia/dziribert, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23f6c9a778d44bf0a825d11110d7c58c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1919 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd59821279e0415792bfc39f6b578db6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 01:41, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>0.939757</td>\n",
       "      <td>0.691667</td>\n",
       "      <td>0.691085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.637600</td>\n",
       "      <td>0.807879</td>\n",
       "      <td>0.735417</td>\n",
       "      <td>0.737532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.369900</td>\n",
       "      <td>0.777808</td>\n",
       "      <td>0.756250</td>\n",
       "      <td>0.760976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.170100</td>\n",
       "      <td>0.862941</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.752794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.072200</td>\n",
       "      <td>0.892245</td>\n",
       "      <td>0.777083</td>\n",
       "      <td>0.781730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.052100</td>\n",
       "      <td>1.030017</td>\n",
       "      <td>0.762500</td>\n",
       "      <td>0.759135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.022000</td>\n",
       "      <td>1.105217</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.765829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.020400</td>\n",
       "      <td>1.158355</td>\n",
       "      <td>0.760417</td>\n",
       "      <td>0.765424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.015400</td>\n",
       "      <td>1.217930</td>\n",
       "      <td>0.764583</td>\n",
       "      <td>0.765493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.012700</td>\n",
       "      <td>1.241812</td>\n",
       "      <td>0.768750</td>\n",
       "      <td>0.771924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.011100</td>\n",
       "      <td>1.300799</td>\n",
       "      <td>0.752083</td>\n",
       "      <td>0.757741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>1.368933</td>\n",
       "      <td>0.737500</td>\n",
       "      <td>0.741772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>1.274969</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.778810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.007900</td>\n",
       "      <td>1.300143</td>\n",
       "      <td>0.777083</td>\n",
       "      <td>0.779227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>1.327700</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.774511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>1.346146</td>\n",
       "      <td>0.762500</td>\n",
       "      <td>0.764914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.005700</td>\n",
       "      <td>1.360457</td>\n",
       "      <td>0.764583</td>\n",
       "      <td>0.768342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>1.343524</td>\n",
       "      <td>0.772917</td>\n",
       "      <td>0.778029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.341810</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.775082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.345457</td>\n",
       "      <td>0.772917</td>\n",
       "      <td>0.777057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>1.343415</td>\n",
       "      <td>0.772917</td>\n",
       "      <td>0.776928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>1.344257</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.775010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.348589</td>\n",
       "      <td>0.768750</td>\n",
       "      <td>0.772897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>1.350347</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.771122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alger-ia/dziribert, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "485ee412c4a44899b423e8f48b1a7e5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1919 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ae13b569c9441f985c6220984954e70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 01:39, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>0.939757</td>\n",
       "      <td>0.691667</td>\n",
       "      <td>0.691085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.637600</td>\n",
       "      <td>0.807879</td>\n",
       "      <td>0.735417</td>\n",
       "      <td>0.737532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.369900</td>\n",
       "      <td>0.777808</td>\n",
       "      <td>0.756250</td>\n",
       "      <td>0.760976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.170100</td>\n",
       "      <td>0.862941</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.752794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.072200</td>\n",
       "      <td>0.892245</td>\n",
       "      <td>0.777083</td>\n",
       "      <td>0.781730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.052100</td>\n",
       "      <td>1.030017</td>\n",
       "      <td>0.762500</td>\n",
       "      <td>0.759135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.022000</td>\n",
       "      <td>1.105217</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.765829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.020400</td>\n",
       "      <td>1.158355</td>\n",
       "      <td>0.760417</td>\n",
       "      <td>0.765424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.015400</td>\n",
       "      <td>1.217930</td>\n",
       "      <td>0.764583</td>\n",
       "      <td>0.765493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.012700</td>\n",
       "      <td>1.241812</td>\n",
       "      <td>0.768750</td>\n",
       "      <td>0.771924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.011100</td>\n",
       "      <td>1.300799</td>\n",
       "      <td>0.752083</td>\n",
       "      <td>0.757741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>1.368933</td>\n",
       "      <td>0.737500</td>\n",
       "      <td>0.741772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>1.274969</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.778810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.007900</td>\n",
       "      <td>1.300143</td>\n",
       "      <td>0.777083</td>\n",
       "      <td>0.779227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>1.327700</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.774511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>1.346146</td>\n",
       "      <td>0.762500</td>\n",
       "      <td>0.764914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.005700</td>\n",
       "      <td>1.360457</td>\n",
       "      <td>0.764583</td>\n",
       "      <td>0.768342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>1.343524</td>\n",
       "      <td>0.772917</td>\n",
       "      <td>0.778029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.341810</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.775082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.345457</td>\n",
       "      <td>0.772917</td>\n",
       "      <td>0.777057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>1.343415</td>\n",
       "      <td>0.772917</td>\n",
       "      <td>0.776928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>1.344257</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.775010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.348589</td>\n",
       "      <td>0.768750</td>\n",
       "      <td>0.772897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>1.350347</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.771122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Tweet', 'label'],\n",
       "        num_rows: 1919\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Tweet', 'label'],\n",
       "        num_rows: 480\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SI2M-Lab/DarijaBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SI2M-Lab/DarijaBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51b5f597582e4cefaf51d2e1a7936d89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1919 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e307ca2c2d614ed5b114643ababd0fad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 01:44, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.536600</td>\n",
       "      <td>1.014449</td>\n",
       "      <td>0.647917</td>\n",
       "      <td>0.648209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.769500</td>\n",
       "      <td>0.812650</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.735025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.471700</td>\n",
       "      <td>0.843040</td>\n",
       "      <td>0.737500</td>\n",
       "      <td>0.735310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.288700</td>\n",
       "      <td>0.772175</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.749759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.168300</td>\n",
       "      <td>0.936126</td>\n",
       "      <td>0.737500</td>\n",
       "      <td>0.734853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.080100</td>\n",
       "      <td>0.975672</td>\n",
       "      <td>0.747917</td>\n",
       "      <td>0.744049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.039500</td>\n",
       "      <td>1.101530</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>0.736467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.027800</td>\n",
       "      <td>1.139319</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>0.780749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.030800</td>\n",
       "      <td>1.239547</td>\n",
       "      <td>0.754167</td>\n",
       "      <td>0.752543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.017800</td>\n",
       "      <td>1.184533</td>\n",
       "      <td>0.768750</td>\n",
       "      <td>0.770647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.021000</td>\n",
       "      <td>1.144464</td>\n",
       "      <td>0.789583</td>\n",
       "      <td>0.791367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.011900</td>\n",
       "      <td>1.252060</td>\n",
       "      <td>0.760417</td>\n",
       "      <td>0.760529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>1.235083</td>\n",
       "      <td>0.758333</td>\n",
       "      <td>0.757809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.006100</td>\n",
       "      <td>1.382425</td>\n",
       "      <td>0.758333</td>\n",
       "      <td>0.758963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.009700</td>\n",
       "      <td>1.238734</td>\n",
       "      <td>0.768750</td>\n",
       "      <td>0.767028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.256788</td>\n",
       "      <td>0.787500</td>\n",
       "      <td>0.787341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>1.262553</td>\n",
       "      <td>0.777083</td>\n",
       "      <td>0.775928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>1.268885</td>\n",
       "      <td>0.785417</td>\n",
       "      <td>0.784185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>1.278095</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.782663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>1.281967</td>\n",
       "      <td>0.779167</td>\n",
       "      <td>0.778128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>1.267466</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.782529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>1.250916</td>\n",
       "      <td>0.785417</td>\n",
       "      <td>0.785670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>1.254306</td>\n",
       "      <td>0.785417</td>\n",
       "      <td>0.785284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>1.256140</td>\n",
       "      <td>0.785417</td>\n",
       "      <td>0.785284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SI2M-Lab/DarijaBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SI2M-Lab/DarijaBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99a25a884843456a898b6d9b16564244",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1919 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ed2e1b830344e799d6d8f2fd9575eba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 01:44, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.536600</td>\n",
       "      <td>1.014449</td>\n",
       "      <td>0.647917</td>\n",
       "      <td>0.648209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.769500</td>\n",
       "      <td>0.812650</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.735025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.471700</td>\n",
       "      <td>0.843040</td>\n",
       "      <td>0.737500</td>\n",
       "      <td>0.735310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.288700</td>\n",
       "      <td>0.772175</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.749759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.168300</td>\n",
       "      <td>0.936126</td>\n",
       "      <td>0.737500</td>\n",
       "      <td>0.734853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.080100</td>\n",
       "      <td>0.975672</td>\n",
       "      <td>0.747917</td>\n",
       "      <td>0.744049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.039500</td>\n",
       "      <td>1.101530</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>0.736467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.027800</td>\n",
       "      <td>1.139319</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>0.780749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.030800</td>\n",
       "      <td>1.239547</td>\n",
       "      <td>0.754167</td>\n",
       "      <td>0.752543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.017800</td>\n",
       "      <td>1.184533</td>\n",
       "      <td>0.768750</td>\n",
       "      <td>0.770647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.021000</td>\n",
       "      <td>1.144464</td>\n",
       "      <td>0.789583</td>\n",
       "      <td>0.791367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.011900</td>\n",
       "      <td>1.252060</td>\n",
       "      <td>0.760417</td>\n",
       "      <td>0.760529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>1.235083</td>\n",
       "      <td>0.758333</td>\n",
       "      <td>0.757809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.006100</td>\n",
       "      <td>1.382425</td>\n",
       "      <td>0.758333</td>\n",
       "      <td>0.758963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.009700</td>\n",
       "      <td>1.238734</td>\n",
       "      <td>0.768750</td>\n",
       "      <td>0.767028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.256788</td>\n",
       "      <td>0.787500</td>\n",
       "      <td>0.787341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>1.262553</td>\n",
       "      <td>0.777083</td>\n",
       "      <td>0.775928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>1.268885</td>\n",
       "      <td>0.785417</td>\n",
       "      <td>0.784185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>1.278095</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.782663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>1.281967</td>\n",
       "      <td>0.779167</td>\n",
       "      <td>0.778128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>1.267466</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.782529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>1.250916</td>\n",
       "      <td>0.785417</td>\n",
       "      <td>0.785670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>1.254306</td>\n",
       "      <td>0.785417</td>\n",
       "      <td>0.785284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>1.256140</td>\n",
       "      <td>0.785417</td>\n",
       "      <td>0.785284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SI2M-Lab/DarijaBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SI2M-Lab/DarijaBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a52239c43853430aac0b89a6cd56886f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1919 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a77133751e1481b80894bea332129b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 01:44, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.536600</td>\n",
       "      <td>1.014449</td>\n",
       "      <td>0.647917</td>\n",
       "      <td>0.648209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.769500</td>\n",
       "      <td>0.812650</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.735025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.471700</td>\n",
       "      <td>0.843040</td>\n",
       "      <td>0.737500</td>\n",
       "      <td>0.735310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.288700</td>\n",
       "      <td>0.772175</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.749759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.168300</td>\n",
       "      <td>0.936126</td>\n",
       "      <td>0.737500</td>\n",
       "      <td>0.734853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.080100</td>\n",
       "      <td>0.975672</td>\n",
       "      <td>0.747917</td>\n",
       "      <td>0.744049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.039500</td>\n",
       "      <td>1.101530</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>0.736467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.027800</td>\n",
       "      <td>1.139319</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>0.780749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.030800</td>\n",
       "      <td>1.239547</td>\n",
       "      <td>0.754167</td>\n",
       "      <td>0.752543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.017800</td>\n",
       "      <td>1.184533</td>\n",
       "      <td>0.768750</td>\n",
       "      <td>0.770647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.021000</td>\n",
       "      <td>1.144464</td>\n",
       "      <td>0.789583</td>\n",
       "      <td>0.791367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.011900</td>\n",
       "      <td>1.252060</td>\n",
       "      <td>0.760417</td>\n",
       "      <td>0.760529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>1.235083</td>\n",
       "      <td>0.758333</td>\n",
       "      <td>0.757809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.006100</td>\n",
       "      <td>1.382425</td>\n",
       "      <td>0.758333</td>\n",
       "      <td>0.758963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.009700</td>\n",
       "      <td>1.238734</td>\n",
       "      <td>0.768750</td>\n",
       "      <td>0.767028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.256788</td>\n",
       "      <td>0.787500</td>\n",
       "      <td>0.787341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>1.262553</td>\n",
       "      <td>0.777083</td>\n",
       "      <td>0.775928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>1.268885</td>\n",
       "      <td>0.785417</td>\n",
       "      <td>0.784185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>1.278095</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.782663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>1.281967</td>\n",
       "      <td>0.779167</td>\n",
       "      <td>0.778128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>1.267466</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.782529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>1.250916</td>\n",
       "      <td>0.785417</td>\n",
       "      <td>0.785670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>1.254306</td>\n",
       "      <td>0.785417</td>\n",
       "      <td>0.785284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>1.256140</td>\n",
       "      <td>0.785417</td>\n",
       "      <td>0.785284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SI2M-Lab/DarijaBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SI2M-Lab/DarijaBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26422f4b227c4b059a081e2aa98b8d60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1919 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35be73764a7543c3a8e3f40f70361953",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 01:45, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.522400</td>\n",
       "      <td>1.032828</td>\n",
       "      <td>0.639583</td>\n",
       "      <td>0.626189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.817400</td>\n",
       "      <td>0.798223</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>0.713822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.469100</td>\n",
       "      <td>0.798380</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>0.735470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.278600</td>\n",
       "      <td>0.903616</td>\n",
       "      <td>0.754167</td>\n",
       "      <td>0.750076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.149300</td>\n",
       "      <td>0.968609</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.743324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.068600</td>\n",
       "      <td>1.041673</td>\n",
       "      <td>0.756250</td>\n",
       "      <td>0.753497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.035300</td>\n",
       "      <td>1.256595</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.745889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.029300</td>\n",
       "      <td>1.231501</td>\n",
       "      <td>0.752083</td>\n",
       "      <td>0.751178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.016000</td>\n",
       "      <td>1.213194</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.773196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.016200</td>\n",
       "      <td>1.379692</td>\n",
       "      <td>0.756250</td>\n",
       "      <td>0.753274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.027300</td>\n",
       "      <td>1.330124</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.763392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.011600</td>\n",
       "      <td>1.355687</td>\n",
       "      <td>0.764583</td>\n",
       "      <td>0.761499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.007400</td>\n",
       "      <td>1.340588</td>\n",
       "      <td>0.764583</td>\n",
       "      <td>0.762821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>1.468635</td>\n",
       "      <td>0.762500</td>\n",
       "      <td>0.757269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>1.518669</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.744478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>1.382909</td>\n",
       "      <td>0.779167</td>\n",
       "      <td>0.775619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.386723</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>0.777991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>1.361539</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.781794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>1.352412</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.780898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.362480</td>\n",
       "      <td>0.795833</td>\n",
       "      <td>0.793818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>1.374506</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.766975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.364929</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.779881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>1.369080</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.779881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>1.369079</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.779942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SI2M-Lab/DarijaBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SI2M-Lab/DarijaBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65fd17cf172e4315ab0bdc3d0ac2fca0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1919 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7eac5a3401c14dc4a176dca841250236",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 01:44, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.522400</td>\n",
       "      <td>1.032828</td>\n",
       "      <td>0.639583</td>\n",
       "      <td>0.626189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.817400</td>\n",
       "      <td>0.798223</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>0.713822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.469100</td>\n",
       "      <td>0.798380</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>0.735470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.278600</td>\n",
       "      <td>0.903616</td>\n",
       "      <td>0.754167</td>\n",
       "      <td>0.750076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.149300</td>\n",
       "      <td>0.968609</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.743324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.068600</td>\n",
       "      <td>1.041673</td>\n",
       "      <td>0.756250</td>\n",
       "      <td>0.753497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.035300</td>\n",
       "      <td>1.256595</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.745889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.029300</td>\n",
       "      <td>1.231501</td>\n",
       "      <td>0.752083</td>\n",
       "      <td>0.751178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.016000</td>\n",
       "      <td>1.213194</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.773196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.016200</td>\n",
       "      <td>1.379692</td>\n",
       "      <td>0.756250</td>\n",
       "      <td>0.753274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.027300</td>\n",
       "      <td>1.330124</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.763392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.011600</td>\n",
       "      <td>1.355687</td>\n",
       "      <td>0.764583</td>\n",
       "      <td>0.761499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.007400</td>\n",
       "      <td>1.340588</td>\n",
       "      <td>0.764583</td>\n",
       "      <td>0.762821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>1.468635</td>\n",
       "      <td>0.762500</td>\n",
       "      <td>0.757269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>1.518669</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.744478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>1.382909</td>\n",
       "      <td>0.779167</td>\n",
       "      <td>0.775619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.386723</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>0.777991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>1.361539</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.781794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>1.352412</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.780898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.362480</td>\n",
       "      <td>0.795833</td>\n",
       "      <td>0.793818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>1.374506</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.766975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.364929</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.779881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>1.369080</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.779881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>1.369079</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.779942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SI2M-Lab/DarijaBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SI2M-Lab/DarijaBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c907c8aee374e84843449aba0486484",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1919 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f367bc3c07345e2ae57f40c0e13bf59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 01:44, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.522400</td>\n",
       "      <td>1.032828</td>\n",
       "      <td>0.639583</td>\n",
       "      <td>0.626189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.817400</td>\n",
       "      <td>0.798223</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>0.713822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.469100</td>\n",
       "      <td>0.798380</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>0.735470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.278600</td>\n",
       "      <td>0.903616</td>\n",
       "      <td>0.754167</td>\n",
       "      <td>0.750076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.149300</td>\n",
       "      <td>0.968609</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.743324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.068600</td>\n",
       "      <td>1.041673</td>\n",
       "      <td>0.756250</td>\n",
       "      <td>0.753497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.035300</td>\n",
       "      <td>1.256595</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.745889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.029300</td>\n",
       "      <td>1.231501</td>\n",
       "      <td>0.752083</td>\n",
       "      <td>0.751178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.016000</td>\n",
       "      <td>1.213194</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.773196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.016200</td>\n",
       "      <td>1.379692</td>\n",
       "      <td>0.756250</td>\n",
       "      <td>0.753274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.027300</td>\n",
       "      <td>1.330124</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.763392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.011600</td>\n",
       "      <td>1.355687</td>\n",
       "      <td>0.764583</td>\n",
       "      <td>0.761499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.007400</td>\n",
       "      <td>1.340588</td>\n",
       "      <td>0.764583</td>\n",
       "      <td>0.762821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>1.468635</td>\n",
       "      <td>0.762500</td>\n",
       "      <td>0.757269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>1.518669</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.744478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>1.382909</td>\n",
       "      <td>0.779167</td>\n",
       "      <td>0.775619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.386723</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>0.777991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>1.361539</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.781794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>1.352412</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.780898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.362480</td>\n",
       "      <td>0.795833</td>\n",
       "      <td>0.793818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>1.374506</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.766975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.364929</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.779881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>1.369080</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.779881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>1.369079</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.779942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SI2M-Lab/DarijaBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SI2M-Lab/DarijaBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "517889d5cf3549769fc0438ba0c77801",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1919 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8a42f5edb5b4c3e935adb90a17e6f29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 01:44, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.531300</td>\n",
       "      <td>1.025934</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.678755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.788600</td>\n",
       "      <td>0.842168</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.731910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.442900</td>\n",
       "      <td>0.804550</td>\n",
       "      <td>0.754167</td>\n",
       "      <td>0.762404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.243700</td>\n",
       "      <td>0.917342</td>\n",
       "      <td>0.745833</td>\n",
       "      <td>0.741507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.118000</td>\n",
       "      <td>1.001361</td>\n",
       "      <td>0.745833</td>\n",
       "      <td>0.751801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.072300</td>\n",
       "      <td>1.059842</td>\n",
       "      <td>0.747917</td>\n",
       "      <td>0.752757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.045100</td>\n",
       "      <td>1.190081</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.737599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.055400</td>\n",
       "      <td>1.137125</td>\n",
       "      <td>0.762500</td>\n",
       "      <td>0.768614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.022400</td>\n",
       "      <td>1.227654</td>\n",
       "      <td>0.752083</td>\n",
       "      <td>0.756656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.016100</td>\n",
       "      <td>1.243558</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.757010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.018000</td>\n",
       "      <td>1.339525</td>\n",
       "      <td>0.758333</td>\n",
       "      <td>0.766767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.007300</td>\n",
       "      <td>1.317080</td>\n",
       "      <td>0.762500</td>\n",
       "      <td>0.770072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>1.284113</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>0.786513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.010700</td>\n",
       "      <td>1.333529</td>\n",
       "      <td>0.779167</td>\n",
       "      <td>0.784410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>1.378324</td>\n",
       "      <td>0.756250</td>\n",
       "      <td>0.763131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.006100</td>\n",
       "      <td>1.384326</td>\n",
       "      <td>0.777083</td>\n",
       "      <td>0.784003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.007400</td>\n",
       "      <td>1.323826</td>\n",
       "      <td>0.785417</td>\n",
       "      <td>0.792029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>1.370934</td>\n",
       "      <td>0.768750</td>\n",
       "      <td>0.775553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.006500</td>\n",
       "      <td>1.338478</td>\n",
       "      <td>0.764583</td>\n",
       "      <td>0.773263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>1.367128</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.774816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>1.366082</td>\n",
       "      <td>0.764583</td>\n",
       "      <td>0.772188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>1.369596</td>\n",
       "      <td>0.768750</td>\n",
       "      <td>0.777034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>1.365124</td>\n",
       "      <td>0.772917</td>\n",
       "      <td>0.780605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>1.365163</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.778871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SI2M-Lab/DarijaBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SI2M-Lab/DarijaBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ba1de9abf0b43cbbd2f68ccde1a7aa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1919 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1808c7e0a42643e99434bb216d4c016b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 01:44, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.531300</td>\n",
       "      <td>1.025934</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.678755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.788600</td>\n",
       "      <td>0.842168</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.731910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.442900</td>\n",
       "      <td>0.804550</td>\n",
       "      <td>0.754167</td>\n",
       "      <td>0.762404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.243700</td>\n",
       "      <td>0.917342</td>\n",
       "      <td>0.745833</td>\n",
       "      <td>0.741507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.118000</td>\n",
       "      <td>1.001361</td>\n",
       "      <td>0.745833</td>\n",
       "      <td>0.751801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.072300</td>\n",
       "      <td>1.059842</td>\n",
       "      <td>0.747917</td>\n",
       "      <td>0.752757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.045100</td>\n",
       "      <td>1.190081</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.737599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.055400</td>\n",
       "      <td>1.137125</td>\n",
       "      <td>0.762500</td>\n",
       "      <td>0.768614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.022400</td>\n",
       "      <td>1.227654</td>\n",
       "      <td>0.752083</td>\n",
       "      <td>0.756656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.016100</td>\n",
       "      <td>1.243558</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.757010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.018000</td>\n",
       "      <td>1.339525</td>\n",
       "      <td>0.758333</td>\n",
       "      <td>0.766767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.007300</td>\n",
       "      <td>1.317080</td>\n",
       "      <td>0.762500</td>\n",
       "      <td>0.770072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>1.284113</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>0.786513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.010700</td>\n",
       "      <td>1.333529</td>\n",
       "      <td>0.779167</td>\n",
       "      <td>0.784410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>1.378324</td>\n",
       "      <td>0.756250</td>\n",
       "      <td>0.763131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.006100</td>\n",
       "      <td>1.384326</td>\n",
       "      <td>0.777083</td>\n",
       "      <td>0.784003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.007400</td>\n",
       "      <td>1.323826</td>\n",
       "      <td>0.785417</td>\n",
       "      <td>0.792029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>1.370934</td>\n",
       "      <td>0.768750</td>\n",
       "      <td>0.775553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.006500</td>\n",
       "      <td>1.338478</td>\n",
       "      <td>0.764583</td>\n",
       "      <td>0.773263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>1.367128</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.774816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>1.366082</td>\n",
       "      <td>0.764583</td>\n",
       "      <td>0.772188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>1.369596</td>\n",
       "      <td>0.768750</td>\n",
       "      <td>0.777034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>1.365124</td>\n",
       "      <td>0.772917</td>\n",
       "      <td>0.780605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>1.365163</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.778871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SI2M-Lab/DarijaBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SI2M-Lab/DarijaBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91f77bef86514fb4a5560381d4543953",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1919 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8b3282486944fd4adb9d15753b21b42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 01:45, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.531300</td>\n",
       "      <td>1.025934</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.678755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.788600</td>\n",
       "      <td>0.842168</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.731910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.442900</td>\n",
       "      <td>0.804550</td>\n",
       "      <td>0.754167</td>\n",
       "      <td>0.762404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.243700</td>\n",
       "      <td>0.917342</td>\n",
       "      <td>0.745833</td>\n",
       "      <td>0.741507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.118000</td>\n",
       "      <td>1.001361</td>\n",
       "      <td>0.745833</td>\n",
       "      <td>0.751801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.072300</td>\n",
       "      <td>1.059842</td>\n",
       "      <td>0.747917</td>\n",
       "      <td>0.752757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.045100</td>\n",
       "      <td>1.190081</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.737599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.055400</td>\n",
       "      <td>1.137125</td>\n",
       "      <td>0.762500</td>\n",
       "      <td>0.768614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.022400</td>\n",
       "      <td>1.227654</td>\n",
       "      <td>0.752083</td>\n",
       "      <td>0.756656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.016100</td>\n",
       "      <td>1.243558</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.757010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.018000</td>\n",
       "      <td>1.339525</td>\n",
       "      <td>0.758333</td>\n",
       "      <td>0.766767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.007300</td>\n",
       "      <td>1.317080</td>\n",
       "      <td>0.762500</td>\n",
       "      <td>0.770072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>1.284113</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>0.786513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.010700</td>\n",
       "      <td>1.333529</td>\n",
       "      <td>0.779167</td>\n",
       "      <td>0.784410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>1.378324</td>\n",
       "      <td>0.756250</td>\n",
       "      <td>0.763131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.006100</td>\n",
       "      <td>1.384326</td>\n",
       "      <td>0.777083</td>\n",
       "      <td>0.784003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.007400</td>\n",
       "      <td>1.323826</td>\n",
       "      <td>0.785417</td>\n",
       "      <td>0.792029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>1.370934</td>\n",
       "      <td>0.768750</td>\n",
       "      <td>0.775553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.006500</td>\n",
       "      <td>1.338478</td>\n",
       "      <td>0.764583</td>\n",
       "      <td>0.773263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>1.367128</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.774816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>1.366082</td>\n",
       "      <td>0.764583</td>\n",
       "      <td>0.772188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>1.369596</td>\n",
       "      <td>0.768750</td>\n",
       "      <td>0.777034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>1.365124</td>\n",
       "      <td>0.772917</td>\n",
       "      <td>0.780605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>1.365163</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.778871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Tweet', 'label'],\n",
       "        num_rows: 1919\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Tweet', 'label'],\n",
       "        num_rows: 480\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorRoBERTa, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at otmangi/MorRoBERTa and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee94b544ee8248a8980793299045f83e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1919 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7058342386dc42929f40dc70afde3b53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 00:56, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.668800</td>\n",
       "      <td>1.206065</td>\n",
       "      <td>0.591667</td>\n",
       "      <td>0.592985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.955500</td>\n",
       "      <td>0.947075</td>\n",
       "      <td>0.685417</td>\n",
       "      <td>0.688493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.580700</td>\n",
       "      <td>0.900047</td>\n",
       "      <td>0.714583</td>\n",
       "      <td>0.717614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.332700</td>\n",
       "      <td>0.888587</td>\n",
       "      <td>0.747917</td>\n",
       "      <td>0.750431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.178800</td>\n",
       "      <td>0.976145</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.726544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.096700</td>\n",
       "      <td>1.045437</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.729874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.053600</td>\n",
       "      <td>1.119776</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.726417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.034100</td>\n",
       "      <td>1.227630</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.735745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>1.245796</td>\n",
       "      <td>0.743750</td>\n",
       "      <td>0.746395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>1.325438</td>\n",
       "      <td>0.731250</td>\n",
       "      <td>0.732733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.012100</td>\n",
       "      <td>1.342356</td>\n",
       "      <td>0.745833</td>\n",
       "      <td>0.749856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.007900</td>\n",
       "      <td>1.371471</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>0.744876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.009100</td>\n",
       "      <td>1.368551</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>0.743851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>1.468010</td>\n",
       "      <td>0.743750</td>\n",
       "      <td>0.748298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>1.431105</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.753630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.476675</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>0.745914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.004800</td>\n",
       "      <td>1.447713</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>0.743407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>1.476513</td>\n",
       "      <td>0.743750</td>\n",
       "      <td>0.747978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>1.484947</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>0.746931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>1.460850</td>\n",
       "      <td>0.743750</td>\n",
       "      <td>0.748522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>1.459709</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>0.745945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>1.460647</td>\n",
       "      <td>0.743750</td>\n",
       "      <td>0.748068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>1.466993</td>\n",
       "      <td>0.747917</td>\n",
       "      <td>0.752542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>1.467839</td>\n",
       "      <td>0.745833</td>\n",
       "      <td>0.750568</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorRoBERTa, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at otmangi/MorRoBERTa and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e4b5a98e13a4359bf7c3158ebea3f28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1919 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b345afda796423dbf8eeea87226fd1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 00:58, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.668800</td>\n",
       "      <td>1.206065</td>\n",
       "      <td>0.591667</td>\n",
       "      <td>0.592985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.955500</td>\n",
       "      <td>0.947075</td>\n",
       "      <td>0.685417</td>\n",
       "      <td>0.688493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.580700</td>\n",
       "      <td>0.900047</td>\n",
       "      <td>0.714583</td>\n",
       "      <td>0.717614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.332700</td>\n",
       "      <td>0.888587</td>\n",
       "      <td>0.747917</td>\n",
       "      <td>0.750431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.178800</td>\n",
       "      <td>0.976145</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.726544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.096700</td>\n",
       "      <td>1.045437</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.729874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.053600</td>\n",
       "      <td>1.119776</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.726417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.034100</td>\n",
       "      <td>1.227630</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.735745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>1.245796</td>\n",
       "      <td>0.743750</td>\n",
       "      <td>0.746395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>1.325438</td>\n",
       "      <td>0.731250</td>\n",
       "      <td>0.732733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.012100</td>\n",
       "      <td>1.342356</td>\n",
       "      <td>0.745833</td>\n",
       "      <td>0.749856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.007900</td>\n",
       "      <td>1.371471</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>0.744876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.009100</td>\n",
       "      <td>1.368551</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>0.743851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>1.468010</td>\n",
       "      <td>0.743750</td>\n",
       "      <td>0.748298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>1.431105</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.753630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.476675</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>0.745914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.004800</td>\n",
       "      <td>1.447713</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>0.743407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>1.476513</td>\n",
       "      <td>0.743750</td>\n",
       "      <td>0.747978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>1.484947</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>0.746931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>1.460850</td>\n",
       "      <td>0.743750</td>\n",
       "      <td>0.748522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>1.459709</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>0.745945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>1.460647</td>\n",
       "      <td>0.743750</td>\n",
       "      <td>0.748068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>1.466993</td>\n",
       "      <td>0.747917</td>\n",
       "      <td>0.752542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>1.467839</td>\n",
       "      <td>0.745833</td>\n",
       "      <td>0.750568</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorRoBERTa, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at otmangi/MorRoBERTa and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f281c4b4e2974b0d97224ebefa47b883",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1919 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb4d9768219a44a6b146389588b60047",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 00:58, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.668800</td>\n",
       "      <td>1.206065</td>\n",
       "      <td>0.591667</td>\n",
       "      <td>0.592985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.955500</td>\n",
       "      <td>0.947075</td>\n",
       "      <td>0.685417</td>\n",
       "      <td>0.688493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.580700</td>\n",
       "      <td>0.900047</td>\n",
       "      <td>0.714583</td>\n",
       "      <td>0.717614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.332700</td>\n",
       "      <td>0.888587</td>\n",
       "      <td>0.747917</td>\n",
       "      <td>0.750431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.178800</td>\n",
       "      <td>0.976145</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.726544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.096700</td>\n",
       "      <td>1.045437</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.729874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.053600</td>\n",
       "      <td>1.119776</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.726417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.034100</td>\n",
       "      <td>1.227630</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.735745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>1.245796</td>\n",
       "      <td>0.743750</td>\n",
       "      <td>0.746395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>1.325438</td>\n",
       "      <td>0.731250</td>\n",
       "      <td>0.732733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.012100</td>\n",
       "      <td>1.342356</td>\n",
       "      <td>0.745833</td>\n",
       "      <td>0.749856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.007900</td>\n",
       "      <td>1.371471</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>0.744876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.009100</td>\n",
       "      <td>1.368551</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>0.743851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>1.468010</td>\n",
       "      <td>0.743750</td>\n",
       "      <td>0.748298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>1.431105</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.753630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.476675</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>0.745914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.004800</td>\n",
       "      <td>1.447713</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>0.743407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>1.476513</td>\n",
       "      <td>0.743750</td>\n",
       "      <td>0.747978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>1.484947</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>0.746931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>1.460850</td>\n",
       "      <td>0.743750</td>\n",
       "      <td>0.748522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>1.459709</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>0.745945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>1.460647</td>\n",
       "      <td>0.743750</td>\n",
       "      <td>0.748068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>1.466993</td>\n",
       "      <td>0.747917</td>\n",
       "      <td>0.752542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>1.467839</td>\n",
       "      <td>0.745833</td>\n",
       "      <td>0.750568</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorRoBERTa, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at otmangi/MorRoBERTa and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf5f779232ca49129d86e6d08c895833",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1919 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b4505a58f844616921343b4e84aa580",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 00:58, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.644300</td>\n",
       "      <td>1.145029</td>\n",
       "      <td>0.595833</td>\n",
       "      <td>0.580887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.971600</td>\n",
       "      <td>0.929896</td>\n",
       "      <td>0.658333</td>\n",
       "      <td>0.652369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.590800</td>\n",
       "      <td>0.874545</td>\n",
       "      <td>0.712500</td>\n",
       "      <td>0.708619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.367900</td>\n",
       "      <td>0.897956</td>\n",
       "      <td>0.710417</td>\n",
       "      <td>0.704605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.189400</td>\n",
       "      <td>0.974132</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.722739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.106300</td>\n",
       "      <td>1.053923</td>\n",
       "      <td>0.722917</td>\n",
       "      <td>0.718335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.051200</td>\n",
       "      <td>1.174000</td>\n",
       "      <td>0.712500</td>\n",
       "      <td>0.711161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.036600</td>\n",
       "      <td>1.263888</td>\n",
       "      <td>0.735417</td>\n",
       "      <td>0.733075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.030800</td>\n",
       "      <td>1.307122</td>\n",
       "      <td>0.706250</td>\n",
       "      <td>0.700270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.014300</td>\n",
       "      <td>1.366643</td>\n",
       "      <td>0.710417</td>\n",
       "      <td>0.706864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>1.383609</td>\n",
       "      <td>0.731250</td>\n",
       "      <td>0.728450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.008700</td>\n",
       "      <td>1.451110</td>\n",
       "      <td>0.720833</td>\n",
       "      <td>0.717266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>1.504927</td>\n",
       "      <td>0.722917</td>\n",
       "      <td>0.721497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>1.517307</td>\n",
       "      <td>0.720833</td>\n",
       "      <td>0.718420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.007100</td>\n",
       "      <td>1.535628</td>\n",
       "      <td>0.722917</td>\n",
       "      <td>0.720076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>1.525910</td>\n",
       "      <td>0.731250</td>\n",
       "      <td>0.727640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>1.524879</td>\n",
       "      <td>0.727083</td>\n",
       "      <td>0.724592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>1.534589</td>\n",
       "      <td>0.720833</td>\n",
       "      <td>0.717842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>1.549231</td>\n",
       "      <td>0.731250</td>\n",
       "      <td>0.727470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.552388</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.717022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>1.568980</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.729510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>1.565749</td>\n",
       "      <td>0.731250</td>\n",
       "      <td>0.727720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>1.566229</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.730176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>1.565356</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.725958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorRoBERTa, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at otmangi/MorRoBERTa and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8b6efee67d346a2bcf74531e9844545",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1919 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63fe2d24020d4d01ab2d39eb3b3bf697",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 00:58, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.644300</td>\n",
       "      <td>1.145029</td>\n",
       "      <td>0.595833</td>\n",
       "      <td>0.580887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.971600</td>\n",
       "      <td>0.929896</td>\n",
       "      <td>0.658333</td>\n",
       "      <td>0.652369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.590800</td>\n",
       "      <td>0.874545</td>\n",
       "      <td>0.712500</td>\n",
       "      <td>0.708619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.367900</td>\n",
       "      <td>0.897956</td>\n",
       "      <td>0.710417</td>\n",
       "      <td>0.704605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.189400</td>\n",
       "      <td>0.974132</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.722739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.106300</td>\n",
       "      <td>1.053923</td>\n",
       "      <td>0.722917</td>\n",
       "      <td>0.718335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.051200</td>\n",
       "      <td>1.174000</td>\n",
       "      <td>0.712500</td>\n",
       "      <td>0.711161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.036600</td>\n",
       "      <td>1.263888</td>\n",
       "      <td>0.735417</td>\n",
       "      <td>0.733075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.030800</td>\n",
       "      <td>1.307122</td>\n",
       "      <td>0.706250</td>\n",
       "      <td>0.700270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.014300</td>\n",
       "      <td>1.366643</td>\n",
       "      <td>0.710417</td>\n",
       "      <td>0.706864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>1.383609</td>\n",
       "      <td>0.731250</td>\n",
       "      <td>0.728450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.008700</td>\n",
       "      <td>1.451110</td>\n",
       "      <td>0.720833</td>\n",
       "      <td>0.717266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>1.504927</td>\n",
       "      <td>0.722917</td>\n",
       "      <td>0.721497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>1.517307</td>\n",
       "      <td>0.720833</td>\n",
       "      <td>0.718420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.007100</td>\n",
       "      <td>1.535628</td>\n",
       "      <td>0.722917</td>\n",
       "      <td>0.720076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>1.525910</td>\n",
       "      <td>0.731250</td>\n",
       "      <td>0.727640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>1.524879</td>\n",
       "      <td>0.727083</td>\n",
       "      <td>0.724592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>1.534589</td>\n",
       "      <td>0.720833</td>\n",
       "      <td>0.717842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>1.549231</td>\n",
       "      <td>0.731250</td>\n",
       "      <td>0.727470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.552388</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.717022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>1.568980</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.729510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>1.565749</td>\n",
       "      <td>0.731250</td>\n",
       "      <td>0.727720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>1.566229</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.730176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>1.565356</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.725958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorRoBERTa, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at otmangi/MorRoBERTa and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17067d83b529471abb226d9b8fe683d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1919 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42fcb991731c4e0ea217dfff1d601fe0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 00:58, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.644300</td>\n",
       "      <td>1.145029</td>\n",
       "      <td>0.595833</td>\n",
       "      <td>0.580887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.971600</td>\n",
       "      <td>0.929896</td>\n",
       "      <td>0.658333</td>\n",
       "      <td>0.652369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.590800</td>\n",
       "      <td>0.874545</td>\n",
       "      <td>0.712500</td>\n",
       "      <td>0.708619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.367900</td>\n",
       "      <td>0.897956</td>\n",
       "      <td>0.710417</td>\n",
       "      <td>0.704605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.189400</td>\n",
       "      <td>0.974132</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.722739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.106300</td>\n",
       "      <td>1.053923</td>\n",
       "      <td>0.722917</td>\n",
       "      <td>0.718335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.051200</td>\n",
       "      <td>1.174000</td>\n",
       "      <td>0.712500</td>\n",
       "      <td>0.711161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.036600</td>\n",
       "      <td>1.263888</td>\n",
       "      <td>0.735417</td>\n",
       "      <td>0.733075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.030800</td>\n",
       "      <td>1.307122</td>\n",
       "      <td>0.706250</td>\n",
       "      <td>0.700270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.014300</td>\n",
       "      <td>1.366643</td>\n",
       "      <td>0.710417</td>\n",
       "      <td>0.706864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>1.383609</td>\n",
       "      <td>0.731250</td>\n",
       "      <td>0.728450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.008700</td>\n",
       "      <td>1.451110</td>\n",
       "      <td>0.720833</td>\n",
       "      <td>0.717266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>1.504927</td>\n",
       "      <td>0.722917</td>\n",
       "      <td>0.721497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>1.517307</td>\n",
       "      <td>0.720833</td>\n",
       "      <td>0.718420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.007100</td>\n",
       "      <td>1.535628</td>\n",
       "      <td>0.722917</td>\n",
       "      <td>0.720076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>1.525910</td>\n",
       "      <td>0.731250</td>\n",
       "      <td>0.727640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>1.524879</td>\n",
       "      <td>0.727083</td>\n",
       "      <td>0.724592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>1.534589</td>\n",
       "      <td>0.720833</td>\n",
       "      <td>0.717842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>1.549231</td>\n",
       "      <td>0.731250</td>\n",
       "      <td>0.727470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.552388</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.717022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>1.568980</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.729510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>1.565749</td>\n",
       "      <td>0.731250</td>\n",
       "      <td>0.727720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>1.566229</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.730176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>1.565356</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.725958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorRoBERTa, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at otmangi/MorRoBERTa and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cb87bd664254fbcb2d0bdbfa3e3aa31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1919 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0b40298776f47508a7d122279475839",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 00:58, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.651100</td>\n",
       "      <td>1.294646</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.523719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.943600</td>\n",
       "      <td>1.074046</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.635097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.608500</td>\n",
       "      <td>1.008356</td>\n",
       "      <td>0.664583</td>\n",
       "      <td>0.669655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.317000</td>\n",
       "      <td>1.062713</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.668912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.197500</td>\n",
       "      <td>1.158361</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.671576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>1.233513</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.679361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.048100</td>\n",
       "      <td>1.317482</td>\n",
       "      <td>0.695833</td>\n",
       "      <td>0.700730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.047800</td>\n",
       "      <td>1.413756</td>\n",
       "      <td>0.670833</td>\n",
       "      <td>0.677346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.017400</td>\n",
       "      <td>1.478149</td>\n",
       "      <td>0.691667</td>\n",
       "      <td>0.694751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.019100</td>\n",
       "      <td>1.561362</td>\n",
       "      <td>0.697917</td>\n",
       "      <td>0.699337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.014100</td>\n",
       "      <td>1.583414</td>\n",
       "      <td>0.697917</td>\n",
       "      <td>0.699859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>1.661204</td>\n",
       "      <td>0.704167</td>\n",
       "      <td>0.706870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.007300</td>\n",
       "      <td>1.688307</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.685980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.010500</td>\n",
       "      <td>1.670121</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.688608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.008200</td>\n",
       "      <td>1.716196</td>\n",
       "      <td>0.695833</td>\n",
       "      <td>0.697923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>1.759590</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.677402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.007200</td>\n",
       "      <td>1.733587</td>\n",
       "      <td>0.697917</td>\n",
       "      <td>0.699977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.005900</td>\n",
       "      <td>1.733959</td>\n",
       "      <td>0.702083</td>\n",
       "      <td>0.704032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.006600</td>\n",
       "      <td>1.742666</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.702199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>1.756411</td>\n",
       "      <td>0.704167</td>\n",
       "      <td>0.706560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>1.753567</td>\n",
       "      <td>0.697917</td>\n",
       "      <td>0.699778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>1.764817</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.702954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>1.762947</td>\n",
       "      <td>0.693750</td>\n",
       "      <td>0.695604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>1.763358</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.702506</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorRoBERTa, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at otmangi/MorRoBERTa and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55dfd3d116524ace93c83569d5752e89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1919 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3765b1d8725a4f5b9d8aecad2b87cb23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 00:58, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.651100</td>\n",
       "      <td>1.294646</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.523719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.943600</td>\n",
       "      <td>1.074046</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.635097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.608500</td>\n",
       "      <td>1.008356</td>\n",
       "      <td>0.664583</td>\n",
       "      <td>0.669655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.317000</td>\n",
       "      <td>1.062713</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.668912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.197500</td>\n",
       "      <td>1.158361</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.671576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>1.233513</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.679361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.048100</td>\n",
       "      <td>1.317482</td>\n",
       "      <td>0.695833</td>\n",
       "      <td>0.700730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.047800</td>\n",
       "      <td>1.413756</td>\n",
       "      <td>0.670833</td>\n",
       "      <td>0.677346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.017400</td>\n",
       "      <td>1.478149</td>\n",
       "      <td>0.691667</td>\n",
       "      <td>0.694751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.019100</td>\n",
       "      <td>1.561362</td>\n",
       "      <td>0.697917</td>\n",
       "      <td>0.699337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.014100</td>\n",
       "      <td>1.583414</td>\n",
       "      <td>0.697917</td>\n",
       "      <td>0.699859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>1.661204</td>\n",
       "      <td>0.704167</td>\n",
       "      <td>0.706870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.007300</td>\n",
       "      <td>1.688307</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.685980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.010500</td>\n",
       "      <td>1.670121</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.688608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.008200</td>\n",
       "      <td>1.716196</td>\n",
       "      <td>0.695833</td>\n",
       "      <td>0.697923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>1.759590</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.677402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.007200</td>\n",
       "      <td>1.733587</td>\n",
       "      <td>0.697917</td>\n",
       "      <td>0.699977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.005900</td>\n",
       "      <td>1.733959</td>\n",
       "      <td>0.702083</td>\n",
       "      <td>0.704032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.006600</td>\n",
       "      <td>1.742666</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.702199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>1.756411</td>\n",
       "      <td>0.704167</td>\n",
       "      <td>0.706560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>1.753567</td>\n",
       "      <td>0.697917</td>\n",
       "      <td>0.699778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>1.764817</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.702954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>1.762947</td>\n",
       "      <td>0.693750</td>\n",
       "      <td>0.695604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>1.763358</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.702506</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorRoBERTa, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at otmangi/MorRoBERTa and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81eef9a53bbb40c29871d1d5a36c58e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1919 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db9f94f5b3f745f6a15e298a1eab09b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 00:58, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.651100</td>\n",
       "      <td>1.294646</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.523719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.943600</td>\n",
       "      <td>1.074046</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.635097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.608500</td>\n",
       "      <td>1.008356</td>\n",
       "      <td>0.664583</td>\n",
       "      <td>0.669655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.317000</td>\n",
       "      <td>1.062713</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.668912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.197500</td>\n",
       "      <td>1.158361</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.671576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>1.233513</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.679361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.048100</td>\n",
       "      <td>1.317482</td>\n",
       "      <td>0.695833</td>\n",
       "      <td>0.700730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.047800</td>\n",
       "      <td>1.413756</td>\n",
       "      <td>0.670833</td>\n",
       "      <td>0.677346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.017400</td>\n",
       "      <td>1.478149</td>\n",
       "      <td>0.691667</td>\n",
       "      <td>0.694751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.019100</td>\n",
       "      <td>1.561362</td>\n",
       "      <td>0.697917</td>\n",
       "      <td>0.699337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.014100</td>\n",
       "      <td>1.583414</td>\n",
       "      <td>0.697917</td>\n",
       "      <td>0.699859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>1.661204</td>\n",
       "      <td>0.704167</td>\n",
       "      <td>0.706870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.007300</td>\n",
       "      <td>1.688307</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.685980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.010500</td>\n",
       "      <td>1.670121</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.688608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.008200</td>\n",
       "      <td>1.716196</td>\n",
       "      <td>0.695833</td>\n",
       "      <td>0.697923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>1.759590</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.677402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.007200</td>\n",
       "      <td>1.733587</td>\n",
       "      <td>0.697917</td>\n",
       "      <td>0.699977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.005900</td>\n",
       "      <td>1.733959</td>\n",
       "      <td>0.702083</td>\n",
       "      <td>0.704032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.006600</td>\n",
       "      <td>1.742666</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.702199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>1.756411</td>\n",
       "      <td>0.704167</td>\n",
       "      <td>0.706560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>1.753567</td>\n",
       "      <td>0.697917</td>\n",
       "      <td>0.699778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>1.764817</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.702954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>1.762947</td>\n",
       "      <td>0.693750</td>\n",
       "      <td>0.695604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>1.763358</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.702506</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Tweet', 'label'],\n",
       "        num_rows: 1919\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Tweet', 'label'],\n",
       "        num_rows: 480\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorrBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at otmangi/MorrBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e8309e77d6f424599bc8e8451e6ff48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1919 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e608177f158441769baa16f3fdf3cb4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 01:42, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.525700</td>\n",
       "      <td>1.160150</td>\n",
       "      <td>0.627083</td>\n",
       "      <td>0.636201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.833800</td>\n",
       "      <td>0.948233</td>\n",
       "      <td>0.689583</td>\n",
       "      <td>0.693585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.507900</td>\n",
       "      <td>0.861818</td>\n",
       "      <td>0.712500</td>\n",
       "      <td>0.714073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.271500</td>\n",
       "      <td>0.903307</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.737120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.131600</td>\n",
       "      <td>1.003772</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.738332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.063100</td>\n",
       "      <td>1.205986</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.725772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.032600</td>\n",
       "      <td>1.283381</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.716198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.018600</td>\n",
       "      <td>1.371716</td>\n",
       "      <td>0.731250</td>\n",
       "      <td>0.732278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.016100</td>\n",
       "      <td>1.485464</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.700585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.014100</td>\n",
       "      <td>1.479308</td>\n",
       "      <td>0.704167</td>\n",
       "      <td>0.707396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.009100</td>\n",
       "      <td>1.523977</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.730496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>1.500690</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.730614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.004800</td>\n",
       "      <td>1.531147</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.732289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>1.642560</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.718419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>1.604245</td>\n",
       "      <td>0.731250</td>\n",
       "      <td>0.732269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.640757</td>\n",
       "      <td>0.720833</td>\n",
       "      <td>0.721028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>1.638334</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.735207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>1.638971</td>\n",
       "      <td>0.735417</td>\n",
       "      <td>0.737444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>1.661963</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>0.740121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.673494</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.734117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>1.674588</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.730699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>1.672960</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.734787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>1.673809</td>\n",
       "      <td>0.731250</td>\n",
       "      <td>0.732746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>1.674785</td>\n",
       "      <td>0.731250</td>\n",
       "      <td>0.732746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorrBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at otmangi/MorrBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d5d8c7d23ea436bb107af33b3a8ddca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1919 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3941862b00ad41d7af422603ff9f4f41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 01:43, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.525700</td>\n",
       "      <td>1.160150</td>\n",
       "      <td>0.627083</td>\n",
       "      <td>0.636201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.833800</td>\n",
       "      <td>0.948233</td>\n",
       "      <td>0.689583</td>\n",
       "      <td>0.693585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.507900</td>\n",
       "      <td>0.861818</td>\n",
       "      <td>0.712500</td>\n",
       "      <td>0.714073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.271500</td>\n",
       "      <td>0.903307</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.737120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.131600</td>\n",
       "      <td>1.003772</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.738332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.063100</td>\n",
       "      <td>1.205986</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.725772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.032600</td>\n",
       "      <td>1.283381</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.716198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.018600</td>\n",
       "      <td>1.371716</td>\n",
       "      <td>0.731250</td>\n",
       "      <td>0.732278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.016100</td>\n",
       "      <td>1.485464</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.700585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.014100</td>\n",
       "      <td>1.479308</td>\n",
       "      <td>0.704167</td>\n",
       "      <td>0.707396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.009100</td>\n",
       "      <td>1.523977</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.730496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>1.500690</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.730614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.004800</td>\n",
       "      <td>1.531147</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.732289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>1.642560</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.718419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>1.604245</td>\n",
       "      <td>0.731250</td>\n",
       "      <td>0.732269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.640757</td>\n",
       "      <td>0.720833</td>\n",
       "      <td>0.721028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>1.638334</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.735207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>1.638971</td>\n",
       "      <td>0.735417</td>\n",
       "      <td>0.737444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>1.661963</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>0.740121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.673494</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.734117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>1.674588</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.730699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>1.672960</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.734787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>1.673809</td>\n",
       "      <td>0.731250</td>\n",
       "      <td>0.732746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>1.674785</td>\n",
       "      <td>0.731250</td>\n",
       "      <td>0.732746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorrBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at otmangi/MorrBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb0a6881e3e34a7a9a055303b98b9de8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1919 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "540a6c5758964dfcbdfe32748897f936",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 01:42, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.525700</td>\n",
       "      <td>1.160150</td>\n",
       "      <td>0.627083</td>\n",
       "      <td>0.636201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.833800</td>\n",
       "      <td>0.948233</td>\n",
       "      <td>0.689583</td>\n",
       "      <td>0.693585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.507900</td>\n",
       "      <td>0.861818</td>\n",
       "      <td>0.712500</td>\n",
       "      <td>0.714073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.271500</td>\n",
       "      <td>0.903307</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.737120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.131600</td>\n",
       "      <td>1.003772</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.738332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.063100</td>\n",
       "      <td>1.205986</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.725772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.032600</td>\n",
       "      <td>1.283381</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.716198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.018600</td>\n",
       "      <td>1.371716</td>\n",
       "      <td>0.731250</td>\n",
       "      <td>0.732278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.016100</td>\n",
       "      <td>1.485464</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.700585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.014100</td>\n",
       "      <td>1.479308</td>\n",
       "      <td>0.704167</td>\n",
       "      <td>0.707396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.009100</td>\n",
       "      <td>1.523977</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.730496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>1.500690</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.730614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.004800</td>\n",
       "      <td>1.531147</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.732289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>1.642560</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.718419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>1.604245</td>\n",
       "      <td>0.731250</td>\n",
       "      <td>0.732269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.640757</td>\n",
       "      <td>0.720833</td>\n",
       "      <td>0.721028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>1.638334</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.735207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>1.638971</td>\n",
       "      <td>0.735417</td>\n",
       "      <td>0.737444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>1.661963</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>0.740121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.673494</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.734117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>1.674588</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.730699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>1.672960</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.734787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>1.673809</td>\n",
       "      <td>0.731250</td>\n",
       "      <td>0.732746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>1.674785</td>\n",
       "      <td>0.731250</td>\n",
       "      <td>0.732746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorrBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at otmangi/MorrBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "205a2ee3a0634acf843717b009001648",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1919 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0aef7ac8c534685a218ad4b79386da9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 01:42, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.493200</td>\n",
       "      <td>1.068575</td>\n",
       "      <td>0.654167</td>\n",
       "      <td>0.652266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.828900</td>\n",
       "      <td>0.871804</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.696639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.471200</td>\n",
       "      <td>0.853406</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.720270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.260200</td>\n",
       "      <td>0.908631</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.725099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.134100</td>\n",
       "      <td>0.974752</td>\n",
       "      <td>0.752083</td>\n",
       "      <td>0.748821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.076300</td>\n",
       "      <td>1.107046</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.729743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.041300</td>\n",
       "      <td>1.242257</td>\n",
       "      <td>0.710417</td>\n",
       "      <td>0.706979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.024000</td>\n",
       "      <td>1.190388</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>0.738152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.022300</td>\n",
       "      <td>1.328773</td>\n",
       "      <td>0.727083</td>\n",
       "      <td>0.722704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.012700</td>\n",
       "      <td>1.341473</td>\n",
       "      <td>0.747917</td>\n",
       "      <td>0.745397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.009100</td>\n",
       "      <td>1.408822</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.726309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.007700</td>\n",
       "      <td>1.358945</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.729907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>1.440628</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.726189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>1.418246</td>\n",
       "      <td>0.743750</td>\n",
       "      <td>0.739795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.006200</td>\n",
       "      <td>1.443066</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>0.738653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>1.527979</td>\n",
       "      <td>0.722917</td>\n",
       "      <td>0.719582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.486649</td>\n",
       "      <td>0.737500</td>\n",
       "      <td>0.734113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>1.473356</td>\n",
       "      <td>0.735417</td>\n",
       "      <td>0.732832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>1.505360</td>\n",
       "      <td>0.720833</td>\n",
       "      <td>0.718139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.485044</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.730747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>1.542969</td>\n",
       "      <td>0.720833</td>\n",
       "      <td>0.717417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>1.532413</td>\n",
       "      <td>0.722917</td>\n",
       "      <td>0.719626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>1.524186</td>\n",
       "      <td>0.727083</td>\n",
       "      <td>0.723671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>1.519618</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.725867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorrBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at otmangi/MorrBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79743c5e45a14d83801d24afd06fc3cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1919 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c14c0da8392844168c6bdfb58b4b3d1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 01:42, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.493200</td>\n",
       "      <td>1.068575</td>\n",
       "      <td>0.654167</td>\n",
       "      <td>0.652266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.828900</td>\n",
       "      <td>0.871804</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.696639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.471200</td>\n",
       "      <td>0.853406</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.720270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.260200</td>\n",
       "      <td>0.908631</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.725099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.134100</td>\n",
       "      <td>0.974752</td>\n",
       "      <td>0.752083</td>\n",
       "      <td>0.748821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.076300</td>\n",
       "      <td>1.107046</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.729743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.041300</td>\n",
       "      <td>1.242257</td>\n",
       "      <td>0.710417</td>\n",
       "      <td>0.706979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.024000</td>\n",
       "      <td>1.190388</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>0.738152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.022300</td>\n",
       "      <td>1.328773</td>\n",
       "      <td>0.727083</td>\n",
       "      <td>0.722704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.012700</td>\n",
       "      <td>1.341473</td>\n",
       "      <td>0.747917</td>\n",
       "      <td>0.745397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.009100</td>\n",
       "      <td>1.408822</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.726309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.007700</td>\n",
       "      <td>1.358945</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.729907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>1.440628</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.726189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>1.418246</td>\n",
       "      <td>0.743750</td>\n",
       "      <td>0.739795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.006200</td>\n",
       "      <td>1.443066</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>0.738653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>1.527979</td>\n",
       "      <td>0.722917</td>\n",
       "      <td>0.719582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.486649</td>\n",
       "      <td>0.737500</td>\n",
       "      <td>0.734113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>1.473356</td>\n",
       "      <td>0.735417</td>\n",
       "      <td>0.732832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>1.505360</td>\n",
       "      <td>0.720833</td>\n",
       "      <td>0.718139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.485044</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.730747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>1.542969</td>\n",
       "      <td>0.720833</td>\n",
       "      <td>0.717417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>1.532413</td>\n",
       "      <td>0.722917</td>\n",
       "      <td>0.719626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>1.524186</td>\n",
       "      <td>0.727083</td>\n",
       "      <td>0.723671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>1.519618</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.725867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorrBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at otmangi/MorrBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a311dbb5f434c10a00220285957e80c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1919 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee409e446fe84626869c4078cafe6301",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 01:17, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.493200</td>\n",
       "      <td>1.068575</td>\n",
       "      <td>0.654167</td>\n",
       "      <td>0.652266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.828900</td>\n",
       "      <td>0.871804</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.696639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.471200</td>\n",
       "      <td>0.853406</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.720270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.260200</td>\n",
       "      <td>0.908631</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.725099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.134100</td>\n",
       "      <td>0.974752</td>\n",
       "      <td>0.752083</td>\n",
       "      <td>0.748821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.076300</td>\n",
       "      <td>1.107046</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.729743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.041300</td>\n",
       "      <td>1.242257</td>\n",
       "      <td>0.710417</td>\n",
       "      <td>0.706979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.024000</td>\n",
       "      <td>1.190388</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>0.738152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.022300</td>\n",
       "      <td>1.328773</td>\n",
       "      <td>0.727083</td>\n",
       "      <td>0.722704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.012700</td>\n",
       "      <td>1.341473</td>\n",
       "      <td>0.747917</td>\n",
       "      <td>0.745397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.009100</td>\n",
       "      <td>1.408822</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.726309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.007700</td>\n",
       "      <td>1.358945</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.729907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>1.440628</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.726189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>1.418246</td>\n",
       "      <td>0.743750</td>\n",
       "      <td>0.739795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.006200</td>\n",
       "      <td>1.443066</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>0.738653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>1.527979</td>\n",
       "      <td>0.722917</td>\n",
       "      <td>0.719582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.486649</td>\n",
       "      <td>0.737500</td>\n",
       "      <td>0.734113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>1.473356</td>\n",
       "      <td>0.735417</td>\n",
       "      <td>0.732832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>1.505360</td>\n",
       "      <td>0.720833</td>\n",
       "      <td>0.718139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.485044</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.730747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>1.542969</td>\n",
       "      <td>0.720833</td>\n",
       "      <td>0.717417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>1.532413</td>\n",
       "      <td>0.722917</td>\n",
       "      <td>0.719626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>1.524186</td>\n",
       "      <td>0.727083</td>\n",
       "      <td>0.723671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>1.519618</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.725867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorrBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at otmangi/MorrBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88cf0992b5c146e395fbb7ab6346b7f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1919 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c82d815bc9546289ee9e8da5feaf443",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 00:52, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.479900</td>\n",
       "      <td>1.155702</td>\n",
       "      <td>0.614583</td>\n",
       "      <td>0.614182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.822500</td>\n",
       "      <td>0.963618</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.678448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.465300</td>\n",
       "      <td>0.983825</td>\n",
       "      <td>0.714583</td>\n",
       "      <td>0.718559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.234900</td>\n",
       "      <td>1.044207</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.704417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.123300</td>\n",
       "      <td>1.202165</td>\n",
       "      <td>0.697917</td>\n",
       "      <td>0.700769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.066300</td>\n",
       "      <td>1.241941</td>\n",
       "      <td>0.695833</td>\n",
       "      <td>0.699047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.030400</td>\n",
       "      <td>1.366338</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.703801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.050900</td>\n",
       "      <td>1.440182</td>\n",
       "      <td>0.691667</td>\n",
       "      <td>0.696254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.016300</td>\n",
       "      <td>1.541231</td>\n",
       "      <td>0.693750</td>\n",
       "      <td>0.699595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.010600</td>\n",
       "      <td>1.551683</td>\n",
       "      <td>0.689583</td>\n",
       "      <td>0.695911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.018000</td>\n",
       "      <td>1.625687</td>\n",
       "      <td>0.704167</td>\n",
       "      <td>0.709131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>1.659428</td>\n",
       "      <td>0.712500</td>\n",
       "      <td>0.717774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>1.615835</td>\n",
       "      <td>0.691667</td>\n",
       "      <td>0.695389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.007300</td>\n",
       "      <td>1.637287</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.693349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.683748</td>\n",
       "      <td>0.693750</td>\n",
       "      <td>0.699715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.664339</td>\n",
       "      <td>0.689583</td>\n",
       "      <td>0.692903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.684065</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.713707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.694354</td>\n",
       "      <td>0.702083</td>\n",
       "      <td>0.705917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>1.702018</td>\n",
       "      <td>0.702083</td>\n",
       "      <td>0.706035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>1.710741</td>\n",
       "      <td>0.702083</td>\n",
       "      <td>0.706668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>1.715667</td>\n",
       "      <td>0.704167</td>\n",
       "      <td>0.709034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>1.716568</td>\n",
       "      <td>0.702083</td>\n",
       "      <td>0.706628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>1.722464</td>\n",
       "      <td>0.702083</td>\n",
       "      <td>0.706628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>1.723387</td>\n",
       "      <td>0.702083</td>\n",
       "      <td>0.706855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorrBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at otmangi/MorrBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eab9f56e8f1a4dad8a5b8be8b8a41253",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1919 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e95794af1dbb43d29fc964c92cfe82d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 00:52, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.479900</td>\n",
       "      <td>1.155702</td>\n",
       "      <td>0.614583</td>\n",
       "      <td>0.614182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.822500</td>\n",
       "      <td>0.963618</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.678448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.465300</td>\n",
       "      <td>0.983825</td>\n",
       "      <td>0.714583</td>\n",
       "      <td>0.718559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.234900</td>\n",
       "      <td>1.044207</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.704417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.123300</td>\n",
       "      <td>1.202165</td>\n",
       "      <td>0.697917</td>\n",
       "      <td>0.700769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.066300</td>\n",
       "      <td>1.241941</td>\n",
       "      <td>0.695833</td>\n",
       "      <td>0.699047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.030400</td>\n",
       "      <td>1.366338</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.703801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.050900</td>\n",
       "      <td>1.440182</td>\n",
       "      <td>0.691667</td>\n",
       "      <td>0.696254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.016300</td>\n",
       "      <td>1.541231</td>\n",
       "      <td>0.693750</td>\n",
       "      <td>0.699595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.010600</td>\n",
       "      <td>1.551683</td>\n",
       "      <td>0.689583</td>\n",
       "      <td>0.695911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.018000</td>\n",
       "      <td>1.625687</td>\n",
       "      <td>0.704167</td>\n",
       "      <td>0.709131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>1.659428</td>\n",
       "      <td>0.712500</td>\n",
       "      <td>0.717774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>1.615835</td>\n",
       "      <td>0.691667</td>\n",
       "      <td>0.695389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.007300</td>\n",
       "      <td>1.637287</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.693349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.683748</td>\n",
       "      <td>0.693750</td>\n",
       "      <td>0.699715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.664339</td>\n",
       "      <td>0.689583</td>\n",
       "      <td>0.692903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.684065</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.713707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.694354</td>\n",
       "      <td>0.702083</td>\n",
       "      <td>0.705917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>1.702018</td>\n",
       "      <td>0.702083</td>\n",
       "      <td>0.706035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>1.710741</td>\n",
       "      <td>0.702083</td>\n",
       "      <td>0.706668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>1.715667</td>\n",
       "      <td>0.704167</td>\n",
       "      <td>0.709034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>1.716568</td>\n",
       "      <td>0.702083</td>\n",
       "      <td>0.706628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>1.722464</td>\n",
       "      <td>0.702083</td>\n",
       "      <td>0.706628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>1.723387</td>\n",
       "      <td>0.702083</td>\n",
       "      <td>0.706855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorrBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at otmangi/MorrBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5374cde49ca443fb57a32e45ae64d9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1919 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e677a860adbe451b944c9a62aff97e28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 00:52, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.479900</td>\n",
       "      <td>1.155702</td>\n",
       "      <td>0.614583</td>\n",
       "      <td>0.614182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.822500</td>\n",
       "      <td>0.963618</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.678448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.465300</td>\n",
       "      <td>0.983825</td>\n",
       "      <td>0.714583</td>\n",
       "      <td>0.718559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.234900</td>\n",
       "      <td>1.044207</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.704417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.123300</td>\n",
       "      <td>1.202165</td>\n",
       "      <td>0.697917</td>\n",
       "      <td>0.700769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.066300</td>\n",
       "      <td>1.241941</td>\n",
       "      <td>0.695833</td>\n",
       "      <td>0.699047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.030400</td>\n",
       "      <td>1.366338</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.703801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.050900</td>\n",
       "      <td>1.440182</td>\n",
       "      <td>0.691667</td>\n",
       "      <td>0.696254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.016300</td>\n",
       "      <td>1.541231</td>\n",
       "      <td>0.693750</td>\n",
       "      <td>0.699595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.010600</td>\n",
       "      <td>1.551683</td>\n",
       "      <td>0.689583</td>\n",
       "      <td>0.695911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.018000</td>\n",
       "      <td>1.625687</td>\n",
       "      <td>0.704167</td>\n",
       "      <td>0.709131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>1.659428</td>\n",
       "      <td>0.712500</td>\n",
       "      <td>0.717774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>1.615835</td>\n",
       "      <td>0.691667</td>\n",
       "      <td>0.695389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.007300</td>\n",
       "      <td>1.637287</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.693349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.683748</td>\n",
       "      <td>0.693750</td>\n",
       "      <td>0.699715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.664339</td>\n",
       "      <td>0.689583</td>\n",
       "      <td>0.692903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.684065</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.713707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.694354</td>\n",
       "      <td>0.702083</td>\n",
       "      <td>0.705917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>1.702018</td>\n",
       "      <td>0.702083</td>\n",
       "      <td>0.706035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>1.710741</td>\n",
       "      <td>0.702083</td>\n",
       "      <td>0.706668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>1.715667</td>\n",
       "      <td>0.704167</td>\n",
       "      <td>0.709034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>1.716568</td>\n",
       "      <td>0.702083</td>\n",
       "      <td>0.706628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>1.722464</td>\n",
       "      <td>0.702083</td>\n",
       "      <td>0.706628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>1.723387</td>\n",
       "      <td>0.702083</td>\n",
       "      <td>0.706855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SI2M-Lab/DarijaBERT</td>\n",
       "      <td>0.795833</td>\n",
       "      <td>0.793818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alger-ia/dziribert</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.817497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>faisalq/EgyBERT</td>\n",
       "      <td>0.822917</td>\n",
       "      <td>0.823959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>faisalq/SaudiBERT</td>\n",
       "      <td>0.835417</td>\n",
       "      <td>0.834487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>otmangi/MorRoBERTa</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.753630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>otmangi/MorrBERT</td>\n",
       "      <td>0.752083</td>\n",
       "      <td>0.748821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>tunis-ai/TunBERT</td>\n",
       "      <td>0.414583</td>\n",
       "      <td>0.415796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model  Accuracy        F1\n",
       "0   SI2M-Lab/DarijaBERT  0.795833  0.793818\n",
       "3    alger-ia/dziribert  0.816667  0.817497\n",
       "9       faisalq/EgyBERT  0.822917  0.823959\n",
       "11    faisalq/SaudiBERT  0.835417  0.834487\n",
       "14   otmangi/MorRoBERTa  0.750000  0.753630\n",
       "17     otmangi/MorrBERT  0.752083  0.748821\n",
       "20     tunis-ai/TunBERT  0.414583  0.415796"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" \n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import pyarabic.araby as araby\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.initializers import TruncatedNormal\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from datasets import load_dataset, Dataset, concatenate_datasets\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', 1000)\n",
    "\n",
    "\n",
    "fname = 'TCMD_2'\n",
    "log_file = fname + '.txt'\n",
    "\n",
    "with open(log_file, 'w') as f:\n",
    "    f.write('Model,Accuracy,F1\\n')\n",
    "\n",
    "\n",
    "df = pd.read_csv('datasets/Tweet_Classification_Moroccan_Dataset/data.csv', encoding='utf-16', engine='python', sep='\\t') #, quotechar=\"'\"  , quoting=3\n",
    "\n",
    "display(len(df))\n",
    "      \n",
    "display(df.columns)\n",
    "display(df[:4])\n",
    "\n",
    "\n",
    "\n",
    "c = df['Topic'].value_counts()\n",
    "display(c)\n",
    "\n",
    "classes = set(df['Topic'].values)\n",
    "display(classes)\n",
    "\n",
    "df['Topic'] = df['Topic'].astype('category')\n",
    "df['label'] = df['Topic'].cat.codes\n",
    "\n",
    "df = df[['Tweet', 'label']]\n",
    "classes_num = len(classes)\n",
    "display(classes_num)\n",
    "display(len(df))\n",
    "\n",
    "\n",
    "max_sequence_length = 128\n",
    "\n",
    "\n",
    "\n",
    "models = [ \n",
    "        'faisalq/EgyBERT',            \n",
    "    'faisalq/SaudiBERT',            \n",
    "    'tunis-ai/TunBERT',\n",
    "    'alger-ia/dziribert',\n",
    "    'SI2M-Lab/DarijaBERT',\n",
    "    'otmangi/MorRoBERTa',\n",
    "    'otmangi/MorrBERT'\n",
    "            \n",
    "]\n",
    "\n",
    "\n",
    "seeds = [0, 1, 42]\n",
    "\n",
    "for model_name in models:\n",
    "    for seed in seeds:\n",
    "        ds = Dataset.from_pandas(df)\n",
    "        ds = ds.train_test_split(test_size=0.2, seed = seed)\n",
    "        if seed==0:\n",
    "            display(ds)\n",
    "            \n",
    "        for i in range(3):\n",
    "            print(f'{model_name}, try:{i}')\n",
    "                  \n",
    "            tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "            model = AutoModelForSequenceClassification.from_pretrained(model_name,\n",
    "                                                                  num_labels=classes_num).to('cuda')                                                 \n",
    "            dataset_train = ds['train']\n",
    "            dataset_validation = ds['test']                                                    \n",
    "            \n",
    "          \n",
    "    \n",
    "            def preprocess_function(examples):\n",
    "                return tokenizer(examples['Tweet'], truncation=True, padding=\"max_length\",\n",
    "                                max_length=max_sequence_length)\n",
    "            \n",
    "            \n",
    "            dataset_train = dataset_train.map(preprocess_function, batched=True)\n",
    "            dataset_validation = dataset_validation.map(preprocess_function, batched=True)\n",
    "            \n",
    "           \n",
    "            \n",
    "            def compute_metrics(eval_pred):\n",
    "                logits, labels = eval_pred\n",
    "                predictions = np.argmax(logits, axis=-1)    \n",
    "                acc = accuracy_score(labels, predictions)        \n",
    "                f1 = f1_score(labels, predictions, average='macro')   \n",
    "                with open(log_file, 'a') as f:\n",
    "                    f.write(f'{model_name},{acc},{f1}\\n')\n",
    "                return {'accuracy': acc, 'f1_score': f1}\n",
    "    \n",
    "    \n",
    "            \n",
    "            \n",
    "            epochs = 20\n",
    "            save_steps = 10000 #save checkpoint every 10000 steps\n",
    "            batch_size = 64\n",
    "            \n",
    "            training_args = TrainingArguments(\n",
    "                output_dir = 'bert/',\n",
    "                overwrite_output_dir=True,\n",
    "                num_train_epochs = epochs,\n",
    "                per_device_train_batch_size = batch_size,\n",
    "                per_device_eval_batch_size = batch_size,\n",
    "                save_steps = save_steps,\n",
    "                save_total_limit = 1, #only save the last 5 checkpoints\n",
    "                fp16=True,\n",
    "                learning_rate = 5e-5,  # 5e-5 is the default\n",
    "                logging_steps = 25, #50_000\n",
    "                evaluation_strategy = 'steps',\n",
    "                # evaluate_during_training = True,\n",
    "                eval_steps = 25\n",
    "                \n",
    "            )\n",
    "            \n",
    "            trainer = Trainer(\n",
    "                model = model,\n",
    "                args = training_args,\n",
    "                # data_collator=data_collator,\n",
    "                train_dataset=dataset_train,\n",
    "                eval_dataset=dataset_validation,\n",
    "                compute_metrics = compute_metrics\n",
    "            )\n",
    "            \n",
    "            \n",
    "            trainer.train()\n",
    "\n",
    "\n",
    "results = pd.read_csv(log_file)\n",
    "\n",
    "best_results = results.groupby('Model', as_index=False)['F1'].max()\n",
    "\n",
    "best_results = pd.merge(best_results, results, on=['Model', 'F1'])\n",
    "best_results = best_results[['Model', 'Accuracy', 'F1']]\n",
    "best_results = best_results.drop_duplicates()\n",
    "best_results.to_csv(f'{fname}.csv')\n",
    "display(best_results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a213ac86-934f-4e82-a949-0bcdcae2188d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220784d6-b06d-4429-adb8-0026654f9d49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8647cf08-3aa6-44eb-846f-4bed97554042",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e203fa6b-c9d7-44a4-b501-a67bfd3e4ce4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8794b705-31a1-45d7-8e88-4017a9c282aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
