{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d804ae66-9435-44be-8aad-beacbdeec0f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-18 17:02:51.259552: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-18 17:02:51.282453: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-18 17:02:51.661024: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Text', 'Tag'], dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>: ุญุงูุฉ ุงูุทูุงุฑุฆ ุงูุตุญูุฉ: ูุซููุฉ ุงูุชููู ูู ุชุณูู ูููุงุตุฑููุ ุนูุฏ ูุฌูุฏ ุญุงูุฉ ุถุฑูุฑูุฉ ูุชููู ุงููุงุตุฑูู ูุง ุจุฏ ุงู ูููููุง ูุฑููููู ุจุงุดุฎุงุต ุจโฆ</td>\n",
       "      <td>social</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>: ุงูุณูุทุงุช ุชุนูู ุนูู ุงูุฅุบูุงู ุงูุดุงูู ูุจููุฒุงูุงุฑู ุงูุจุคุฑุฉ ุงูุฌุฏูุฏุฉ ูฺคูุฑูุณ ููุฑููุง ุจุงููุบุฑุจ ูุงูุฃูุงููู ุงูุฌููุจูุฉ.</td>\n",
       "      <td>sante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ููุฃุณู ูุงุฏู ุฃูุงููุฉ ูููู ูุจุนููู ุนุฌุจูู ุงูุฑุฏ ุฏูุงูู ููููู , ุฃูููููู ุดูุฑุง ุฎููุง</td>\n",
       "      <td>autre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ุงูุง ููู ูุงูุง ุงููู ุฑุงุฌุนูู. ุงููู ูุฑุญููุง ู ูุบูุฑ ููุง</td>\n",
       "      <td>autre</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                          Text   \n",
       "0  : ุญุงูุฉ ุงูุทูุงุฑุฆ ุงูุตุญูุฉ: ูุซููุฉ ุงูุชููู ูู ุชุณูู ูููุงุตุฑููุ ุนูุฏ ูุฌูุฏ ุญุงูุฉ ุถุฑูุฑูุฉ ูุชููู ุงููุงุตุฑูู ูุง ุจุฏ ุงู ูููููุง ูุฑููููู ุจุงุดุฎุงุต ุจโฆ  \\\n",
       "1                        : ุงูุณูุทุงุช ุชุนูู ุนูู ุงูุฅุบูุงู ุงูุดุงูู ูุจููุฒุงูุงุฑู ุงูุจุคุฑุฉ ุงูุฌุฏูุฏุฉ ูฺคูุฑูุณ ููุฑููุง ุจุงููุบุฑุจ ูุงูุฃูุงููู ุงูุฌููุจูุฉ.   \n",
       "2                                                     ููุฃุณู ูุงุฏู ุฃูุงููุฉ ูููู ูุจุนููู ุนุฌุจูู ุงูุฑุฏ ุฏูุงูู ููููู , ุฃูููููู ุดูุฑุง ุฎููุง   \n",
       "3                                                                             ุงูุง ููู ูุงูุง ุงููู ุฑุงุฌุนูู. ุงููู ูุฑุญููุง ู ูุบูุฑ ููุง   \n",
       "\n",
       "      Tag  \n",
       "0  social  \n",
       "1   sante  \n",
       "2   autre  \n",
       "3   autre  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['Twits', 'dialect'], dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Twits</th>\n",
       "      <th>dialect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13393</th>\n",
       "      <td>slawiya msikina tb9a f darha ๐๐๐</td>\n",
       "      <td>Morocco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13394</th>\n",
       "      <td>ูุงุณ ุฏ ุงูุฑุจุงุท ุฃุด ูุงูุน ุนูุฏูู ุชูุง ... ูุงููุง ุดู ุดุจู ุนุงุฆููุฉ ๐</td>\n",
       "      <td>Morocco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13395</th>\n",
       "      <td>ูู ุฏูุง ูุดุงุง ๐๐</td>\n",
       "      <td>Morocco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13396</th>\n",
       "      <td>: ูุฒุฑุงุก ุชููููุง</td>\n",
       "      <td>Morocco</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                          Twits  dialect\n",
       "13393                          slawiya msikina tb9a f darha ๐๐๐  Morocco\n",
       "13394  ูุงุณ ุฏ ุงูุฑุจุงุท ุฃุด ูุงูุน ุนูุฏูู ุชูุง ... ูุงููุง ุดู ุดุจู ุนุงุฆููุฉ ๐  Morocco\n",
       "13395                                            ูู ุฏูุง ูุดุงุง ๐๐  Morocco\n",
       "13396                                            : ูุฒุฑุงุก ุชููููุง  Morocco"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "9965"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>: ุญุงูุฉ ุงูุทูุงุฑุฆ ุงูุตุญูุฉ: ูุซููุฉ ุงูุชููู ูู ุชุณูู ูููุงุตุฑููุ ุนูุฏ ูุฌูุฏ ุญุงูุฉ ุถุฑูุฑูุฉ ูุชููู ุงููุงุตุฑูู ูุง ุจุฏ ุงู ูููููุง ูุฑููููู ุจุงุดุฎุงุต ุจโฆ</td>\n",
       "      <td>social</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>: ุงูุณูุทุงุช ุชุนูู ุนูู ุงูุฅุบูุงู ุงูุดุงูู ูุจููุฒุงูุงุฑู ุงูุจุคุฑุฉ ุงูุฌุฏูุฏุฉ ูฺคูุฑูุณ ููุฑููุง ุจุงููุบุฑุจ ูุงูุฃูุงููู ุงูุฌููุจูุฉ.</td>\n",
       "      <td>sante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ููุฃุณู ูุงุฏู ุฃูุงููุฉ ูููู ูุจุนููู ุนุฌุจูู ุงูุฑุฏ ุฏูุงูู ููููู , ุฃูููููู ุดูุฑุง ุฎููุง</td>\n",
       "      <td>autre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ุงูุง ููู ูุงูุง ุงููู ุฑุงุฌุนูู. ุงููู ูุฑุญููุง ู ูุบูุฑ ููุง</td>\n",
       "      <td>autre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ูุงููุง</td>\n",
       "      <td>autre</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                          Text   \n",
       "0  : ุญุงูุฉ ุงูุทูุงุฑุฆ ุงูุตุญูุฉ: ูุซููุฉ ุงูุชููู ูู ุชุณูู ูููุงุตุฑููุ ุนูุฏ ูุฌูุฏ ุญุงูุฉ ุถุฑูุฑูุฉ ูุชููู ุงููุงุตุฑูู ูุง ุจุฏ ุงู ูููููุง ูุฑููููู ุจุงุดุฎุงุต ุจโฆ  \\\n",
       "1                        : ุงูุณูุทุงุช ุชุนูู ุนูู ุงูุฅุบูุงู ุงูุดุงูู ูุจููุฒุงูุงุฑู ุงูุจุคุฑุฉ ุงูุฌุฏูุฏุฉ ูฺคูุฑูุณ ููุฑููุง ุจุงููุบุฑุจ ูุงูุฃูุงููู ุงูุฌููุจูุฉ.   \n",
       "2                                                     ููุฃุณู ูุงุฏู ุฃูุงููุฉ ูููู ูุจุนููู ุนุฌุจูู ุงูุฑุฏ ุฏูุงูู ููููู , ุฃูููููู ุดูุฑุง ุฎููุง   \n",
       "3                                                                             ุงูุง ููู ูุงูุง ุงููู ุฑุงุฌุนูู. ุงููู ูุฑุญููุง ู ูุบูุฑ ููุง   \n",
       "4                                                                                                                        ูุงููุง   \n",
       "\n",
       "      Tag  \n",
       "0  social  \n",
       "1   sante  \n",
       "2   autre  \n",
       "3   autre  \n",
       "4   autre  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "6091"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Tag\n",
       "autre         5411\n",
       "social         346\n",
       "sante          217\n",
       "politique       93\n",
       "sport           12\n",
       "รฉconomique      12\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'autre', 'politique', 'sante', 'social', 'sport', 'รฉconomique'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "6091"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Text', 'label', '__index_level_0__'],\n",
       "        num_rows: 4872\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Text', 'label', '__index_level_0__'],\n",
       "        num_rows: 1219\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/EgyBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/EgyBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1155' max='1155' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1155/1155 01:45, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.452000</td>\n",
       "      <td>1.028969</td>\n",
       "      <td>0.898277</td>\n",
       "      <td>0.189283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>0.500593</td>\n",
       "      <td>0.898277</td>\n",
       "      <td>0.189283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.472400</td>\n",
       "      <td>0.354701</td>\n",
       "      <td>0.898277</td>\n",
       "      <td>0.189283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.372400</td>\n",
       "      <td>0.346108</td>\n",
       "      <td>0.904840</td>\n",
       "      <td>0.224008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.351600</td>\n",
       "      <td>0.315257</td>\n",
       "      <td>0.913864</td>\n",
       "      <td>0.332044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.302100</td>\n",
       "      <td>0.333672</td>\n",
       "      <td>0.908942</td>\n",
       "      <td>0.370651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.265100</td>\n",
       "      <td>0.331183</td>\n",
       "      <td>0.914684</td>\n",
       "      <td>0.384682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.235000</td>\n",
       "      <td>0.342069</td>\n",
       "      <td>0.894176</td>\n",
       "      <td>0.287182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.235500</td>\n",
       "      <td>0.358776</td>\n",
       "      <td>0.901559</td>\n",
       "      <td>0.266944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.198500</td>\n",
       "      <td>0.375592</td>\n",
       "      <td>0.894176</td>\n",
       "      <td>0.275286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.190500</td>\n",
       "      <td>0.384850</td>\n",
       "      <td>0.895816</td>\n",
       "      <td>0.283835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.186100</td>\n",
       "      <td>0.391057</td>\n",
       "      <td>0.876948</td>\n",
       "      <td>0.270308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.169500</td>\n",
       "      <td>0.386102</td>\n",
       "      <td>0.912223</td>\n",
       "      <td>0.413652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.155400</td>\n",
       "      <td>0.396595</td>\n",
       "      <td>0.917145</td>\n",
       "      <td>0.410523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.157200</td>\n",
       "      <td>0.442382</td>\n",
       "      <td>0.891715</td>\n",
       "      <td>0.408429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.154200</td>\n",
       "      <td>0.414021</td>\n",
       "      <td>0.899098</td>\n",
       "      <td>0.410270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.147300</td>\n",
       "      <td>0.400502</td>\n",
       "      <td>0.909762</td>\n",
       "      <td>0.395856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.150100</td>\n",
       "      <td>0.409384</td>\n",
       "      <td>0.916325</td>\n",
       "      <td>0.424782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.131400</td>\n",
       "      <td>0.402384</td>\n",
       "      <td>0.910582</td>\n",
       "      <td>0.424536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.126000</td>\n",
       "      <td>0.402788</td>\n",
       "      <td>0.908942</td>\n",
       "      <td>0.418282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.123200</td>\n",
       "      <td>0.418227</td>\n",
       "      <td>0.908942</td>\n",
       "      <td>0.408823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.109600</td>\n",
       "      <td>0.414362</td>\n",
       "      <td>0.908942</td>\n",
       "      <td>0.415408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.129100</td>\n",
       "      <td>0.413432</td>\n",
       "      <td>0.908942</td>\n",
       "      <td>0.416723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/EgyBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/EgyBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1155' max='1155' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1155/1155 01:46, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.443500</td>\n",
       "      <td>1.062250</td>\n",
       "      <td>0.898277</td>\n",
       "      <td>0.189283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.773400</td>\n",
       "      <td>0.511089</td>\n",
       "      <td>0.898277</td>\n",
       "      <td>0.189283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.544100</td>\n",
       "      <td>0.463856</td>\n",
       "      <td>0.898277</td>\n",
       "      <td>0.189283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.476900</td>\n",
       "      <td>0.382015</td>\n",
       "      <td>0.898277</td>\n",
       "      <td>0.189283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.472600</td>\n",
       "      <td>0.355594</td>\n",
       "      <td>0.898277</td>\n",
       "      <td>0.189283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.414700</td>\n",
       "      <td>0.365478</td>\n",
       "      <td>0.898277</td>\n",
       "      <td>0.189283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.416500</td>\n",
       "      <td>0.375122</td>\n",
       "      <td>0.898277</td>\n",
       "      <td>0.189283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.367700</td>\n",
       "      <td>0.334945</td>\n",
       "      <td>0.898277</td>\n",
       "      <td>0.189283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.396800</td>\n",
       "      <td>0.318373</td>\n",
       "      <td>0.916325</td>\n",
       "      <td>0.320642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.352700</td>\n",
       "      <td>0.312062</td>\n",
       "      <td>0.898277</td>\n",
       "      <td>0.189283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.312560</td>\n",
       "      <td>0.902379</td>\n",
       "      <td>0.237312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.317400</td>\n",
       "      <td>0.310992</td>\n",
       "      <td>0.906481</td>\n",
       "      <td>0.270996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.317600</td>\n",
       "      <td>0.308884</td>\n",
       "      <td>0.904840</td>\n",
       "      <td>0.249768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.306400</td>\n",
       "      <td>0.363140</td>\n",
       "      <td>0.863823</td>\n",
       "      <td>0.269872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.273600</td>\n",
       "      <td>0.293730</td>\n",
       "      <td>0.904840</td>\n",
       "      <td>0.267666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.275900</td>\n",
       "      <td>0.297428</td>\n",
       "      <td>0.906481</td>\n",
       "      <td>0.252554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.230200</td>\n",
       "      <td>0.298919</td>\n",
       "      <td>0.904020</td>\n",
       "      <td>0.274559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.242600</td>\n",
       "      <td>0.328322</td>\n",
       "      <td>0.899918</td>\n",
       "      <td>0.258646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.233500</td>\n",
       "      <td>0.329694</td>\n",
       "      <td>0.904840</td>\n",
       "      <td>0.270962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.226800</td>\n",
       "      <td>0.328326</td>\n",
       "      <td>0.893355</td>\n",
       "      <td>0.272439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.223600</td>\n",
       "      <td>0.330438</td>\n",
       "      <td>0.897457</td>\n",
       "      <td>0.265892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.195300</td>\n",
       "      <td>0.336399</td>\n",
       "      <td>0.896637</td>\n",
       "      <td>0.266775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.224500</td>\n",
       "      <td>0.338752</td>\n",
       "      <td>0.895816</td>\n",
       "      <td>0.266277</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/EgyBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/EgyBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1155' max='1155' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1155/1155 01:46, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.443500</td>\n",
       "      <td>1.062250</td>\n",
       "      <td>0.898277</td>\n",
       "      <td>0.189283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.773400</td>\n",
       "      <td>0.511089</td>\n",
       "      <td>0.898277</td>\n",
       "      <td>0.189283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.544100</td>\n",
       "      <td>0.463856</td>\n",
       "      <td>0.898277</td>\n",
       "      <td>0.189283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.476900</td>\n",
       "      <td>0.382015</td>\n",
       "      <td>0.898277</td>\n",
       "      <td>0.189283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.472600</td>\n",
       "      <td>0.355594</td>\n",
       "      <td>0.898277</td>\n",
       "      <td>0.189283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.414700</td>\n",
       "      <td>0.365478</td>\n",
       "      <td>0.898277</td>\n",
       "      <td>0.189283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.416500</td>\n",
       "      <td>0.375122</td>\n",
       "      <td>0.898277</td>\n",
       "      <td>0.189283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.367700</td>\n",
       "      <td>0.334945</td>\n",
       "      <td>0.898277</td>\n",
       "      <td>0.189283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.396800</td>\n",
       "      <td>0.318373</td>\n",
       "      <td>0.916325</td>\n",
       "      <td>0.320642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.352700</td>\n",
       "      <td>0.312062</td>\n",
       "      <td>0.898277</td>\n",
       "      <td>0.189283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.312560</td>\n",
       "      <td>0.902379</td>\n",
       "      <td>0.237312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.317400</td>\n",
       "      <td>0.310992</td>\n",
       "      <td>0.906481</td>\n",
       "      <td>0.270996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.317600</td>\n",
       "      <td>0.308884</td>\n",
       "      <td>0.904840</td>\n",
       "      <td>0.249768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.306400</td>\n",
       "      <td>0.363140</td>\n",
       "      <td>0.863823</td>\n",
       "      <td>0.269872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.273600</td>\n",
       "      <td>0.293730</td>\n",
       "      <td>0.904840</td>\n",
       "      <td>0.267666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.275900</td>\n",
       "      <td>0.297428</td>\n",
       "      <td>0.906481</td>\n",
       "      <td>0.252554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.230200</td>\n",
       "      <td>0.298919</td>\n",
       "      <td>0.904020</td>\n",
       "      <td>0.274559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.242600</td>\n",
       "      <td>0.328322</td>\n",
       "      <td>0.899918</td>\n",
       "      <td>0.258646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.233500</td>\n",
       "      <td>0.329694</td>\n",
       "      <td>0.904840</td>\n",
       "      <td>0.270962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.226800</td>\n",
       "      <td>0.328326</td>\n",
       "      <td>0.893355</td>\n",
       "      <td>0.272439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.223600</td>\n",
       "      <td>0.330438</td>\n",
       "      <td>0.897457</td>\n",
       "      <td>0.265892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.195300</td>\n",
       "      <td>0.336399</td>\n",
       "      <td>0.896637</td>\n",
       "      <td>0.266775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.224500</td>\n",
       "      <td>0.338752</td>\n",
       "      <td>0.895816</td>\n",
       "      <td>0.266277</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/EgyBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/EgyBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1155' max='1155' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1155/1155 01:46, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.448800</td>\n",
       "      <td>1.083109</td>\n",
       "      <td>0.884331</td>\n",
       "      <td>0.156436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.792500</td>\n",
       "      <td>0.556945</td>\n",
       "      <td>0.884331</td>\n",
       "      <td>0.156436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.512600</td>\n",
       "      <td>0.499725</td>\n",
       "      <td>0.884331</td>\n",
       "      <td>0.156436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.466500</td>\n",
       "      <td>0.429699</td>\n",
       "      <td>0.884331</td>\n",
       "      <td>0.156436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.372400</td>\n",
       "      <td>0.359431</td>\n",
       "      <td>0.882691</td>\n",
       "      <td>0.174100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.334700</td>\n",
       "      <td>0.363672</td>\n",
       "      <td>0.894176</td>\n",
       "      <td>0.247893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.363089</td>\n",
       "      <td>0.906481</td>\n",
       "      <td>0.322683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.286600</td>\n",
       "      <td>0.376338</td>\n",
       "      <td>0.904840</td>\n",
       "      <td>0.316705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.240300</td>\n",
       "      <td>0.392517</td>\n",
       "      <td>0.883511</td>\n",
       "      <td>0.201317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.229700</td>\n",
       "      <td>0.412451</td>\n",
       "      <td>0.890074</td>\n",
       "      <td>0.214463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.173200</td>\n",
       "      <td>0.419759</td>\n",
       "      <td>0.888433</td>\n",
       "      <td>0.311176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.189300</td>\n",
       "      <td>0.443229</td>\n",
       "      <td>0.893355</td>\n",
       "      <td>0.285991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.167600</td>\n",
       "      <td>0.403134</td>\n",
       "      <td>0.899918</td>\n",
       "      <td>0.342683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.166600</td>\n",
       "      <td>0.415551</td>\n",
       "      <td>0.899918</td>\n",
       "      <td>0.351717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.151700</td>\n",
       "      <td>0.442172</td>\n",
       "      <td>0.906481</td>\n",
       "      <td>0.333148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.132900</td>\n",
       "      <td>0.417531</td>\n",
       "      <td>0.903199</td>\n",
       "      <td>0.346816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.129800</td>\n",
       "      <td>0.417767</td>\n",
       "      <td>0.899098</td>\n",
       "      <td>0.351225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.111400</td>\n",
       "      <td>0.436023</td>\n",
       "      <td>0.901559</td>\n",
       "      <td>0.343333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.102800</td>\n",
       "      <td>0.434332</td>\n",
       "      <td>0.899098</td>\n",
       "      <td>0.345208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.100400</td>\n",
       "      <td>0.431657</td>\n",
       "      <td>0.906481</td>\n",
       "      <td>0.352504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.102400</td>\n",
       "      <td>0.439781</td>\n",
       "      <td>0.904840</td>\n",
       "      <td>0.353628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.081700</td>\n",
       "      <td>0.441726</td>\n",
       "      <td>0.898277</td>\n",
       "      <td>0.350700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.093400</td>\n",
       "      <td>0.443396</td>\n",
       "      <td>0.899918</td>\n",
       "      <td>0.350373</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/EgyBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/EgyBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1155' max='1155' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1155/1155 01:46, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.448800</td>\n",
       "      <td>1.083109</td>\n",
       "      <td>0.884331</td>\n",
       "      <td>0.156436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.792500</td>\n",
       "      <td>0.556945</td>\n",
       "      <td>0.884331</td>\n",
       "      <td>0.156436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.512600</td>\n",
       "      <td>0.499725</td>\n",
       "      <td>0.884331</td>\n",
       "      <td>0.156436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.466500</td>\n",
       "      <td>0.429699</td>\n",
       "      <td>0.884331</td>\n",
       "      <td>0.156436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.372400</td>\n",
       "      <td>0.359431</td>\n",
       "      <td>0.882691</td>\n",
       "      <td>0.174100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.334700</td>\n",
       "      <td>0.363672</td>\n",
       "      <td>0.894176</td>\n",
       "      <td>0.247893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.363089</td>\n",
       "      <td>0.906481</td>\n",
       "      <td>0.322683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.286600</td>\n",
       "      <td>0.376338</td>\n",
       "      <td>0.904840</td>\n",
       "      <td>0.316705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.240300</td>\n",
       "      <td>0.392517</td>\n",
       "      <td>0.883511</td>\n",
       "      <td>0.201317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.229700</td>\n",
       "      <td>0.412451</td>\n",
       "      <td>0.890074</td>\n",
       "      <td>0.214463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.173200</td>\n",
       "      <td>0.419759</td>\n",
       "      <td>0.888433</td>\n",
       "      <td>0.311176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.189300</td>\n",
       "      <td>0.443229</td>\n",
       "      <td>0.893355</td>\n",
       "      <td>0.285991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.167600</td>\n",
       "      <td>0.403134</td>\n",
       "      <td>0.899918</td>\n",
       "      <td>0.342683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.166600</td>\n",
       "      <td>0.415551</td>\n",
       "      <td>0.899918</td>\n",
       "      <td>0.351717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.151700</td>\n",
       "      <td>0.442172</td>\n",
       "      <td>0.906481</td>\n",
       "      <td>0.333148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.132900</td>\n",
       "      <td>0.417531</td>\n",
       "      <td>0.903199</td>\n",
       "      <td>0.346816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.129800</td>\n",
       "      <td>0.417767</td>\n",
       "      <td>0.899098</td>\n",
       "      <td>0.351225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.111400</td>\n",
       "      <td>0.436023</td>\n",
       "      <td>0.901559</td>\n",
       "      <td>0.343333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.102800</td>\n",
       "      <td>0.434332</td>\n",
       "      <td>0.899098</td>\n",
       "      <td>0.345208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.100400</td>\n",
       "      <td>0.431657</td>\n",
       "      <td>0.906481</td>\n",
       "      <td>0.352504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.102400</td>\n",
       "      <td>0.439781</td>\n",
       "      <td>0.904840</td>\n",
       "      <td>0.353628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.081700</td>\n",
       "      <td>0.441726</td>\n",
       "      <td>0.898277</td>\n",
       "      <td>0.350700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.093400</td>\n",
       "      <td>0.443396</td>\n",
       "      <td>0.899918</td>\n",
       "      <td>0.350373</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/EgyBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/EgyBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1155' max='1155' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1155/1155 01:46, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.448800</td>\n",
       "      <td>1.083109</td>\n",
       "      <td>0.884331</td>\n",
       "      <td>0.156436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.792500</td>\n",
       "      <td>0.556945</td>\n",
       "      <td>0.884331</td>\n",
       "      <td>0.156436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.512600</td>\n",
       "      <td>0.499725</td>\n",
       "      <td>0.884331</td>\n",
       "      <td>0.156436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.466500</td>\n",
       "      <td>0.429699</td>\n",
       "      <td>0.884331</td>\n",
       "      <td>0.156436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.372400</td>\n",
       "      <td>0.359431</td>\n",
       "      <td>0.882691</td>\n",
       "      <td>0.174100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.334700</td>\n",
       "      <td>0.363672</td>\n",
       "      <td>0.894176</td>\n",
       "      <td>0.247893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.363089</td>\n",
       "      <td>0.906481</td>\n",
       "      <td>0.322683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.286600</td>\n",
       "      <td>0.376338</td>\n",
       "      <td>0.904840</td>\n",
       "      <td>0.316705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.240300</td>\n",
       "      <td>0.392517</td>\n",
       "      <td>0.883511</td>\n",
       "      <td>0.201317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.229700</td>\n",
       "      <td>0.412451</td>\n",
       "      <td>0.890074</td>\n",
       "      <td>0.214463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.173200</td>\n",
       "      <td>0.419759</td>\n",
       "      <td>0.888433</td>\n",
       "      <td>0.311176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.189300</td>\n",
       "      <td>0.443229</td>\n",
       "      <td>0.893355</td>\n",
       "      <td>0.285991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.167600</td>\n",
       "      <td>0.403134</td>\n",
       "      <td>0.899918</td>\n",
       "      <td>0.342683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.166600</td>\n",
       "      <td>0.415551</td>\n",
       "      <td>0.899918</td>\n",
       "      <td>0.351717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.151700</td>\n",
       "      <td>0.442172</td>\n",
       "      <td>0.906481</td>\n",
       "      <td>0.333148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.132900</td>\n",
       "      <td>0.417531</td>\n",
       "      <td>0.903199</td>\n",
       "      <td>0.346816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.129800</td>\n",
       "      <td>0.417767</td>\n",
       "      <td>0.899098</td>\n",
       "      <td>0.351225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.111400</td>\n",
       "      <td>0.436023</td>\n",
       "      <td>0.901559</td>\n",
       "      <td>0.343333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.102800</td>\n",
       "      <td>0.434332</td>\n",
       "      <td>0.899098</td>\n",
       "      <td>0.345208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.100400</td>\n",
       "      <td>0.431657</td>\n",
       "      <td>0.906481</td>\n",
       "      <td>0.352504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.102400</td>\n",
       "      <td>0.439781</td>\n",
       "      <td>0.904840</td>\n",
       "      <td>0.353628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.081700</td>\n",
       "      <td>0.441726</td>\n",
       "      <td>0.898277</td>\n",
       "      <td>0.350700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.093400</td>\n",
       "      <td>0.443396</td>\n",
       "      <td>0.899918</td>\n",
       "      <td>0.350373</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/EgyBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/EgyBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1155' max='1155' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1155/1155 01:46, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.468900</td>\n",
       "      <td>1.180937</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.156667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.881900</td>\n",
       "      <td>0.599113</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.156667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.539800</td>\n",
       "      <td>0.503301</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.156667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.488600</td>\n",
       "      <td>0.496204</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.156667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.482600</td>\n",
       "      <td>0.448140</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.156667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.397700</td>\n",
       "      <td>0.366558</td>\n",
       "      <td>0.900738</td>\n",
       "      <td>0.256127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.341000</td>\n",
       "      <td>0.333267</td>\n",
       "      <td>0.904020</td>\n",
       "      <td>0.260512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.307300</td>\n",
       "      <td>0.318960</td>\n",
       "      <td>0.917966</td>\n",
       "      <td>0.337257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.275300</td>\n",
       "      <td>0.308355</td>\n",
       "      <td>0.902379</td>\n",
       "      <td>0.294310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.235800</td>\n",
       "      <td>0.340173</td>\n",
       "      <td>0.912223</td>\n",
       "      <td>0.321625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.238300</td>\n",
       "      <td>0.350508</td>\n",
       "      <td>0.915505</td>\n",
       "      <td>0.335557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.209900</td>\n",
       "      <td>0.335363</td>\n",
       "      <td>0.914684</td>\n",
       "      <td>0.342540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.203000</td>\n",
       "      <td>0.345171</td>\n",
       "      <td>0.918786</td>\n",
       "      <td>0.352551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.173700</td>\n",
       "      <td>0.352885</td>\n",
       "      <td>0.915505</td>\n",
       "      <td>0.364583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.160400</td>\n",
       "      <td>0.360544</td>\n",
       "      <td>0.917966</td>\n",
       "      <td>0.353115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.160400</td>\n",
       "      <td>0.339007</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.365176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.155000</td>\n",
       "      <td>0.361098</td>\n",
       "      <td>0.918786</td>\n",
       "      <td>0.368100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.127000</td>\n",
       "      <td>0.341196</td>\n",
       "      <td>0.917145</td>\n",
       "      <td>0.374348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.138600</td>\n",
       "      <td>0.354601</td>\n",
       "      <td>0.918786</td>\n",
       "      <td>0.372491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.119900</td>\n",
       "      <td>0.346018</td>\n",
       "      <td>0.915505</td>\n",
       "      <td>0.370434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.103000</td>\n",
       "      <td>0.351025</td>\n",
       "      <td>0.920427</td>\n",
       "      <td>0.371620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.125800</td>\n",
       "      <td>0.348622</td>\n",
       "      <td>0.919606</td>\n",
       "      <td>0.377132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.121300</td>\n",
       "      <td>0.349456</td>\n",
       "      <td>0.918786</td>\n",
       "      <td>0.373689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/EgyBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/EgyBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d29b78817f754451af2516220c5780d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cf69d866fce46a19bd8bed7a126f82b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1155' max='1155' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1155/1155 01:45, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.468900</td>\n",
       "      <td>1.180937</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.156667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.881900</td>\n",
       "      <td>0.599113</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.156667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.539800</td>\n",
       "      <td>0.503301</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.156667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.488600</td>\n",
       "      <td>0.496204</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.156667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.482600</td>\n",
       "      <td>0.448140</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.156667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.397700</td>\n",
       "      <td>0.366558</td>\n",
       "      <td>0.900738</td>\n",
       "      <td>0.256127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.341000</td>\n",
       "      <td>0.333267</td>\n",
       "      <td>0.904020</td>\n",
       "      <td>0.260512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.307300</td>\n",
       "      <td>0.318960</td>\n",
       "      <td>0.917966</td>\n",
       "      <td>0.337257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.275300</td>\n",
       "      <td>0.308355</td>\n",
       "      <td>0.902379</td>\n",
       "      <td>0.294310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.235800</td>\n",
       "      <td>0.340173</td>\n",
       "      <td>0.912223</td>\n",
       "      <td>0.321625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.238300</td>\n",
       "      <td>0.350508</td>\n",
       "      <td>0.915505</td>\n",
       "      <td>0.335557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.209900</td>\n",
       "      <td>0.335363</td>\n",
       "      <td>0.914684</td>\n",
       "      <td>0.342540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.203000</td>\n",
       "      <td>0.345171</td>\n",
       "      <td>0.918786</td>\n",
       "      <td>0.352551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.173700</td>\n",
       "      <td>0.352885</td>\n",
       "      <td>0.915505</td>\n",
       "      <td>0.364583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.160400</td>\n",
       "      <td>0.360544</td>\n",
       "      <td>0.917966</td>\n",
       "      <td>0.353115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.160400</td>\n",
       "      <td>0.339007</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.365176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.155000</td>\n",
       "      <td>0.361098</td>\n",
       "      <td>0.918786</td>\n",
       "      <td>0.368100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.127000</td>\n",
       "      <td>0.341196</td>\n",
       "      <td>0.917145</td>\n",
       "      <td>0.374348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.138600</td>\n",
       "      <td>0.354601</td>\n",
       "      <td>0.918786</td>\n",
       "      <td>0.372491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.119900</td>\n",
       "      <td>0.346018</td>\n",
       "      <td>0.915505</td>\n",
       "      <td>0.370434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.103000</td>\n",
       "      <td>0.351025</td>\n",
       "      <td>0.920427</td>\n",
       "      <td>0.371620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.125800</td>\n",
       "      <td>0.348622</td>\n",
       "      <td>0.919606</td>\n",
       "      <td>0.377132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.121300</td>\n",
       "      <td>0.349456</td>\n",
       "      <td>0.918786</td>\n",
       "      <td>0.373689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/EgyBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/EgyBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0779e477d71b4eceb1bda81900485099",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a69ea9a85e24c9c8a920045cba3b188",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1155' max='1155' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1155/1155 01:46, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.468900</td>\n",
       "      <td>1.180937</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.156667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.881900</td>\n",
       "      <td>0.599113</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.156667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.539800</td>\n",
       "      <td>0.503301</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.156667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.488600</td>\n",
       "      <td>0.496204</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.156667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.482600</td>\n",
       "      <td>0.448140</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.156667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.397700</td>\n",
       "      <td>0.366558</td>\n",
       "      <td>0.900738</td>\n",
       "      <td>0.256127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.341000</td>\n",
       "      <td>0.333267</td>\n",
       "      <td>0.904020</td>\n",
       "      <td>0.260512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.307300</td>\n",
       "      <td>0.318960</td>\n",
       "      <td>0.917966</td>\n",
       "      <td>0.337257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.275300</td>\n",
       "      <td>0.308355</td>\n",
       "      <td>0.902379</td>\n",
       "      <td>0.294310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.235800</td>\n",
       "      <td>0.340173</td>\n",
       "      <td>0.912223</td>\n",
       "      <td>0.321625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.238300</td>\n",
       "      <td>0.350508</td>\n",
       "      <td>0.915505</td>\n",
       "      <td>0.335557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.209900</td>\n",
       "      <td>0.335363</td>\n",
       "      <td>0.914684</td>\n",
       "      <td>0.342540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.203000</td>\n",
       "      <td>0.345171</td>\n",
       "      <td>0.918786</td>\n",
       "      <td>0.352551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.173700</td>\n",
       "      <td>0.352885</td>\n",
       "      <td>0.915505</td>\n",
       "      <td>0.364583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.160400</td>\n",
       "      <td>0.360544</td>\n",
       "      <td>0.917966</td>\n",
       "      <td>0.353115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.160400</td>\n",
       "      <td>0.339007</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.365176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.155000</td>\n",
       "      <td>0.361098</td>\n",
       "      <td>0.918786</td>\n",
       "      <td>0.368100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.127000</td>\n",
       "      <td>0.341196</td>\n",
       "      <td>0.917145</td>\n",
       "      <td>0.374348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.138600</td>\n",
       "      <td>0.354601</td>\n",
       "      <td>0.918786</td>\n",
       "      <td>0.372491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.119900</td>\n",
       "      <td>0.346018</td>\n",
       "      <td>0.915505</td>\n",
       "      <td>0.370434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.103000</td>\n",
       "      <td>0.351025</td>\n",
       "      <td>0.920427</td>\n",
       "      <td>0.371620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.125800</td>\n",
       "      <td>0.348622</td>\n",
       "      <td>0.919606</td>\n",
       "      <td>0.377132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.121300</td>\n",
       "      <td>0.349456</td>\n",
       "      <td>0.918786</td>\n",
       "      <td>0.373689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Text', 'label', '__index_level_0__'],\n",
       "        num_rows: 4872\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Text', 'label', '__index_level_0__'],\n",
       "        num_rows: 1219\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6694bc6529ef4401a4387dd8c8d41be9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3ddcbc893cc4c5da5c6a86574633e96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1155' max='1155' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1155/1155 01:47, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.392900</td>\n",
       "      <td>0.208489</td>\n",
       "      <td>0.925349</td>\n",
       "      <td>0.409819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>0.221950</td>\n",
       "      <td>0.920427</td>\n",
       "      <td>0.433376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.192600</td>\n",
       "      <td>0.221866</td>\n",
       "      <td>0.926169</td>\n",
       "      <td>0.418675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.113500</td>\n",
       "      <td>0.313264</td>\n",
       "      <td>0.921247</td>\n",
       "      <td>0.532405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>0.312892</td>\n",
       "      <td>0.927810</td>\n",
       "      <td>0.500254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.050600</td>\n",
       "      <td>0.360930</td>\n",
       "      <td>0.928630</td>\n",
       "      <td>0.539744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.026400</td>\n",
       "      <td>0.369709</td>\n",
       "      <td>0.927810</td>\n",
       "      <td>0.401491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.014500</td>\n",
       "      <td>0.436763</td>\n",
       "      <td>0.918786</td>\n",
       "      <td>0.521496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.440025</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.520653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>0.477509</td>\n",
       "      <td>0.917145</td>\n",
       "      <td>0.471431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>0.475257</td>\n",
       "      <td>0.923708</td>\n",
       "      <td>0.522169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.510115</td>\n",
       "      <td>0.919606</td>\n",
       "      <td>0.508592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.479187</td>\n",
       "      <td>0.920427</td>\n",
       "      <td>0.524318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.484043</td>\n",
       "      <td>0.922888</td>\n",
       "      <td>0.526851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.499519</td>\n",
       "      <td>0.920427</td>\n",
       "      <td>0.513948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.521605</td>\n",
       "      <td>0.920427</td>\n",
       "      <td>0.514077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.523682</td>\n",
       "      <td>0.919606</td>\n",
       "      <td>0.511488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.518685</td>\n",
       "      <td>0.918786</td>\n",
       "      <td>0.506307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.515604</td>\n",
       "      <td>0.921247</td>\n",
       "      <td>0.513985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.512460</td>\n",
       "      <td>0.921247</td>\n",
       "      <td>0.516314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.512674</td>\n",
       "      <td>0.921247</td>\n",
       "      <td>0.516649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.513171</td>\n",
       "      <td>0.921247</td>\n",
       "      <td>0.516649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.513593</td>\n",
       "      <td>0.921247</td>\n",
       "      <td>0.516649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fa956fc9afa49bd9a5aed6684b80b83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdb9bee060384bde93ea3d6b448daff1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1155' max='1155' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1155/1155 01:47, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.392900</td>\n",
       "      <td>0.208489</td>\n",
       "      <td>0.925349</td>\n",
       "      <td>0.409819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>0.221950</td>\n",
       "      <td>0.920427</td>\n",
       "      <td>0.433376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.192600</td>\n",
       "      <td>0.221866</td>\n",
       "      <td>0.926169</td>\n",
       "      <td>0.418675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.113500</td>\n",
       "      <td>0.313264</td>\n",
       "      <td>0.921247</td>\n",
       "      <td>0.532405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>0.312892</td>\n",
       "      <td>0.927810</td>\n",
       "      <td>0.500254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.050600</td>\n",
       "      <td>0.360930</td>\n",
       "      <td>0.928630</td>\n",
       "      <td>0.539744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.026400</td>\n",
       "      <td>0.369709</td>\n",
       "      <td>0.927810</td>\n",
       "      <td>0.401491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.014500</td>\n",
       "      <td>0.436763</td>\n",
       "      <td>0.918786</td>\n",
       "      <td>0.521496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.440025</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.520653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>0.477509</td>\n",
       "      <td>0.917145</td>\n",
       "      <td>0.471431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>0.475257</td>\n",
       "      <td>0.923708</td>\n",
       "      <td>0.522169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.510115</td>\n",
       "      <td>0.919606</td>\n",
       "      <td>0.508592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.479187</td>\n",
       "      <td>0.920427</td>\n",
       "      <td>0.524318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.484043</td>\n",
       "      <td>0.922888</td>\n",
       "      <td>0.526851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.499519</td>\n",
       "      <td>0.920427</td>\n",
       "      <td>0.513948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.521605</td>\n",
       "      <td>0.920427</td>\n",
       "      <td>0.514077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.523682</td>\n",
       "      <td>0.919606</td>\n",
       "      <td>0.511488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.518685</td>\n",
       "      <td>0.918786</td>\n",
       "      <td>0.506307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.515604</td>\n",
       "      <td>0.921247</td>\n",
       "      <td>0.513985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.512460</td>\n",
       "      <td>0.921247</td>\n",
       "      <td>0.516314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.512674</td>\n",
       "      <td>0.921247</td>\n",
       "      <td>0.516649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.513171</td>\n",
       "      <td>0.921247</td>\n",
       "      <td>0.516649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.513593</td>\n",
       "      <td>0.921247</td>\n",
       "      <td>0.516649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a1a0253f00d4fc28689664189ceec2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15b41b9c249a46d1a07d543d2e5564ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1155' max='1155' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1155/1155 01:47, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.392900</td>\n",
       "      <td>0.208489</td>\n",
       "      <td>0.925349</td>\n",
       "      <td>0.409819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>0.221950</td>\n",
       "      <td>0.920427</td>\n",
       "      <td>0.433376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.192600</td>\n",
       "      <td>0.221866</td>\n",
       "      <td>0.926169</td>\n",
       "      <td>0.418675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.113500</td>\n",
       "      <td>0.313264</td>\n",
       "      <td>0.921247</td>\n",
       "      <td>0.532405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>0.312892</td>\n",
       "      <td>0.927810</td>\n",
       "      <td>0.500254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.050600</td>\n",
       "      <td>0.360930</td>\n",
       "      <td>0.928630</td>\n",
       "      <td>0.539744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.026400</td>\n",
       "      <td>0.369709</td>\n",
       "      <td>0.927810</td>\n",
       "      <td>0.401491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.014500</td>\n",
       "      <td>0.436763</td>\n",
       "      <td>0.918786</td>\n",
       "      <td>0.521496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.440025</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.520653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>0.477509</td>\n",
       "      <td>0.917145</td>\n",
       "      <td>0.471431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>0.475257</td>\n",
       "      <td>0.923708</td>\n",
       "      <td>0.522169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.510115</td>\n",
       "      <td>0.919606</td>\n",
       "      <td>0.508592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.479187</td>\n",
       "      <td>0.920427</td>\n",
       "      <td>0.524318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.484043</td>\n",
       "      <td>0.922888</td>\n",
       "      <td>0.526851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.499519</td>\n",
       "      <td>0.920427</td>\n",
       "      <td>0.513948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.521605</td>\n",
       "      <td>0.920427</td>\n",
       "      <td>0.514077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.523682</td>\n",
       "      <td>0.919606</td>\n",
       "      <td>0.511488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.518685</td>\n",
       "      <td>0.918786</td>\n",
       "      <td>0.506307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.515604</td>\n",
       "      <td>0.921247</td>\n",
       "      <td>0.513985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.512460</td>\n",
       "      <td>0.921247</td>\n",
       "      <td>0.516314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.512674</td>\n",
       "      <td>0.921247</td>\n",
       "      <td>0.516649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.513171</td>\n",
       "      <td>0.921247</td>\n",
       "      <td>0.516649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.513593</td>\n",
       "      <td>0.921247</td>\n",
       "      <td>0.516649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7019f355e3ac4c9383c169f477dea1f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "221ec4b1a3ff4480840cf5dc5b7e0327",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1155' max='1155' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1155/1155 01:47, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.380100</td>\n",
       "      <td>0.269527</td>\n",
       "      <td>0.908942</td>\n",
       "      <td>0.292528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.220900</td>\n",
       "      <td>0.249000</td>\n",
       "      <td>0.922888</td>\n",
       "      <td>0.426160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.186300</td>\n",
       "      <td>0.261915</td>\n",
       "      <td>0.926989</td>\n",
       "      <td>0.415579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.097400</td>\n",
       "      <td>0.295371</td>\n",
       "      <td>0.926989</td>\n",
       "      <td>0.432941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.076800</td>\n",
       "      <td>0.302658</td>\n",
       "      <td>0.931091</td>\n",
       "      <td>0.443688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.045200</td>\n",
       "      <td>0.372874</td>\n",
       "      <td>0.927810</td>\n",
       "      <td>0.540112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.010500</td>\n",
       "      <td>0.392948</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.503745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.019900</td>\n",
       "      <td>0.404478</td>\n",
       "      <td>0.926989</td>\n",
       "      <td>0.538760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.008400</td>\n",
       "      <td>0.422026</td>\n",
       "      <td>0.925349</td>\n",
       "      <td>0.512056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>0.407275</td>\n",
       "      <td>0.921247</td>\n",
       "      <td>0.521964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.440456</td>\n",
       "      <td>0.923708</td>\n",
       "      <td>0.522115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>0.444354</td>\n",
       "      <td>0.927810</td>\n",
       "      <td>0.527513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.449049</td>\n",
       "      <td>0.926989</td>\n",
       "      <td>0.523008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.459308</td>\n",
       "      <td>0.928630</td>\n",
       "      <td>0.526911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.455891</td>\n",
       "      <td>0.927810</td>\n",
       "      <td>0.525895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.458766</td>\n",
       "      <td>0.927810</td>\n",
       "      <td>0.523715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.464310</td>\n",
       "      <td>0.927810</td>\n",
       "      <td>0.523715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.468584</td>\n",
       "      <td>0.927810</td>\n",
       "      <td>0.526637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.470001</td>\n",
       "      <td>0.927810</td>\n",
       "      <td>0.526637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.472715</td>\n",
       "      <td>0.927810</td>\n",
       "      <td>0.526637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.474322</td>\n",
       "      <td>0.927810</td>\n",
       "      <td>0.526637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.475046</td>\n",
       "      <td>0.927810</td>\n",
       "      <td>0.526637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.475258</td>\n",
       "      <td>0.927810</td>\n",
       "      <td>0.526637</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e19269e12fce4ca292b676b165d224fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a627f0161a0a4de191d0c98c7e6bb263",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1155' max='1155' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1155/1155 01:47, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.380100</td>\n",
       "      <td>0.269527</td>\n",
       "      <td>0.908942</td>\n",
       "      <td>0.292528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.220900</td>\n",
       "      <td>0.249000</td>\n",
       "      <td>0.922888</td>\n",
       "      <td>0.426160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.186300</td>\n",
       "      <td>0.261915</td>\n",
       "      <td>0.926989</td>\n",
       "      <td>0.415579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.097400</td>\n",
       "      <td>0.295371</td>\n",
       "      <td>0.926989</td>\n",
       "      <td>0.432941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.076800</td>\n",
       "      <td>0.302658</td>\n",
       "      <td>0.931091</td>\n",
       "      <td>0.443688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.045200</td>\n",
       "      <td>0.372874</td>\n",
       "      <td>0.927810</td>\n",
       "      <td>0.540112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.010500</td>\n",
       "      <td>0.392948</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.503745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.019900</td>\n",
       "      <td>0.404478</td>\n",
       "      <td>0.926989</td>\n",
       "      <td>0.538760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.008400</td>\n",
       "      <td>0.422026</td>\n",
       "      <td>0.925349</td>\n",
       "      <td>0.512056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>0.407275</td>\n",
       "      <td>0.921247</td>\n",
       "      <td>0.521964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.440456</td>\n",
       "      <td>0.923708</td>\n",
       "      <td>0.522115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>0.444354</td>\n",
       "      <td>0.927810</td>\n",
       "      <td>0.527513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.449049</td>\n",
       "      <td>0.926989</td>\n",
       "      <td>0.523008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.459308</td>\n",
       "      <td>0.928630</td>\n",
       "      <td>0.526911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.455891</td>\n",
       "      <td>0.927810</td>\n",
       "      <td>0.525895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.458766</td>\n",
       "      <td>0.927810</td>\n",
       "      <td>0.523715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.464310</td>\n",
       "      <td>0.927810</td>\n",
       "      <td>0.523715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.468584</td>\n",
       "      <td>0.927810</td>\n",
       "      <td>0.526637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.470001</td>\n",
       "      <td>0.927810</td>\n",
       "      <td>0.526637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.472715</td>\n",
       "      <td>0.927810</td>\n",
       "      <td>0.526637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.474322</td>\n",
       "      <td>0.927810</td>\n",
       "      <td>0.526637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.475046</td>\n",
       "      <td>0.927810</td>\n",
       "      <td>0.526637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.475258</td>\n",
       "      <td>0.927810</td>\n",
       "      <td>0.526637</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "412cbc9095fb41a9980b43bcbbb22401",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b085a8efb744f9f88d4b225cf60be32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1155' max='1155' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1155/1155 01:44, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.380100</td>\n",
       "      <td>0.269527</td>\n",
       "      <td>0.908942</td>\n",
       "      <td>0.292528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.220900</td>\n",
       "      <td>0.249000</td>\n",
       "      <td>0.922888</td>\n",
       "      <td>0.426160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.186300</td>\n",
       "      <td>0.261915</td>\n",
       "      <td>0.926989</td>\n",
       "      <td>0.415579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.097400</td>\n",
       "      <td>0.295371</td>\n",
       "      <td>0.926989</td>\n",
       "      <td>0.432941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.076800</td>\n",
       "      <td>0.302658</td>\n",
       "      <td>0.931091</td>\n",
       "      <td>0.443688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.045200</td>\n",
       "      <td>0.372874</td>\n",
       "      <td>0.927810</td>\n",
       "      <td>0.540112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.010500</td>\n",
       "      <td>0.392948</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.503745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.019900</td>\n",
       "      <td>0.404478</td>\n",
       "      <td>0.926989</td>\n",
       "      <td>0.538760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.008400</td>\n",
       "      <td>0.422026</td>\n",
       "      <td>0.925349</td>\n",
       "      <td>0.512056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>0.407275</td>\n",
       "      <td>0.921247</td>\n",
       "      <td>0.521964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.440456</td>\n",
       "      <td>0.923708</td>\n",
       "      <td>0.522115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>0.444354</td>\n",
       "      <td>0.927810</td>\n",
       "      <td>0.527513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.449049</td>\n",
       "      <td>0.926989</td>\n",
       "      <td>0.523008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.459308</td>\n",
       "      <td>0.928630</td>\n",
       "      <td>0.526911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.455891</td>\n",
       "      <td>0.927810</td>\n",
       "      <td>0.525895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.458766</td>\n",
       "      <td>0.927810</td>\n",
       "      <td>0.523715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.464310</td>\n",
       "      <td>0.927810</td>\n",
       "      <td>0.523715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.468584</td>\n",
       "      <td>0.927810</td>\n",
       "      <td>0.526637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.470001</td>\n",
       "      <td>0.927810</td>\n",
       "      <td>0.526637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.472715</td>\n",
       "      <td>0.927810</td>\n",
       "      <td>0.526637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.474322</td>\n",
       "      <td>0.927810</td>\n",
       "      <td>0.526637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.475046</td>\n",
       "      <td>0.927810</td>\n",
       "      <td>0.526637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.475258</td>\n",
       "      <td>0.927810</td>\n",
       "      <td>0.526637</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39ec943cfb44447eba73b9898d333dfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c80db88c3ea842449fdeccc8624ad48c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1155' max='1155' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1155/1155 01:44, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.359300</td>\n",
       "      <td>0.314084</td>\n",
       "      <td>0.904020</td>\n",
       "      <td>0.272265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.249800</td>\n",
       "      <td>0.320104</td>\n",
       "      <td>0.913864</td>\n",
       "      <td>0.338079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.204800</td>\n",
       "      <td>0.238615</td>\n",
       "      <td>0.917966</td>\n",
       "      <td>0.394359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.116200</td>\n",
       "      <td>0.298814</td>\n",
       "      <td>0.913864</td>\n",
       "      <td>0.508373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.079700</td>\n",
       "      <td>0.343433</td>\n",
       "      <td>0.916325</td>\n",
       "      <td>0.495403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.048200</td>\n",
       "      <td>0.334610</td>\n",
       "      <td>0.923708</td>\n",
       "      <td>0.536460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.025900</td>\n",
       "      <td>0.379459</td>\n",
       "      <td>0.908121</td>\n",
       "      <td>0.410841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.013300</td>\n",
       "      <td>0.452809</td>\n",
       "      <td>0.904020</td>\n",
       "      <td>0.497853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>0.411591</td>\n",
       "      <td>0.930271</td>\n",
       "      <td>0.530725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.440414</td>\n",
       "      <td>0.918786</td>\n",
       "      <td>0.487410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.428976</td>\n",
       "      <td>0.922067</td>\n",
       "      <td>0.550801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.437276</td>\n",
       "      <td>0.922888</td>\n",
       "      <td>0.573169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.455220</td>\n",
       "      <td>0.917966</td>\n",
       "      <td>0.481293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.477101</td>\n",
       "      <td>0.917966</td>\n",
       "      <td>0.487345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.470333</td>\n",
       "      <td>0.926169</td>\n",
       "      <td>0.484414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.490581</td>\n",
       "      <td>0.916325</td>\n",
       "      <td>0.487862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.503166</td>\n",
       "      <td>0.915505</td>\n",
       "      <td>0.487064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.489726</td>\n",
       "      <td>0.921247</td>\n",
       "      <td>0.494303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.493232</td>\n",
       "      <td>0.921247</td>\n",
       "      <td>0.494303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.494417</td>\n",
       "      <td>0.921247</td>\n",
       "      <td>0.494303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.495800</td>\n",
       "      <td>0.922067</td>\n",
       "      <td>0.495053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.496834</td>\n",
       "      <td>0.921247</td>\n",
       "      <td>0.494303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.496941</td>\n",
       "      <td>0.922067</td>\n",
       "      <td>0.495053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03fca069a46c416998b719263cf2d07d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70a9480f657648b88b83e2f044184bb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1155' max='1155' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1155/1155 01:44, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.359300</td>\n",
       "      <td>0.314084</td>\n",
       "      <td>0.904020</td>\n",
       "      <td>0.272265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.249800</td>\n",
       "      <td>0.320104</td>\n",
       "      <td>0.913864</td>\n",
       "      <td>0.338079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.204800</td>\n",
       "      <td>0.238615</td>\n",
       "      <td>0.917966</td>\n",
       "      <td>0.394359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.116200</td>\n",
       "      <td>0.298814</td>\n",
       "      <td>0.913864</td>\n",
       "      <td>0.508373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.079700</td>\n",
       "      <td>0.343433</td>\n",
       "      <td>0.916325</td>\n",
       "      <td>0.495403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.048200</td>\n",
       "      <td>0.334610</td>\n",
       "      <td>0.923708</td>\n",
       "      <td>0.536460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.025900</td>\n",
       "      <td>0.379459</td>\n",
       "      <td>0.908121</td>\n",
       "      <td>0.410841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.013300</td>\n",
       "      <td>0.452809</td>\n",
       "      <td>0.904020</td>\n",
       "      <td>0.497853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>0.411591</td>\n",
       "      <td>0.930271</td>\n",
       "      <td>0.530725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.440414</td>\n",
       "      <td>0.918786</td>\n",
       "      <td>0.487410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.428976</td>\n",
       "      <td>0.922067</td>\n",
       "      <td>0.550801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.437276</td>\n",
       "      <td>0.922888</td>\n",
       "      <td>0.573169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.455220</td>\n",
       "      <td>0.917966</td>\n",
       "      <td>0.481293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.477101</td>\n",
       "      <td>0.917966</td>\n",
       "      <td>0.487345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.470333</td>\n",
       "      <td>0.926169</td>\n",
       "      <td>0.484414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.490581</td>\n",
       "      <td>0.916325</td>\n",
       "      <td>0.487862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.503166</td>\n",
       "      <td>0.915505</td>\n",
       "      <td>0.487064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.489726</td>\n",
       "      <td>0.921247</td>\n",
       "      <td>0.494303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.493232</td>\n",
       "      <td>0.921247</td>\n",
       "      <td>0.494303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.494417</td>\n",
       "      <td>0.921247</td>\n",
       "      <td>0.494303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.495800</td>\n",
       "      <td>0.922067</td>\n",
       "      <td>0.495053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.496834</td>\n",
       "      <td>0.921247</td>\n",
       "      <td>0.494303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.496941</td>\n",
       "      <td>0.922067</td>\n",
       "      <td>0.495053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d57bde76b79490f88a60c26cae2d4e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7387842d4a484bc691b38e7d1b7df7f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1155' max='1155' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1155/1155 01:44, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.359300</td>\n",
       "      <td>0.314084</td>\n",
       "      <td>0.904020</td>\n",
       "      <td>0.272265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.249800</td>\n",
       "      <td>0.320104</td>\n",
       "      <td>0.913864</td>\n",
       "      <td>0.338079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.204800</td>\n",
       "      <td>0.238615</td>\n",
       "      <td>0.917966</td>\n",
       "      <td>0.394359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.116200</td>\n",
       "      <td>0.298814</td>\n",
       "      <td>0.913864</td>\n",
       "      <td>0.508373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.079700</td>\n",
       "      <td>0.343433</td>\n",
       "      <td>0.916325</td>\n",
       "      <td>0.495403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.048200</td>\n",
       "      <td>0.334610</td>\n",
       "      <td>0.923708</td>\n",
       "      <td>0.536460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.025900</td>\n",
       "      <td>0.379459</td>\n",
       "      <td>0.908121</td>\n",
       "      <td>0.410841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.013300</td>\n",
       "      <td>0.452809</td>\n",
       "      <td>0.904020</td>\n",
       "      <td>0.497853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>0.411591</td>\n",
       "      <td>0.930271</td>\n",
       "      <td>0.530725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.440414</td>\n",
       "      <td>0.918786</td>\n",
       "      <td>0.487410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.428976</td>\n",
       "      <td>0.922067</td>\n",
       "      <td>0.550801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.437276</td>\n",
       "      <td>0.922888</td>\n",
       "      <td>0.573169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.455220</td>\n",
       "      <td>0.917966</td>\n",
       "      <td>0.481293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.477101</td>\n",
       "      <td>0.917966</td>\n",
       "      <td>0.487345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.470333</td>\n",
       "      <td>0.926169</td>\n",
       "      <td>0.484414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.490581</td>\n",
       "      <td>0.916325</td>\n",
       "      <td>0.487862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.503166</td>\n",
       "      <td>0.915505</td>\n",
       "      <td>0.487064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.489726</td>\n",
       "      <td>0.921247</td>\n",
       "      <td>0.494303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.493232</td>\n",
       "      <td>0.921247</td>\n",
       "      <td>0.494303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.494417</td>\n",
       "      <td>0.921247</td>\n",
       "      <td>0.494303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.495800</td>\n",
       "      <td>0.922067</td>\n",
       "      <td>0.495053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.496834</td>\n",
       "      <td>0.921247</td>\n",
       "      <td>0.494303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.496941</td>\n",
       "      <td>0.922067</td>\n",
       "      <td>0.495053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Text', 'label', '__index_level_0__'],\n",
       "        num_rows: 4872\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Text', 'label', '__index_level_0__'],\n",
       "        num_rows: 1219\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunis-ai/TunBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tunis-ai/TunBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f3b8f75e6474aec831ad3878215d1af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "906d5ab1c505448796452f9647622720",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1155' max='1155' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1155/1155 01:39, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.423700</td>\n",
       "      <td>0.318051</td>\n",
       "      <td>0.898277</td>\n",
       "      <td>0.189283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.340100</td>\n",
       "      <td>0.281540</td>\n",
       "      <td>0.894996</td>\n",
       "      <td>0.278557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.336700</td>\n",
       "      <td>0.268409</td>\n",
       "      <td>0.904020</td>\n",
       "      <td>0.290998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.308500</td>\n",
       "      <td>0.288913</td>\n",
       "      <td>0.906481</td>\n",
       "      <td>0.274018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.310400</td>\n",
       "      <td>0.264992</td>\n",
       "      <td>0.904020</td>\n",
       "      <td>0.379989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.291300</td>\n",
       "      <td>0.254567</td>\n",
       "      <td>0.908942</td>\n",
       "      <td>0.393911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.303200</td>\n",
       "      <td>0.264433</td>\n",
       "      <td>0.908121</td>\n",
       "      <td>0.345351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.272500</td>\n",
       "      <td>0.261467</td>\n",
       "      <td>0.910582</td>\n",
       "      <td>0.388239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.295300</td>\n",
       "      <td>0.264179</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.324718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.250800</td>\n",
       "      <td>0.249008</td>\n",
       "      <td>0.910582</td>\n",
       "      <td>0.398813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.240300</td>\n",
       "      <td>0.244646</td>\n",
       "      <td>0.923708</td>\n",
       "      <td>0.403577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.247700</td>\n",
       "      <td>0.374205</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.320096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.245300</td>\n",
       "      <td>0.288071</td>\n",
       "      <td>0.920427</td>\n",
       "      <td>0.372121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.211200</td>\n",
       "      <td>0.304228</td>\n",
       "      <td>0.920427</td>\n",
       "      <td>0.395000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.208800</td>\n",
       "      <td>0.274839</td>\n",
       "      <td>0.904840</td>\n",
       "      <td>0.379824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.222700</td>\n",
       "      <td>0.315740</td>\n",
       "      <td>0.920427</td>\n",
       "      <td>0.383123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.198200</td>\n",
       "      <td>0.302177</td>\n",
       "      <td>0.923708</td>\n",
       "      <td>0.399165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.183300</td>\n",
       "      <td>0.322982</td>\n",
       "      <td>0.907301</td>\n",
       "      <td>0.387084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.195400</td>\n",
       "      <td>0.320238</td>\n",
       "      <td>0.909762</td>\n",
       "      <td>0.388475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.173100</td>\n",
       "      <td>0.316074</td>\n",
       "      <td>0.901559</td>\n",
       "      <td>0.385918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.167300</td>\n",
       "      <td>0.343124</td>\n",
       "      <td>0.908121</td>\n",
       "      <td>0.387265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.142500</td>\n",
       "      <td>0.354082</td>\n",
       "      <td>0.906481</td>\n",
       "      <td>0.389827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.156700</td>\n",
       "      <td>0.351360</td>\n",
       "      <td>0.904020</td>\n",
       "      <td>0.377939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunis-ai/TunBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tunis-ai/TunBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c420d9b8e074f87bdfb2f248ce6417e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29b10e431f11463bb1fa514cb1d7aa07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1155' max='1155' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1155/1155 01:39, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.423700</td>\n",
       "      <td>0.318051</td>\n",
       "      <td>0.898277</td>\n",
       "      <td>0.189283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.340100</td>\n",
       "      <td>0.281540</td>\n",
       "      <td>0.894996</td>\n",
       "      <td>0.278557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.336700</td>\n",
       "      <td>0.268409</td>\n",
       "      <td>0.904020</td>\n",
       "      <td>0.290998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.308500</td>\n",
       "      <td>0.288913</td>\n",
       "      <td>0.906481</td>\n",
       "      <td>0.274018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.310400</td>\n",
       "      <td>0.264992</td>\n",
       "      <td>0.904020</td>\n",
       "      <td>0.379989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.291300</td>\n",
       "      <td>0.254567</td>\n",
       "      <td>0.908942</td>\n",
       "      <td>0.393911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.303200</td>\n",
       "      <td>0.264433</td>\n",
       "      <td>0.908121</td>\n",
       "      <td>0.345351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.272500</td>\n",
       "      <td>0.261467</td>\n",
       "      <td>0.910582</td>\n",
       "      <td>0.388239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.295300</td>\n",
       "      <td>0.264179</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.324718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.250800</td>\n",
       "      <td>0.249008</td>\n",
       "      <td>0.910582</td>\n",
       "      <td>0.398813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.240300</td>\n",
       "      <td>0.244646</td>\n",
       "      <td>0.923708</td>\n",
       "      <td>0.403577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.247700</td>\n",
       "      <td>0.374205</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.320096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.245300</td>\n",
       "      <td>0.288071</td>\n",
       "      <td>0.920427</td>\n",
       "      <td>0.372121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.211200</td>\n",
       "      <td>0.304228</td>\n",
       "      <td>0.920427</td>\n",
       "      <td>0.395000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.208800</td>\n",
       "      <td>0.274839</td>\n",
       "      <td>0.904840</td>\n",
       "      <td>0.379824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.222700</td>\n",
       "      <td>0.315740</td>\n",
       "      <td>0.920427</td>\n",
       "      <td>0.383123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.198200</td>\n",
       "      <td>0.302177</td>\n",
       "      <td>0.923708</td>\n",
       "      <td>0.399165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.183300</td>\n",
       "      <td>0.322982</td>\n",
       "      <td>0.907301</td>\n",
       "      <td>0.387084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.195400</td>\n",
       "      <td>0.320238</td>\n",
       "      <td>0.909762</td>\n",
       "      <td>0.388475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.173100</td>\n",
       "      <td>0.316074</td>\n",
       "      <td>0.901559</td>\n",
       "      <td>0.385918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.167300</td>\n",
       "      <td>0.343124</td>\n",
       "      <td>0.908121</td>\n",
       "      <td>0.387265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.142500</td>\n",
       "      <td>0.354082</td>\n",
       "      <td>0.906481</td>\n",
       "      <td>0.389827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.156700</td>\n",
       "      <td>0.351360</td>\n",
       "      <td>0.904020</td>\n",
       "      <td>0.377939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunis-ai/TunBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tunis-ai/TunBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39d3bc73da6a407c823a635d4f728466",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "192df89f5ed841d2b265913ede7537de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1155' max='1155' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1155/1155 01:39, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.423700</td>\n",
       "      <td>0.318051</td>\n",
       "      <td>0.898277</td>\n",
       "      <td>0.189283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.340100</td>\n",
       "      <td>0.281540</td>\n",
       "      <td>0.894996</td>\n",
       "      <td>0.278557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.336700</td>\n",
       "      <td>0.268409</td>\n",
       "      <td>0.904020</td>\n",
       "      <td>0.290998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.308500</td>\n",
       "      <td>0.288913</td>\n",
       "      <td>0.906481</td>\n",
       "      <td>0.274018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.310400</td>\n",
       "      <td>0.264992</td>\n",
       "      <td>0.904020</td>\n",
       "      <td>0.379989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.291300</td>\n",
       "      <td>0.254567</td>\n",
       "      <td>0.908942</td>\n",
       "      <td>0.393911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.303200</td>\n",
       "      <td>0.264433</td>\n",
       "      <td>0.908121</td>\n",
       "      <td>0.345351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.272500</td>\n",
       "      <td>0.261467</td>\n",
       "      <td>0.910582</td>\n",
       "      <td>0.388239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.295300</td>\n",
       "      <td>0.264179</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.324718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.250800</td>\n",
       "      <td>0.249008</td>\n",
       "      <td>0.910582</td>\n",
       "      <td>0.398813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.240300</td>\n",
       "      <td>0.244646</td>\n",
       "      <td>0.923708</td>\n",
       "      <td>0.403577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.247700</td>\n",
       "      <td>0.374205</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.320096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.245300</td>\n",
       "      <td>0.288071</td>\n",
       "      <td>0.920427</td>\n",
       "      <td>0.372121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.211200</td>\n",
       "      <td>0.304228</td>\n",
       "      <td>0.920427</td>\n",
       "      <td>0.395000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.208800</td>\n",
       "      <td>0.274839</td>\n",
       "      <td>0.904840</td>\n",
       "      <td>0.379824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.222700</td>\n",
       "      <td>0.315740</td>\n",
       "      <td>0.920427</td>\n",
       "      <td>0.383123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.198200</td>\n",
       "      <td>0.302177</td>\n",
       "      <td>0.923708</td>\n",
       "      <td>0.399165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.183300</td>\n",
       "      <td>0.322982</td>\n",
       "      <td>0.907301</td>\n",
       "      <td>0.387084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.195400</td>\n",
       "      <td>0.320238</td>\n",
       "      <td>0.909762</td>\n",
       "      <td>0.388475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.173100</td>\n",
       "      <td>0.316074</td>\n",
       "      <td>0.901559</td>\n",
       "      <td>0.385918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.167300</td>\n",
       "      <td>0.343124</td>\n",
       "      <td>0.908121</td>\n",
       "      <td>0.387265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.142500</td>\n",
       "      <td>0.354082</td>\n",
       "      <td>0.906481</td>\n",
       "      <td>0.389827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.156700</td>\n",
       "      <td>0.351360</td>\n",
       "      <td>0.904020</td>\n",
       "      <td>0.377939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunis-ai/TunBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tunis-ai/TunBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "830ba2291b0844688aa07c37ead250b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30b6ee50f7a24620bde9a66c5cffd4e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1155' max='1155' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1155/1155 01:39, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.437200</td>\n",
       "      <td>0.396763</td>\n",
       "      <td>0.884331</td>\n",
       "      <td>0.156436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.344400</td>\n",
       "      <td>0.341917</td>\n",
       "      <td>0.884331</td>\n",
       "      <td>0.165370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.326300</td>\n",
       "      <td>0.330977</td>\n",
       "      <td>0.884331</td>\n",
       "      <td>0.156436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.337200</td>\n",
       "      <td>0.332945</td>\n",
       "      <td>0.885152</td>\n",
       "      <td>0.213303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.340400</td>\n",
       "      <td>0.317804</td>\n",
       "      <td>0.904020</td>\n",
       "      <td>0.324954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.298800</td>\n",
       "      <td>0.308792</td>\n",
       "      <td>0.901559</td>\n",
       "      <td>0.260504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.308788</td>\n",
       "      <td>0.902379</td>\n",
       "      <td>0.287517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.276800</td>\n",
       "      <td>0.307075</td>\n",
       "      <td>0.906481</td>\n",
       "      <td>0.336307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.270500</td>\n",
       "      <td>0.312303</td>\n",
       "      <td>0.904020</td>\n",
       "      <td>0.312458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.271300</td>\n",
       "      <td>0.303797</td>\n",
       "      <td>0.899098</td>\n",
       "      <td>0.330578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.210000</td>\n",
       "      <td>0.391972</td>\n",
       "      <td>0.904840</td>\n",
       "      <td>0.297775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.238000</td>\n",
       "      <td>0.366677</td>\n",
       "      <td>0.899918</td>\n",
       "      <td>0.295714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.225300</td>\n",
       "      <td>0.354843</td>\n",
       "      <td>0.899918</td>\n",
       "      <td>0.306104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.218200</td>\n",
       "      <td>0.373466</td>\n",
       "      <td>0.894996</td>\n",
       "      <td>0.308351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.207900</td>\n",
       "      <td>0.355922</td>\n",
       "      <td>0.890894</td>\n",
       "      <td>0.321830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.198400</td>\n",
       "      <td>0.351402</td>\n",
       "      <td>0.894176</td>\n",
       "      <td>0.333858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.188100</td>\n",
       "      <td>0.392797</td>\n",
       "      <td>0.890074</td>\n",
       "      <td>0.328675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.183700</td>\n",
       "      <td>0.398505</td>\n",
       "      <td>0.887613</td>\n",
       "      <td>0.329455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.179600</td>\n",
       "      <td>0.376195</td>\n",
       "      <td>0.894996</td>\n",
       "      <td>0.335104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.173700</td>\n",
       "      <td>0.403924</td>\n",
       "      <td>0.895816</td>\n",
       "      <td>0.328308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.167200</td>\n",
       "      <td>0.399248</td>\n",
       "      <td>0.894176</td>\n",
       "      <td>0.325833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.442224</td>\n",
       "      <td>0.898277</td>\n",
       "      <td>0.332409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.168200</td>\n",
       "      <td>0.435335</td>\n",
       "      <td>0.890894</td>\n",
       "      <td>0.325742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunis-ai/TunBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tunis-ai/TunBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa5b594f052c499cb902a9adb6503172",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bed8ae687264b9193de2a42574638da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1155' max='1155' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1155/1155 01:39, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.437200</td>\n",
       "      <td>0.396763</td>\n",
       "      <td>0.884331</td>\n",
       "      <td>0.156436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.344400</td>\n",
       "      <td>0.341917</td>\n",
       "      <td>0.884331</td>\n",
       "      <td>0.165370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.326300</td>\n",
       "      <td>0.330977</td>\n",
       "      <td>0.884331</td>\n",
       "      <td>0.156436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.337200</td>\n",
       "      <td>0.332945</td>\n",
       "      <td>0.885152</td>\n",
       "      <td>0.213303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.340400</td>\n",
       "      <td>0.317804</td>\n",
       "      <td>0.904020</td>\n",
       "      <td>0.324954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.298800</td>\n",
       "      <td>0.308792</td>\n",
       "      <td>0.901559</td>\n",
       "      <td>0.260504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.308788</td>\n",
       "      <td>0.902379</td>\n",
       "      <td>0.287517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.276800</td>\n",
       "      <td>0.307075</td>\n",
       "      <td>0.906481</td>\n",
       "      <td>0.336307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.270500</td>\n",
       "      <td>0.312303</td>\n",
       "      <td>0.904020</td>\n",
       "      <td>0.312458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.271300</td>\n",
       "      <td>0.303797</td>\n",
       "      <td>0.899098</td>\n",
       "      <td>0.330578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.210000</td>\n",
       "      <td>0.391972</td>\n",
       "      <td>0.904840</td>\n",
       "      <td>0.297775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.238000</td>\n",
       "      <td>0.366677</td>\n",
       "      <td>0.899918</td>\n",
       "      <td>0.295714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.225300</td>\n",
       "      <td>0.354843</td>\n",
       "      <td>0.899918</td>\n",
       "      <td>0.306104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.218200</td>\n",
       "      <td>0.373466</td>\n",
       "      <td>0.894996</td>\n",
       "      <td>0.308351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.207900</td>\n",
       "      <td>0.355922</td>\n",
       "      <td>0.890894</td>\n",
       "      <td>0.321830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.198400</td>\n",
       "      <td>0.351402</td>\n",
       "      <td>0.894176</td>\n",
       "      <td>0.333858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.188100</td>\n",
       "      <td>0.392797</td>\n",
       "      <td>0.890074</td>\n",
       "      <td>0.328675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.183700</td>\n",
       "      <td>0.398505</td>\n",
       "      <td>0.887613</td>\n",
       "      <td>0.329455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.179600</td>\n",
       "      <td>0.376195</td>\n",
       "      <td>0.894996</td>\n",
       "      <td>0.335104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.173700</td>\n",
       "      <td>0.403924</td>\n",
       "      <td>0.895816</td>\n",
       "      <td>0.328308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.167200</td>\n",
       "      <td>0.399248</td>\n",
       "      <td>0.894176</td>\n",
       "      <td>0.325833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.442224</td>\n",
       "      <td>0.898277</td>\n",
       "      <td>0.332409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.168200</td>\n",
       "      <td>0.435335</td>\n",
       "      <td>0.890894</td>\n",
       "      <td>0.325742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunis-ai/TunBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tunis-ai/TunBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b51daef93c86410a8902ca200ea6dd65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c544d3dcd1ad479e86c7bd6de5e55fc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1155' max='1155' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1155/1155 01:39, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.437200</td>\n",
       "      <td>0.396763</td>\n",
       "      <td>0.884331</td>\n",
       "      <td>0.156436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.344400</td>\n",
       "      <td>0.341917</td>\n",
       "      <td>0.884331</td>\n",
       "      <td>0.165370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.326300</td>\n",
       "      <td>0.330977</td>\n",
       "      <td>0.884331</td>\n",
       "      <td>0.156436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.337200</td>\n",
       "      <td>0.332945</td>\n",
       "      <td>0.885152</td>\n",
       "      <td>0.213303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.340400</td>\n",
       "      <td>0.317804</td>\n",
       "      <td>0.904020</td>\n",
       "      <td>0.324954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.298800</td>\n",
       "      <td>0.308792</td>\n",
       "      <td>0.901559</td>\n",
       "      <td>0.260504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.308788</td>\n",
       "      <td>0.902379</td>\n",
       "      <td>0.287517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.276800</td>\n",
       "      <td>0.307075</td>\n",
       "      <td>0.906481</td>\n",
       "      <td>0.336307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.270500</td>\n",
       "      <td>0.312303</td>\n",
       "      <td>0.904020</td>\n",
       "      <td>0.312458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.271300</td>\n",
       "      <td>0.303797</td>\n",
       "      <td>0.899098</td>\n",
       "      <td>0.330578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.210000</td>\n",
       "      <td>0.391972</td>\n",
       "      <td>0.904840</td>\n",
       "      <td>0.297775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.238000</td>\n",
       "      <td>0.366677</td>\n",
       "      <td>0.899918</td>\n",
       "      <td>0.295714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.225300</td>\n",
       "      <td>0.354843</td>\n",
       "      <td>0.899918</td>\n",
       "      <td>0.306104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.218200</td>\n",
       "      <td>0.373466</td>\n",
       "      <td>0.894996</td>\n",
       "      <td>0.308351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.207900</td>\n",
       "      <td>0.355922</td>\n",
       "      <td>0.890894</td>\n",
       "      <td>0.321830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.198400</td>\n",
       "      <td>0.351402</td>\n",
       "      <td>0.894176</td>\n",
       "      <td>0.333858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.188100</td>\n",
       "      <td>0.392797</td>\n",
       "      <td>0.890074</td>\n",
       "      <td>0.328675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.183700</td>\n",
       "      <td>0.398505</td>\n",
       "      <td>0.887613</td>\n",
       "      <td>0.329455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.179600</td>\n",
       "      <td>0.376195</td>\n",
       "      <td>0.894996</td>\n",
       "      <td>0.335104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.173700</td>\n",
       "      <td>0.403924</td>\n",
       "      <td>0.895816</td>\n",
       "      <td>0.328308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.167200</td>\n",
       "      <td>0.399248</td>\n",
       "      <td>0.894176</td>\n",
       "      <td>0.325833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.442224</td>\n",
       "      <td>0.898277</td>\n",
       "      <td>0.332409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.168200</td>\n",
       "      <td>0.435335</td>\n",
       "      <td>0.890894</td>\n",
       "      <td>0.325742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunis-ai/TunBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tunis-ai/TunBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b37703c7519342f9a54c374cd3cebe00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdcfd1a20a6448dba1b2af03d02418d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1155' max='1155' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1155/1155 01:39, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.443200</td>\n",
       "      <td>0.338249</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.156667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.345000</td>\n",
       "      <td>0.325414</td>\n",
       "      <td>0.895816</td>\n",
       "      <td>0.221319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.324600</td>\n",
       "      <td>0.306570</td>\n",
       "      <td>0.906481</td>\n",
       "      <td>0.299968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.309200</td>\n",
       "      <td>0.308564</td>\n",
       "      <td>0.903199</td>\n",
       "      <td>0.276163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.298800</td>\n",
       "      <td>0.302842</td>\n",
       "      <td>0.902379</td>\n",
       "      <td>0.270491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.286300</td>\n",
       "      <td>0.330600</td>\n",
       "      <td>0.889253</td>\n",
       "      <td>0.316838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.270400</td>\n",
       "      <td>0.336739</td>\n",
       "      <td>0.903199</td>\n",
       "      <td>0.316336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.250900</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.893355</td>\n",
       "      <td>0.315393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.252900</td>\n",
       "      <td>0.325087</td>\n",
       "      <td>0.908942</td>\n",
       "      <td>0.317305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.239600</td>\n",
       "      <td>0.353184</td>\n",
       "      <td>0.907301</td>\n",
       "      <td>0.304737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.234300</td>\n",
       "      <td>0.356570</td>\n",
       "      <td>0.902379</td>\n",
       "      <td>0.311097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.235100</td>\n",
       "      <td>0.338443</td>\n",
       "      <td>0.903199</td>\n",
       "      <td>0.292049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.223000</td>\n",
       "      <td>0.359515</td>\n",
       "      <td>0.893355</td>\n",
       "      <td>0.325147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.189300</td>\n",
       "      <td>0.385020</td>\n",
       "      <td>0.880230</td>\n",
       "      <td>0.309902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.196800</td>\n",
       "      <td>0.372942</td>\n",
       "      <td>0.899918</td>\n",
       "      <td>0.317846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.196600</td>\n",
       "      <td>0.380019</td>\n",
       "      <td>0.904020</td>\n",
       "      <td>0.310522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.180300</td>\n",
       "      <td>0.387222</td>\n",
       "      <td>0.901559</td>\n",
       "      <td>0.318683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.150100</td>\n",
       "      <td>0.398896</td>\n",
       "      <td>0.887613</td>\n",
       "      <td>0.316099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.172400</td>\n",
       "      <td>0.394721</td>\n",
       "      <td>0.898277</td>\n",
       "      <td>0.333544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.152800</td>\n",
       "      <td>0.404682</td>\n",
       "      <td>0.899098</td>\n",
       "      <td>0.333196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.113900</td>\n",
       "      <td>0.453069</td>\n",
       "      <td>0.897457</td>\n",
       "      <td>0.321750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.154200</td>\n",
       "      <td>0.449274</td>\n",
       "      <td>0.894176</td>\n",
       "      <td>0.320267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.139300</td>\n",
       "      <td>0.426193</td>\n",
       "      <td>0.896637</td>\n",
       "      <td>0.317841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunis-ai/TunBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tunis-ai/TunBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0f4f73dccdc4300bdaa6bac5079861d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79814af6dbf44f9abd6c9aeb98502d2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1155' max='1155' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1155/1155 01:39, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.443200</td>\n",
       "      <td>0.338249</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.156667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.345000</td>\n",
       "      <td>0.325414</td>\n",
       "      <td>0.895816</td>\n",
       "      <td>0.221319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.324600</td>\n",
       "      <td>0.306570</td>\n",
       "      <td>0.906481</td>\n",
       "      <td>0.299968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.309200</td>\n",
       "      <td>0.308564</td>\n",
       "      <td>0.903199</td>\n",
       "      <td>0.276163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.298800</td>\n",
       "      <td>0.302842</td>\n",
       "      <td>0.902379</td>\n",
       "      <td>0.270491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.286300</td>\n",
       "      <td>0.330600</td>\n",
       "      <td>0.889253</td>\n",
       "      <td>0.316838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.270400</td>\n",
       "      <td>0.336739</td>\n",
       "      <td>0.903199</td>\n",
       "      <td>0.316336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.250900</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.893355</td>\n",
       "      <td>0.315393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.252900</td>\n",
       "      <td>0.325087</td>\n",
       "      <td>0.908942</td>\n",
       "      <td>0.317305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.239600</td>\n",
       "      <td>0.353184</td>\n",
       "      <td>0.907301</td>\n",
       "      <td>0.304737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.234300</td>\n",
       "      <td>0.356570</td>\n",
       "      <td>0.902379</td>\n",
       "      <td>0.311097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.235100</td>\n",
       "      <td>0.338443</td>\n",
       "      <td>0.903199</td>\n",
       "      <td>0.292049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.223000</td>\n",
       "      <td>0.359515</td>\n",
       "      <td>0.893355</td>\n",
       "      <td>0.325147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.189300</td>\n",
       "      <td>0.385020</td>\n",
       "      <td>0.880230</td>\n",
       "      <td>0.309902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.196800</td>\n",
       "      <td>0.372942</td>\n",
       "      <td>0.899918</td>\n",
       "      <td>0.317846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.196600</td>\n",
       "      <td>0.380019</td>\n",
       "      <td>0.904020</td>\n",
       "      <td>0.310522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.180300</td>\n",
       "      <td>0.387222</td>\n",
       "      <td>0.901559</td>\n",
       "      <td>0.318683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.150100</td>\n",
       "      <td>0.398896</td>\n",
       "      <td>0.887613</td>\n",
       "      <td>0.316099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.172400</td>\n",
       "      <td>0.394721</td>\n",
       "      <td>0.898277</td>\n",
       "      <td>0.333544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.152800</td>\n",
       "      <td>0.404682</td>\n",
       "      <td>0.899098</td>\n",
       "      <td>0.333196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.113900</td>\n",
       "      <td>0.453069</td>\n",
       "      <td>0.897457</td>\n",
       "      <td>0.321750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.154200</td>\n",
       "      <td>0.449274</td>\n",
       "      <td>0.894176</td>\n",
       "      <td>0.320267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.139300</td>\n",
       "      <td>0.426193</td>\n",
       "      <td>0.896637</td>\n",
       "      <td>0.317841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunis-ai/TunBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tunis-ai/TunBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "353c903c40c14a7894bc92392202eec6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dcbc8aa7da64781820d7c61a246ce5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1155' max='1155' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1155/1155 01:39, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.443200</td>\n",
       "      <td>0.338249</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.156667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.345000</td>\n",
       "      <td>0.325414</td>\n",
       "      <td>0.895816</td>\n",
       "      <td>0.221319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.324600</td>\n",
       "      <td>0.306570</td>\n",
       "      <td>0.906481</td>\n",
       "      <td>0.299968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.309200</td>\n",
       "      <td>0.308564</td>\n",
       "      <td>0.903199</td>\n",
       "      <td>0.276163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.298800</td>\n",
       "      <td>0.302842</td>\n",
       "      <td>0.902379</td>\n",
       "      <td>0.270491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.286300</td>\n",
       "      <td>0.330600</td>\n",
       "      <td>0.889253</td>\n",
       "      <td>0.316838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.270400</td>\n",
       "      <td>0.336739</td>\n",
       "      <td>0.903199</td>\n",
       "      <td>0.316336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.250900</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.893355</td>\n",
       "      <td>0.315393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.252900</td>\n",
       "      <td>0.325087</td>\n",
       "      <td>0.908942</td>\n",
       "      <td>0.317305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.239600</td>\n",
       "      <td>0.353184</td>\n",
       "      <td>0.907301</td>\n",
       "      <td>0.304737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.234300</td>\n",
       "      <td>0.356570</td>\n",
       "      <td>0.902379</td>\n",
       "      <td>0.311097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.235100</td>\n",
       "      <td>0.338443</td>\n",
       "      <td>0.903199</td>\n",
       "      <td>0.292049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.223000</td>\n",
       "      <td>0.359515</td>\n",
       "      <td>0.893355</td>\n",
       "      <td>0.325147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.189300</td>\n",
       "      <td>0.385020</td>\n",
       "      <td>0.880230</td>\n",
       "      <td>0.309902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.196800</td>\n",
       "      <td>0.372942</td>\n",
       "      <td>0.899918</td>\n",
       "      <td>0.317846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.196600</td>\n",
       "      <td>0.380019</td>\n",
       "      <td>0.904020</td>\n",
       "      <td>0.310522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.180300</td>\n",
       "      <td>0.387222</td>\n",
       "      <td>0.901559</td>\n",
       "      <td>0.318683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.150100</td>\n",
       "      <td>0.398896</td>\n",
       "      <td>0.887613</td>\n",
       "      <td>0.316099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.172400</td>\n",
       "      <td>0.394721</td>\n",
       "      <td>0.898277</td>\n",
       "      <td>0.333544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.152800</td>\n",
       "      <td>0.404682</td>\n",
       "      <td>0.899098</td>\n",
       "      <td>0.333196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.113900</td>\n",
       "      <td>0.453069</td>\n",
       "      <td>0.897457</td>\n",
       "      <td>0.321750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.154200</td>\n",
       "      <td>0.449274</td>\n",
       "      <td>0.894176</td>\n",
       "      <td>0.320267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.139300</td>\n",
       "      <td>0.426193</td>\n",
       "      <td>0.896637</td>\n",
       "      <td>0.317841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Text', 'label', '__index_level_0__'],\n",
       "        num_rows: 4872\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Text', 'label', '__index_level_0__'],\n",
       "        num_rows: 1219\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alger-ia/dziribert, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17b419cb11984d149a499935d05948bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca331708f6a645e795d3109c10b7ee54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1155' max='1155' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1155/1155 01:41, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.385100</td>\n",
       "      <td>0.200919</td>\n",
       "      <td>0.933552</td>\n",
       "      <td>0.461619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.213700</td>\n",
       "      <td>0.227290</td>\n",
       "      <td>0.931091</td>\n",
       "      <td>0.478360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.169500</td>\n",
       "      <td>0.222884</td>\n",
       "      <td>0.926169</td>\n",
       "      <td>0.419873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.076700</td>\n",
       "      <td>0.300231</td>\n",
       "      <td>0.928630</td>\n",
       "      <td>0.429074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.055200</td>\n",
       "      <td>0.298003</td>\n",
       "      <td>0.919606</td>\n",
       "      <td>0.420402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.021500</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>0.926989</td>\n",
       "      <td>0.424790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.013900</td>\n",
       "      <td>0.406827</td>\n",
       "      <td>0.929450</td>\n",
       "      <td>0.436016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.006100</td>\n",
       "      <td>0.429357</td>\n",
       "      <td>0.931091</td>\n",
       "      <td>0.440465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.435716</td>\n",
       "      <td>0.927810</td>\n",
       "      <td>0.434896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>0.434552</td>\n",
       "      <td>0.930271</td>\n",
       "      <td>0.426910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>0.493674</td>\n",
       "      <td>0.914684</td>\n",
       "      <td>0.554747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.447241</td>\n",
       "      <td>0.933552</td>\n",
       "      <td>0.454157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.457636</td>\n",
       "      <td>0.934372</td>\n",
       "      <td>0.454887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.463275</td>\n",
       "      <td>0.932732</td>\n",
       "      <td>0.448883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.464416</td>\n",
       "      <td>0.933552</td>\n",
       "      <td>0.457402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.470923</td>\n",
       "      <td>0.932732</td>\n",
       "      <td>0.448883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.476466</td>\n",
       "      <td>0.933552</td>\n",
       "      <td>0.447685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.478550</td>\n",
       "      <td>0.933552</td>\n",
       "      <td>0.449679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.480152</td>\n",
       "      <td>0.932732</td>\n",
       "      <td>0.446878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.481739</td>\n",
       "      <td>0.932732</td>\n",
       "      <td>0.449601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.482834</td>\n",
       "      <td>0.932732</td>\n",
       "      <td>0.449601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.483659</td>\n",
       "      <td>0.931911</td>\n",
       "      <td>0.446800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.484011</td>\n",
       "      <td>0.931911</td>\n",
       "      <td>0.446800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alger-ia/dziribert, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44823a9183a84598913a468f87ffd9f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fad7930773d4fb09e10d6594e426884",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1155' max='1155' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1155/1155 01:41, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.385100</td>\n",
       "      <td>0.200919</td>\n",
       "      <td>0.933552</td>\n",
       "      <td>0.461619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.213700</td>\n",
       "      <td>0.227290</td>\n",
       "      <td>0.931091</td>\n",
       "      <td>0.478360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.169500</td>\n",
       "      <td>0.222884</td>\n",
       "      <td>0.926169</td>\n",
       "      <td>0.419873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.076700</td>\n",
       "      <td>0.300231</td>\n",
       "      <td>0.928630</td>\n",
       "      <td>0.429074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.055200</td>\n",
       "      <td>0.298003</td>\n",
       "      <td>0.919606</td>\n",
       "      <td>0.420402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.021500</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>0.926989</td>\n",
       "      <td>0.424790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.013900</td>\n",
       "      <td>0.406827</td>\n",
       "      <td>0.929450</td>\n",
       "      <td>0.436016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.006100</td>\n",
       "      <td>0.429357</td>\n",
       "      <td>0.931091</td>\n",
       "      <td>0.440465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.435716</td>\n",
       "      <td>0.927810</td>\n",
       "      <td>0.434896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>0.434552</td>\n",
       "      <td>0.930271</td>\n",
       "      <td>0.426910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>0.493674</td>\n",
       "      <td>0.914684</td>\n",
       "      <td>0.554747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.447241</td>\n",
       "      <td>0.933552</td>\n",
       "      <td>0.454157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.457636</td>\n",
       "      <td>0.934372</td>\n",
       "      <td>0.454887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.463275</td>\n",
       "      <td>0.932732</td>\n",
       "      <td>0.448883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.464416</td>\n",
       "      <td>0.933552</td>\n",
       "      <td>0.457402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.470923</td>\n",
       "      <td>0.932732</td>\n",
       "      <td>0.448883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.476466</td>\n",
       "      <td>0.933552</td>\n",
       "      <td>0.447685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.478550</td>\n",
       "      <td>0.933552</td>\n",
       "      <td>0.449679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.480152</td>\n",
       "      <td>0.932732</td>\n",
       "      <td>0.446878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.481739</td>\n",
       "      <td>0.932732</td>\n",
       "      <td>0.449601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.482834</td>\n",
       "      <td>0.932732</td>\n",
       "      <td>0.449601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.483659</td>\n",
       "      <td>0.931911</td>\n",
       "      <td>0.446800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.484011</td>\n",
       "      <td>0.931911</td>\n",
       "      <td>0.446800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alger-ia/dziribert, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71968a1034a144428e8a0bb1684662e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92a6cd0353ec4e88b43d249372058706",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1155' max='1155' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1155/1155 01:41, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.385100</td>\n",
       "      <td>0.200919</td>\n",
       "      <td>0.933552</td>\n",
       "      <td>0.461619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.213700</td>\n",
       "      <td>0.227290</td>\n",
       "      <td>0.931091</td>\n",
       "      <td>0.478360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.169500</td>\n",
       "      <td>0.222884</td>\n",
       "      <td>0.926169</td>\n",
       "      <td>0.419873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.076700</td>\n",
       "      <td>0.300231</td>\n",
       "      <td>0.928630</td>\n",
       "      <td>0.429074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.055200</td>\n",
       "      <td>0.298003</td>\n",
       "      <td>0.919606</td>\n",
       "      <td>0.420402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.021500</td>\n",
       "      <td>0.398624</td>\n",
       "      <td>0.926989</td>\n",
       "      <td>0.424790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.013900</td>\n",
       "      <td>0.406827</td>\n",
       "      <td>0.929450</td>\n",
       "      <td>0.436016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.006100</td>\n",
       "      <td>0.429357</td>\n",
       "      <td>0.931091</td>\n",
       "      <td>0.440465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.435716</td>\n",
       "      <td>0.927810</td>\n",
       "      <td>0.434896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>0.434552</td>\n",
       "      <td>0.930271</td>\n",
       "      <td>0.426910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>0.493674</td>\n",
       "      <td>0.914684</td>\n",
       "      <td>0.554747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.447241</td>\n",
       "      <td>0.933552</td>\n",
       "      <td>0.454157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.457636</td>\n",
       "      <td>0.934372</td>\n",
       "      <td>0.454887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.463275</td>\n",
       "      <td>0.932732</td>\n",
       "      <td>0.448883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.464416</td>\n",
       "      <td>0.933552</td>\n",
       "      <td>0.457402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.470923</td>\n",
       "      <td>0.932732</td>\n",
       "      <td>0.448883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.476466</td>\n",
       "      <td>0.933552</td>\n",
       "      <td>0.447685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.478550</td>\n",
       "      <td>0.933552</td>\n",
       "      <td>0.449679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.480152</td>\n",
       "      <td>0.932732</td>\n",
       "      <td>0.446878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.481739</td>\n",
       "      <td>0.932732</td>\n",
       "      <td>0.449601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.482834</td>\n",
       "      <td>0.932732</td>\n",
       "      <td>0.449601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.483659</td>\n",
       "      <td>0.931911</td>\n",
       "      <td>0.446800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.484011</td>\n",
       "      <td>0.931911</td>\n",
       "      <td>0.446800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alger-ia/dziribert, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f529e033c6fd42a7bf4a375ba2b43852",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0a1dca30e29477d9e07d551b5c29971",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1155' max='1155' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1155/1155 01:41, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.365900</td>\n",
       "      <td>0.285600</td>\n",
       "      <td>0.904020</td>\n",
       "      <td>0.290628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.210400</td>\n",
       "      <td>0.254726</td>\n",
       "      <td>0.917145</td>\n",
       "      <td>0.383686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.166900</td>\n",
       "      <td>0.260080</td>\n",
       "      <td>0.928630</td>\n",
       "      <td>0.412256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.085400</td>\n",
       "      <td>0.345979</td>\n",
       "      <td>0.914684</td>\n",
       "      <td>0.536757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.080100</td>\n",
       "      <td>0.434695</td>\n",
       "      <td>0.916325</td>\n",
       "      <td>0.401179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.042700</td>\n",
       "      <td>0.460675</td>\n",
       "      <td>0.912223</td>\n",
       "      <td>0.379165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.018700</td>\n",
       "      <td>0.465439</td>\n",
       "      <td>0.917145</td>\n",
       "      <td>0.415181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.017600</td>\n",
       "      <td>0.437645</td>\n",
       "      <td>0.926169</td>\n",
       "      <td>0.599642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.009700</td>\n",
       "      <td>0.480408</td>\n",
       "      <td>0.917145</td>\n",
       "      <td>0.410910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.489378</td>\n",
       "      <td>0.921247</td>\n",
       "      <td>0.425914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.486579</td>\n",
       "      <td>0.923708</td>\n",
       "      <td>0.431574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>0.510431</td>\n",
       "      <td>0.926169</td>\n",
       "      <td>0.422695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>0.491644</td>\n",
       "      <td>0.920427</td>\n",
       "      <td>0.563336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.523475</td>\n",
       "      <td>0.926989</td>\n",
       "      <td>0.539274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.531279</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.590918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.537066</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.590918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.537454</td>\n",
       "      <td>0.925349</td>\n",
       "      <td>0.592192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.541987</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.590287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.544135</td>\n",
       "      <td>0.925349</td>\n",
       "      <td>0.592192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.546720</td>\n",
       "      <td>0.925349</td>\n",
       "      <td>0.592192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.548640</td>\n",
       "      <td>0.925349</td>\n",
       "      <td>0.592192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.549854</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.590287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.550296</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.590287</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alger-ia/dziribert, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f51fb1d7f7c41158ec3b71582ab610f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "049a968b128c4fd69cd90d82f272dc13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1155' max='1155' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1155/1155 01:42, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.365900</td>\n",
       "      <td>0.285600</td>\n",
       "      <td>0.904020</td>\n",
       "      <td>0.290628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.210400</td>\n",
       "      <td>0.254726</td>\n",
       "      <td>0.917145</td>\n",
       "      <td>0.383686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.166900</td>\n",
       "      <td>0.260080</td>\n",
       "      <td>0.928630</td>\n",
       "      <td>0.412256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.085400</td>\n",
       "      <td>0.345979</td>\n",
       "      <td>0.914684</td>\n",
       "      <td>0.536757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.080100</td>\n",
       "      <td>0.434695</td>\n",
       "      <td>0.916325</td>\n",
       "      <td>0.401179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.042700</td>\n",
       "      <td>0.460675</td>\n",
       "      <td>0.912223</td>\n",
       "      <td>0.379165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.018700</td>\n",
       "      <td>0.465439</td>\n",
       "      <td>0.917145</td>\n",
       "      <td>0.415181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.017600</td>\n",
       "      <td>0.437645</td>\n",
       "      <td>0.926169</td>\n",
       "      <td>0.599642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.009700</td>\n",
       "      <td>0.480408</td>\n",
       "      <td>0.917145</td>\n",
       "      <td>0.410910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.489378</td>\n",
       "      <td>0.921247</td>\n",
       "      <td>0.425914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.486579</td>\n",
       "      <td>0.923708</td>\n",
       "      <td>0.431574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>0.510431</td>\n",
       "      <td>0.926169</td>\n",
       "      <td>0.422695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>0.491644</td>\n",
       "      <td>0.920427</td>\n",
       "      <td>0.563336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.523475</td>\n",
       "      <td>0.926989</td>\n",
       "      <td>0.539274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.531279</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.590918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.537066</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.590918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.537454</td>\n",
       "      <td>0.925349</td>\n",
       "      <td>0.592192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.541987</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.590287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.544135</td>\n",
       "      <td>0.925349</td>\n",
       "      <td>0.592192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.546720</td>\n",
       "      <td>0.925349</td>\n",
       "      <td>0.592192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.548640</td>\n",
       "      <td>0.925349</td>\n",
       "      <td>0.592192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.549854</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.590287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.550296</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.590287</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alger-ia/dziribert, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1d7dd85c53948db8995aa1bf9e2dc5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68f5b927296f4f6a9e72bc84b891175e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1155' max='1155' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1155/1155 01:41, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.365900</td>\n",
       "      <td>0.285600</td>\n",
       "      <td>0.904020</td>\n",
       "      <td>0.290628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.210400</td>\n",
       "      <td>0.254726</td>\n",
       "      <td>0.917145</td>\n",
       "      <td>0.383686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.166900</td>\n",
       "      <td>0.260080</td>\n",
       "      <td>0.928630</td>\n",
       "      <td>0.412256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.085400</td>\n",
       "      <td>0.345979</td>\n",
       "      <td>0.914684</td>\n",
       "      <td>0.536757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.080100</td>\n",
       "      <td>0.434695</td>\n",
       "      <td>0.916325</td>\n",
       "      <td>0.401179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.042700</td>\n",
       "      <td>0.460675</td>\n",
       "      <td>0.912223</td>\n",
       "      <td>0.379165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.018700</td>\n",
       "      <td>0.465439</td>\n",
       "      <td>0.917145</td>\n",
       "      <td>0.415181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.017600</td>\n",
       "      <td>0.437645</td>\n",
       "      <td>0.926169</td>\n",
       "      <td>0.599642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.009700</td>\n",
       "      <td>0.480408</td>\n",
       "      <td>0.917145</td>\n",
       "      <td>0.410910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.489378</td>\n",
       "      <td>0.921247</td>\n",
       "      <td>0.425914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.486579</td>\n",
       "      <td>0.923708</td>\n",
       "      <td>0.431574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>0.510431</td>\n",
       "      <td>0.926169</td>\n",
       "      <td>0.422695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>0.491644</td>\n",
       "      <td>0.920427</td>\n",
       "      <td>0.563336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.523475</td>\n",
       "      <td>0.926989</td>\n",
       "      <td>0.539274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.531279</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.590918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.537066</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.590918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.537454</td>\n",
       "      <td>0.925349</td>\n",
       "      <td>0.592192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.541987</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.590287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.544135</td>\n",
       "      <td>0.925349</td>\n",
       "      <td>0.592192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.546720</td>\n",
       "      <td>0.925349</td>\n",
       "      <td>0.592192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.548640</td>\n",
       "      <td>0.925349</td>\n",
       "      <td>0.592192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.549854</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.590287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.550296</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.590287</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alger-ia/dziribert, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ba894811d7d4a54a10b312530ad015c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dc1d3962f3c4991b776348d200b3c12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1155' max='1155' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1155/1155 01:42, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.352400</td>\n",
       "      <td>0.351506</td>\n",
       "      <td>0.904020</td>\n",
       "      <td>0.260122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.250100</td>\n",
       "      <td>0.293682</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.382542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.187700</td>\n",
       "      <td>0.252182</td>\n",
       "      <td>0.926169</td>\n",
       "      <td>0.389856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.097500</td>\n",
       "      <td>0.296222</td>\n",
       "      <td>0.922888</td>\n",
       "      <td>0.467797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.064900</td>\n",
       "      <td>0.349970</td>\n",
       "      <td>0.926169</td>\n",
       "      <td>0.498877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.031500</td>\n",
       "      <td>0.332955</td>\n",
       "      <td>0.922888</td>\n",
       "      <td>0.496902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.010800</td>\n",
       "      <td>0.378980</td>\n",
       "      <td>0.928630</td>\n",
       "      <td>0.535904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.010300</td>\n",
       "      <td>0.395692</td>\n",
       "      <td>0.926169</td>\n",
       "      <td>0.564689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>0.453059</td>\n",
       "      <td>0.925349</td>\n",
       "      <td>0.541022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.428592</td>\n",
       "      <td>0.926169</td>\n",
       "      <td>0.565605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.456675</td>\n",
       "      <td>0.923708</td>\n",
       "      <td>0.632646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.445461</td>\n",
       "      <td>0.928630</td>\n",
       "      <td>0.652564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.458093</td>\n",
       "      <td>0.927810</td>\n",
       "      <td>0.562724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.462081</td>\n",
       "      <td>0.927810</td>\n",
       "      <td>0.564522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.489738</td>\n",
       "      <td>0.928630</td>\n",
       "      <td>0.572700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.476328</td>\n",
       "      <td>0.930271</td>\n",
       "      <td>0.578948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.475533</td>\n",
       "      <td>0.928630</td>\n",
       "      <td>0.562522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.476810</td>\n",
       "      <td>0.928630</td>\n",
       "      <td>0.563019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.478022</td>\n",
       "      <td>0.928630</td>\n",
       "      <td>0.563568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.479422</td>\n",
       "      <td>0.928630</td>\n",
       "      <td>0.564203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.480582</td>\n",
       "      <td>0.928630</td>\n",
       "      <td>0.563568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.481142</td>\n",
       "      <td>0.928630</td>\n",
       "      <td>0.563568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.481451</td>\n",
       "      <td>0.928630</td>\n",
       "      <td>0.563568</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alger-ia/dziribert, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5418a18b32a347749e86938bdb7e5a8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fb756c9270443aab9ae632f9ab36981",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1155' max='1155' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1155/1155 01:42, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.352400</td>\n",
       "      <td>0.351506</td>\n",
       "      <td>0.904020</td>\n",
       "      <td>0.260122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.250100</td>\n",
       "      <td>0.293682</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.382542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.187700</td>\n",
       "      <td>0.252182</td>\n",
       "      <td>0.926169</td>\n",
       "      <td>0.389856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.097500</td>\n",
       "      <td>0.296222</td>\n",
       "      <td>0.922888</td>\n",
       "      <td>0.467797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.064900</td>\n",
       "      <td>0.349970</td>\n",
       "      <td>0.926169</td>\n",
       "      <td>0.498877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.031500</td>\n",
       "      <td>0.332955</td>\n",
       "      <td>0.922888</td>\n",
       "      <td>0.496902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.010800</td>\n",
       "      <td>0.378980</td>\n",
       "      <td>0.928630</td>\n",
       "      <td>0.535904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.010300</td>\n",
       "      <td>0.395692</td>\n",
       "      <td>0.926169</td>\n",
       "      <td>0.564689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>0.453059</td>\n",
       "      <td>0.925349</td>\n",
       "      <td>0.541022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.428592</td>\n",
       "      <td>0.926169</td>\n",
       "      <td>0.565605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.456675</td>\n",
       "      <td>0.923708</td>\n",
       "      <td>0.632646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.445461</td>\n",
       "      <td>0.928630</td>\n",
       "      <td>0.652564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.458093</td>\n",
       "      <td>0.927810</td>\n",
       "      <td>0.562724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.462081</td>\n",
       "      <td>0.927810</td>\n",
       "      <td>0.564522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.489738</td>\n",
       "      <td>0.928630</td>\n",
       "      <td>0.572700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.476328</td>\n",
       "      <td>0.930271</td>\n",
       "      <td>0.578948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.475533</td>\n",
       "      <td>0.928630</td>\n",
       "      <td>0.562522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.476810</td>\n",
       "      <td>0.928630</td>\n",
       "      <td>0.563019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.478022</td>\n",
       "      <td>0.928630</td>\n",
       "      <td>0.563568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.479422</td>\n",
       "      <td>0.928630</td>\n",
       "      <td>0.564203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.480582</td>\n",
       "      <td>0.928630</td>\n",
       "      <td>0.563568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.481142</td>\n",
       "      <td>0.928630</td>\n",
       "      <td>0.563568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.481451</td>\n",
       "      <td>0.928630</td>\n",
       "      <td>0.563568</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alger-ia/dziribert, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d64a70ae7114aea8b6dd3575172f813",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89f23bbff97f4f9fb96f0533cfe32140",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1155' max='1155' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1155/1155 01:41, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.352400</td>\n",
       "      <td>0.351506</td>\n",
       "      <td>0.904020</td>\n",
       "      <td>0.260122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.250100</td>\n",
       "      <td>0.293682</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.382542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.187700</td>\n",
       "      <td>0.252182</td>\n",
       "      <td>0.926169</td>\n",
       "      <td>0.389856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.097500</td>\n",
       "      <td>0.296222</td>\n",
       "      <td>0.922888</td>\n",
       "      <td>0.467797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.064900</td>\n",
       "      <td>0.349970</td>\n",
       "      <td>0.926169</td>\n",
       "      <td>0.498877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.031500</td>\n",
       "      <td>0.332955</td>\n",
       "      <td>0.922888</td>\n",
       "      <td>0.496902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.010800</td>\n",
       "      <td>0.378980</td>\n",
       "      <td>0.928630</td>\n",
       "      <td>0.535904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.010300</td>\n",
       "      <td>0.395692</td>\n",
       "      <td>0.926169</td>\n",
       "      <td>0.564689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>0.453059</td>\n",
       "      <td>0.925349</td>\n",
       "      <td>0.541022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.428592</td>\n",
       "      <td>0.926169</td>\n",
       "      <td>0.565605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.456675</td>\n",
       "      <td>0.923708</td>\n",
       "      <td>0.632646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.445461</td>\n",
       "      <td>0.928630</td>\n",
       "      <td>0.652564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.458093</td>\n",
       "      <td>0.927810</td>\n",
       "      <td>0.562724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.462081</td>\n",
       "      <td>0.927810</td>\n",
       "      <td>0.564522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.489738</td>\n",
       "      <td>0.928630</td>\n",
       "      <td>0.572700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.476328</td>\n",
       "      <td>0.930271</td>\n",
       "      <td>0.578948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.475533</td>\n",
       "      <td>0.928630</td>\n",
       "      <td>0.562522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.476810</td>\n",
       "      <td>0.928630</td>\n",
       "      <td>0.563019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.478022</td>\n",
       "      <td>0.928630</td>\n",
       "      <td>0.563568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.479422</td>\n",
       "      <td>0.928630</td>\n",
       "      <td>0.564203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.480582</td>\n",
       "      <td>0.928630</td>\n",
       "      <td>0.563568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.481142</td>\n",
       "      <td>0.928630</td>\n",
       "      <td>0.563568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.481451</td>\n",
       "      <td>0.928630</td>\n",
       "      <td>0.563568</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Text', 'label', '__index_level_0__'],\n",
       "        num_rows: 4872\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Text', 'label', '__index_level_0__'],\n",
       "        num_rows: 1219\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SI2M-Lab/DarijaBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SI2M-Lab/DarijaBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc2071ca37cf4e39bbd7f9bc3c8a8de0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b72850eede6744c490538b5db2952ad7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1155' max='1155' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1155/1155 01:45, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.388200</td>\n",
       "      <td>0.224275</td>\n",
       "      <td>0.920427</td>\n",
       "      <td>0.388315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.217000</td>\n",
       "      <td>0.223593</td>\n",
       "      <td>0.931911</td>\n",
       "      <td>0.459194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.193900</td>\n",
       "      <td>0.278205</td>\n",
       "      <td>0.929450</td>\n",
       "      <td>0.449519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.095100</td>\n",
       "      <td>0.330859</td>\n",
       "      <td>0.932732</td>\n",
       "      <td>0.489276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.055100</td>\n",
       "      <td>0.342464</td>\n",
       "      <td>0.918786</td>\n",
       "      <td>0.430867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.037800</td>\n",
       "      <td>0.417089</td>\n",
       "      <td>0.931911</td>\n",
       "      <td>0.416578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.022500</td>\n",
       "      <td>0.403189</td>\n",
       "      <td>0.925349</td>\n",
       "      <td>0.424600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.014500</td>\n",
       "      <td>0.396952</td>\n",
       "      <td>0.929450</td>\n",
       "      <td>0.422603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.012700</td>\n",
       "      <td>0.420418</td>\n",
       "      <td>0.931911</td>\n",
       "      <td>0.444796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>0.410270</td>\n",
       "      <td>0.930271</td>\n",
       "      <td>0.424187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.443151</td>\n",
       "      <td>0.932732</td>\n",
       "      <td>0.419789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>0.443813</td>\n",
       "      <td>0.931091</td>\n",
       "      <td>0.431604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>0.452614</td>\n",
       "      <td>0.929450</td>\n",
       "      <td>0.416668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.456299</td>\n",
       "      <td>0.933552</td>\n",
       "      <td>0.431758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.460296</td>\n",
       "      <td>0.933552</td>\n",
       "      <td>0.431758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.467639</td>\n",
       "      <td>0.933552</td>\n",
       "      <td>0.428958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.469583</td>\n",
       "      <td>0.933552</td>\n",
       "      <td>0.430282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.471164</td>\n",
       "      <td>0.930271</td>\n",
       "      <td>0.425992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.471824</td>\n",
       "      <td>0.930271</td>\n",
       "      <td>0.425464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.473904</td>\n",
       "      <td>0.930271</td>\n",
       "      <td>0.425464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.475430</td>\n",
       "      <td>0.930271</td>\n",
       "      <td>0.425464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.476636</td>\n",
       "      <td>0.930271</td>\n",
       "      <td>0.425464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.476982</td>\n",
       "      <td>0.930271</td>\n",
       "      <td>0.425464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SI2M-Lab/DarijaBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SI2M-Lab/DarijaBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e166335ac2043aebe7ff9af1aa6d33b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0220858c8cac437daf5806c895bded25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1155' max='1155' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1155/1155 01:45, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.388200</td>\n",
       "      <td>0.224275</td>\n",
       "      <td>0.920427</td>\n",
       "      <td>0.388315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.217000</td>\n",
       "      <td>0.223593</td>\n",
       "      <td>0.931911</td>\n",
       "      <td>0.459194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.193900</td>\n",
       "      <td>0.278205</td>\n",
       "      <td>0.929450</td>\n",
       "      <td>0.449519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.095100</td>\n",
       "      <td>0.330859</td>\n",
       "      <td>0.932732</td>\n",
       "      <td>0.489276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.055100</td>\n",
       "      <td>0.342464</td>\n",
       "      <td>0.918786</td>\n",
       "      <td>0.430867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.037800</td>\n",
       "      <td>0.417089</td>\n",
       "      <td>0.931911</td>\n",
       "      <td>0.416578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.022500</td>\n",
       "      <td>0.403189</td>\n",
       "      <td>0.925349</td>\n",
       "      <td>0.424600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.014500</td>\n",
       "      <td>0.396952</td>\n",
       "      <td>0.929450</td>\n",
       "      <td>0.422603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.012700</td>\n",
       "      <td>0.420418</td>\n",
       "      <td>0.931911</td>\n",
       "      <td>0.444796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>0.410270</td>\n",
       "      <td>0.930271</td>\n",
       "      <td>0.424187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.443151</td>\n",
       "      <td>0.932732</td>\n",
       "      <td>0.419789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>0.443813</td>\n",
       "      <td>0.931091</td>\n",
       "      <td>0.431604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>0.452614</td>\n",
       "      <td>0.929450</td>\n",
       "      <td>0.416668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.456299</td>\n",
       "      <td>0.933552</td>\n",
       "      <td>0.431758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.460296</td>\n",
       "      <td>0.933552</td>\n",
       "      <td>0.431758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.467639</td>\n",
       "      <td>0.933552</td>\n",
       "      <td>0.428958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.469583</td>\n",
       "      <td>0.933552</td>\n",
       "      <td>0.430282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.471164</td>\n",
       "      <td>0.930271</td>\n",
       "      <td>0.425992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.471824</td>\n",
       "      <td>0.930271</td>\n",
       "      <td>0.425464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.473904</td>\n",
       "      <td>0.930271</td>\n",
       "      <td>0.425464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.475430</td>\n",
       "      <td>0.930271</td>\n",
       "      <td>0.425464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.476636</td>\n",
       "      <td>0.930271</td>\n",
       "      <td>0.425464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.476982</td>\n",
       "      <td>0.930271</td>\n",
       "      <td>0.425464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SI2M-Lab/DarijaBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SI2M-Lab/DarijaBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcdb723efc844e2bae5b772cf2a522e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09b51dd903f3403383a1866c01843365",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1155' max='1155' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1155/1155 01:45, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.388200</td>\n",
       "      <td>0.224275</td>\n",
       "      <td>0.920427</td>\n",
       "      <td>0.388315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.217000</td>\n",
       "      <td>0.223593</td>\n",
       "      <td>0.931911</td>\n",
       "      <td>0.459194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.193900</td>\n",
       "      <td>0.278205</td>\n",
       "      <td>0.929450</td>\n",
       "      <td>0.449519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.095100</td>\n",
       "      <td>0.330859</td>\n",
       "      <td>0.932732</td>\n",
       "      <td>0.489276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.055100</td>\n",
       "      <td>0.342464</td>\n",
       "      <td>0.918786</td>\n",
       "      <td>0.430867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.037800</td>\n",
       "      <td>0.417089</td>\n",
       "      <td>0.931911</td>\n",
       "      <td>0.416578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.022500</td>\n",
       "      <td>0.403189</td>\n",
       "      <td>0.925349</td>\n",
       "      <td>0.424600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.014500</td>\n",
       "      <td>0.396952</td>\n",
       "      <td>0.929450</td>\n",
       "      <td>0.422603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.012700</td>\n",
       "      <td>0.420418</td>\n",
       "      <td>0.931911</td>\n",
       "      <td>0.444796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>0.410270</td>\n",
       "      <td>0.930271</td>\n",
       "      <td>0.424187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.443151</td>\n",
       "      <td>0.932732</td>\n",
       "      <td>0.419789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>0.443813</td>\n",
       "      <td>0.931091</td>\n",
       "      <td>0.431604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>0.452614</td>\n",
       "      <td>0.929450</td>\n",
       "      <td>0.416668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.456299</td>\n",
       "      <td>0.933552</td>\n",
       "      <td>0.431758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.460296</td>\n",
       "      <td>0.933552</td>\n",
       "      <td>0.431758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.467639</td>\n",
       "      <td>0.933552</td>\n",
       "      <td>0.428958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.469583</td>\n",
       "      <td>0.933552</td>\n",
       "      <td>0.430282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.471164</td>\n",
       "      <td>0.930271</td>\n",
       "      <td>0.425992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.471824</td>\n",
       "      <td>0.930271</td>\n",
       "      <td>0.425464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.473904</td>\n",
       "      <td>0.930271</td>\n",
       "      <td>0.425464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.475430</td>\n",
       "      <td>0.930271</td>\n",
       "      <td>0.425464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.476636</td>\n",
       "      <td>0.930271</td>\n",
       "      <td>0.425464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.476982</td>\n",
       "      <td>0.930271</td>\n",
       "      <td>0.425464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SI2M-Lab/DarijaBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SI2M-Lab/DarijaBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "742b8c1222834783918cf3bef3a353c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "317b947a4e04467e9043cab074a08a75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1155' max='1155' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1155/1155 01:45, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.371400</td>\n",
       "      <td>0.297970</td>\n",
       "      <td>0.912223</td>\n",
       "      <td>0.309759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.230400</td>\n",
       "      <td>0.263252</td>\n",
       "      <td>0.922067</td>\n",
       "      <td>0.372680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.185100</td>\n",
       "      <td>0.283346</td>\n",
       "      <td>0.922888</td>\n",
       "      <td>0.379124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.108300</td>\n",
       "      <td>0.296465</td>\n",
       "      <td>0.916325</td>\n",
       "      <td>0.435736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.074300</td>\n",
       "      <td>0.327890</td>\n",
       "      <td>0.920427</td>\n",
       "      <td>0.451936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.040500</td>\n",
       "      <td>0.481948</td>\n",
       "      <td>0.917966</td>\n",
       "      <td>0.390981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.023500</td>\n",
       "      <td>0.391353</td>\n",
       "      <td>0.926169</td>\n",
       "      <td>0.439490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.013400</td>\n",
       "      <td>0.387128</td>\n",
       "      <td>0.928630</td>\n",
       "      <td>0.468118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.008400</td>\n",
       "      <td>0.424875</td>\n",
       "      <td>0.925349</td>\n",
       "      <td>0.446147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>0.457509</td>\n",
       "      <td>0.927810</td>\n",
       "      <td>0.418368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.457886</td>\n",
       "      <td>0.926169</td>\n",
       "      <td>0.434671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.457996</td>\n",
       "      <td>0.927810</td>\n",
       "      <td>0.441252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.484015</td>\n",
       "      <td>0.926989</td>\n",
       "      <td>0.434979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.486201</td>\n",
       "      <td>0.927810</td>\n",
       "      <td>0.437308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.489262</td>\n",
       "      <td>0.927810</td>\n",
       "      <td>0.437308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.500437</td>\n",
       "      <td>0.926989</td>\n",
       "      <td>0.434979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.503383</td>\n",
       "      <td>0.927810</td>\n",
       "      <td>0.437308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.505729</td>\n",
       "      <td>0.927810</td>\n",
       "      <td>0.437308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.507492</td>\n",
       "      <td>0.928630</td>\n",
       "      <td>0.440291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.508569</td>\n",
       "      <td>0.928630</td>\n",
       "      <td>0.440291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.508046</td>\n",
       "      <td>0.927810</td>\n",
       "      <td>0.438421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.508825</td>\n",
       "      <td>0.927810</td>\n",
       "      <td>0.438421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.508937</td>\n",
       "      <td>0.927810</td>\n",
       "      <td>0.438421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SI2M-Lab/DarijaBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SI2M-Lab/DarijaBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ad1b503e73e4dff96fee4c6d8f983ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0819e026a9224a5b883ee55de1893fce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1155' max='1155' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1155/1155 01:45, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.371400</td>\n",
       "      <td>0.297970</td>\n",
       "      <td>0.912223</td>\n",
       "      <td>0.309759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.230400</td>\n",
       "      <td>0.263252</td>\n",
       "      <td>0.922067</td>\n",
       "      <td>0.372680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.185100</td>\n",
       "      <td>0.283346</td>\n",
       "      <td>0.922888</td>\n",
       "      <td>0.379124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.108300</td>\n",
       "      <td>0.296465</td>\n",
       "      <td>0.916325</td>\n",
       "      <td>0.435736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.074300</td>\n",
       "      <td>0.327890</td>\n",
       "      <td>0.920427</td>\n",
       "      <td>0.451936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.040500</td>\n",
       "      <td>0.481948</td>\n",
       "      <td>0.917966</td>\n",
       "      <td>0.390981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.023500</td>\n",
       "      <td>0.391353</td>\n",
       "      <td>0.926169</td>\n",
       "      <td>0.439490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.013400</td>\n",
       "      <td>0.387128</td>\n",
       "      <td>0.928630</td>\n",
       "      <td>0.468118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.008400</td>\n",
       "      <td>0.424875</td>\n",
       "      <td>0.925349</td>\n",
       "      <td>0.446147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>0.457509</td>\n",
       "      <td>0.927810</td>\n",
       "      <td>0.418368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.457886</td>\n",
       "      <td>0.926169</td>\n",
       "      <td>0.434671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.457996</td>\n",
       "      <td>0.927810</td>\n",
       "      <td>0.441252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.484015</td>\n",
       "      <td>0.926989</td>\n",
       "      <td>0.434979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.486201</td>\n",
       "      <td>0.927810</td>\n",
       "      <td>0.437308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.489262</td>\n",
       "      <td>0.927810</td>\n",
       "      <td>0.437308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.500437</td>\n",
       "      <td>0.926989</td>\n",
       "      <td>0.434979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.503383</td>\n",
       "      <td>0.927810</td>\n",
       "      <td>0.437308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.505729</td>\n",
       "      <td>0.927810</td>\n",
       "      <td>0.437308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.507492</td>\n",
       "      <td>0.928630</td>\n",
       "      <td>0.440291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.508569</td>\n",
       "      <td>0.928630</td>\n",
       "      <td>0.440291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.508046</td>\n",
       "      <td>0.927810</td>\n",
       "      <td>0.438421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.508825</td>\n",
       "      <td>0.927810</td>\n",
       "      <td>0.438421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.508937</td>\n",
       "      <td>0.927810</td>\n",
       "      <td>0.438421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SI2M-Lab/DarijaBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SI2M-Lab/DarijaBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5fbd41c5d7147428ca8df87a53b8725",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31d5d5470d1042f596438552d52ca1d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1155' max='1155' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1155/1155 01:45, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.371400</td>\n",
       "      <td>0.297970</td>\n",
       "      <td>0.912223</td>\n",
       "      <td>0.309759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.230400</td>\n",
       "      <td>0.263252</td>\n",
       "      <td>0.922067</td>\n",
       "      <td>0.372680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.185100</td>\n",
       "      <td>0.283346</td>\n",
       "      <td>0.922888</td>\n",
       "      <td>0.379124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.108300</td>\n",
       "      <td>0.296465</td>\n",
       "      <td>0.916325</td>\n",
       "      <td>0.435736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.074300</td>\n",
       "      <td>0.327890</td>\n",
       "      <td>0.920427</td>\n",
       "      <td>0.451936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.040500</td>\n",
       "      <td>0.481948</td>\n",
       "      <td>0.917966</td>\n",
       "      <td>0.390981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.023500</td>\n",
       "      <td>0.391353</td>\n",
       "      <td>0.926169</td>\n",
       "      <td>0.439490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.013400</td>\n",
       "      <td>0.387128</td>\n",
       "      <td>0.928630</td>\n",
       "      <td>0.468118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.008400</td>\n",
       "      <td>0.424875</td>\n",
       "      <td>0.925349</td>\n",
       "      <td>0.446147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>0.457509</td>\n",
       "      <td>0.927810</td>\n",
       "      <td>0.418368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.457886</td>\n",
       "      <td>0.926169</td>\n",
       "      <td>0.434671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.457996</td>\n",
       "      <td>0.927810</td>\n",
       "      <td>0.441252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.484015</td>\n",
       "      <td>0.926989</td>\n",
       "      <td>0.434979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.486201</td>\n",
       "      <td>0.927810</td>\n",
       "      <td>0.437308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.489262</td>\n",
       "      <td>0.927810</td>\n",
       "      <td>0.437308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.500437</td>\n",
       "      <td>0.926989</td>\n",
       "      <td>0.434979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.503383</td>\n",
       "      <td>0.927810</td>\n",
       "      <td>0.437308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.505729</td>\n",
       "      <td>0.927810</td>\n",
       "      <td>0.437308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.507492</td>\n",
       "      <td>0.928630</td>\n",
       "      <td>0.440291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.508569</td>\n",
       "      <td>0.928630</td>\n",
       "      <td>0.440291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.508046</td>\n",
       "      <td>0.927810</td>\n",
       "      <td>0.438421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.508825</td>\n",
       "      <td>0.927810</td>\n",
       "      <td>0.438421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.508937</td>\n",
       "      <td>0.927810</td>\n",
       "      <td>0.438421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SI2M-Lab/DarijaBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SI2M-Lab/DarijaBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74c8bc862c62405b9b2e8108eba7fa5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0163dd51809a473792240d868c1734a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1155' max='1155' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1155/1155 01:45, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.358600</td>\n",
       "      <td>0.366475</td>\n",
       "      <td>0.899918</td>\n",
       "      <td>0.246861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.242800</td>\n",
       "      <td>0.322837</td>\n",
       "      <td>0.922888</td>\n",
       "      <td>0.347337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.192500</td>\n",
       "      <td>0.258813</td>\n",
       "      <td>0.918786</td>\n",
       "      <td>0.398076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.098900</td>\n",
       "      <td>0.381548</td>\n",
       "      <td>0.922888</td>\n",
       "      <td>0.423934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.085400</td>\n",
       "      <td>0.349352</td>\n",
       "      <td>0.913864</td>\n",
       "      <td>0.403086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.041000</td>\n",
       "      <td>0.348980</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.427678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.025200</td>\n",
       "      <td>0.424925</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.409086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>0.420960</td>\n",
       "      <td>0.927810</td>\n",
       "      <td>0.426560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.010400</td>\n",
       "      <td>0.479778</td>\n",
       "      <td>0.923708</td>\n",
       "      <td>0.412039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.010600</td>\n",
       "      <td>0.485664</td>\n",
       "      <td>0.922888</td>\n",
       "      <td>0.446543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.475422</td>\n",
       "      <td>0.923708</td>\n",
       "      <td>0.407616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>0.497815</td>\n",
       "      <td>0.926169</td>\n",
       "      <td>0.404614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.005700</td>\n",
       "      <td>0.500082</td>\n",
       "      <td>0.926989</td>\n",
       "      <td>0.416204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.502050</td>\n",
       "      <td>0.926989</td>\n",
       "      <td>0.421761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.512291</td>\n",
       "      <td>0.920427</td>\n",
       "      <td>0.410338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.502954</td>\n",
       "      <td>0.923708</td>\n",
       "      <td>0.414100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>0.525627</td>\n",
       "      <td>0.926169</td>\n",
       "      <td>0.420160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.532010</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.405129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.521957</td>\n",
       "      <td>0.922067</td>\n",
       "      <td>0.407083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.520935</td>\n",
       "      <td>0.922888</td>\n",
       "      <td>0.397713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.519466</td>\n",
       "      <td>0.923708</td>\n",
       "      <td>0.399780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>0.516546</td>\n",
       "      <td>0.925349</td>\n",
       "      <td>0.403815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.516716</td>\n",
       "      <td>0.925349</td>\n",
       "      <td>0.403815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SI2M-Lab/DarijaBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SI2M-Lab/DarijaBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86d21e00ce9e4b0599e5078d9e79fe59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b83ea80d375143a1b478025c5ab47cf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1155' max='1155' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1155/1155 01:45, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.358600</td>\n",
       "      <td>0.366475</td>\n",
       "      <td>0.899918</td>\n",
       "      <td>0.246861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.242800</td>\n",
       "      <td>0.322837</td>\n",
       "      <td>0.922888</td>\n",
       "      <td>0.347337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.192500</td>\n",
       "      <td>0.258813</td>\n",
       "      <td>0.918786</td>\n",
       "      <td>0.398076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.098900</td>\n",
       "      <td>0.381548</td>\n",
       "      <td>0.922888</td>\n",
       "      <td>0.423934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.085400</td>\n",
       "      <td>0.349352</td>\n",
       "      <td>0.913864</td>\n",
       "      <td>0.403086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.041000</td>\n",
       "      <td>0.348980</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.427678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.025200</td>\n",
       "      <td>0.424925</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.409086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>0.420960</td>\n",
       "      <td>0.927810</td>\n",
       "      <td>0.426560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.010400</td>\n",
       "      <td>0.479778</td>\n",
       "      <td>0.923708</td>\n",
       "      <td>0.412039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.010600</td>\n",
       "      <td>0.485664</td>\n",
       "      <td>0.922888</td>\n",
       "      <td>0.446543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.475422</td>\n",
       "      <td>0.923708</td>\n",
       "      <td>0.407616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>0.497815</td>\n",
       "      <td>0.926169</td>\n",
       "      <td>0.404614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.005700</td>\n",
       "      <td>0.500082</td>\n",
       "      <td>0.926989</td>\n",
       "      <td>0.416204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.502050</td>\n",
       "      <td>0.926989</td>\n",
       "      <td>0.421761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.512291</td>\n",
       "      <td>0.920427</td>\n",
       "      <td>0.410338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.502954</td>\n",
       "      <td>0.923708</td>\n",
       "      <td>0.414100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>0.525627</td>\n",
       "      <td>0.926169</td>\n",
       "      <td>0.420160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.532010</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.405129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.521957</td>\n",
       "      <td>0.922067</td>\n",
       "      <td>0.407083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.520935</td>\n",
       "      <td>0.922888</td>\n",
       "      <td>0.397713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.519466</td>\n",
       "      <td>0.923708</td>\n",
       "      <td>0.399780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>0.516546</td>\n",
       "      <td>0.925349</td>\n",
       "      <td>0.403815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.516716</td>\n",
       "      <td>0.925349</td>\n",
       "      <td>0.403815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SI2M-Lab/DarijaBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SI2M-Lab/DarijaBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf3404c8d01347b08c2ac093b5b0950f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d96494d61b7c4ec5b69a6878386cd4d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1155' max='1155' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1155/1155 01:45, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.358600</td>\n",
       "      <td>0.366475</td>\n",
       "      <td>0.899918</td>\n",
       "      <td>0.246861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.242800</td>\n",
       "      <td>0.322837</td>\n",
       "      <td>0.922888</td>\n",
       "      <td>0.347337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.192500</td>\n",
       "      <td>0.258813</td>\n",
       "      <td>0.918786</td>\n",
       "      <td>0.398076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.098900</td>\n",
       "      <td>0.381548</td>\n",
       "      <td>0.922888</td>\n",
       "      <td>0.423934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.085400</td>\n",
       "      <td>0.349352</td>\n",
       "      <td>0.913864</td>\n",
       "      <td>0.403086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.041000</td>\n",
       "      <td>0.348980</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.427678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.025200</td>\n",
       "      <td>0.424925</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.409086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>0.420960</td>\n",
       "      <td>0.927810</td>\n",
       "      <td>0.426560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.010400</td>\n",
       "      <td>0.479778</td>\n",
       "      <td>0.923708</td>\n",
       "      <td>0.412039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.010600</td>\n",
       "      <td>0.485664</td>\n",
       "      <td>0.922888</td>\n",
       "      <td>0.446543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.475422</td>\n",
       "      <td>0.923708</td>\n",
       "      <td>0.407616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>0.497815</td>\n",
       "      <td>0.926169</td>\n",
       "      <td>0.404614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.005700</td>\n",
       "      <td>0.500082</td>\n",
       "      <td>0.926989</td>\n",
       "      <td>0.416204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.502050</td>\n",
       "      <td>0.926989</td>\n",
       "      <td>0.421761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.512291</td>\n",
       "      <td>0.920427</td>\n",
       "      <td>0.410338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.502954</td>\n",
       "      <td>0.923708</td>\n",
       "      <td>0.414100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>0.525627</td>\n",
       "      <td>0.926169</td>\n",
       "      <td>0.420160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.532010</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.405129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.521957</td>\n",
       "      <td>0.922067</td>\n",
       "      <td>0.407083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.520935</td>\n",
       "      <td>0.922888</td>\n",
       "      <td>0.397713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.519466</td>\n",
       "      <td>0.923708</td>\n",
       "      <td>0.399780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>0.516546</td>\n",
       "      <td>0.925349</td>\n",
       "      <td>0.403815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.516716</td>\n",
       "      <td>0.925349</td>\n",
       "      <td>0.403815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Text', 'label', '__index_level_0__'],\n",
       "        num_rows: 4872\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Text', 'label', '__index_level_0__'],\n",
       "        num_rows: 1219\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorRoBERTa, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at otmangi/MorRoBERTa and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59947db0a2374ae180b1e18773f13671",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7d41cf7746843619a7f992eefda7706",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1155' max='1155' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1155/1155 00:56, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.464800</td>\n",
       "      <td>0.269860</td>\n",
       "      <td>0.904020</td>\n",
       "      <td>0.248180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.250500</td>\n",
       "      <td>0.225219</td>\n",
       "      <td>0.919606</td>\n",
       "      <td>0.422375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.229600</td>\n",
       "      <td>0.223425</td>\n",
       "      <td>0.925349</td>\n",
       "      <td>0.426298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.134500</td>\n",
       "      <td>0.313974</td>\n",
       "      <td>0.922888</td>\n",
       "      <td>0.407866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.121900</td>\n",
       "      <td>0.290104</td>\n",
       "      <td>0.926169</td>\n",
       "      <td>0.488694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.059800</td>\n",
       "      <td>0.360112</td>\n",
       "      <td>0.926989</td>\n",
       "      <td>0.487135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.046600</td>\n",
       "      <td>0.397208</td>\n",
       "      <td>0.922067</td>\n",
       "      <td>0.381375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.023000</td>\n",
       "      <td>0.440896</td>\n",
       "      <td>0.922067</td>\n",
       "      <td>0.397351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.013700</td>\n",
       "      <td>0.446510</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.421212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>0.437996</td>\n",
       "      <td>0.923708</td>\n",
       "      <td>0.410518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>0.430578</td>\n",
       "      <td>0.930271</td>\n",
       "      <td>0.441730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.430133</td>\n",
       "      <td>0.933552</td>\n",
       "      <td>0.450329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.422857</td>\n",
       "      <td>0.933552</td>\n",
       "      <td>0.457436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.434993</td>\n",
       "      <td>0.930271</td>\n",
       "      <td>0.434907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.438406</td>\n",
       "      <td>0.933552</td>\n",
       "      <td>0.451704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.443697</td>\n",
       "      <td>0.933552</td>\n",
       "      <td>0.452480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.449270</td>\n",
       "      <td>0.931911</td>\n",
       "      <td>0.448049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.447980</td>\n",
       "      <td>0.933552</td>\n",
       "      <td>0.449702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.449717</td>\n",
       "      <td>0.932732</td>\n",
       "      <td>0.447773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.454323</td>\n",
       "      <td>0.931911</td>\n",
       "      <td>0.447324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.455708</td>\n",
       "      <td>0.932732</td>\n",
       "      <td>0.449481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.455676</td>\n",
       "      <td>0.932732</td>\n",
       "      <td>0.449481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.456039</td>\n",
       "      <td>0.932732</td>\n",
       "      <td>0.449481</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorRoBERTa, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at otmangi/MorRoBERTa and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f33f6e3e025d40c0887dbd8aa993a393",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76dc6a0d0b9b4a1aa6aaf614c934aa12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1155' max='1155' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1155/1155 00:56, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.464800</td>\n",
       "      <td>0.269860</td>\n",
       "      <td>0.904020</td>\n",
       "      <td>0.248180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.250500</td>\n",
       "      <td>0.225219</td>\n",
       "      <td>0.919606</td>\n",
       "      <td>0.422375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.229600</td>\n",
       "      <td>0.223425</td>\n",
       "      <td>0.925349</td>\n",
       "      <td>0.426298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.134500</td>\n",
       "      <td>0.313974</td>\n",
       "      <td>0.922888</td>\n",
       "      <td>0.407866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.121900</td>\n",
       "      <td>0.290104</td>\n",
       "      <td>0.926169</td>\n",
       "      <td>0.488694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.059800</td>\n",
       "      <td>0.360112</td>\n",
       "      <td>0.926989</td>\n",
       "      <td>0.487135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.046600</td>\n",
       "      <td>0.397208</td>\n",
       "      <td>0.922067</td>\n",
       "      <td>0.381375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.023000</td>\n",
       "      <td>0.440896</td>\n",
       "      <td>0.922067</td>\n",
       "      <td>0.397351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.013700</td>\n",
       "      <td>0.446510</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.421212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>0.437996</td>\n",
       "      <td>0.923708</td>\n",
       "      <td>0.410518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>0.430578</td>\n",
       "      <td>0.930271</td>\n",
       "      <td>0.441730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.430133</td>\n",
       "      <td>0.933552</td>\n",
       "      <td>0.450329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.422857</td>\n",
       "      <td>0.933552</td>\n",
       "      <td>0.457436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.434993</td>\n",
       "      <td>0.930271</td>\n",
       "      <td>0.434907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.438406</td>\n",
       "      <td>0.933552</td>\n",
       "      <td>0.451704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.443697</td>\n",
       "      <td>0.933552</td>\n",
       "      <td>0.452480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.449270</td>\n",
       "      <td>0.931911</td>\n",
       "      <td>0.448049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.447980</td>\n",
       "      <td>0.933552</td>\n",
       "      <td>0.449702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.449717</td>\n",
       "      <td>0.932732</td>\n",
       "      <td>0.447773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.454323</td>\n",
       "      <td>0.931911</td>\n",
       "      <td>0.447324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.455708</td>\n",
       "      <td>0.932732</td>\n",
       "      <td>0.449481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.455676</td>\n",
       "      <td>0.932732</td>\n",
       "      <td>0.449481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.456039</td>\n",
       "      <td>0.932732</td>\n",
       "      <td>0.449481</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorRoBERTa, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at otmangi/MorRoBERTa and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d95d8ee5f96b4ee8af5f05ef78c98254",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a48be96abf7441b4a776b63325a23436",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1155' max='1155' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1155/1155 00:56, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.464800</td>\n",
       "      <td>0.269860</td>\n",
       "      <td>0.904020</td>\n",
       "      <td>0.248180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.250500</td>\n",
       "      <td>0.225219</td>\n",
       "      <td>0.919606</td>\n",
       "      <td>0.422375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.229600</td>\n",
       "      <td>0.223425</td>\n",
       "      <td>0.925349</td>\n",
       "      <td>0.426298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.134500</td>\n",
       "      <td>0.313974</td>\n",
       "      <td>0.922888</td>\n",
       "      <td>0.407866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.121900</td>\n",
       "      <td>0.290104</td>\n",
       "      <td>0.926169</td>\n",
       "      <td>0.488694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.059800</td>\n",
       "      <td>0.360112</td>\n",
       "      <td>0.926989</td>\n",
       "      <td>0.487135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.046600</td>\n",
       "      <td>0.397208</td>\n",
       "      <td>0.922067</td>\n",
       "      <td>0.381375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.023000</td>\n",
       "      <td>0.440896</td>\n",
       "      <td>0.922067</td>\n",
       "      <td>0.397351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.013700</td>\n",
       "      <td>0.446510</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.421212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>0.437996</td>\n",
       "      <td>0.923708</td>\n",
       "      <td>0.410518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>0.430578</td>\n",
       "      <td>0.930271</td>\n",
       "      <td>0.441730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.430133</td>\n",
       "      <td>0.933552</td>\n",
       "      <td>0.450329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.422857</td>\n",
       "      <td>0.933552</td>\n",
       "      <td>0.457436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.434993</td>\n",
       "      <td>0.930271</td>\n",
       "      <td>0.434907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.438406</td>\n",
       "      <td>0.933552</td>\n",
       "      <td>0.451704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.443697</td>\n",
       "      <td>0.933552</td>\n",
       "      <td>0.452480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.449270</td>\n",
       "      <td>0.931911</td>\n",
       "      <td>0.448049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.447980</td>\n",
       "      <td>0.933552</td>\n",
       "      <td>0.449702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.449717</td>\n",
       "      <td>0.932732</td>\n",
       "      <td>0.447773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.454323</td>\n",
       "      <td>0.931911</td>\n",
       "      <td>0.447324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.455708</td>\n",
       "      <td>0.932732</td>\n",
       "      <td>0.449481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.455676</td>\n",
       "      <td>0.932732</td>\n",
       "      <td>0.449481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.456039</td>\n",
       "      <td>0.932732</td>\n",
       "      <td>0.449481</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorRoBERTa, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at otmangi/MorRoBERTa and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36a158d929ac4bf28449782adf2c85c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7113ded73750449da7b10015100e8541",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1155' max='1155' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1155/1155 00:56, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.422800</td>\n",
       "      <td>0.300765</td>\n",
       "      <td>0.908121</td>\n",
       "      <td>0.288336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.248000</td>\n",
       "      <td>0.283611</td>\n",
       "      <td>0.909762</td>\n",
       "      <td>0.360737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.212100</td>\n",
       "      <td>0.278108</td>\n",
       "      <td>0.919606</td>\n",
       "      <td>0.359297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.139300</td>\n",
       "      <td>0.422324</td>\n",
       "      <td>0.876128</td>\n",
       "      <td>0.366336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.119400</td>\n",
       "      <td>0.358313</td>\n",
       "      <td>0.913864</td>\n",
       "      <td>0.398871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.075400</td>\n",
       "      <td>0.390263</td>\n",
       "      <td>0.915505</td>\n",
       "      <td>0.498508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.040900</td>\n",
       "      <td>0.399375</td>\n",
       "      <td>0.922888</td>\n",
       "      <td>0.552395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.034800</td>\n",
       "      <td>0.432917</td>\n",
       "      <td>0.914684</td>\n",
       "      <td>0.498080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.017400</td>\n",
       "      <td>0.450463</td>\n",
       "      <td>0.917145</td>\n",
       "      <td>0.555557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.008900</td>\n",
       "      <td>0.450301</td>\n",
       "      <td>0.921247</td>\n",
       "      <td>0.511130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>0.498503</td>\n",
       "      <td>0.914684</td>\n",
       "      <td>0.552790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.493362</td>\n",
       "      <td>0.916325</td>\n",
       "      <td>0.556551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.505892</td>\n",
       "      <td>0.917145</td>\n",
       "      <td>0.551865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>0.526978</td>\n",
       "      <td>0.913864</td>\n",
       "      <td>0.544330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.517489</td>\n",
       "      <td>0.917145</td>\n",
       "      <td>0.558960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.522670</td>\n",
       "      <td>0.916325</td>\n",
       "      <td>0.553089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.525361</td>\n",
       "      <td>0.916325</td>\n",
       "      <td>0.553568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.529547</td>\n",
       "      <td>0.916325</td>\n",
       "      <td>0.554194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.532885</td>\n",
       "      <td>0.914684</td>\n",
       "      <td>0.548308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.534784</td>\n",
       "      <td>0.916325</td>\n",
       "      <td>0.553382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.535407</td>\n",
       "      <td>0.916325</td>\n",
       "      <td>0.553382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.536005</td>\n",
       "      <td>0.916325</td>\n",
       "      <td>0.553382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.536293</td>\n",
       "      <td>0.916325</td>\n",
       "      <td>0.554194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorRoBERTa, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at otmangi/MorRoBERTa and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69b4bab891c74d4fb7f5f6798d68b50f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "044bec7e774148b0a39390f95ea011da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1155' max='1155' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1155/1155 00:56, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.422800</td>\n",
       "      <td>0.300765</td>\n",
       "      <td>0.908121</td>\n",
       "      <td>0.288336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.248000</td>\n",
       "      <td>0.283611</td>\n",
       "      <td>0.909762</td>\n",
       "      <td>0.360737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.212100</td>\n",
       "      <td>0.278108</td>\n",
       "      <td>0.919606</td>\n",
       "      <td>0.359297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.139300</td>\n",
       "      <td>0.422324</td>\n",
       "      <td>0.876128</td>\n",
       "      <td>0.366336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.119400</td>\n",
       "      <td>0.358313</td>\n",
       "      <td>0.913864</td>\n",
       "      <td>0.398871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.075400</td>\n",
       "      <td>0.390263</td>\n",
       "      <td>0.915505</td>\n",
       "      <td>0.498508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.040900</td>\n",
       "      <td>0.399375</td>\n",
       "      <td>0.922888</td>\n",
       "      <td>0.552395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.034800</td>\n",
       "      <td>0.432917</td>\n",
       "      <td>0.914684</td>\n",
       "      <td>0.498080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.017400</td>\n",
       "      <td>0.450463</td>\n",
       "      <td>0.917145</td>\n",
       "      <td>0.555557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.008900</td>\n",
       "      <td>0.450301</td>\n",
       "      <td>0.921247</td>\n",
       "      <td>0.511130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>0.498503</td>\n",
       "      <td>0.914684</td>\n",
       "      <td>0.552790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.493362</td>\n",
       "      <td>0.916325</td>\n",
       "      <td>0.556551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.505892</td>\n",
       "      <td>0.917145</td>\n",
       "      <td>0.551865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>0.526978</td>\n",
       "      <td>0.913864</td>\n",
       "      <td>0.544330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.517489</td>\n",
       "      <td>0.917145</td>\n",
       "      <td>0.558960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.522670</td>\n",
       "      <td>0.916325</td>\n",
       "      <td>0.553089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.525361</td>\n",
       "      <td>0.916325</td>\n",
       "      <td>0.553568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.529547</td>\n",
       "      <td>0.916325</td>\n",
       "      <td>0.554194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.532885</td>\n",
       "      <td>0.914684</td>\n",
       "      <td>0.548308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.534784</td>\n",
       "      <td>0.916325</td>\n",
       "      <td>0.553382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.535407</td>\n",
       "      <td>0.916325</td>\n",
       "      <td>0.553382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.536005</td>\n",
       "      <td>0.916325</td>\n",
       "      <td>0.553382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.536293</td>\n",
       "      <td>0.916325</td>\n",
       "      <td>0.554194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorRoBERTa, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at otmangi/MorRoBERTa and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9dfb53d2cf14f09b4d7a25c3616b353",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54517faacf044f5584e3e42e503d14b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1155' max='1155' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1155/1155 00:56, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.422800</td>\n",
       "      <td>0.300765</td>\n",
       "      <td>0.908121</td>\n",
       "      <td>0.288336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.248000</td>\n",
       "      <td>0.283611</td>\n",
       "      <td>0.909762</td>\n",
       "      <td>0.360737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.212100</td>\n",
       "      <td>0.278108</td>\n",
       "      <td>0.919606</td>\n",
       "      <td>0.359297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.139300</td>\n",
       "      <td>0.422324</td>\n",
       "      <td>0.876128</td>\n",
       "      <td>0.366336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.119400</td>\n",
       "      <td>0.358313</td>\n",
       "      <td>0.913864</td>\n",
       "      <td>0.398871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.075400</td>\n",
       "      <td>0.390263</td>\n",
       "      <td>0.915505</td>\n",
       "      <td>0.498508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.040900</td>\n",
       "      <td>0.399375</td>\n",
       "      <td>0.922888</td>\n",
       "      <td>0.552395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.034800</td>\n",
       "      <td>0.432917</td>\n",
       "      <td>0.914684</td>\n",
       "      <td>0.498080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.017400</td>\n",
       "      <td>0.450463</td>\n",
       "      <td>0.917145</td>\n",
       "      <td>0.555557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.008900</td>\n",
       "      <td>0.450301</td>\n",
       "      <td>0.921247</td>\n",
       "      <td>0.511130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>0.498503</td>\n",
       "      <td>0.914684</td>\n",
       "      <td>0.552790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.493362</td>\n",
       "      <td>0.916325</td>\n",
       "      <td>0.556551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.505892</td>\n",
       "      <td>0.917145</td>\n",
       "      <td>0.551865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>0.526978</td>\n",
       "      <td>0.913864</td>\n",
       "      <td>0.544330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.517489</td>\n",
       "      <td>0.917145</td>\n",
       "      <td>0.558960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.522670</td>\n",
       "      <td>0.916325</td>\n",
       "      <td>0.553089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.525361</td>\n",
       "      <td>0.916325</td>\n",
       "      <td>0.553568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.529547</td>\n",
       "      <td>0.916325</td>\n",
       "      <td>0.554194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.532885</td>\n",
       "      <td>0.914684</td>\n",
       "      <td>0.548308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.534784</td>\n",
       "      <td>0.916325</td>\n",
       "      <td>0.553382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.535407</td>\n",
       "      <td>0.916325</td>\n",
       "      <td>0.553382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.536005</td>\n",
       "      <td>0.916325</td>\n",
       "      <td>0.553382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.536293</td>\n",
       "      <td>0.916325</td>\n",
       "      <td>0.554194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorRoBERTa, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at otmangi/MorRoBERTa and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba0de53f891f4c6abda4f3f589af651b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f714b98870e48acad84e46e8328855e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1155' max='1155' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1155/1155 00:56, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.397600</td>\n",
       "      <td>0.329307</td>\n",
       "      <td>0.901559</td>\n",
       "      <td>0.255608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.243200</td>\n",
       "      <td>0.312319</td>\n",
       "      <td>0.921247</td>\n",
       "      <td>0.352948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.210100</td>\n",
       "      <td>0.304582</td>\n",
       "      <td>0.922888</td>\n",
       "      <td>0.350478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.132100</td>\n",
       "      <td>0.352185</td>\n",
       "      <td>0.913864</td>\n",
       "      <td>0.356594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.092600</td>\n",
       "      <td>0.372322</td>\n",
       "      <td>0.910582</td>\n",
       "      <td>0.344839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.065300</td>\n",
       "      <td>0.434745</td>\n",
       "      <td>0.920427</td>\n",
       "      <td>0.395227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.029800</td>\n",
       "      <td>0.439273</td>\n",
       "      <td>0.914684</td>\n",
       "      <td>0.390277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.025900</td>\n",
       "      <td>0.456410</td>\n",
       "      <td>0.911403</td>\n",
       "      <td>0.378158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.008800</td>\n",
       "      <td>0.496368</td>\n",
       "      <td>0.915505</td>\n",
       "      <td>0.407204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.008300</td>\n",
       "      <td>0.497617</td>\n",
       "      <td>0.912223</td>\n",
       "      <td>0.422266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.503786</td>\n",
       "      <td>0.913864</td>\n",
       "      <td>0.457247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>0.496503</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.437909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.505506</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.406185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.514588</td>\n",
       "      <td>0.917145</td>\n",
       "      <td>0.406939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.533071</td>\n",
       "      <td>0.911403</td>\n",
       "      <td>0.401655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.532231</td>\n",
       "      <td>0.916325</td>\n",
       "      <td>0.405176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.535280</td>\n",
       "      <td>0.915505</td>\n",
       "      <td>0.402372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.538126</td>\n",
       "      <td>0.915505</td>\n",
       "      <td>0.402372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.539773</td>\n",
       "      <td>0.915505</td>\n",
       "      <td>0.402372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.541710</td>\n",
       "      <td>0.915505</td>\n",
       "      <td>0.402372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.543100</td>\n",
       "      <td>0.915505</td>\n",
       "      <td>0.402372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.543757</td>\n",
       "      <td>0.915505</td>\n",
       "      <td>0.402372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.543917</td>\n",
       "      <td>0.915505</td>\n",
       "      <td>0.402372</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorRoBERTa, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at otmangi/MorRoBERTa and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41907dacfa394613b20424ec59f11752",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4b938cddfc7434d8db1c1659d2e40c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1155' max='1155' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1155/1155 00:56, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.397600</td>\n",
       "      <td>0.329307</td>\n",
       "      <td>0.901559</td>\n",
       "      <td>0.255608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.243200</td>\n",
       "      <td>0.312319</td>\n",
       "      <td>0.921247</td>\n",
       "      <td>0.352948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.210100</td>\n",
       "      <td>0.304582</td>\n",
       "      <td>0.922888</td>\n",
       "      <td>0.350478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.132100</td>\n",
       "      <td>0.352185</td>\n",
       "      <td>0.913864</td>\n",
       "      <td>0.356594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.092600</td>\n",
       "      <td>0.372322</td>\n",
       "      <td>0.910582</td>\n",
       "      <td>0.344839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.065300</td>\n",
       "      <td>0.434745</td>\n",
       "      <td>0.920427</td>\n",
       "      <td>0.395227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.029800</td>\n",
       "      <td>0.439273</td>\n",
       "      <td>0.914684</td>\n",
       "      <td>0.390277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.025900</td>\n",
       "      <td>0.456410</td>\n",
       "      <td>0.911403</td>\n",
       "      <td>0.378158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.008800</td>\n",
       "      <td>0.496368</td>\n",
       "      <td>0.915505</td>\n",
       "      <td>0.407204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.008300</td>\n",
       "      <td>0.497617</td>\n",
       "      <td>0.912223</td>\n",
       "      <td>0.422266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.503786</td>\n",
       "      <td>0.913864</td>\n",
       "      <td>0.457247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>0.496503</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.437909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.505506</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.406185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.514588</td>\n",
       "      <td>0.917145</td>\n",
       "      <td>0.406939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.533071</td>\n",
       "      <td>0.911403</td>\n",
       "      <td>0.401655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.532231</td>\n",
       "      <td>0.916325</td>\n",
       "      <td>0.405176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.535280</td>\n",
       "      <td>0.915505</td>\n",
       "      <td>0.402372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.538126</td>\n",
       "      <td>0.915505</td>\n",
       "      <td>0.402372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.539773</td>\n",
       "      <td>0.915505</td>\n",
       "      <td>0.402372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.541710</td>\n",
       "      <td>0.915505</td>\n",
       "      <td>0.402372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.543100</td>\n",
       "      <td>0.915505</td>\n",
       "      <td>0.402372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.543757</td>\n",
       "      <td>0.915505</td>\n",
       "      <td>0.402372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.543917</td>\n",
       "      <td>0.915505</td>\n",
       "      <td>0.402372</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorRoBERTa, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at otmangi/MorRoBERTa and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b13351ff9f024f4d9404db3587e719bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5ed89ee8fc146c49021445bf5ad7a12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1155' max='1155' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1155/1155 00:56, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.397600</td>\n",
       "      <td>0.329307</td>\n",
       "      <td>0.901559</td>\n",
       "      <td>0.255608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.243200</td>\n",
       "      <td>0.312319</td>\n",
       "      <td>0.921247</td>\n",
       "      <td>0.352948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.210100</td>\n",
       "      <td>0.304582</td>\n",
       "      <td>0.922888</td>\n",
       "      <td>0.350478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.132100</td>\n",
       "      <td>0.352185</td>\n",
       "      <td>0.913864</td>\n",
       "      <td>0.356594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.092600</td>\n",
       "      <td>0.372322</td>\n",
       "      <td>0.910582</td>\n",
       "      <td>0.344839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.065300</td>\n",
       "      <td>0.434745</td>\n",
       "      <td>0.920427</td>\n",
       "      <td>0.395227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.029800</td>\n",
       "      <td>0.439273</td>\n",
       "      <td>0.914684</td>\n",
       "      <td>0.390277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.025900</td>\n",
       "      <td>0.456410</td>\n",
       "      <td>0.911403</td>\n",
       "      <td>0.378158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.008800</td>\n",
       "      <td>0.496368</td>\n",
       "      <td>0.915505</td>\n",
       "      <td>0.407204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.008300</td>\n",
       "      <td>0.497617</td>\n",
       "      <td>0.912223</td>\n",
       "      <td>0.422266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.503786</td>\n",
       "      <td>0.913864</td>\n",
       "      <td>0.457247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>0.496503</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.437909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.505506</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.406185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.514588</td>\n",
       "      <td>0.917145</td>\n",
       "      <td>0.406939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.533071</td>\n",
       "      <td>0.911403</td>\n",
       "      <td>0.401655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.532231</td>\n",
       "      <td>0.916325</td>\n",
       "      <td>0.405176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.535280</td>\n",
       "      <td>0.915505</td>\n",
       "      <td>0.402372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.538126</td>\n",
       "      <td>0.915505</td>\n",
       "      <td>0.402372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.539773</td>\n",
       "      <td>0.915505</td>\n",
       "      <td>0.402372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.541710</td>\n",
       "      <td>0.915505</td>\n",
       "      <td>0.402372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.543100</td>\n",
       "      <td>0.915505</td>\n",
       "      <td>0.402372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.543757</td>\n",
       "      <td>0.915505</td>\n",
       "      <td>0.402372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.543917</td>\n",
       "      <td>0.915505</td>\n",
       "      <td>0.402372</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Text', 'label', '__index_level_0__'],\n",
       "        num_rows: 4872\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Text', 'label', '__index_level_0__'],\n",
       "        num_rows: 1219\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorrBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at otmangi/MorrBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d01bf44071e4454caffbf6ca95b17577",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b18a7cba6b4a439d9c3b83c37cea2ab0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1155' max='1155' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1155/1155 01:42, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.416300</td>\n",
       "      <td>0.251025</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.314631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.248900</td>\n",
       "      <td>0.226937</td>\n",
       "      <td>0.918786</td>\n",
       "      <td>0.449525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.212100</td>\n",
       "      <td>0.258299</td>\n",
       "      <td>0.922067</td>\n",
       "      <td>0.465399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.124400</td>\n",
       "      <td>0.277201</td>\n",
       "      <td>0.926989</td>\n",
       "      <td>0.481524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.074600</td>\n",
       "      <td>0.342715</td>\n",
       "      <td>0.919606</td>\n",
       "      <td>0.415255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.043500</td>\n",
       "      <td>0.381168</td>\n",
       "      <td>0.920427</td>\n",
       "      <td>0.361955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.026900</td>\n",
       "      <td>0.390646</td>\n",
       "      <td>0.921247</td>\n",
       "      <td>0.416047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.015400</td>\n",
       "      <td>0.426804</td>\n",
       "      <td>0.914684</td>\n",
       "      <td>0.415627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.007200</td>\n",
       "      <td>0.488062</td>\n",
       "      <td>0.922888</td>\n",
       "      <td>0.476668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.452337</td>\n",
       "      <td>0.920427</td>\n",
       "      <td>0.397153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.464454</td>\n",
       "      <td>0.914684</td>\n",
       "      <td>0.394084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.464960</td>\n",
       "      <td>0.917145</td>\n",
       "      <td>0.404640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.482525</td>\n",
       "      <td>0.918786</td>\n",
       "      <td>0.401285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.500767</td>\n",
       "      <td>0.921247</td>\n",
       "      <td>0.413930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.507293</td>\n",
       "      <td>0.921247</td>\n",
       "      <td>0.413661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.507025</td>\n",
       "      <td>0.920427</td>\n",
       "      <td>0.412952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.507830</td>\n",
       "      <td>0.920427</td>\n",
       "      <td>0.412952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.513818</td>\n",
       "      <td>0.920427</td>\n",
       "      <td>0.412952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.514323</td>\n",
       "      <td>0.920427</td>\n",
       "      <td>0.412952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.517041</td>\n",
       "      <td>0.920427</td>\n",
       "      <td>0.412952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.518158</td>\n",
       "      <td>0.920427</td>\n",
       "      <td>0.412952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.517323</td>\n",
       "      <td>0.920427</td>\n",
       "      <td>0.412952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.517015</td>\n",
       "      <td>0.920427</td>\n",
       "      <td>0.412952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorrBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at otmangi/MorrBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "630ebee1910f444ab6ca1583a092423b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "285dbc95f2ba42e89ac2b7d5fa300a5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1155' max='1155' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1155/1155 01:41, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.416300</td>\n",
       "      <td>0.251025</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.314631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.248900</td>\n",
       "      <td>0.226937</td>\n",
       "      <td>0.918786</td>\n",
       "      <td>0.449525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.212100</td>\n",
       "      <td>0.258299</td>\n",
       "      <td>0.922067</td>\n",
       "      <td>0.465399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.124400</td>\n",
       "      <td>0.277201</td>\n",
       "      <td>0.926989</td>\n",
       "      <td>0.481524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.074600</td>\n",
       "      <td>0.342715</td>\n",
       "      <td>0.919606</td>\n",
       "      <td>0.415255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.043500</td>\n",
       "      <td>0.381168</td>\n",
       "      <td>0.920427</td>\n",
       "      <td>0.361955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.026900</td>\n",
       "      <td>0.390646</td>\n",
       "      <td>0.921247</td>\n",
       "      <td>0.416047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.015400</td>\n",
       "      <td>0.426804</td>\n",
       "      <td>0.914684</td>\n",
       "      <td>0.415627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.007200</td>\n",
       "      <td>0.488062</td>\n",
       "      <td>0.922888</td>\n",
       "      <td>0.476668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.452337</td>\n",
       "      <td>0.920427</td>\n",
       "      <td>0.397153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.464454</td>\n",
       "      <td>0.914684</td>\n",
       "      <td>0.394084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.464960</td>\n",
       "      <td>0.917145</td>\n",
       "      <td>0.404640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.482525</td>\n",
       "      <td>0.918786</td>\n",
       "      <td>0.401285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.500767</td>\n",
       "      <td>0.921247</td>\n",
       "      <td>0.413930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.507293</td>\n",
       "      <td>0.921247</td>\n",
       "      <td>0.413661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.507025</td>\n",
       "      <td>0.920427</td>\n",
       "      <td>0.412952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.507830</td>\n",
       "      <td>0.920427</td>\n",
       "      <td>0.412952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.513818</td>\n",
       "      <td>0.920427</td>\n",
       "      <td>0.412952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.514323</td>\n",
       "      <td>0.920427</td>\n",
       "      <td>0.412952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.517041</td>\n",
       "      <td>0.920427</td>\n",
       "      <td>0.412952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.518158</td>\n",
       "      <td>0.920427</td>\n",
       "      <td>0.412952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.517323</td>\n",
       "      <td>0.920427</td>\n",
       "      <td>0.412952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.517015</td>\n",
       "      <td>0.920427</td>\n",
       "      <td>0.412952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorrBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at otmangi/MorrBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b297d113e0a343c99c5f1def4bf80aa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a75fba1b9e994981ba51401766758eac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1155' max='1155' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1155/1155 01:41, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.416300</td>\n",
       "      <td>0.251025</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.314631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.248900</td>\n",
       "      <td>0.226937</td>\n",
       "      <td>0.918786</td>\n",
       "      <td>0.449525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.212100</td>\n",
       "      <td>0.258299</td>\n",
       "      <td>0.922067</td>\n",
       "      <td>0.465399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.124400</td>\n",
       "      <td>0.277201</td>\n",
       "      <td>0.926989</td>\n",
       "      <td>0.481524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.074600</td>\n",
       "      <td>0.342715</td>\n",
       "      <td>0.919606</td>\n",
       "      <td>0.415255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.043500</td>\n",
       "      <td>0.381168</td>\n",
       "      <td>0.920427</td>\n",
       "      <td>0.361955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.026900</td>\n",
       "      <td>0.390646</td>\n",
       "      <td>0.921247</td>\n",
       "      <td>0.416047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.015400</td>\n",
       "      <td>0.426804</td>\n",
       "      <td>0.914684</td>\n",
       "      <td>0.415627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.007200</td>\n",
       "      <td>0.488062</td>\n",
       "      <td>0.922888</td>\n",
       "      <td>0.476668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.452337</td>\n",
       "      <td>0.920427</td>\n",
       "      <td>0.397153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.464454</td>\n",
       "      <td>0.914684</td>\n",
       "      <td>0.394084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.464960</td>\n",
       "      <td>0.917145</td>\n",
       "      <td>0.404640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.482525</td>\n",
       "      <td>0.918786</td>\n",
       "      <td>0.401285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.500767</td>\n",
       "      <td>0.921247</td>\n",
       "      <td>0.413930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.507293</td>\n",
       "      <td>0.921247</td>\n",
       "      <td>0.413661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.507025</td>\n",
       "      <td>0.920427</td>\n",
       "      <td>0.412952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.507830</td>\n",
       "      <td>0.920427</td>\n",
       "      <td>0.412952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.513818</td>\n",
       "      <td>0.920427</td>\n",
       "      <td>0.412952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.514323</td>\n",
       "      <td>0.920427</td>\n",
       "      <td>0.412952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.517041</td>\n",
       "      <td>0.920427</td>\n",
       "      <td>0.412952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.518158</td>\n",
       "      <td>0.920427</td>\n",
       "      <td>0.412952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.517323</td>\n",
       "      <td>0.920427</td>\n",
       "      <td>0.412952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.517015</td>\n",
       "      <td>0.920427</td>\n",
       "      <td>0.412952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorrBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at otmangi/MorrBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc49c9ba766f4d8ca4e8514e25c88c31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "397b33b090024d2b89fafd5ede56c1fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1155' max='1155' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1155/1155 01:41, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.388400</td>\n",
       "      <td>0.274160</td>\n",
       "      <td>0.912223</td>\n",
       "      <td>0.319811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.229500</td>\n",
       "      <td>0.261748</td>\n",
       "      <td>0.922067</td>\n",
       "      <td>0.389062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.187200</td>\n",
       "      <td>0.324861</td>\n",
       "      <td>0.914684</td>\n",
       "      <td>0.348795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.106600</td>\n",
       "      <td>0.304713</td>\n",
       "      <td>0.917966</td>\n",
       "      <td>0.577857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.086700</td>\n",
       "      <td>0.355132</td>\n",
       "      <td>0.904840</td>\n",
       "      <td>0.506596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.044300</td>\n",
       "      <td>0.462311</td>\n",
       "      <td>0.912223</td>\n",
       "      <td>0.398172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.022900</td>\n",
       "      <td>0.447051</td>\n",
       "      <td>0.917966</td>\n",
       "      <td>0.418683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.018300</td>\n",
       "      <td>0.390288</td>\n",
       "      <td>0.922067</td>\n",
       "      <td>0.517871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.441436</td>\n",
       "      <td>0.916325</td>\n",
       "      <td>0.522039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.474859</td>\n",
       "      <td>0.920427</td>\n",
       "      <td>0.530838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.513243</td>\n",
       "      <td>0.925349</td>\n",
       "      <td>0.527646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.511483</td>\n",
       "      <td>0.919606</td>\n",
       "      <td>0.521574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.517739</td>\n",
       "      <td>0.920427</td>\n",
       "      <td>0.526079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.521725</td>\n",
       "      <td>0.919606</td>\n",
       "      <td>0.522804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.529987</td>\n",
       "      <td>0.921247</td>\n",
       "      <td>0.523896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.535026</td>\n",
       "      <td>0.921247</td>\n",
       "      <td>0.523896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.536658</td>\n",
       "      <td>0.921247</td>\n",
       "      <td>0.525119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.540729</td>\n",
       "      <td>0.922067</td>\n",
       "      <td>0.523975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.542432</td>\n",
       "      <td>0.921247</td>\n",
       "      <td>0.525119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.543750</td>\n",
       "      <td>0.921247</td>\n",
       "      <td>0.525119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.545991</td>\n",
       "      <td>0.921247</td>\n",
       "      <td>0.523138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.547034</td>\n",
       "      <td>0.921247</td>\n",
       "      <td>0.523138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.547475</td>\n",
       "      <td>0.921247</td>\n",
       "      <td>0.523138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorrBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at otmangi/MorrBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d822f616ee445e882d6e111638721a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "403781beac624109ad1ae309d1c42db1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1155' max='1155' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1155/1155 01:41, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.388400</td>\n",
       "      <td>0.274160</td>\n",
       "      <td>0.912223</td>\n",
       "      <td>0.319811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.229500</td>\n",
       "      <td>0.261748</td>\n",
       "      <td>0.922067</td>\n",
       "      <td>0.389062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.187200</td>\n",
       "      <td>0.324861</td>\n",
       "      <td>0.914684</td>\n",
       "      <td>0.348795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.106600</td>\n",
       "      <td>0.304713</td>\n",
       "      <td>0.917966</td>\n",
       "      <td>0.577857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.086700</td>\n",
       "      <td>0.355132</td>\n",
       "      <td>0.904840</td>\n",
       "      <td>0.506596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.044300</td>\n",
       "      <td>0.462311</td>\n",
       "      <td>0.912223</td>\n",
       "      <td>0.398172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.022900</td>\n",
       "      <td>0.447051</td>\n",
       "      <td>0.917966</td>\n",
       "      <td>0.418683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.018300</td>\n",
       "      <td>0.390288</td>\n",
       "      <td>0.922067</td>\n",
       "      <td>0.517871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.441436</td>\n",
       "      <td>0.916325</td>\n",
       "      <td>0.522039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.474859</td>\n",
       "      <td>0.920427</td>\n",
       "      <td>0.530838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.513243</td>\n",
       "      <td>0.925349</td>\n",
       "      <td>0.527646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.511483</td>\n",
       "      <td>0.919606</td>\n",
       "      <td>0.521574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.517739</td>\n",
       "      <td>0.920427</td>\n",
       "      <td>0.526079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.521725</td>\n",
       "      <td>0.919606</td>\n",
       "      <td>0.522804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.529987</td>\n",
       "      <td>0.921247</td>\n",
       "      <td>0.523896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.535026</td>\n",
       "      <td>0.921247</td>\n",
       "      <td>0.523896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.536658</td>\n",
       "      <td>0.921247</td>\n",
       "      <td>0.525119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.540729</td>\n",
       "      <td>0.922067</td>\n",
       "      <td>0.523975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.542432</td>\n",
       "      <td>0.921247</td>\n",
       "      <td>0.525119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.543750</td>\n",
       "      <td>0.921247</td>\n",
       "      <td>0.525119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.545991</td>\n",
       "      <td>0.921247</td>\n",
       "      <td>0.523138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.547034</td>\n",
       "      <td>0.921247</td>\n",
       "      <td>0.523138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.547475</td>\n",
       "      <td>0.921247</td>\n",
       "      <td>0.523138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorrBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at otmangi/MorrBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24af9ccf258b40cbb7604f8ad9c75be6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cda4f77706dd4b218497d3f8c3a63c77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1155' max='1155' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1155/1155 01:41, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.388400</td>\n",
       "      <td>0.274160</td>\n",
       "      <td>0.912223</td>\n",
       "      <td>0.319811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.229500</td>\n",
       "      <td>0.261748</td>\n",
       "      <td>0.922067</td>\n",
       "      <td>0.389062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.187200</td>\n",
       "      <td>0.324861</td>\n",
       "      <td>0.914684</td>\n",
       "      <td>0.348795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.106600</td>\n",
       "      <td>0.304713</td>\n",
       "      <td>0.917966</td>\n",
       "      <td>0.577857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.086700</td>\n",
       "      <td>0.355132</td>\n",
       "      <td>0.904840</td>\n",
       "      <td>0.506596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.044300</td>\n",
       "      <td>0.462311</td>\n",
       "      <td>0.912223</td>\n",
       "      <td>0.398172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.022900</td>\n",
       "      <td>0.447051</td>\n",
       "      <td>0.917966</td>\n",
       "      <td>0.418683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.018300</td>\n",
       "      <td>0.390288</td>\n",
       "      <td>0.922067</td>\n",
       "      <td>0.517871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.441436</td>\n",
       "      <td>0.916325</td>\n",
       "      <td>0.522039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.474859</td>\n",
       "      <td>0.920427</td>\n",
       "      <td>0.530838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.513243</td>\n",
       "      <td>0.925349</td>\n",
       "      <td>0.527646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.511483</td>\n",
       "      <td>0.919606</td>\n",
       "      <td>0.521574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.517739</td>\n",
       "      <td>0.920427</td>\n",
       "      <td>0.526079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.521725</td>\n",
       "      <td>0.919606</td>\n",
       "      <td>0.522804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.529987</td>\n",
       "      <td>0.921247</td>\n",
       "      <td>0.523896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.535026</td>\n",
       "      <td>0.921247</td>\n",
       "      <td>0.523896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.536658</td>\n",
       "      <td>0.921247</td>\n",
       "      <td>0.525119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.540729</td>\n",
       "      <td>0.922067</td>\n",
       "      <td>0.523975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.542432</td>\n",
       "      <td>0.921247</td>\n",
       "      <td>0.525119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.543750</td>\n",
       "      <td>0.921247</td>\n",
       "      <td>0.525119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.545991</td>\n",
       "      <td>0.921247</td>\n",
       "      <td>0.523138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.547034</td>\n",
       "      <td>0.921247</td>\n",
       "      <td>0.523138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.547475</td>\n",
       "      <td>0.921247</td>\n",
       "      <td>0.523138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorrBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at otmangi/MorrBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "074139d1ae1948e58e46cfa2a6ffd636",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29836c2d0a8c4cf2be91a790cd3d392f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1155' max='1155' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1155/1155 01:41, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.370600</td>\n",
       "      <td>0.308925</td>\n",
       "      <td>0.903199</td>\n",
       "      <td>0.261940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.242100</td>\n",
       "      <td>0.329249</td>\n",
       "      <td>0.917966</td>\n",
       "      <td>0.347258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.201900</td>\n",
       "      <td>0.282367</td>\n",
       "      <td>0.917966</td>\n",
       "      <td>0.383871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.101700</td>\n",
       "      <td>0.342012</td>\n",
       "      <td>0.916325</td>\n",
       "      <td>0.388643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.085700</td>\n",
       "      <td>0.375341</td>\n",
       "      <td>0.916325</td>\n",
       "      <td>0.391318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.037000</td>\n",
       "      <td>0.414324</td>\n",
       "      <td>0.917145</td>\n",
       "      <td>0.501705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.012900</td>\n",
       "      <td>0.488669</td>\n",
       "      <td>0.904840</td>\n",
       "      <td>0.353331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.011100</td>\n",
       "      <td>0.469964</td>\n",
       "      <td>0.915505</td>\n",
       "      <td>0.406796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.008100</td>\n",
       "      <td>0.476869</td>\n",
       "      <td>0.922888</td>\n",
       "      <td>0.424318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>0.499405</td>\n",
       "      <td>0.922067</td>\n",
       "      <td>0.412261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.506840</td>\n",
       "      <td>0.921247</td>\n",
       "      <td>0.404587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>0.520138</td>\n",
       "      <td>0.918786</td>\n",
       "      <td>0.418659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.520089</td>\n",
       "      <td>0.919606</td>\n",
       "      <td>0.410788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.526138</td>\n",
       "      <td>0.922888</td>\n",
       "      <td>0.420408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.532535</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.423889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.535662</td>\n",
       "      <td>0.922888</td>\n",
       "      <td>0.417133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.540353</td>\n",
       "      <td>0.922888</td>\n",
       "      <td>0.419848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.543552</td>\n",
       "      <td>0.923708</td>\n",
       "      <td>0.422160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.546294</td>\n",
       "      <td>0.923708</td>\n",
       "      <td>0.422160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.548370</td>\n",
       "      <td>0.923708</td>\n",
       "      <td>0.422160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.549701</td>\n",
       "      <td>0.923708</td>\n",
       "      <td>0.422160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.550545</td>\n",
       "      <td>0.923708</td>\n",
       "      <td>0.422160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.550992</td>\n",
       "      <td>0.923708</td>\n",
       "      <td>0.422160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorrBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at otmangi/MorrBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad2f63618caa4f6b9c48d9f66641ea6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed4fe417871f456ebcc5ec13eaf0cadb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1155' max='1155' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1155/1155 01:42, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.370600</td>\n",
       "      <td>0.308925</td>\n",
       "      <td>0.903199</td>\n",
       "      <td>0.261940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.242100</td>\n",
       "      <td>0.329249</td>\n",
       "      <td>0.917966</td>\n",
       "      <td>0.347258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.201900</td>\n",
       "      <td>0.282367</td>\n",
       "      <td>0.917966</td>\n",
       "      <td>0.383871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.101700</td>\n",
       "      <td>0.342012</td>\n",
       "      <td>0.916325</td>\n",
       "      <td>0.388643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.085700</td>\n",
       "      <td>0.375341</td>\n",
       "      <td>0.916325</td>\n",
       "      <td>0.391318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.037000</td>\n",
       "      <td>0.414324</td>\n",
       "      <td>0.917145</td>\n",
       "      <td>0.501705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.012900</td>\n",
       "      <td>0.488669</td>\n",
       "      <td>0.904840</td>\n",
       "      <td>0.353331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.011100</td>\n",
       "      <td>0.469964</td>\n",
       "      <td>0.915505</td>\n",
       "      <td>0.406796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.008100</td>\n",
       "      <td>0.476869</td>\n",
       "      <td>0.922888</td>\n",
       "      <td>0.424318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>0.499405</td>\n",
       "      <td>0.922067</td>\n",
       "      <td>0.412261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.506840</td>\n",
       "      <td>0.921247</td>\n",
       "      <td>0.404587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>0.520138</td>\n",
       "      <td>0.918786</td>\n",
       "      <td>0.418659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.520089</td>\n",
       "      <td>0.919606</td>\n",
       "      <td>0.410788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.526138</td>\n",
       "      <td>0.922888</td>\n",
       "      <td>0.420408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.532535</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.423889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.535662</td>\n",
       "      <td>0.922888</td>\n",
       "      <td>0.417133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.540353</td>\n",
       "      <td>0.922888</td>\n",
       "      <td>0.419848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.543552</td>\n",
       "      <td>0.923708</td>\n",
       "      <td>0.422160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.546294</td>\n",
       "      <td>0.923708</td>\n",
       "      <td>0.422160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.548370</td>\n",
       "      <td>0.923708</td>\n",
       "      <td>0.422160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.549701</td>\n",
       "      <td>0.923708</td>\n",
       "      <td>0.422160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.550545</td>\n",
       "      <td>0.923708</td>\n",
       "      <td>0.422160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.550992</td>\n",
       "      <td>0.923708</td>\n",
       "      <td>0.422160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorrBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at otmangi/MorrBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bee3318836ed4f628f9244d97acf478d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdaa0e03cdbe48dd8cd195c7b771c705",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1155' max='1155' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1155/1155 01:42, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.370600</td>\n",
       "      <td>0.308925</td>\n",
       "      <td>0.903199</td>\n",
       "      <td>0.261940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.242100</td>\n",
       "      <td>0.329249</td>\n",
       "      <td>0.917966</td>\n",
       "      <td>0.347258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.201900</td>\n",
       "      <td>0.282367</td>\n",
       "      <td>0.917966</td>\n",
       "      <td>0.383871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.101700</td>\n",
       "      <td>0.342012</td>\n",
       "      <td>0.916325</td>\n",
       "      <td>0.388643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.085700</td>\n",
       "      <td>0.375341</td>\n",
       "      <td>0.916325</td>\n",
       "      <td>0.391318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.037000</td>\n",
       "      <td>0.414324</td>\n",
       "      <td>0.917145</td>\n",
       "      <td>0.501705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.012900</td>\n",
       "      <td>0.488669</td>\n",
       "      <td>0.904840</td>\n",
       "      <td>0.353331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.011100</td>\n",
       "      <td>0.469964</td>\n",
       "      <td>0.915505</td>\n",
       "      <td>0.406796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.008100</td>\n",
       "      <td>0.476869</td>\n",
       "      <td>0.922888</td>\n",
       "      <td>0.424318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>0.499405</td>\n",
       "      <td>0.922067</td>\n",
       "      <td>0.412261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.506840</td>\n",
       "      <td>0.921247</td>\n",
       "      <td>0.404587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>0.520138</td>\n",
       "      <td>0.918786</td>\n",
       "      <td>0.418659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.520089</td>\n",
       "      <td>0.919606</td>\n",
       "      <td>0.410788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.526138</td>\n",
       "      <td>0.922888</td>\n",
       "      <td>0.420408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.532535</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.423889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.535662</td>\n",
       "      <td>0.922888</td>\n",
       "      <td>0.417133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.540353</td>\n",
       "      <td>0.922888</td>\n",
       "      <td>0.419848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.543552</td>\n",
       "      <td>0.923708</td>\n",
       "      <td>0.422160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.546294</td>\n",
       "      <td>0.923708</td>\n",
       "      <td>0.422160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.548370</td>\n",
       "      <td>0.923708</td>\n",
       "      <td>0.422160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.549701</td>\n",
       "      <td>0.923708</td>\n",
       "      <td>0.422160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.550545</td>\n",
       "      <td>0.923708</td>\n",
       "      <td>0.422160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.550992</td>\n",
       "      <td>0.923708</td>\n",
       "      <td>0.422160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SI2M-Lab/DarijaBERT</td>\n",
       "      <td>0.932732</td>\n",
       "      <td>0.489276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alger-ia/dziribert</td>\n",
       "      <td>0.928630</td>\n",
       "      <td>0.652564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>faisalq/EgyBERT</td>\n",
       "      <td>0.916325</td>\n",
       "      <td>0.424782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>faisalq/SaudiBERT</td>\n",
       "      <td>0.922888</td>\n",
       "      <td>0.573169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>otmangi/MorRoBERTa</td>\n",
       "      <td>0.917145</td>\n",
       "      <td>0.558960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>otmangi/MorrBERT</td>\n",
       "      <td>0.917966</td>\n",
       "      <td>0.577857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>tunis-ai/TunBERT</td>\n",
       "      <td>0.923708</td>\n",
       "      <td>0.403577</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model  Accuracy        F1\n",
       "0   SI2M-Lab/DarijaBERT  0.932732  0.489276\n",
       "3    alger-ia/dziribert  0.928630  0.652564\n",
       "6       faisalq/EgyBERT  0.916325  0.424782\n",
       "7     faisalq/SaudiBERT  0.922888  0.573169\n",
       "10   otmangi/MorRoBERTa  0.917145  0.558960\n",
       "13     otmangi/MorrBERT  0.917966  0.577857\n",
       "16     tunis-ai/TunBERT  0.923708  0.403577"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" \n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import pyarabic.araby as araby\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.initializers import TruncatedNormal\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from datasets import load_dataset, Dataset, concatenate_datasets\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', 1000)\n",
    "\n",
    "\n",
    "fname = 'OpenTC_2'\n",
    "log_file = fname + '.txt'\n",
    "\n",
    "with open(log_file, 'w') as f:\n",
    "    f.write('Model,Accuracy,F1\\n')\n",
    "\n",
    "\n",
    "df1 = pd.read_csv('datasets/OpenAccessArDialect/Topic.csv', encoding='utf-8', engine='python', sep='\\t') #, quotechar=\"'\"  , quoting=3\n",
    "df2 = pd.read_csv('datasets/OpenAccessArDialect/dialect.csv', encoding='utf-8', engine='python') #, quotechar=\"'\"  , quoting=3\n",
    "\n",
    "df2 = df2[df2['dialect'] == 'Morocco']\n",
    "      \n",
    "display(df1.columns)\n",
    "display(df1[:4])\n",
    "\n",
    "display(df2.columns)\n",
    "display(df2[:4])\n",
    "display(len(df2))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df = df1[df1['Text'].isin(df2['Twits'])]\n",
    "\n",
    "display(df[:5])\n",
    "display(len(df))\n",
    "\n",
    "c = df['Tag'].value_counts()\n",
    "display(c)\n",
    "\n",
    "classes = set(df['Tag'].values)\n",
    "display(classes)\n",
    "\n",
    "df['Tag'] = df['Tag'].astype('category')\n",
    "df['label'] = df['Tag'].cat.codes\n",
    "\n",
    "df = df[['Text', 'label']]\n",
    "classes_num = len(classes)\n",
    "display(classes_num)\n",
    "display(len(df))\n",
    "\n",
    "\n",
    "\n",
    "max_sequence_length = 128\n",
    "\n",
    "\n",
    "\n",
    "models = [ \n",
    "        'faisalq/EgyBERT',            \n",
    "    'faisalq/SaudiBERT',            \n",
    "    'tunis-ai/TunBERT',\n",
    "    'alger-ia/dziribert',\n",
    "    'SI2M-Lab/DarijaBERT',\n",
    "    'otmangi/MorRoBERTa',\n",
    "    'otmangi/MorrBERT'\n",
    "            \n",
    "]\n",
    "\n",
    "\n",
    "seeds = [0, 1, 42]\n",
    "\n",
    "for model_name in models:\n",
    "    for seed in seeds:\n",
    "        ds = Dataset.from_pandas(df)\n",
    "        ds = ds.train_test_split(test_size=0.2, seed = seed)\n",
    "        if seed==0:\n",
    "            display(ds)\n",
    "            \n",
    "        for i in range(3):\n",
    "            print(f'{model_name}, try:{i}')\n",
    "                  \n",
    "            tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "            model = AutoModelForSequenceClassification.from_pretrained(model_name,\n",
    "                                                                  num_labels=classes_num).to('cuda')                                                 \n",
    "            dataset_train = ds['train']\n",
    "            dataset_validation = ds['test']                                                    \n",
    "            \n",
    "          \n",
    "    \n",
    "            def preprocess_function(examples):\n",
    "                return tokenizer(examples['Text'], truncation=True, padding=\"max_length\",\n",
    "                                max_length=max_sequence_length)\n",
    "            \n",
    "            \n",
    "            dataset_train = dataset_train.map(preprocess_function, batched=True)\n",
    "            dataset_validation = dataset_validation.map(preprocess_function, batched=True)\n",
    "            \n",
    "           \n",
    "            \n",
    "            def compute_metrics(eval_pred):\n",
    "                logits, labels = eval_pred\n",
    "                predictions = np.argmax(logits, axis=-1)    \n",
    "                acc = accuracy_score(labels, predictions)        \n",
    "                f1 = f1_score(labels, predictions, average='macro')   \n",
    "                with open(log_file, 'a') as f:\n",
    "                    f.write(f'{model_name},{acc},{f1}\\n')\n",
    "                return {'accuracy': acc, 'f1_score': f1}\n",
    "    \n",
    "    \n",
    "            \n",
    "            \n",
    "            epochs = 15\n",
    "            save_steps = 10000 #save checkpoint every 10000 steps\n",
    "            batch_size = 64\n",
    "            \n",
    "            training_args = TrainingArguments(\n",
    "                output_dir = 'bert/',\n",
    "                overwrite_output_dir=True,\n",
    "                num_train_epochs = epochs,\n",
    "                per_device_train_batch_size = batch_size,\n",
    "                per_device_eval_batch_size = batch_size,\n",
    "                save_steps = save_steps,\n",
    "                save_total_limit = 1, #only save the last 5 checkpoints\n",
    "                fp16=True,\n",
    "                learning_rate = 5e-5,  # 5e-5 is the default\n",
    "                logging_steps = 50, #50_000\n",
    "                evaluation_strategy = 'steps',\n",
    "                # evaluate_during_training = True,\n",
    "                eval_steps = 50\n",
    "                \n",
    "            )\n",
    "            \n",
    "            trainer = Trainer(\n",
    "                model = model,\n",
    "                args = training_args,\n",
    "                # data_collator=data_collator,\n",
    "                train_dataset=dataset_train,\n",
    "                eval_dataset=dataset_validation,\n",
    "                compute_metrics = compute_metrics\n",
    "            )\n",
    "            \n",
    "            \n",
    "            trainer.train()\n",
    "\n",
    "\n",
    "results = pd.read_csv(log_file)\n",
    "\n",
    "best_results = results.groupby('Model', as_index=False)['F1'].max()\n",
    "\n",
    "best_results = pd.merge(best_results, results, on=['Model', 'F1'])\n",
    "best_results = best_results[['Model', 'Accuracy', 'F1']]\n",
    "best_results = best_results.drop_duplicates()\n",
    "best_results.to_csv(f'{fname}.csv')\n",
    "display(best_results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a213ac86-934f-4e82-a949-0bcdcae2188d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220784d6-b06d-4429-adb8-0026654f9d49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8647cf08-3aa6-44eb-846f-4bed97554042",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e203fa6b-c9d7-44a4-b501-a67bfd3e4ce4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8794b705-31a1-45d7-8e88-4017a9c282aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
