{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d804ae66-9435-44be-8aad-beacbdeec0f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-16 17:27:29.555766: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-16 17:27:29.579015: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-16 17:27:29.982299: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['text', 'label'], dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "20402"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eh mais enfaite ‘zebi’ ça veut dire bise’ en verlan nan</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>je vais me réveiller à 6h au lieu de 7h histoire de réviser un peu zebi oslm tu m’a plus jamais revu</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ma matrixe la video il est trop chou zebi</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mmh tu manquer l’odeur de ta culotte nahchtoulimek y’a zebi</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                   text   \n",
       "0                                               eh mais enfaite ‘zebi’ ça veut dire bise’ en verlan nan  \\\n",
       "1  je vais me réveiller à 6h au lieu de 7h histoire de réviser un peu zebi oslm tu m’a plus jamais revu   \n",
       "2                                                             ma matrixe la video il est trop chou zebi   \n",
       "3                                           mmh tu manquer l’odeur de ta culotte nahchtoulimek y’a zebi   \n",
       "\n",
       "   label  \n",
       "0      1  \n",
       "1      1  \n",
       "2      1  \n",
       "3      1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{0, 1}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    12685\n",
       "1     7717\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "20402"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 16321\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 4081\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 16321\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 4081\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/EgyBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/EgyBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16321 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4081 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3072' max='3072' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3072/3072 05:04, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.554400</td>\n",
       "      <td>0.459178</td>\n",
       "      <td>0.806420</td>\n",
       "      <td>0.767203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.398700</td>\n",
       "      <td>0.345347</td>\n",
       "      <td>0.849792</td>\n",
       "      <td>0.839143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.337800</td>\n",
       "      <td>0.315817</td>\n",
       "      <td>0.871845</td>\n",
       "      <td>0.859132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.281900</td>\n",
       "      <td>0.340039</td>\n",
       "      <td>0.870620</td>\n",
       "      <td>0.858794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.269700</td>\n",
       "      <td>0.297994</td>\n",
       "      <td>0.875521</td>\n",
       "      <td>0.867653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.213900</td>\n",
       "      <td>0.358614</td>\n",
       "      <td>0.873805</td>\n",
       "      <td>0.866183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.211200</td>\n",
       "      <td>0.328354</td>\n",
       "      <td>0.879196</td>\n",
       "      <td>0.868894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.185500</td>\n",
       "      <td>0.386616</td>\n",
       "      <td>0.881157</td>\n",
       "      <td>0.873694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.148600</td>\n",
       "      <td>0.362102</td>\n",
       "      <td>0.883607</td>\n",
       "      <td>0.876484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.159300</td>\n",
       "      <td>0.344611</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.879729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.133800</td>\n",
       "      <td>0.356856</td>\n",
       "      <td>0.887773</td>\n",
       "      <td>0.879735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.121900</td>\n",
       "      <td>0.360126</td>\n",
       "      <td>0.887773</td>\n",
       "      <td>0.880949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.123300</td>\n",
       "      <td>0.378062</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.879328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.095000</td>\n",
       "      <td>0.410440</td>\n",
       "      <td>0.890713</td>\n",
       "      <td>0.882791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.096200</td>\n",
       "      <td>0.371730</td>\n",
       "      <td>0.882872</td>\n",
       "      <td>0.876116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.083900</td>\n",
       "      <td>0.444296</td>\n",
       "      <td>0.886547</td>\n",
       "      <td>0.879514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.080500</td>\n",
       "      <td>0.465595</td>\n",
       "      <td>0.887528</td>\n",
       "      <td>0.880096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.082800</td>\n",
       "      <td>0.433864</td>\n",
       "      <td>0.889978</td>\n",
       "      <td>0.883274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.470258</td>\n",
       "      <td>0.884097</td>\n",
       "      <td>0.876850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.069100</td>\n",
       "      <td>0.487001</td>\n",
       "      <td>0.886547</td>\n",
       "      <td>0.879019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.528339</td>\n",
       "      <td>0.888998</td>\n",
       "      <td>0.882638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.066100</td>\n",
       "      <td>0.477043</td>\n",
       "      <td>0.890713</td>\n",
       "      <td>0.882597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.062200</td>\n",
       "      <td>0.468092</td>\n",
       "      <td>0.889488</td>\n",
       "      <td>0.881844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.047400</td>\n",
       "      <td>0.517186</td>\n",
       "      <td>0.892183</td>\n",
       "      <td>0.884304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.052200</td>\n",
       "      <td>0.532555</td>\n",
       "      <td>0.890468</td>\n",
       "      <td>0.881546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>0.565463</td>\n",
       "      <td>0.891693</td>\n",
       "      <td>0.883874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.044600</td>\n",
       "      <td>0.530890</td>\n",
       "      <td>0.891203</td>\n",
       "      <td>0.883878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.045000</td>\n",
       "      <td>0.530801</td>\n",
       "      <td>0.890958</td>\n",
       "      <td>0.883196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.038300</td>\n",
       "      <td>0.542915</td>\n",
       "      <td>0.889733</td>\n",
       "      <td>0.881900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.041800</td>\n",
       "      <td>0.542360</td>\n",
       "      <td>0.891203</td>\n",
       "      <td>0.884209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/EgyBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/EgyBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16321 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4081 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3072' max='3072' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3072/3072 05:04, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.543600</td>\n",
       "      <td>0.409549</td>\n",
       "      <td>0.825778</td>\n",
       "      <td>0.797802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.384700</td>\n",
       "      <td>0.332016</td>\n",
       "      <td>0.857388</td>\n",
       "      <td>0.845295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.312800</td>\n",
       "      <td>0.312811</td>\n",
       "      <td>0.874296</td>\n",
       "      <td>0.864601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.254700</td>\n",
       "      <td>0.342192</td>\n",
       "      <td>0.875766</td>\n",
       "      <td>0.862444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.249600</td>\n",
       "      <td>0.293227</td>\n",
       "      <td>0.878951</td>\n",
       "      <td>0.869262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.186400</td>\n",
       "      <td>0.340344</td>\n",
       "      <td>0.875766</td>\n",
       "      <td>0.866033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.178000</td>\n",
       "      <td>0.320200</td>\n",
       "      <td>0.887283</td>\n",
       "      <td>0.879405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.151800</td>\n",
       "      <td>0.367211</td>\n",
       "      <td>0.889243</td>\n",
       "      <td>0.881754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.126000</td>\n",
       "      <td>0.351527</td>\n",
       "      <td>0.885812</td>\n",
       "      <td>0.878900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.137200</td>\n",
       "      <td>0.345163</td>\n",
       "      <td>0.892918</td>\n",
       "      <td>0.885265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.106800</td>\n",
       "      <td>0.359782</td>\n",
       "      <td>0.889243</td>\n",
       "      <td>0.882712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.098900</td>\n",
       "      <td>0.375920</td>\n",
       "      <td>0.889978</td>\n",
       "      <td>0.882018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.102300</td>\n",
       "      <td>0.395095</td>\n",
       "      <td>0.889733</td>\n",
       "      <td>0.883373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.073600</td>\n",
       "      <td>0.417167</td>\n",
       "      <td>0.891938</td>\n",
       "      <td>0.884464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.085700</td>\n",
       "      <td>0.384182</td>\n",
       "      <td>0.888753</td>\n",
       "      <td>0.881871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.066600</td>\n",
       "      <td>0.474310</td>\n",
       "      <td>0.893899</td>\n",
       "      <td>0.886438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.067100</td>\n",
       "      <td>0.478909</td>\n",
       "      <td>0.891203</td>\n",
       "      <td>0.883380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.072600</td>\n",
       "      <td>0.475068</td>\n",
       "      <td>0.888753</td>\n",
       "      <td>0.880623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.055400</td>\n",
       "      <td>0.499079</td>\n",
       "      <td>0.888998</td>\n",
       "      <td>0.881755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.057200</td>\n",
       "      <td>0.491627</td>\n",
       "      <td>0.888508</td>\n",
       "      <td>0.880922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.048100</td>\n",
       "      <td>0.545312</td>\n",
       "      <td>0.888753</td>\n",
       "      <td>0.881930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.062000</td>\n",
       "      <td>0.527110</td>\n",
       "      <td>0.890958</td>\n",
       "      <td>0.882515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.051700</td>\n",
       "      <td>0.521177</td>\n",
       "      <td>0.887528</td>\n",
       "      <td>0.879225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.040400</td>\n",
       "      <td>0.538952</td>\n",
       "      <td>0.890468</td>\n",
       "      <td>0.882923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.047500</td>\n",
       "      <td>0.569317</td>\n",
       "      <td>0.889243</td>\n",
       "      <td>0.881785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.041000</td>\n",
       "      <td>0.567174</td>\n",
       "      <td>0.891938</td>\n",
       "      <td>0.884184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.042500</td>\n",
       "      <td>0.549860</td>\n",
       "      <td>0.893899</td>\n",
       "      <td>0.886710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.039900</td>\n",
       "      <td>0.552291</td>\n",
       "      <td>0.893899</td>\n",
       "      <td>0.886590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.036700</td>\n",
       "      <td>0.551670</td>\n",
       "      <td>0.891203</td>\n",
       "      <td>0.884238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.035300</td>\n",
       "      <td>0.565592</td>\n",
       "      <td>0.894144</td>\n",
       "      <td>0.887251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/EgyBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/EgyBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16321 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4081 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3072' max='3072' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3072/3072 05:02, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.543600</td>\n",
       "      <td>0.409549</td>\n",
       "      <td>0.825778</td>\n",
       "      <td>0.797802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.384700</td>\n",
       "      <td>0.332016</td>\n",
       "      <td>0.857388</td>\n",
       "      <td>0.845295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.312800</td>\n",
       "      <td>0.312811</td>\n",
       "      <td>0.874296</td>\n",
       "      <td>0.864601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.254700</td>\n",
       "      <td>0.342192</td>\n",
       "      <td>0.875766</td>\n",
       "      <td>0.862444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.249600</td>\n",
       "      <td>0.293227</td>\n",
       "      <td>0.878951</td>\n",
       "      <td>0.869262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.186400</td>\n",
       "      <td>0.340344</td>\n",
       "      <td>0.875766</td>\n",
       "      <td>0.866033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.178000</td>\n",
       "      <td>0.320200</td>\n",
       "      <td>0.887283</td>\n",
       "      <td>0.879405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.151800</td>\n",
       "      <td>0.367211</td>\n",
       "      <td>0.889243</td>\n",
       "      <td>0.881754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.126000</td>\n",
       "      <td>0.351527</td>\n",
       "      <td>0.885812</td>\n",
       "      <td>0.878900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.137200</td>\n",
       "      <td>0.345163</td>\n",
       "      <td>0.892918</td>\n",
       "      <td>0.885265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.106800</td>\n",
       "      <td>0.359782</td>\n",
       "      <td>0.889243</td>\n",
       "      <td>0.882712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.098900</td>\n",
       "      <td>0.375920</td>\n",
       "      <td>0.889978</td>\n",
       "      <td>0.882018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.102300</td>\n",
       "      <td>0.395095</td>\n",
       "      <td>0.889733</td>\n",
       "      <td>0.883373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.073600</td>\n",
       "      <td>0.417167</td>\n",
       "      <td>0.891938</td>\n",
       "      <td>0.884464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.085700</td>\n",
       "      <td>0.384182</td>\n",
       "      <td>0.888753</td>\n",
       "      <td>0.881871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.066600</td>\n",
       "      <td>0.474310</td>\n",
       "      <td>0.893899</td>\n",
       "      <td>0.886438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.067100</td>\n",
       "      <td>0.478909</td>\n",
       "      <td>0.891203</td>\n",
       "      <td>0.883380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.072600</td>\n",
       "      <td>0.475068</td>\n",
       "      <td>0.888753</td>\n",
       "      <td>0.880623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.055400</td>\n",
       "      <td>0.499079</td>\n",
       "      <td>0.888998</td>\n",
       "      <td>0.881755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.057200</td>\n",
       "      <td>0.491627</td>\n",
       "      <td>0.888508</td>\n",
       "      <td>0.880922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.048100</td>\n",
       "      <td>0.545312</td>\n",
       "      <td>0.888753</td>\n",
       "      <td>0.881930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.062000</td>\n",
       "      <td>0.527110</td>\n",
       "      <td>0.890958</td>\n",
       "      <td>0.882515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.051700</td>\n",
       "      <td>0.521177</td>\n",
       "      <td>0.887528</td>\n",
       "      <td>0.879225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.040400</td>\n",
       "      <td>0.538952</td>\n",
       "      <td>0.890468</td>\n",
       "      <td>0.882923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.047500</td>\n",
       "      <td>0.569317</td>\n",
       "      <td>0.889243</td>\n",
       "      <td>0.881785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.041000</td>\n",
       "      <td>0.567174</td>\n",
       "      <td>0.891938</td>\n",
       "      <td>0.884184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.042500</td>\n",
       "      <td>0.549860</td>\n",
       "      <td>0.893899</td>\n",
       "      <td>0.886710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.039900</td>\n",
       "      <td>0.552291</td>\n",
       "      <td>0.893899</td>\n",
       "      <td>0.886590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.036700</td>\n",
       "      <td>0.551670</td>\n",
       "      <td>0.891203</td>\n",
       "      <td>0.884238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.035300</td>\n",
       "      <td>0.565592</td>\n",
       "      <td>0.894144</td>\n",
       "      <td>0.887251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/EgyBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/EgyBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16321 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4081 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3072' max='3072' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3072/3072 05:03, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.551100</td>\n",
       "      <td>0.414939</td>\n",
       "      <td>0.775300</td>\n",
       "      <td>0.717968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.384600</td>\n",
       "      <td>0.353279</td>\n",
       "      <td>0.852487</td>\n",
       "      <td>0.838140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.351900</td>\n",
       "      <td>0.322297</td>\n",
       "      <td>0.862779</td>\n",
       "      <td>0.850050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.289500</td>\n",
       "      <td>0.301971</td>\n",
       "      <td>0.870130</td>\n",
       "      <td>0.858736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.271700</td>\n",
       "      <td>0.285631</td>\n",
       "      <td>0.883852</td>\n",
       "      <td>0.876385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.218100</td>\n",
       "      <td>0.335656</td>\n",
       "      <td>0.873805</td>\n",
       "      <td>0.860601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.215700</td>\n",
       "      <td>0.286475</td>\n",
       "      <td>0.879196</td>\n",
       "      <td>0.870978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.220800</td>\n",
       "      <td>0.319154</td>\n",
       "      <td>0.890468</td>\n",
       "      <td>0.882153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.166200</td>\n",
       "      <td>0.335870</td>\n",
       "      <td>0.883362</td>\n",
       "      <td>0.871645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.162200</td>\n",
       "      <td>0.333442</td>\n",
       "      <td>0.890223</td>\n",
       "      <td>0.881160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.118300</td>\n",
       "      <td>0.372625</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.887125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.118900</td>\n",
       "      <td>0.351769</td>\n",
       "      <td>0.893163</td>\n",
       "      <td>0.885543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.125900</td>\n",
       "      <td>0.403115</td>\n",
       "      <td>0.888018</td>\n",
       "      <td>0.877801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.091100</td>\n",
       "      <td>0.394850</td>\n",
       "      <td>0.888508</td>\n",
       "      <td>0.879943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.105800</td>\n",
       "      <td>0.348722</td>\n",
       "      <td>0.888753</td>\n",
       "      <td>0.881417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.093700</td>\n",
       "      <td>0.411297</td>\n",
       "      <td>0.892918</td>\n",
       "      <td>0.883506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.088000</td>\n",
       "      <td>0.388300</td>\n",
       "      <td>0.893408</td>\n",
       "      <td>0.884693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.075700</td>\n",
       "      <td>0.458068</td>\n",
       "      <td>0.891693</td>\n",
       "      <td>0.881794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.071600</td>\n",
       "      <td>0.415506</td>\n",
       "      <td>0.890958</td>\n",
       "      <td>0.882746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.074600</td>\n",
       "      <td>0.456647</td>\n",
       "      <td>0.890468</td>\n",
       "      <td>0.881649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.064800</td>\n",
       "      <td>0.463729</td>\n",
       "      <td>0.892183</td>\n",
       "      <td>0.883486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.059800</td>\n",
       "      <td>0.428671</td>\n",
       "      <td>0.894389</td>\n",
       "      <td>0.886435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.061800</td>\n",
       "      <td>0.416248</td>\n",
       "      <td>0.891938</td>\n",
       "      <td>0.883768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.055800</td>\n",
       "      <td>0.450353</td>\n",
       "      <td>0.893408</td>\n",
       "      <td>0.885477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.053500</td>\n",
       "      <td>0.486671</td>\n",
       "      <td>0.893899</td>\n",
       "      <td>0.885940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.050300</td>\n",
       "      <td>0.521755</td>\n",
       "      <td>0.889733</td>\n",
       "      <td>0.880240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.047900</td>\n",
       "      <td>0.483174</td>\n",
       "      <td>0.895369</td>\n",
       "      <td>0.887830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.049400</td>\n",
       "      <td>0.501209</td>\n",
       "      <td>0.889978</td>\n",
       "      <td>0.880701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.050700</td>\n",
       "      <td>0.500446</td>\n",
       "      <td>0.892183</td>\n",
       "      <td>0.883110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.044500</td>\n",
       "      <td>0.511926</td>\n",
       "      <td>0.891938</td>\n",
       "      <td>0.882792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/EgyBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/EgyBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16321 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4081 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3072' max='3072' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3072/3072 05:03, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.551100</td>\n",
       "      <td>0.414939</td>\n",
       "      <td>0.775300</td>\n",
       "      <td>0.717968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.384600</td>\n",
       "      <td>0.353279</td>\n",
       "      <td>0.852487</td>\n",
       "      <td>0.838140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.351900</td>\n",
       "      <td>0.322297</td>\n",
       "      <td>0.862779</td>\n",
       "      <td>0.850050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.289500</td>\n",
       "      <td>0.301971</td>\n",
       "      <td>0.870130</td>\n",
       "      <td>0.858736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.271700</td>\n",
       "      <td>0.285631</td>\n",
       "      <td>0.883852</td>\n",
       "      <td>0.876385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.218100</td>\n",
       "      <td>0.335656</td>\n",
       "      <td>0.873805</td>\n",
       "      <td>0.860601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.215700</td>\n",
       "      <td>0.286475</td>\n",
       "      <td>0.879196</td>\n",
       "      <td>0.870978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.220800</td>\n",
       "      <td>0.319154</td>\n",
       "      <td>0.890468</td>\n",
       "      <td>0.882153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.166200</td>\n",
       "      <td>0.335870</td>\n",
       "      <td>0.883362</td>\n",
       "      <td>0.871645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.162200</td>\n",
       "      <td>0.333442</td>\n",
       "      <td>0.890223</td>\n",
       "      <td>0.881160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.118300</td>\n",
       "      <td>0.372625</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.887125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.118900</td>\n",
       "      <td>0.351769</td>\n",
       "      <td>0.893163</td>\n",
       "      <td>0.885543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.125900</td>\n",
       "      <td>0.403115</td>\n",
       "      <td>0.888018</td>\n",
       "      <td>0.877801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.091100</td>\n",
       "      <td>0.394850</td>\n",
       "      <td>0.888508</td>\n",
       "      <td>0.879943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.105800</td>\n",
       "      <td>0.348722</td>\n",
       "      <td>0.888753</td>\n",
       "      <td>0.881417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.093700</td>\n",
       "      <td>0.411297</td>\n",
       "      <td>0.892918</td>\n",
       "      <td>0.883506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.088000</td>\n",
       "      <td>0.388300</td>\n",
       "      <td>0.893408</td>\n",
       "      <td>0.884693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.075700</td>\n",
       "      <td>0.458068</td>\n",
       "      <td>0.891693</td>\n",
       "      <td>0.881794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.071600</td>\n",
       "      <td>0.415506</td>\n",
       "      <td>0.890958</td>\n",
       "      <td>0.882746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.074600</td>\n",
       "      <td>0.456647</td>\n",
       "      <td>0.890468</td>\n",
       "      <td>0.881649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.064800</td>\n",
       "      <td>0.463729</td>\n",
       "      <td>0.892183</td>\n",
       "      <td>0.883486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.059800</td>\n",
       "      <td>0.428671</td>\n",
       "      <td>0.894389</td>\n",
       "      <td>0.886435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.061800</td>\n",
       "      <td>0.416248</td>\n",
       "      <td>0.891938</td>\n",
       "      <td>0.883768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.055800</td>\n",
       "      <td>0.450353</td>\n",
       "      <td>0.893408</td>\n",
       "      <td>0.885477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.053500</td>\n",
       "      <td>0.486671</td>\n",
       "      <td>0.893899</td>\n",
       "      <td>0.885940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.050300</td>\n",
       "      <td>0.521755</td>\n",
       "      <td>0.889733</td>\n",
       "      <td>0.880240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.047900</td>\n",
       "      <td>0.483174</td>\n",
       "      <td>0.895369</td>\n",
       "      <td>0.887830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.049400</td>\n",
       "      <td>0.501209</td>\n",
       "      <td>0.889978</td>\n",
       "      <td>0.880701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.050700</td>\n",
       "      <td>0.500446</td>\n",
       "      <td>0.892183</td>\n",
       "      <td>0.883110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.044500</td>\n",
       "      <td>0.511926</td>\n",
       "      <td>0.891938</td>\n",
       "      <td>0.882792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/EgyBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/EgyBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16321 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4081 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3072' max='3072' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3072/3072 05:03, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.551100</td>\n",
       "      <td>0.414939</td>\n",
       "      <td>0.775300</td>\n",
       "      <td>0.717968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.384600</td>\n",
       "      <td>0.353279</td>\n",
       "      <td>0.852487</td>\n",
       "      <td>0.838140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.351900</td>\n",
       "      <td>0.322297</td>\n",
       "      <td>0.862779</td>\n",
       "      <td>0.850050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.289500</td>\n",
       "      <td>0.301971</td>\n",
       "      <td>0.870130</td>\n",
       "      <td>0.858736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.271700</td>\n",
       "      <td>0.285631</td>\n",
       "      <td>0.883852</td>\n",
       "      <td>0.876385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.218100</td>\n",
       "      <td>0.335656</td>\n",
       "      <td>0.873805</td>\n",
       "      <td>0.860601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.215700</td>\n",
       "      <td>0.286475</td>\n",
       "      <td>0.879196</td>\n",
       "      <td>0.870978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.220800</td>\n",
       "      <td>0.319154</td>\n",
       "      <td>0.890468</td>\n",
       "      <td>0.882153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.166200</td>\n",
       "      <td>0.335870</td>\n",
       "      <td>0.883362</td>\n",
       "      <td>0.871645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.162200</td>\n",
       "      <td>0.333442</td>\n",
       "      <td>0.890223</td>\n",
       "      <td>0.881160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.118300</td>\n",
       "      <td>0.372625</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.887125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.118900</td>\n",
       "      <td>0.351769</td>\n",
       "      <td>0.893163</td>\n",
       "      <td>0.885543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.125900</td>\n",
       "      <td>0.403115</td>\n",
       "      <td>0.888018</td>\n",
       "      <td>0.877801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.091100</td>\n",
       "      <td>0.394850</td>\n",
       "      <td>0.888508</td>\n",
       "      <td>0.879943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.105800</td>\n",
       "      <td>0.348722</td>\n",
       "      <td>0.888753</td>\n",
       "      <td>0.881417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.093700</td>\n",
       "      <td>0.411297</td>\n",
       "      <td>0.892918</td>\n",
       "      <td>0.883506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.088000</td>\n",
       "      <td>0.388300</td>\n",
       "      <td>0.893408</td>\n",
       "      <td>0.884693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.075700</td>\n",
       "      <td>0.458068</td>\n",
       "      <td>0.891693</td>\n",
       "      <td>0.881794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.071600</td>\n",
       "      <td>0.415506</td>\n",
       "      <td>0.890958</td>\n",
       "      <td>0.882746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.074600</td>\n",
       "      <td>0.456647</td>\n",
       "      <td>0.890468</td>\n",
       "      <td>0.881649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.064800</td>\n",
       "      <td>0.463729</td>\n",
       "      <td>0.892183</td>\n",
       "      <td>0.883486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.059800</td>\n",
       "      <td>0.428671</td>\n",
       "      <td>0.894389</td>\n",
       "      <td>0.886435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.061800</td>\n",
       "      <td>0.416248</td>\n",
       "      <td>0.891938</td>\n",
       "      <td>0.883768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.055800</td>\n",
       "      <td>0.450353</td>\n",
       "      <td>0.893408</td>\n",
       "      <td>0.885477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.053500</td>\n",
       "      <td>0.486671</td>\n",
       "      <td>0.893899</td>\n",
       "      <td>0.885940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.050300</td>\n",
       "      <td>0.521755</td>\n",
       "      <td>0.889733</td>\n",
       "      <td>0.880240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.047900</td>\n",
       "      <td>0.483174</td>\n",
       "      <td>0.895369</td>\n",
       "      <td>0.887830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.049400</td>\n",
       "      <td>0.501209</td>\n",
       "      <td>0.889978</td>\n",
       "      <td>0.880701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.050700</td>\n",
       "      <td>0.500446</td>\n",
       "      <td>0.892183</td>\n",
       "      <td>0.883110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.044500</td>\n",
       "      <td>0.511926</td>\n",
       "      <td>0.891938</td>\n",
       "      <td>0.882792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/EgyBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/EgyBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16321 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4081 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3072' max='3072' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3072/3072 05:03, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.558800</td>\n",
       "      <td>0.411026</td>\n",
       "      <td>0.829699</td>\n",
       "      <td>0.810858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.378400</td>\n",
       "      <td>0.344967</td>\n",
       "      <td>0.854447</td>\n",
       "      <td>0.841045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.300700</td>\n",
       "      <td>0.349942</td>\n",
       "      <td>0.863514</td>\n",
       "      <td>0.849483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.259100</td>\n",
       "      <td>0.301726</td>\n",
       "      <td>0.870865</td>\n",
       "      <td>0.861710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.261900</td>\n",
       "      <td>0.310194</td>\n",
       "      <td>0.876746</td>\n",
       "      <td>0.866668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.178900</td>\n",
       "      <td>0.339545</td>\n",
       "      <td>0.882872</td>\n",
       "      <td>0.873052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.168300</td>\n",
       "      <td>0.380990</td>\n",
       "      <td>0.880421</td>\n",
       "      <td>0.870998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.171000</td>\n",
       "      <td>0.418336</td>\n",
       "      <td>0.881892</td>\n",
       "      <td>0.871491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.124700</td>\n",
       "      <td>0.384654</td>\n",
       "      <td>0.878461</td>\n",
       "      <td>0.871168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.129900</td>\n",
       "      <td>0.371545</td>\n",
       "      <td>0.880912</td>\n",
       "      <td>0.873858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.104400</td>\n",
       "      <td>0.453397</td>\n",
       "      <td>0.880667</td>\n",
       "      <td>0.870946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.086200</td>\n",
       "      <td>0.436087</td>\n",
       "      <td>0.885812</td>\n",
       "      <td>0.878060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.105400</td>\n",
       "      <td>0.439481</td>\n",
       "      <td>0.883607</td>\n",
       "      <td>0.875456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.075400</td>\n",
       "      <td>0.463866</td>\n",
       "      <td>0.881647</td>\n",
       "      <td>0.871244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.084900</td>\n",
       "      <td>0.446612</td>\n",
       "      <td>0.887037</td>\n",
       "      <td>0.878291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.066700</td>\n",
       "      <td>0.487682</td>\n",
       "      <td>0.884097</td>\n",
       "      <td>0.877545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.062400</td>\n",
       "      <td>0.482681</td>\n",
       "      <td>0.888508</td>\n",
       "      <td>0.880343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.489592</td>\n",
       "      <td>0.887283</td>\n",
       "      <td>0.879177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.057200</td>\n",
       "      <td>0.582143</td>\n",
       "      <td>0.881402</td>\n",
       "      <td>0.871383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.057800</td>\n",
       "      <td>0.524891</td>\n",
       "      <td>0.888998</td>\n",
       "      <td>0.880267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.047300</td>\n",
       "      <td>0.565634</td>\n",
       "      <td>0.886057</td>\n",
       "      <td>0.877781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.053100</td>\n",
       "      <td>0.552933</td>\n",
       "      <td>0.887283</td>\n",
       "      <td>0.878084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.050200</td>\n",
       "      <td>0.490321</td>\n",
       "      <td>0.887773</td>\n",
       "      <td>0.879735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.034200</td>\n",
       "      <td>0.600959</td>\n",
       "      <td>0.885322</td>\n",
       "      <td>0.875745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.046000</td>\n",
       "      <td>0.580444</td>\n",
       "      <td>0.887773</td>\n",
       "      <td>0.878997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.045700</td>\n",
       "      <td>0.590327</td>\n",
       "      <td>0.887528</td>\n",
       "      <td>0.878681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.034500</td>\n",
       "      <td>0.605045</td>\n",
       "      <td>0.888753</td>\n",
       "      <td>0.880088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.037600</td>\n",
       "      <td>0.587752</td>\n",
       "      <td>0.889733</td>\n",
       "      <td>0.882059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.033200</td>\n",
       "      <td>0.608851</td>\n",
       "      <td>0.888263</td>\n",
       "      <td>0.879491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.031700</td>\n",
       "      <td>0.624436</td>\n",
       "      <td>0.887773</td>\n",
       "      <td>0.878928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/EgyBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/EgyBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16321 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4081 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3072' max='3072' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3072/3072 05:03, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.558800</td>\n",
       "      <td>0.411026</td>\n",
       "      <td>0.829699</td>\n",
       "      <td>0.810858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.378400</td>\n",
       "      <td>0.344967</td>\n",
       "      <td>0.854447</td>\n",
       "      <td>0.841045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.300700</td>\n",
       "      <td>0.349942</td>\n",
       "      <td>0.863514</td>\n",
       "      <td>0.849483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.259100</td>\n",
       "      <td>0.301726</td>\n",
       "      <td>0.870865</td>\n",
       "      <td>0.861710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.261900</td>\n",
       "      <td>0.310194</td>\n",
       "      <td>0.876746</td>\n",
       "      <td>0.866668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.178900</td>\n",
       "      <td>0.339545</td>\n",
       "      <td>0.882872</td>\n",
       "      <td>0.873052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.168300</td>\n",
       "      <td>0.380990</td>\n",
       "      <td>0.880421</td>\n",
       "      <td>0.870998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.171000</td>\n",
       "      <td>0.418336</td>\n",
       "      <td>0.881892</td>\n",
       "      <td>0.871491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.124700</td>\n",
       "      <td>0.384654</td>\n",
       "      <td>0.878461</td>\n",
       "      <td>0.871168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.129900</td>\n",
       "      <td>0.371545</td>\n",
       "      <td>0.880912</td>\n",
       "      <td>0.873858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.104400</td>\n",
       "      <td>0.453397</td>\n",
       "      <td>0.880667</td>\n",
       "      <td>0.870946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.086200</td>\n",
       "      <td>0.436087</td>\n",
       "      <td>0.885812</td>\n",
       "      <td>0.878060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.105400</td>\n",
       "      <td>0.439481</td>\n",
       "      <td>0.883607</td>\n",
       "      <td>0.875456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.075400</td>\n",
       "      <td>0.463866</td>\n",
       "      <td>0.881647</td>\n",
       "      <td>0.871244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.084900</td>\n",
       "      <td>0.446612</td>\n",
       "      <td>0.887037</td>\n",
       "      <td>0.878291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.066700</td>\n",
       "      <td>0.487682</td>\n",
       "      <td>0.884097</td>\n",
       "      <td>0.877545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.062400</td>\n",
       "      <td>0.482681</td>\n",
       "      <td>0.888508</td>\n",
       "      <td>0.880343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.489592</td>\n",
       "      <td>0.887283</td>\n",
       "      <td>0.879177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.057200</td>\n",
       "      <td>0.582143</td>\n",
       "      <td>0.881402</td>\n",
       "      <td>0.871383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.057800</td>\n",
       "      <td>0.524891</td>\n",
       "      <td>0.888998</td>\n",
       "      <td>0.880267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.047300</td>\n",
       "      <td>0.565634</td>\n",
       "      <td>0.886057</td>\n",
       "      <td>0.877781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.053100</td>\n",
       "      <td>0.552933</td>\n",
       "      <td>0.887283</td>\n",
       "      <td>0.878084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.050200</td>\n",
       "      <td>0.490321</td>\n",
       "      <td>0.887773</td>\n",
       "      <td>0.879735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.034200</td>\n",
       "      <td>0.600959</td>\n",
       "      <td>0.885322</td>\n",
       "      <td>0.875745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.046000</td>\n",
       "      <td>0.580444</td>\n",
       "      <td>0.887773</td>\n",
       "      <td>0.878997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.045700</td>\n",
       "      <td>0.590327</td>\n",
       "      <td>0.887528</td>\n",
       "      <td>0.878681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.034500</td>\n",
       "      <td>0.605045</td>\n",
       "      <td>0.888753</td>\n",
       "      <td>0.880088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.037600</td>\n",
       "      <td>0.587752</td>\n",
       "      <td>0.889733</td>\n",
       "      <td>0.882059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.033200</td>\n",
       "      <td>0.608851</td>\n",
       "      <td>0.888263</td>\n",
       "      <td>0.879491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.031700</td>\n",
       "      <td>0.624436</td>\n",
       "      <td>0.887773</td>\n",
       "      <td>0.878928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/EgyBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/EgyBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3be575268e524d8ea540feb98a4b1552",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16321 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e48e2eade92f4d17ac5f68426212ec79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4081 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3072' max='3072' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3072/3072 04:59, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.558800</td>\n",
       "      <td>0.411026</td>\n",
       "      <td>0.829699</td>\n",
       "      <td>0.810858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.378400</td>\n",
       "      <td>0.344967</td>\n",
       "      <td>0.854447</td>\n",
       "      <td>0.841045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.300700</td>\n",
       "      <td>0.349942</td>\n",
       "      <td>0.863514</td>\n",
       "      <td>0.849483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.259100</td>\n",
       "      <td>0.301726</td>\n",
       "      <td>0.870865</td>\n",
       "      <td>0.861710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.261900</td>\n",
       "      <td>0.310194</td>\n",
       "      <td>0.876746</td>\n",
       "      <td>0.866668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.178900</td>\n",
       "      <td>0.339545</td>\n",
       "      <td>0.882872</td>\n",
       "      <td>0.873052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.168300</td>\n",
       "      <td>0.380990</td>\n",
       "      <td>0.880421</td>\n",
       "      <td>0.870998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.171000</td>\n",
       "      <td>0.418336</td>\n",
       "      <td>0.881892</td>\n",
       "      <td>0.871491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.124700</td>\n",
       "      <td>0.384654</td>\n",
       "      <td>0.878461</td>\n",
       "      <td>0.871168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.129900</td>\n",
       "      <td>0.371545</td>\n",
       "      <td>0.880912</td>\n",
       "      <td>0.873858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.104400</td>\n",
       "      <td>0.453397</td>\n",
       "      <td>0.880667</td>\n",
       "      <td>0.870946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.086200</td>\n",
       "      <td>0.436087</td>\n",
       "      <td>0.885812</td>\n",
       "      <td>0.878060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.105400</td>\n",
       "      <td>0.439481</td>\n",
       "      <td>0.883607</td>\n",
       "      <td>0.875456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.075400</td>\n",
       "      <td>0.463866</td>\n",
       "      <td>0.881647</td>\n",
       "      <td>0.871244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.084900</td>\n",
       "      <td>0.446612</td>\n",
       "      <td>0.887037</td>\n",
       "      <td>0.878291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.066700</td>\n",
       "      <td>0.487682</td>\n",
       "      <td>0.884097</td>\n",
       "      <td>0.877545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.062400</td>\n",
       "      <td>0.482681</td>\n",
       "      <td>0.888508</td>\n",
       "      <td>0.880343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.489592</td>\n",
       "      <td>0.887283</td>\n",
       "      <td>0.879177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.057200</td>\n",
       "      <td>0.582143</td>\n",
       "      <td>0.881402</td>\n",
       "      <td>0.871383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.057800</td>\n",
       "      <td>0.524891</td>\n",
       "      <td>0.888998</td>\n",
       "      <td>0.880267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.047300</td>\n",
       "      <td>0.565634</td>\n",
       "      <td>0.886057</td>\n",
       "      <td>0.877781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.053100</td>\n",
       "      <td>0.552933</td>\n",
       "      <td>0.887283</td>\n",
       "      <td>0.878084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.050200</td>\n",
       "      <td>0.490321</td>\n",
       "      <td>0.887773</td>\n",
       "      <td>0.879735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.034200</td>\n",
       "      <td>0.600959</td>\n",
       "      <td>0.885322</td>\n",
       "      <td>0.875745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.046000</td>\n",
       "      <td>0.580444</td>\n",
       "      <td>0.887773</td>\n",
       "      <td>0.878997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.045700</td>\n",
       "      <td>0.590327</td>\n",
       "      <td>0.887528</td>\n",
       "      <td>0.878681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.034500</td>\n",
       "      <td>0.605045</td>\n",
       "      <td>0.888753</td>\n",
       "      <td>0.880088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.037600</td>\n",
       "      <td>0.587752</td>\n",
       "      <td>0.889733</td>\n",
       "      <td>0.882059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.033200</td>\n",
       "      <td>0.608851</td>\n",
       "      <td>0.888263</td>\n",
       "      <td>0.879491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.031700</td>\n",
       "      <td>0.624436</td>\n",
       "      <td>0.887773</td>\n",
       "      <td>0.878928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 16321\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 4081\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06b05e859679452dab03e3f6f8c38576",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16321 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d2abc9474ef460889a03e953f546834",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4081 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3072' max='3072' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3072/3072 04:58, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.396500</td>\n",
       "      <td>0.311262</td>\n",
       "      <td>0.858858</td>\n",
       "      <td>0.847026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.327700</td>\n",
       "      <td>0.292305</td>\n",
       "      <td>0.881647</td>\n",
       "      <td>0.872980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.248900</td>\n",
       "      <td>0.336736</td>\n",
       "      <td>0.875031</td>\n",
       "      <td>0.869095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.179700</td>\n",
       "      <td>0.298168</td>\n",
       "      <td>0.889488</td>\n",
       "      <td>0.882308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.185600</td>\n",
       "      <td>0.301157</td>\n",
       "      <td>0.881157</td>\n",
       "      <td>0.875977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.106400</td>\n",
       "      <td>0.373354</td>\n",
       "      <td>0.884832</td>\n",
       "      <td>0.879013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.108600</td>\n",
       "      <td>0.324828</td>\n",
       "      <td>0.889488</td>\n",
       "      <td>0.883652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.094700</td>\n",
       "      <td>0.489099</td>\n",
       "      <td>0.882382</td>\n",
       "      <td>0.877294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.070700</td>\n",
       "      <td>0.478762</td>\n",
       "      <td>0.890223</td>\n",
       "      <td>0.883374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.093200</td>\n",
       "      <td>0.461746</td>\n",
       "      <td>0.892673</td>\n",
       "      <td>0.884767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.062900</td>\n",
       "      <td>0.551272</td>\n",
       "      <td>0.879196</td>\n",
       "      <td>0.873610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.065100</td>\n",
       "      <td>0.442640</td>\n",
       "      <td>0.884832</td>\n",
       "      <td>0.879415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.071500</td>\n",
       "      <td>0.507765</td>\n",
       "      <td>0.892183</td>\n",
       "      <td>0.885104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.042100</td>\n",
       "      <td>0.577885</td>\n",
       "      <td>0.894634</td>\n",
       "      <td>0.888583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.057200</td>\n",
       "      <td>0.481105</td>\n",
       "      <td>0.890713</td>\n",
       "      <td>0.885243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.039900</td>\n",
       "      <td>0.630378</td>\n",
       "      <td>0.893899</td>\n",
       "      <td>0.887293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.041100</td>\n",
       "      <td>0.619795</td>\n",
       "      <td>0.889733</td>\n",
       "      <td>0.882823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.039400</td>\n",
       "      <td>0.612616</td>\n",
       "      <td>0.893163</td>\n",
       "      <td>0.887056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.027600</td>\n",
       "      <td>0.687614</td>\n",
       "      <td>0.891203</td>\n",
       "      <td>0.883939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.037300</td>\n",
       "      <td>0.646821</td>\n",
       "      <td>0.889488</td>\n",
       "      <td>0.882578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.026400</td>\n",
       "      <td>0.691008</td>\n",
       "      <td>0.890223</td>\n",
       "      <td>0.883549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.033200</td>\n",
       "      <td>0.706981</td>\n",
       "      <td>0.892183</td>\n",
       "      <td>0.885514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.031200</td>\n",
       "      <td>0.671458</td>\n",
       "      <td>0.893163</td>\n",
       "      <td>0.886030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.020500</td>\n",
       "      <td>0.734267</td>\n",
       "      <td>0.892918</td>\n",
       "      <td>0.885843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.028100</td>\n",
       "      <td>0.735026</td>\n",
       "      <td>0.891203</td>\n",
       "      <td>0.884531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.019400</td>\n",
       "      <td>0.788506</td>\n",
       "      <td>0.891448</td>\n",
       "      <td>0.883595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.022400</td>\n",
       "      <td>0.783860</td>\n",
       "      <td>0.893163</td>\n",
       "      <td>0.885324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.021800</td>\n",
       "      <td>0.793593</td>\n",
       "      <td>0.892428</td>\n",
       "      <td>0.884834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.023100</td>\n",
       "      <td>0.794520</td>\n",
       "      <td>0.891938</td>\n",
       "      <td>0.884586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.020100</td>\n",
       "      <td>0.793297</td>\n",
       "      <td>0.892183</td>\n",
       "      <td>0.885074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34d22b5c1cec4966bd4651cf9cca59c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16321 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cd8d91925564c0c8d2346566c779987",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4081 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3072' max='3072' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3072/3072 04:57, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.396500</td>\n",
       "      <td>0.311262</td>\n",
       "      <td>0.858858</td>\n",
       "      <td>0.847026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.327700</td>\n",
       "      <td>0.292305</td>\n",
       "      <td>0.881647</td>\n",
       "      <td>0.872980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.248900</td>\n",
       "      <td>0.336736</td>\n",
       "      <td>0.875031</td>\n",
       "      <td>0.869095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.179700</td>\n",
       "      <td>0.298168</td>\n",
       "      <td>0.889488</td>\n",
       "      <td>0.882308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.185600</td>\n",
       "      <td>0.301157</td>\n",
       "      <td>0.881157</td>\n",
       "      <td>0.875977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.106400</td>\n",
       "      <td>0.373354</td>\n",
       "      <td>0.884832</td>\n",
       "      <td>0.879013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.108600</td>\n",
       "      <td>0.324828</td>\n",
       "      <td>0.889488</td>\n",
       "      <td>0.883652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.094700</td>\n",
       "      <td>0.489099</td>\n",
       "      <td>0.882382</td>\n",
       "      <td>0.877294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.070700</td>\n",
       "      <td>0.478762</td>\n",
       "      <td>0.890223</td>\n",
       "      <td>0.883374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.093200</td>\n",
       "      <td>0.461746</td>\n",
       "      <td>0.892673</td>\n",
       "      <td>0.884767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.062900</td>\n",
       "      <td>0.551272</td>\n",
       "      <td>0.879196</td>\n",
       "      <td>0.873610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.065100</td>\n",
       "      <td>0.442640</td>\n",
       "      <td>0.884832</td>\n",
       "      <td>0.879415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.071500</td>\n",
       "      <td>0.507765</td>\n",
       "      <td>0.892183</td>\n",
       "      <td>0.885104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.042100</td>\n",
       "      <td>0.577885</td>\n",
       "      <td>0.894634</td>\n",
       "      <td>0.888583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.057200</td>\n",
       "      <td>0.481105</td>\n",
       "      <td>0.890713</td>\n",
       "      <td>0.885243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.039900</td>\n",
       "      <td>0.630378</td>\n",
       "      <td>0.893899</td>\n",
       "      <td>0.887293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.041100</td>\n",
       "      <td>0.619795</td>\n",
       "      <td>0.889733</td>\n",
       "      <td>0.882823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.039400</td>\n",
       "      <td>0.612616</td>\n",
       "      <td>0.893163</td>\n",
       "      <td>0.887056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.027600</td>\n",
       "      <td>0.687614</td>\n",
       "      <td>0.891203</td>\n",
       "      <td>0.883939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.037300</td>\n",
       "      <td>0.646821</td>\n",
       "      <td>0.889488</td>\n",
       "      <td>0.882578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.026400</td>\n",
       "      <td>0.691008</td>\n",
       "      <td>0.890223</td>\n",
       "      <td>0.883549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.033200</td>\n",
       "      <td>0.706981</td>\n",
       "      <td>0.892183</td>\n",
       "      <td>0.885514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.031200</td>\n",
       "      <td>0.671458</td>\n",
       "      <td>0.893163</td>\n",
       "      <td>0.886030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.020500</td>\n",
       "      <td>0.734267</td>\n",
       "      <td>0.892918</td>\n",
       "      <td>0.885843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.028100</td>\n",
       "      <td>0.735026</td>\n",
       "      <td>0.891203</td>\n",
       "      <td>0.884531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.019400</td>\n",
       "      <td>0.788506</td>\n",
       "      <td>0.891448</td>\n",
       "      <td>0.883595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.022400</td>\n",
       "      <td>0.783860</td>\n",
       "      <td>0.893163</td>\n",
       "      <td>0.885324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.021800</td>\n",
       "      <td>0.793593</td>\n",
       "      <td>0.892428</td>\n",
       "      <td>0.884834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.023100</td>\n",
       "      <td>0.794520</td>\n",
       "      <td>0.891938</td>\n",
       "      <td>0.884586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.020100</td>\n",
       "      <td>0.793297</td>\n",
       "      <td>0.892183</td>\n",
       "      <td>0.885074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9d2ebc5da0a41858ecae6a190454282",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16321 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1f0c11c081c418b9abceb70e54907f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4081 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3072' max='3072' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3072/3072 04:57, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.396500</td>\n",
       "      <td>0.311262</td>\n",
       "      <td>0.858858</td>\n",
       "      <td>0.847026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.327700</td>\n",
       "      <td>0.292305</td>\n",
       "      <td>0.881647</td>\n",
       "      <td>0.872980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.248900</td>\n",
       "      <td>0.336736</td>\n",
       "      <td>0.875031</td>\n",
       "      <td>0.869095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.179700</td>\n",
       "      <td>0.298168</td>\n",
       "      <td>0.889488</td>\n",
       "      <td>0.882308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.185600</td>\n",
       "      <td>0.301157</td>\n",
       "      <td>0.881157</td>\n",
       "      <td>0.875977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.106400</td>\n",
       "      <td>0.373354</td>\n",
       "      <td>0.884832</td>\n",
       "      <td>0.879013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.108600</td>\n",
       "      <td>0.324828</td>\n",
       "      <td>0.889488</td>\n",
       "      <td>0.883652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.094700</td>\n",
       "      <td>0.489099</td>\n",
       "      <td>0.882382</td>\n",
       "      <td>0.877294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.070700</td>\n",
       "      <td>0.478762</td>\n",
       "      <td>0.890223</td>\n",
       "      <td>0.883374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.093200</td>\n",
       "      <td>0.461746</td>\n",
       "      <td>0.892673</td>\n",
       "      <td>0.884767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.062900</td>\n",
       "      <td>0.551272</td>\n",
       "      <td>0.879196</td>\n",
       "      <td>0.873610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.065100</td>\n",
       "      <td>0.442640</td>\n",
       "      <td>0.884832</td>\n",
       "      <td>0.879415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.071500</td>\n",
       "      <td>0.507765</td>\n",
       "      <td>0.892183</td>\n",
       "      <td>0.885104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.042100</td>\n",
       "      <td>0.577885</td>\n",
       "      <td>0.894634</td>\n",
       "      <td>0.888583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.057200</td>\n",
       "      <td>0.481105</td>\n",
       "      <td>0.890713</td>\n",
       "      <td>0.885243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.039900</td>\n",
       "      <td>0.630378</td>\n",
       "      <td>0.893899</td>\n",
       "      <td>0.887293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.041100</td>\n",
       "      <td>0.619795</td>\n",
       "      <td>0.889733</td>\n",
       "      <td>0.882823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.039400</td>\n",
       "      <td>0.612616</td>\n",
       "      <td>0.893163</td>\n",
       "      <td>0.887056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.027600</td>\n",
       "      <td>0.687614</td>\n",
       "      <td>0.891203</td>\n",
       "      <td>0.883939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.037300</td>\n",
       "      <td>0.646821</td>\n",
       "      <td>0.889488</td>\n",
       "      <td>0.882578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.026400</td>\n",
       "      <td>0.691008</td>\n",
       "      <td>0.890223</td>\n",
       "      <td>0.883549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.033200</td>\n",
       "      <td>0.706981</td>\n",
       "      <td>0.892183</td>\n",
       "      <td>0.885514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.031200</td>\n",
       "      <td>0.671458</td>\n",
       "      <td>0.893163</td>\n",
       "      <td>0.886030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.020500</td>\n",
       "      <td>0.734267</td>\n",
       "      <td>0.892918</td>\n",
       "      <td>0.885843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.028100</td>\n",
       "      <td>0.735026</td>\n",
       "      <td>0.891203</td>\n",
       "      <td>0.884531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.019400</td>\n",
       "      <td>0.788506</td>\n",
       "      <td>0.891448</td>\n",
       "      <td>0.883595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.022400</td>\n",
       "      <td>0.783860</td>\n",
       "      <td>0.893163</td>\n",
       "      <td>0.885324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.021800</td>\n",
       "      <td>0.793593</td>\n",
       "      <td>0.892428</td>\n",
       "      <td>0.884834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.023100</td>\n",
       "      <td>0.794520</td>\n",
       "      <td>0.891938</td>\n",
       "      <td>0.884586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.020100</td>\n",
       "      <td>0.793297</td>\n",
       "      <td>0.892183</td>\n",
       "      <td>0.885074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7a4213537fb4c4d82c8c0210a95c87f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16321 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b9b9056e9c940cfbd178c484fd898eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4081 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3072' max='3072' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3072/3072 04:58, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.403800</td>\n",
       "      <td>0.314613</td>\n",
       "      <td>0.859593</td>\n",
       "      <td>0.850120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.308700</td>\n",
       "      <td>0.301105</td>\n",
       "      <td>0.876501</td>\n",
       "      <td>0.867329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.266100</td>\n",
       "      <td>0.299247</td>\n",
       "      <td>0.888508</td>\n",
       "      <td>0.877801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.183800</td>\n",
       "      <td>0.322765</td>\n",
       "      <td>0.887283</td>\n",
       "      <td>0.878434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.194800</td>\n",
       "      <td>0.253942</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.888903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.119900</td>\n",
       "      <td>0.319725</td>\n",
       "      <td>0.895369</td>\n",
       "      <td>0.887204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.113600</td>\n",
       "      <td>0.303263</td>\n",
       "      <td>0.891693</td>\n",
       "      <td>0.885419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.107200</td>\n",
       "      <td>0.463727</td>\n",
       "      <td>0.892918</td>\n",
       "      <td>0.886223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.078100</td>\n",
       "      <td>0.387389</td>\n",
       "      <td>0.890223</td>\n",
       "      <td>0.881504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.098500</td>\n",
       "      <td>0.366529</td>\n",
       "      <td>0.893408</td>\n",
       "      <td>0.887675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.066400</td>\n",
       "      <td>0.487309</td>\n",
       "      <td>0.894879</td>\n",
       "      <td>0.887150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.060600</td>\n",
       "      <td>0.514329</td>\n",
       "      <td>0.888753</td>\n",
       "      <td>0.883237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.066300</td>\n",
       "      <td>0.584480</td>\n",
       "      <td>0.897574</td>\n",
       "      <td>0.890357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.052200</td>\n",
       "      <td>0.506660</td>\n",
       "      <td>0.894144</td>\n",
       "      <td>0.887251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.055100</td>\n",
       "      <td>0.485303</td>\n",
       "      <td>0.892673</td>\n",
       "      <td>0.887600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.045700</td>\n",
       "      <td>0.633459</td>\n",
       "      <td>0.896594</td>\n",
       "      <td>0.888729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.045100</td>\n",
       "      <td>0.496252</td>\n",
       "      <td>0.896839</td>\n",
       "      <td>0.888914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.041800</td>\n",
       "      <td>0.666781</td>\n",
       "      <td>0.890713</td>\n",
       "      <td>0.879852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.032200</td>\n",
       "      <td>0.639856</td>\n",
       "      <td>0.894389</td>\n",
       "      <td>0.887381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.042700</td>\n",
       "      <td>0.566107</td>\n",
       "      <td>0.890713</td>\n",
       "      <td>0.884325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.034600</td>\n",
       "      <td>0.625918</td>\n",
       "      <td>0.893163</td>\n",
       "      <td>0.884545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.030700</td>\n",
       "      <td>0.607332</td>\n",
       "      <td>0.895369</td>\n",
       "      <td>0.888368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.029000</td>\n",
       "      <td>0.604190</td>\n",
       "      <td>0.897819</td>\n",
       "      <td>0.890001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.031900</td>\n",
       "      <td>0.584536</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.889167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.027000</td>\n",
       "      <td>0.621087</td>\n",
       "      <td>0.896594</td>\n",
       "      <td>0.888349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.023800</td>\n",
       "      <td>0.655270</td>\n",
       "      <td>0.895124</td>\n",
       "      <td>0.888003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.024400</td>\n",
       "      <td>0.667445</td>\n",
       "      <td>0.894634</td>\n",
       "      <td>0.887057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.024900</td>\n",
       "      <td>0.671425</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.888633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.026600</td>\n",
       "      <td>0.685557</td>\n",
       "      <td>0.896594</td>\n",
       "      <td>0.889248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.020500</td>\n",
       "      <td>0.692378</td>\n",
       "      <td>0.897084</td>\n",
       "      <td>0.889684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cab63acef5f142de9d8cc79cc69a98dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16321 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c82e41630ed74532ba4720123652c9a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4081 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3072' max='3072' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3072/3072 04:58, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.403800</td>\n",
       "      <td>0.314613</td>\n",
       "      <td>0.859593</td>\n",
       "      <td>0.850120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.308700</td>\n",
       "      <td>0.301105</td>\n",
       "      <td>0.876501</td>\n",
       "      <td>0.867329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.266100</td>\n",
       "      <td>0.299247</td>\n",
       "      <td>0.888508</td>\n",
       "      <td>0.877801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.183800</td>\n",
       "      <td>0.322765</td>\n",
       "      <td>0.887283</td>\n",
       "      <td>0.878434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.194800</td>\n",
       "      <td>0.253942</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.888903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.119900</td>\n",
       "      <td>0.319725</td>\n",
       "      <td>0.895369</td>\n",
       "      <td>0.887204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.113600</td>\n",
       "      <td>0.303263</td>\n",
       "      <td>0.891693</td>\n",
       "      <td>0.885419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.107200</td>\n",
       "      <td>0.463727</td>\n",
       "      <td>0.892918</td>\n",
       "      <td>0.886223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.078100</td>\n",
       "      <td>0.387389</td>\n",
       "      <td>0.890223</td>\n",
       "      <td>0.881504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.098500</td>\n",
       "      <td>0.366529</td>\n",
       "      <td>0.893408</td>\n",
       "      <td>0.887675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.066400</td>\n",
       "      <td>0.487309</td>\n",
       "      <td>0.894879</td>\n",
       "      <td>0.887150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.060600</td>\n",
       "      <td>0.514329</td>\n",
       "      <td>0.888753</td>\n",
       "      <td>0.883237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.066300</td>\n",
       "      <td>0.584480</td>\n",
       "      <td>0.897574</td>\n",
       "      <td>0.890357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.052200</td>\n",
       "      <td>0.506660</td>\n",
       "      <td>0.894144</td>\n",
       "      <td>0.887251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.055100</td>\n",
       "      <td>0.485303</td>\n",
       "      <td>0.892673</td>\n",
       "      <td>0.887600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.045700</td>\n",
       "      <td>0.633459</td>\n",
       "      <td>0.896594</td>\n",
       "      <td>0.888729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.045100</td>\n",
       "      <td>0.496252</td>\n",
       "      <td>0.896839</td>\n",
       "      <td>0.888914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.041800</td>\n",
       "      <td>0.666781</td>\n",
       "      <td>0.890713</td>\n",
       "      <td>0.879852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.032200</td>\n",
       "      <td>0.639856</td>\n",
       "      <td>0.894389</td>\n",
       "      <td>0.887381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.042700</td>\n",
       "      <td>0.566107</td>\n",
       "      <td>0.890713</td>\n",
       "      <td>0.884325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.034600</td>\n",
       "      <td>0.625918</td>\n",
       "      <td>0.893163</td>\n",
       "      <td>0.884545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.030700</td>\n",
       "      <td>0.607332</td>\n",
       "      <td>0.895369</td>\n",
       "      <td>0.888368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.029000</td>\n",
       "      <td>0.604190</td>\n",
       "      <td>0.897819</td>\n",
       "      <td>0.890001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.031900</td>\n",
       "      <td>0.584536</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.889167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.027000</td>\n",
       "      <td>0.621087</td>\n",
       "      <td>0.896594</td>\n",
       "      <td>0.888349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.023800</td>\n",
       "      <td>0.655270</td>\n",
       "      <td>0.895124</td>\n",
       "      <td>0.888003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.024400</td>\n",
       "      <td>0.667445</td>\n",
       "      <td>0.894634</td>\n",
       "      <td>0.887057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.024900</td>\n",
       "      <td>0.671425</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.888633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.026600</td>\n",
       "      <td>0.685557</td>\n",
       "      <td>0.896594</td>\n",
       "      <td>0.889248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.020500</td>\n",
       "      <td>0.692378</td>\n",
       "      <td>0.897084</td>\n",
       "      <td>0.889684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ce26be75f404aeb8dfe2492131aeae1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16321 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "292a8b65ecac432b940a77007a42faa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4081 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3072' max='3072' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3072/3072 05:00, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.403800</td>\n",
       "      <td>0.314613</td>\n",
       "      <td>0.859593</td>\n",
       "      <td>0.850120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.308700</td>\n",
       "      <td>0.301105</td>\n",
       "      <td>0.876501</td>\n",
       "      <td>0.867329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.266100</td>\n",
       "      <td>0.299247</td>\n",
       "      <td>0.888508</td>\n",
       "      <td>0.877801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.183800</td>\n",
       "      <td>0.322765</td>\n",
       "      <td>0.887283</td>\n",
       "      <td>0.878434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.194800</td>\n",
       "      <td>0.253942</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.888903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.119900</td>\n",
       "      <td>0.319725</td>\n",
       "      <td>0.895369</td>\n",
       "      <td>0.887204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.113600</td>\n",
       "      <td>0.303263</td>\n",
       "      <td>0.891693</td>\n",
       "      <td>0.885419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.107200</td>\n",
       "      <td>0.463727</td>\n",
       "      <td>0.892918</td>\n",
       "      <td>0.886223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.078100</td>\n",
       "      <td>0.387389</td>\n",
       "      <td>0.890223</td>\n",
       "      <td>0.881504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.098500</td>\n",
       "      <td>0.366529</td>\n",
       "      <td>0.893408</td>\n",
       "      <td>0.887675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.066400</td>\n",
       "      <td>0.487309</td>\n",
       "      <td>0.894879</td>\n",
       "      <td>0.887150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.060600</td>\n",
       "      <td>0.514329</td>\n",
       "      <td>0.888753</td>\n",
       "      <td>0.883237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.066300</td>\n",
       "      <td>0.584480</td>\n",
       "      <td>0.897574</td>\n",
       "      <td>0.890357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.052200</td>\n",
       "      <td>0.506660</td>\n",
       "      <td>0.894144</td>\n",
       "      <td>0.887251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.055100</td>\n",
       "      <td>0.485303</td>\n",
       "      <td>0.892673</td>\n",
       "      <td>0.887600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.045700</td>\n",
       "      <td>0.633459</td>\n",
       "      <td>0.896594</td>\n",
       "      <td>0.888729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.045100</td>\n",
       "      <td>0.496252</td>\n",
       "      <td>0.896839</td>\n",
       "      <td>0.888914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.041800</td>\n",
       "      <td>0.666781</td>\n",
       "      <td>0.890713</td>\n",
       "      <td>0.879852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.032200</td>\n",
       "      <td>0.639856</td>\n",
       "      <td>0.894389</td>\n",
       "      <td>0.887381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.042700</td>\n",
       "      <td>0.566107</td>\n",
       "      <td>0.890713</td>\n",
       "      <td>0.884325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.034600</td>\n",
       "      <td>0.625918</td>\n",
       "      <td>0.893163</td>\n",
       "      <td>0.884545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.030700</td>\n",
       "      <td>0.607332</td>\n",
       "      <td>0.895369</td>\n",
       "      <td>0.888368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.029000</td>\n",
       "      <td>0.604190</td>\n",
       "      <td>0.897819</td>\n",
       "      <td>0.890001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.031900</td>\n",
       "      <td>0.584536</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.889167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.027000</td>\n",
       "      <td>0.621087</td>\n",
       "      <td>0.896594</td>\n",
       "      <td>0.888349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.023800</td>\n",
       "      <td>0.655270</td>\n",
       "      <td>0.895124</td>\n",
       "      <td>0.888003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.024400</td>\n",
       "      <td>0.667445</td>\n",
       "      <td>0.894634</td>\n",
       "      <td>0.887057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.024900</td>\n",
       "      <td>0.671425</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.888633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.026600</td>\n",
       "      <td>0.685557</td>\n",
       "      <td>0.896594</td>\n",
       "      <td>0.889248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.020500</td>\n",
       "      <td>0.692378</td>\n",
       "      <td>0.897084</td>\n",
       "      <td>0.889684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46c97fe95c294e4cb73348a81482543c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16321 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9c0ee78815949bfb078c1edbef6c1ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4081 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3072' max='3072' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3072/3072 04:58, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.401300</td>\n",
       "      <td>0.312691</td>\n",
       "      <td>0.865474</td>\n",
       "      <td>0.851497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.323400</td>\n",
       "      <td>0.301766</td>\n",
       "      <td>0.875031</td>\n",
       "      <td>0.863310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.247500</td>\n",
       "      <td>0.311041</td>\n",
       "      <td>0.881647</td>\n",
       "      <td>0.871244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.186200</td>\n",
       "      <td>0.312344</td>\n",
       "      <td>0.875276</td>\n",
       "      <td>0.870597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.186000</td>\n",
       "      <td>0.294535</td>\n",
       "      <td>0.889733</td>\n",
       "      <td>0.883624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.113700</td>\n",
       "      <td>0.368680</td>\n",
       "      <td>0.887283</td>\n",
       "      <td>0.878434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.114100</td>\n",
       "      <td>0.387116</td>\n",
       "      <td>0.895614</td>\n",
       "      <td>0.889073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>0.460286</td>\n",
       "      <td>0.897574</td>\n",
       "      <td>0.891481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.075500</td>\n",
       "      <td>0.416303</td>\n",
       "      <td>0.891938</td>\n",
       "      <td>0.886491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.081000</td>\n",
       "      <td>0.438132</td>\n",
       "      <td>0.894144</td>\n",
       "      <td>0.887902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.060600</td>\n",
       "      <td>0.553588</td>\n",
       "      <td>0.891938</td>\n",
       "      <td>0.885802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.062900</td>\n",
       "      <td>0.446368</td>\n",
       "      <td>0.894879</td>\n",
       "      <td>0.888612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.065300</td>\n",
       "      <td>0.577540</td>\n",
       "      <td>0.895369</td>\n",
       "      <td>0.889767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.043700</td>\n",
       "      <td>0.512755</td>\n",
       "      <td>0.895614</td>\n",
       "      <td>0.889593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.047000</td>\n",
       "      <td>0.597262</td>\n",
       "      <td>0.892673</td>\n",
       "      <td>0.886808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.044400</td>\n",
       "      <td>0.588776</td>\n",
       "      <td>0.891203</td>\n",
       "      <td>0.883724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.038000</td>\n",
       "      <td>0.619135</td>\n",
       "      <td>0.894144</td>\n",
       "      <td>0.886867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.039400</td>\n",
       "      <td>0.588579</td>\n",
       "      <td>0.897819</td>\n",
       "      <td>0.891913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.032700</td>\n",
       "      <td>0.594874</td>\n",
       "      <td>0.897574</td>\n",
       "      <td>0.891374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.027500</td>\n",
       "      <td>0.638835</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.889951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.024800</td>\n",
       "      <td>0.707438</td>\n",
       "      <td>0.898064</td>\n",
       "      <td>0.892027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.030600</td>\n",
       "      <td>0.629305</td>\n",
       "      <td>0.895859</td>\n",
       "      <td>0.889458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.027300</td>\n",
       "      <td>0.680761</td>\n",
       "      <td>0.900025</td>\n",
       "      <td>0.894051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.021300</td>\n",
       "      <td>0.686421</td>\n",
       "      <td>0.900515</td>\n",
       "      <td>0.894413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.026100</td>\n",
       "      <td>0.645750</td>\n",
       "      <td>0.899289</td>\n",
       "      <td>0.892992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.026600</td>\n",
       "      <td>0.680065</td>\n",
       "      <td>0.899289</td>\n",
       "      <td>0.893285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.019400</td>\n",
       "      <td>0.700348</td>\n",
       "      <td>0.899044</td>\n",
       "      <td>0.892906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.019400</td>\n",
       "      <td>0.740715</td>\n",
       "      <td>0.899044</td>\n",
       "      <td>0.892906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.018500</td>\n",
       "      <td>0.740339</td>\n",
       "      <td>0.900270</td>\n",
       "      <td>0.893926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.021400</td>\n",
       "      <td>0.749319</td>\n",
       "      <td>0.900025</td>\n",
       "      <td>0.893760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcd9e16c12084c8eae40de81d89bfd39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16321 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b6e5de97d674337b6cc04d104457b13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4081 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3072' max='3072' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3072/3072 04:59, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.401300</td>\n",
       "      <td>0.312691</td>\n",
       "      <td>0.865474</td>\n",
       "      <td>0.851497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.323400</td>\n",
       "      <td>0.301766</td>\n",
       "      <td>0.875031</td>\n",
       "      <td>0.863310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.247500</td>\n",
       "      <td>0.311041</td>\n",
       "      <td>0.881647</td>\n",
       "      <td>0.871244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.186200</td>\n",
       "      <td>0.312344</td>\n",
       "      <td>0.875276</td>\n",
       "      <td>0.870597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.186000</td>\n",
       "      <td>0.294535</td>\n",
       "      <td>0.889733</td>\n",
       "      <td>0.883624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.113700</td>\n",
       "      <td>0.368680</td>\n",
       "      <td>0.887283</td>\n",
       "      <td>0.878434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.114100</td>\n",
       "      <td>0.387116</td>\n",
       "      <td>0.895614</td>\n",
       "      <td>0.889073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>0.460286</td>\n",
       "      <td>0.897574</td>\n",
       "      <td>0.891481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.075500</td>\n",
       "      <td>0.416303</td>\n",
       "      <td>0.891938</td>\n",
       "      <td>0.886491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.081000</td>\n",
       "      <td>0.438132</td>\n",
       "      <td>0.894144</td>\n",
       "      <td>0.887902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.060600</td>\n",
       "      <td>0.553588</td>\n",
       "      <td>0.891938</td>\n",
       "      <td>0.885802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.062900</td>\n",
       "      <td>0.446368</td>\n",
       "      <td>0.894879</td>\n",
       "      <td>0.888612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.065300</td>\n",
       "      <td>0.577540</td>\n",
       "      <td>0.895369</td>\n",
       "      <td>0.889767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.043700</td>\n",
       "      <td>0.512755</td>\n",
       "      <td>0.895614</td>\n",
       "      <td>0.889593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.047000</td>\n",
       "      <td>0.597262</td>\n",
       "      <td>0.892673</td>\n",
       "      <td>0.886808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.044400</td>\n",
       "      <td>0.588776</td>\n",
       "      <td>0.891203</td>\n",
       "      <td>0.883724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.038000</td>\n",
       "      <td>0.619135</td>\n",
       "      <td>0.894144</td>\n",
       "      <td>0.886867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.039400</td>\n",
       "      <td>0.588579</td>\n",
       "      <td>0.897819</td>\n",
       "      <td>0.891913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.032700</td>\n",
       "      <td>0.594874</td>\n",
       "      <td>0.897574</td>\n",
       "      <td>0.891374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.027500</td>\n",
       "      <td>0.638835</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.889951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.024800</td>\n",
       "      <td>0.707438</td>\n",
       "      <td>0.898064</td>\n",
       "      <td>0.892027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.030600</td>\n",
       "      <td>0.629305</td>\n",
       "      <td>0.895859</td>\n",
       "      <td>0.889458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.027300</td>\n",
       "      <td>0.680761</td>\n",
       "      <td>0.900025</td>\n",
       "      <td>0.894051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.021300</td>\n",
       "      <td>0.686421</td>\n",
       "      <td>0.900515</td>\n",
       "      <td>0.894413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.026100</td>\n",
       "      <td>0.645750</td>\n",
       "      <td>0.899289</td>\n",
       "      <td>0.892992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.026600</td>\n",
       "      <td>0.680065</td>\n",
       "      <td>0.899289</td>\n",
       "      <td>0.893285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.019400</td>\n",
       "      <td>0.700348</td>\n",
       "      <td>0.899044</td>\n",
       "      <td>0.892906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.019400</td>\n",
       "      <td>0.740715</td>\n",
       "      <td>0.899044</td>\n",
       "      <td>0.892906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.018500</td>\n",
       "      <td>0.740339</td>\n",
       "      <td>0.900270</td>\n",
       "      <td>0.893926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.021400</td>\n",
       "      <td>0.749319</td>\n",
       "      <td>0.900025</td>\n",
       "      <td>0.893760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30573397bab047359a2031d7d1bf1430",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16321 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "885f7fdb28b04ec1a7003d459f83a45c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4081 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3072' max='3072' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3072/3072 04:59, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.401300</td>\n",
       "      <td>0.312691</td>\n",
       "      <td>0.865474</td>\n",
       "      <td>0.851497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.323400</td>\n",
       "      <td>0.301766</td>\n",
       "      <td>0.875031</td>\n",
       "      <td>0.863310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.247500</td>\n",
       "      <td>0.311041</td>\n",
       "      <td>0.881647</td>\n",
       "      <td>0.871244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.186200</td>\n",
       "      <td>0.312344</td>\n",
       "      <td>0.875276</td>\n",
       "      <td>0.870597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.186000</td>\n",
       "      <td>0.294535</td>\n",
       "      <td>0.889733</td>\n",
       "      <td>0.883624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.113700</td>\n",
       "      <td>0.368680</td>\n",
       "      <td>0.887283</td>\n",
       "      <td>0.878434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.114100</td>\n",
       "      <td>0.387116</td>\n",
       "      <td>0.895614</td>\n",
       "      <td>0.889073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>0.460286</td>\n",
       "      <td>0.897574</td>\n",
       "      <td>0.891481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.075500</td>\n",
       "      <td>0.416303</td>\n",
       "      <td>0.891938</td>\n",
       "      <td>0.886491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.081000</td>\n",
       "      <td>0.438132</td>\n",
       "      <td>0.894144</td>\n",
       "      <td>0.887902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.060600</td>\n",
       "      <td>0.553588</td>\n",
       "      <td>0.891938</td>\n",
       "      <td>0.885802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.062900</td>\n",
       "      <td>0.446368</td>\n",
       "      <td>0.894879</td>\n",
       "      <td>0.888612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.065300</td>\n",
       "      <td>0.577540</td>\n",
       "      <td>0.895369</td>\n",
       "      <td>0.889767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.043700</td>\n",
       "      <td>0.512755</td>\n",
       "      <td>0.895614</td>\n",
       "      <td>0.889593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.047000</td>\n",
       "      <td>0.597262</td>\n",
       "      <td>0.892673</td>\n",
       "      <td>0.886808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.044400</td>\n",
       "      <td>0.588776</td>\n",
       "      <td>0.891203</td>\n",
       "      <td>0.883724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.038000</td>\n",
       "      <td>0.619135</td>\n",
       "      <td>0.894144</td>\n",
       "      <td>0.886867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.039400</td>\n",
       "      <td>0.588579</td>\n",
       "      <td>0.897819</td>\n",
       "      <td>0.891913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.032700</td>\n",
       "      <td>0.594874</td>\n",
       "      <td>0.897574</td>\n",
       "      <td>0.891374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.027500</td>\n",
       "      <td>0.638835</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.889951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.024800</td>\n",
       "      <td>0.707438</td>\n",
       "      <td>0.898064</td>\n",
       "      <td>0.892027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.030600</td>\n",
       "      <td>0.629305</td>\n",
       "      <td>0.895859</td>\n",
       "      <td>0.889458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.027300</td>\n",
       "      <td>0.680761</td>\n",
       "      <td>0.900025</td>\n",
       "      <td>0.894051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.021300</td>\n",
       "      <td>0.686421</td>\n",
       "      <td>0.900515</td>\n",
       "      <td>0.894413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.026100</td>\n",
       "      <td>0.645750</td>\n",
       "      <td>0.899289</td>\n",
       "      <td>0.892992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.026600</td>\n",
       "      <td>0.680065</td>\n",
       "      <td>0.899289</td>\n",
       "      <td>0.893285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.019400</td>\n",
       "      <td>0.700348</td>\n",
       "      <td>0.899044</td>\n",
       "      <td>0.892906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.019400</td>\n",
       "      <td>0.740715</td>\n",
       "      <td>0.899044</td>\n",
       "      <td>0.892906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.018500</td>\n",
       "      <td>0.740339</td>\n",
       "      <td>0.900270</td>\n",
       "      <td>0.893926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.021400</td>\n",
       "      <td>0.749319</td>\n",
       "      <td>0.900025</td>\n",
       "      <td>0.893760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 16321\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 4081\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunis-ai/TunBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tunis-ai/TunBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1580b17d0dd4509aa8a10274b8fd4bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16321 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61a6b1bcccb64f49a026f632764865f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4081 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3072' max='3072' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3072/3072 04:46, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.674400</td>\n",
       "      <td>0.505514</td>\n",
       "      <td>0.764273</td>\n",
       "      <td>0.699823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.517600</td>\n",
       "      <td>0.505401</td>\n",
       "      <td>0.768929</td>\n",
       "      <td>0.704810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.512600</td>\n",
       "      <td>0.500012</td>\n",
       "      <td>0.769419</td>\n",
       "      <td>0.706630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.522900</td>\n",
       "      <td>0.616922</td>\n",
       "      <td>0.768929</td>\n",
       "      <td>0.733718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.501600</td>\n",
       "      <td>0.483955</td>\n",
       "      <td>0.768194</td>\n",
       "      <td>0.741063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.489100</td>\n",
       "      <td>0.470176</td>\n",
       "      <td>0.767949</td>\n",
       "      <td>0.742100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.467000</td>\n",
       "      <td>0.450640</td>\n",
       "      <td>0.786817</td>\n",
       "      <td>0.751043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.457300</td>\n",
       "      <td>0.464561</td>\n",
       "      <td>0.783141</td>\n",
       "      <td>0.757023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.432400</td>\n",
       "      <td>0.458720</td>\n",
       "      <td>0.786082</td>\n",
       "      <td>0.752254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.443700</td>\n",
       "      <td>0.458032</td>\n",
       "      <td>0.788042</td>\n",
       "      <td>0.756932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.410100</td>\n",
       "      <td>0.473649</td>\n",
       "      <td>0.790738</td>\n",
       "      <td>0.758302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.414000</td>\n",
       "      <td>0.445419</td>\n",
       "      <td>0.793923</td>\n",
       "      <td>0.763294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.413600</td>\n",
       "      <td>0.520855</td>\n",
       "      <td>0.761333</td>\n",
       "      <td>0.749667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.389300</td>\n",
       "      <td>0.481457</td>\n",
       "      <td>0.787552</td>\n",
       "      <td>0.765557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.406300</td>\n",
       "      <td>0.483082</td>\n",
       "      <td>0.788532</td>\n",
       "      <td>0.763487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.503924</td>\n",
       "      <td>0.763783</td>\n",
       "      <td>0.752016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.388500</td>\n",
       "      <td>0.515482</td>\n",
       "      <td>0.775790</td>\n",
       "      <td>0.759504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.393200</td>\n",
       "      <td>0.442545</td>\n",
       "      <td>0.793923</td>\n",
       "      <td>0.769269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.357100</td>\n",
       "      <td>0.500845</td>\n",
       "      <td>0.800294</td>\n",
       "      <td>0.769100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.367200</td>\n",
       "      <td>0.481446</td>\n",
       "      <td>0.794903</td>\n",
       "      <td>0.759382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.358000</td>\n",
       "      <td>0.459831</td>\n",
       "      <td>0.796864</td>\n",
       "      <td>0.769416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.361500</td>\n",
       "      <td>0.508322</td>\n",
       "      <td>0.781181</td>\n",
       "      <td>0.765093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.345600</td>\n",
       "      <td>0.489201</td>\n",
       "      <td>0.790983</td>\n",
       "      <td>0.767539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.332500</td>\n",
       "      <td>0.501044</td>\n",
       "      <td>0.781426</td>\n",
       "      <td>0.761888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.349400</td>\n",
       "      <td>0.496623</td>\n",
       "      <td>0.794658</td>\n",
       "      <td>0.771109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.336700</td>\n",
       "      <td>0.497940</td>\n",
       "      <td>0.781671</td>\n",
       "      <td>0.765098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.325700</td>\n",
       "      <td>0.501996</td>\n",
       "      <td>0.790002</td>\n",
       "      <td>0.769095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.327800</td>\n",
       "      <td>0.492751</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.769965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.327600</td>\n",
       "      <td>0.505598</td>\n",
       "      <td>0.786082</td>\n",
       "      <td>0.766566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.507066</td>\n",
       "      <td>0.793923</td>\n",
       "      <td>0.769269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunis-ai/TunBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tunis-ai/TunBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cf20b719abd4dcf8838f2ecacd61b4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16321 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6a1b10e546d401aa67e68b1ea5725ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4081 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3072' max='3072' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3072/3072 04:44, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.674400</td>\n",
       "      <td>0.505514</td>\n",
       "      <td>0.764273</td>\n",
       "      <td>0.699823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.517600</td>\n",
       "      <td>0.505401</td>\n",
       "      <td>0.768929</td>\n",
       "      <td>0.704810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.512600</td>\n",
       "      <td>0.500012</td>\n",
       "      <td>0.769419</td>\n",
       "      <td>0.706630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.522900</td>\n",
       "      <td>0.616922</td>\n",
       "      <td>0.768929</td>\n",
       "      <td>0.733718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.501600</td>\n",
       "      <td>0.483955</td>\n",
       "      <td>0.768194</td>\n",
       "      <td>0.741063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.489100</td>\n",
       "      <td>0.470176</td>\n",
       "      <td>0.767949</td>\n",
       "      <td>0.742100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.467000</td>\n",
       "      <td>0.450640</td>\n",
       "      <td>0.786817</td>\n",
       "      <td>0.751043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.457300</td>\n",
       "      <td>0.464561</td>\n",
       "      <td>0.783141</td>\n",
       "      <td>0.757023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.432400</td>\n",
       "      <td>0.458720</td>\n",
       "      <td>0.786082</td>\n",
       "      <td>0.752254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.443700</td>\n",
       "      <td>0.458032</td>\n",
       "      <td>0.788042</td>\n",
       "      <td>0.756932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.410100</td>\n",
       "      <td>0.473649</td>\n",
       "      <td>0.790738</td>\n",
       "      <td>0.758302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.414000</td>\n",
       "      <td>0.445419</td>\n",
       "      <td>0.793923</td>\n",
       "      <td>0.763294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.413600</td>\n",
       "      <td>0.520855</td>\n",
       "      <td>0.761333</td>\n",
       "      <td>0.749667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.389300</td>\n",
       "      <td>0.481457</td>\n",
       "      <td>0.787552</td>\n",
       "      <td>0.765557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.406300</td>\n",
       "      <td>0.483082</td>\n",
       "      <td>0.788532</td>\n",
       "      <td>0.763487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.503924</td>\n",
       "      <td>0.763783</td>\n",
       "      <td>0.752016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.388500</td>\n",
       "      <td>0.515482</td>\n",
       "      <td>0.775790</td>\n",
       "      <td>0.759504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.393200</td>\n",
       "      <td>0.442545</td>\n",
       "      <td>0.793923</td>\n",
       "      <td>0.769269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.357100</td>\n",
       "      <td>0.500845</td>\n",
       "      <td>0.800294</td>\n",
       "      <td>0.769100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.367200</td>\n",
       "      <td>0.481446</td>\n",
       "      <td>0.794903</td>\n",
       "      <td>0.759382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.358000</td>\n",
       "      <td>0.459831</td>\n",
       "      <td>0.796864</td>\n",
       "      <td>0.769416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.361500</td>\n",
       "      <td>0.508322</td>\n",
       "      <td>0.781181</td>\n",
       "      <td>0.765093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.345600</td>\n",
       "      <td>0.489201</td>\n",
       "      <td>0.790983</td>\n",
       "      <td>0.767539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.332500</td>\n",
       "      <td>0.501044</td>\n",
       "      <td>0.781426</td>\n",
       "      <td>0.761888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.349400</td>\n",
       "      <td>0.496623</td>\n",
       "      <td>0.794658</td>\n",
       "      <td>0.771109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.336700</td>\n",
       "      <td>0.497940</td>\n",
       "      <td>0.781671</td>\n",
       "      <td>0.765098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.325700</td>\n",
       "      <td>0.501996</td>\n",
       "      <td>0.790002</td>\n",
       "      <td>0.769095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.327800</td>\n",
       "      <td>0.492751</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.769965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.327600</td>\n",
       "      <td>0.505598</td>\n",
       "      <td>0.786082</td>\n",
       "      <td>0.766566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.507066</td>\n",
       "      <td>0.793923</td>\n",
       "      <td>0.769269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunis-ai/TunBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tunis-ai/TunBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7ef8a1d85a047d48f76c4f2e9ba3a45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16321 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "666d2cc665264698a3275b3ed0f12445",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4081 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3072' max='3072' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3072/3072 04:44, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.674400</td>\n",
       "      <td>0.505514</td>\n",
       "      <td>0.764273</td>\n",
       "      <td>0.699823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.517600</td>\n",
       "      <td>0.505401</td>\n",
       "      <td>0.768929</td>\n",
       "      <td>0.704810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.512600</td>\n",
       "      <td>0.500012</td>\n",
       "      <td>0.769419</td>\n",
       "      <td>0.706630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.522900</td>\n",
       "      <td>0.616922</td>\n",
       "      <td>0.768929</td>\n",
       "      <td>0.733718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.501600</td>\n",
       "      <td>0.483955</td>\n",
       "      <td>0.768194</td>\n",
       "      <td>0.741063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.489100</td>\n",
       "      <td>0.470176</td>\n",
       "      <td>0.767949</td>\n",
       "      <td>0.742100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.467000</td>\n",
       "      <td>0.450640</td>\n",
       "      <td>0.786817</td>\n",
       "      <td>0.751043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.457300</td>\n",
       "      <td>0.464561</td>\n",
       "      <td>0.783141</td>\n",
       "      <td>0.757023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.432400</td>\n",
       "      <td>0.458720</td>\n",
       "      <td>0.786082</td>\n",
       "      <td>0.752254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.443700</td>\n",
       "      <td>0.458032</td>\n",
       "      <td>0.788042</td>\n",
       "      <td>0.756932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.410100</td>\n",
       "      <td>0.473649</td>\n",
       "      <td>0.790738</td>\n",
       "      <td>0.758302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.414000</td>\n",
       "      <td>0.445419</td>\n",
       "      <td>0.793923</td>\n",
       "      <td>0.763294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.413600</td>\n",
       "      <td>0.520855</td>\n",
       "      <td>0.761333</td>\n",
       "      <td>0.749667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.389300</td>\n",
       "      <td>0.481457</td>\n",
       "      <td>0.787552</td>\n",
       "      <td>0.765557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.406300</td>\n",
       "      <td>0.483082</td>\n",
       "      <td>0.788532</td>\n",
       "      <td>0.763487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.503924</td>\n",
       "      <td>0.763783</td>\n",
       "      <td>0.752016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.388500</td>\n",
       "      <td>0.515482</td>\n",
       "      <td>0.775790</td>\n",
       "      <td>0.759504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.393200</td>\n",
       "      <td>0.442545</td>\n",
       "      <td>0.793923</td>\n",
       "      <td>0.769269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.357100</td>\n",
       "      <td>0.500845</td>\n",
       "      <td>0.800294</td>\n",
       "      <td>0.769100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.367200</td>\n",
       "      <td>0.481446</td>\n",
       "      <td>0.794903</td>\n",
       "      <td>0.759382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.358000</td>\n",
       "      <td>0.459831</td>\n",
       "      <td>0.796864</td>\n",
       "      <td>0.769416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.361500</td>\n",
       "      <td>0.508322</td>\n",
       "      <td>0.781181</td>\n",
       "      <td>0.765093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.345600</td>\n",
       "      <td>0.489201</td>\n",
       "      <td>0.790983</td>\n",
       "      <td>0.767539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.332500</td>\n",
       "      <td>0.501044</td>\n",
       "      <td>0.781426</td>\n",
       "      <td>0.761888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.349400</td>\n",
       "      <td>0.496623</td>\n",
       "      <td>0.794658</td>\n",
       "      <td>0.771109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.336700</td>\n",
       "      <td>0.497940</td>\n",
       "      <td>0.781671</td>\n",
       "      <td>0.765098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.325700</td>\n",
       "      <td>0.501996</td>\n",
       "      <td>0.790002</td>\n",
       "      <td>0.769095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.327800</td>\n",
       "      <td>0.492751</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.769965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.327600</td>\n",
       "      <td>0.505598</td>\n",
       "      <td>0.786082</td>\n",
       "      <td>0.766566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.507066</td>\n",
       "      <td>0.793923</td>\n",
       "      <td>0.769269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunis-ai/TunBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tunis-ai/TunBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3dafa7cd1a749ea92637ecfb74b41bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16321 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6ce5fd25eaa437da45393838f3b4d54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4081 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3072' max='3072' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3072/3072 04:44, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.655400</td>\n",
       "      <td>0.596433</td>\n",
       "      <td>0.726783</td>\n",
       "      <td>0.688051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.558900</td>\n",
       "      <td>0.513574</td>\n",
       "      <td>0.764028</td>\n",
       "      <td>0.695684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.524500</td>\n",
       "      <td>0.507637</td>\n",
       "      <td>0.765989</td>\n",
       "      <td>0.697849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.523800</td>\n",
       "      <td>0.512263</td>\n",
       "      <td>0.765009</td>\n",
       "      <td>0.697491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.509800</td>\n",
       "      <td>0.523901</td>\n",
       "      <td>0.764764</td>\n",
       "      <td>0.697445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.527000</td>\n",
       "      <td>0.515182</td>\n",
       "      <td>0.765254</td>\n",
       "      <td>0.697896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.516700</td>\n",
       "      <td>0.506161</td>\n",
       "      <td>0.772360</td>\n",
       "      <td>0.711202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.519200</td>\n",
       "      <td>0.506119</td>\n",
       "      <td>0.765744</td>\n",
       "      <td>0.725956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.477200</td>\n",
       "      <td>0.501930</td>\n",
       "      <td>0.777260</td>\n",
       "      <td>0.724931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.481700</td>\n",
       "      <td>0.479109</td>\n",
       "      <td>0.783141</td>\n",
       "      <td>0.729598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.459200</td>\n",
       "      <td>0.500718</td>\n",
       "      <td>0.765744</td>\n",
       "      <td>0.735942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.439100</td>\n",
       "      <td>0.485228</td>\n",
       "      <td>0.784857</td>\n",
       "      <td>0.733677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.457600</td>\n",
       "      <td>0.509926</td>\n",
       "      <td>0.786082</td>\n",
       "      <td>0.733119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.416400</td>\n",
       "      <td>0.460877</td>\n",
       "      <td>0.772605</td>\n",
       "      <td>0.742421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.426600</td>\n",
       "      <td>0.458018</td>\n",
       "      <td>0.783631</td>\n",
       "      <td>0.751574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.407200</td>\n",
       "      <td>0.495633</td>\n",
       "      <td>0.753492</td>\n",
       "      <td>0.739587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.397900</td>\n",
       "      <td>0.490512</td>\n",
       "      <td>0.765989</td>\n",
       "      <td>0.745110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.394900</td>\n",
       "      <td>0.478876</td>\n",
       "      <td>0.772605</td>\n",
       "      <td>0.753831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.381900</td>\n",
       "      <td>0.502502</td>\n",
       "      <td>0.774075</td>\n",
       "      <td>0.755062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.393700</td>\n",
       "      <td>0.481129</td>\n",
       "      <td>0.788287</td>\n",
       "      <td>0.753399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.385300</td>\n",
       "      <td>0.463088</td>\n",
       "      <td>0.791718</td>\n",
       "      <td>0.750721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.368800</td>\n",
       "      <td>0.491726</td>\n",
       "      <td>0.793678</td>\n",
       "      <td>0.752950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.380800</td>\n",
       "      <td>0.480027</td>\n",
       "      <td>0.787552</td>\n",
       "      <td>0.754163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.383600</td>\n",
       "      <td>0.478768</td>\n",
       "      <td>0.791473</td>\n",
       "      <td>0.759697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.357900</td>\n",
       "      <td>0.501456</td>\n",
       "      <td>0.770889</td>\n",
       "      <td>0.753220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.355800</td>\n",
       "      <td>0.504388</td>\n",
       "      <td>0.791473</td>\n",
       "      <td>0.759301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.351300</td>\n",
       "      <td>0.495474</td>\n",
       "      <td>0.786817</td>\n",
       "      <td>0.760491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.356800</td>\n",
       "      <td>0.486933</td>\n",
       "      <td>0.791718</td>\n",
       "      <td>0.762981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.344900</td>\n",
       "      <td>0.510761</td>\n",
       "      <td>0.790247</td>\n",
       "      <td>0.763299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.350600</td>\n",
       "      <td>0.497345</td>\n",
       "      <td>0.790983</td>\n",
       "      <td>0.762741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunis-ai/TunBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tunis-ai/TunBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae363bb6d01d4cfd866f37bf102b0f41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16321 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebec450c0d01479abd4be31aad901c73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4081 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3072' max='3072' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3072/3072 04:44, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.655400</td>\n",
       "      <td>0.596433</td>\n",
       "      <td>0.726783</td>\n",
       "      <td>0.688051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.558900</td>\n",
       "      <td>0.513574</td>\n",
       "      <td>0.764028</td>\n",
       "      <td>0.695684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.524500</td>\n",
       "      <td>0.507637</td>\n",
       "      <td>0.765989</td>\n",
       "      <td>0.697849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.523800</td>\n",
       "      <td>0.512263</td>\n",
       "      <td>0.765009</td>\n",
       "      <td>0.697491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.509800</td>\n",
       "      <td>0.523901</td>\n",
       "      <td>0.764764</td>\n",
       "      <td>0.697445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.527000</td>\n",
       "      <td>0.515182</td>\n",
       "      <td>0.765254</td>\n",
       "      <td>0.697896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.516700</td>\n",
       "      <td>0.506161</td>\n",
       "      <td>0.772360</td>\n",
       "      <td>0.711202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.519200</td>\n",
       "      <td>0.506119</td>\n",
       "      <td>0.765744</td>\n",
       "      <td>0.725956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.477200</td>\n",
       "      <td>0.501930</td>\n",
       "      <td>0.777260</td>\n",
       "      <td>0.724931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.481700</td>\n",
       "      <td>0.479109</td>\n",
       "      <td>0.783141</td>\n",
       "      <td>0.729598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.459200</td>\n",
       "      <td>0.500718</td>\n",
       "      <td>0.765744</td>\n",
       "      <td>0.735942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.439100</td>\n",
       "      <td>0.485228</td>\n",
       "      <td>0.784857</td>\n",
       "      <td>0.733677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.457600</td>\n",
       "      <td>0.509926</td>\n",
       "      <td>0.786082</td>\n",
       "      <td>0.733119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.416400</td>\n",
       "      <td>0.460877</td>\n",
       "      <td>0.772605</td>\n",
       "      <td>0.742421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.426600</td>\n",
       "      <td>0.458018</td>\n",
       "      <td>0.783631</td>\n",
       "      <td>0.751574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.407200</td>\n",
       "      <td>0.495633</td>\n",
       "      <td>0.753492</td>\n",
       "      <td>0.739587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.397900</td>\n",
       "      <td>0.490512</td>\n",
       "      <td>0.765989</td>\n",
       "      <td>0.745110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.394900</td>\n",
       "      <td>0.478876</td>\n",
       "      <td>0.772605</td>\n",
       "      <td>0.753831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.381900</td>\n",
       "      <td>0.502502</td>\n",
       "      <td>0.774075</td>\n",
       "      <td>0.755062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.393700</td>\n",
       "      <td>0.481129</td>\n",
       "      <td>0.788287</td>\n",
       "      <td>0.753399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.385300</td>\n",
       "      <td>0.463088</td>\n",
       "      <td>0.791718</td>\n",
       "      <td>0.750721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.368800</td>\n",
       "      <td>0.491726</td>\n",
       "      <td>0.793678</td>\n",
       "      <td>0.752950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.380800</td>\n",
       "      <td>0.480027</td>\n",
       "      <td>0.787552</td>\n",
       "      <td>0.754163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.383600</td>\n",
       "      <td>0.478768</td>\n",
       "      <td>0.791473</td>\n",
       "      <td>0.759697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.357900</td>\n",
       "      <td>0.501456</td>\n",
       "      <td>0.770889</td>\n",
       "      <td>0.753220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.355800</td>\n",
       "      <td>0.504388</td>\n",
       "      <td>0.791473</td>\n",
       "      <td>0.759301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.351300</td>\n",
       "      <td>0.495474</td>\n",
       "      <td>0.786817</td>\n",
       "      <td>0.760491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.356800</td>\n",
       "      <td>0.486933</td>\n",
       "      <td>0.791718</td>\n",
       "      <td>0.762981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.344900</td>\n",
       "      <td>0.510761</td>\n",
       "      <td>0.790247</td>\n",
       "      <td>0.763299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.350600</td>\n",
       "      <td>0.497345</td>\n",
       "      <td>0.790983</td>\n",
       "      <td>0.762741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunis-ai/TunBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tunis-ai/TunBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9ec9fbad7a64b048fae6892f5a86c43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16321 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7389e023f9064269b8971b309c0c3932",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4081 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3072' max='3072' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3072/3072 04:45, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.655400</td>\n",
       "      <td>0.596433</td>\n",
       "      <td>0.726783</td>\n",
       "      <td>0.688051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.558900</td>\n",
       "      <td>0.513574</td>\n",
       "      <td>0.764028</td>\n",
       "      <td>0.695684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.524500</td>\n",
       "      <td>0.507637</td>\n",
       "      <td>0.765989</td>\n",
       "      <td>0.697849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.523800</td>\n",
       "      <td>0.512263</td>\n",
       "      <td>0.765009</td>\n",
       "      <td>0.697491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.509800</td>\n",
       "      <td>0.523901</td>\n",
       "      <td>0.764764</td>\n",
       "      <td>0.697445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.527000</td>\n",
       "      <td>0.515182</td>\n",
       "      <td>0.765254</td>\n",
       "      <td>0.697896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.516700</td>\n",
       "      <td>0.506161</td>\n",
       "      <td>0.772360</td>\n",
       "      <td>0.711202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.519200</td>\n",
       "      <td>0.506119</td>\n",
       "      <td>0.765744</td>\n",
       "      <td>0.725956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.477200</td>\n",
       "      <td>0.501930</td>\n",
       "      <td>0.777260</td>\n",
       "      <td>0.724931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.481700</td>\n",
       "      <td>0.479109</td>\n",
       "      <td>0.783141</td>\n",
       "      <td>0.729598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.459200</td>\n",
       "      <td>0.500718</td>\n",
       "      <td>0.765744</td>\n",
       "      <td>0.735942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.439100</td>\n",
       "      <td>0.485228</td>\n",
       "      <td>0.784857</td>\n",
       "      <td>0.733677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.457600</td>\n",
       "      <td>0.509926</td>\n",
       "      <td>0.786082</td>\n",
       "      <td>0.733119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.416400</td>\n",
       "      <td>0.460877</td>\n",
       "      <td>0.772605</td>\n",
       "      <td>0.742421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.426600</td>\n",
       "      <td>0.458018</td>\n",
       "      <td>0.783631</td>\n",
       "      <td>0.751574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.407200</td>\n",
       "      <td>0.495633</td>\n",
       "      <td>0.753492</td>\n",
       "      <td>0.739587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.397900</td>\n",
       "      <td>0.490512</td>\n",
       "      <td>0.765989</td>\n",
       "      <td>0.745110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.394900</td>\n",
       "      <td>0.478876</td>\n",
       "      <td>0.772605</td>\n",
       "      <td>0.753831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.381900</td>\n",
       "      <td>0.502502</td>\n",
       "      <td>0.774075</td>\n",
       "      <td>0.755062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.393700</td>\n",
       "      <td>0.481129</td>\n",
       "      <td>0.788287</td>\n",
       "      <td>0.753399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.385300</td>\n",
       "      <td>0.463088</td>\n",
       "      <td>0.791718</td>\n",
       "      <td>0.750721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.368800</td>\n",
       "      <td>0.491726</td>\n",
       "      <td>0.793678</td>\n",
       "      <td>0.752950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.380800</td>\n",
       "      <td>0.480027</td>\n",
       "      <td>0.787552</td>\n",
       "      <td>0.754163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.383600</td>\n",
       "      <td>0.478768</td>\n",
       "      <td>0.791473</td>\n",
       "      <td>0.759697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.357900</td>\n",
       "      <td>0.501456</td>\n",
       "      <td>0.770889</td>\n",
       "      <td>0.753220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.355800</td>\n",
       "      <td>0.504388</td>\n",
       "      <td>0.791473</td>\n",
       "      <td>0.759301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.351300</td>\n",
       "      <td>0.495474</td>\n",
       "      <td>0.786817</td>\n",
       "      <td>0.760491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.356800</td>\n",
       "      <td>0.486933</td>\n",
       "      <td>0.791718</td>\n",
       "      <td>0.762981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.344900</td>\n",
       "      <td>0.510761</td>\n",
       "      <td>0.790247</td>\n",
       "      <td>0.763299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.350600</td>\n",
       "      <td>0.497345</td>\n",
       "      <td>0.790983</td>\n",
       "      <td>0.762741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunis-ai/TunBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tunis-ai/TunBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "700658fa4b074ee3a3451ebc7b4485a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16321 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0ac658ced0b41b09fc821c05607569c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4081 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3072' max='3072' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3072/3072 04:43, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.582300</td>\n",
       "      <td>0.515445</td>\n",
       "      <td>0.765009</td>\n",
       "      <td>0.701705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.519500</td>\n",
       "      <td>0.500694</td>\n",
       "      <td>0.765009</td>\n",
       "      <td>0.700499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.509500</td>\n",
       "      <td>0.514866</td>\n",
       "      <td>0.772360</td>\n",
       "      <td>0.714593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.497400</td>\n",
       "      <td>0.483160</td>\n",
       "      <td>0.774810</td>\n",
       "      <td>0.716406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.486600</td>\n",
       "      <td>0.471885</td>\n",
       "      <td>0.771380</td>\n",
       "      <td>0.710948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.456520</td>\n",
       "      <td>0.788042</td>\n",
       "      <td>0.741869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.456400</td>\n",
       "      <td>0.461255</td>\n",
       "      <td>0.779711</td>\n",
       "      <td>0.724569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.460700</td>\n",
       "      <td>0.446364</td>\n",
       "      <td>0.793923</td>\n",
       "      <td>0.759393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.433600</td>\n",
       "      <td>0.450687</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.754867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.430900</td>\n",
       "      <td>0.455145</td>\n",
       "      <td>0.788777</td>\n",
       "      <td>0.761551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.424300</td>\n",
       "      <td>0.459581</td>\n",
       "      <td>0.789267</td>\n",
       "      <td>0.765914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.404900</td>\n",
       "      <td>0.444487</td>\n",
       "      <td>0.791963</td>\n",
       "      <td>0.766400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.407500</td>\n",
       "      <td>0.475878</td>\n",
       "      <td>0.796864</td>\n",
       "      <td>0.769328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.395400</td>\n",
       "      <td>0.471427</td>\n",
       "      <td>0.799069</td>\n",
       "      <td>0.769065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.388300</td>\n",
       "      <td>0.483512</td>\n",
       "      <td>0.791228</td>\n",
       "      <td>0.764052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.380900</td>\n",
       "      <td>0.507111</td>\n",
       "      <td>0.801029</td>\n",
       "      <td>0.763865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.382200</td>\n",
       "      <td>0.498332</td>\n",
       "      <td>0.797109</td>\n",
       "      <td>0.756825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.376200</td>\n",
       "      <td>0.477436</td>\n",
       "      <td>0.795393</td>\n",
       "      <td>0.773146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.357800</td>\n",
       "      <td>0.464428</td>\n",
       "      <td>0.798824</td>\n",
       "      <td>0.768073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.363500</td>\n",
       "      <td>0.464162</td>\n",
       "      <td>0.791228</td>\n",
       "      <td>0.770849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.357300</td>\n",
       "      <td>0.521688</td>\n",
       "      <td>0.780936</td>\n",
       "      <td>0.768245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.347400</td>\n",
       "      <td>0.466546</td>\n",
       "      <td>0.790247</td>\n",
       "      <td>0.771428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.345100</td>\n",
       "      <td>0.475805</td>\n",
       "      <td>0.804460</td>\n",
       "      <td>0.773585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.331100</td>\n",
       "      <td>0.482720</td>\n",
       "      <td>0.798334</td>\n",
       "      <td>0.772720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.323600</td>\n",
       "      <td>0.515780</td>\n",
       "      <td>0.791228</td>\n",
       "      <td>0.771215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.336400</td>\n",
       "      <td>0.503465</td>\n",
       "      <td>0.790493</td>\n",
       "      <td>0.770006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.314000</td>\n",
       "      <td>0.501701</td>\n",
       "      <td>0.799314</td>\n",
       "      <td>0.777870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.325400</td>\n",
       "      <td>0.500643</td>\n",
       "      <td>0.798579</td>\n",
       "      <td>0.778561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.302900</td>\n",
       "      <td>0.505562</td>\n",
       "      <td>0.802989</td>\n",
       "      <td>0.781232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.302400</td>\n",
       "      <td>0.499544</td>\n",
       "      <td>0.800784</td>\n",
       "      <td>0.777586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunis-ai/TunBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tunis-ai/TunBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2ac2d707c304e39a1710f4a4fff3578",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16321 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fd1c1c45f93464a92295fb613d8d9fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4081 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3072' max='3072' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3072/3072 04:44, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.582300</td>\n",
       "      <td>0.515445</td>\n",
       "      <td>0.765009</td>\n",
       "      <td>0.701705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.519500</td>\n",
       "      <td>0.500694</td>\n",
       "      <td>0.765009</td>\n",
       "      <td>0.700499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.509500</td>\n",
       "      <td>0.514866</td>\n",
       "      <td>0.772360</td>\n",
       "      <td>0.714593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.497400</td>\n",
       "      <td>0.483160</td>\n",
       "      <td>0.774810</td>\n",
       "      <td>0.716406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.486600</td>\n",
       "      <td>0.471885</td>\n",
       "      <td>0.771380</td>\n",
       "      <td>0.710948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.456520</td>\n",
       "      <td>0.788042</td>\n",
       "      <td>0.741869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.456400</td>\n",
       "      <td>0.461255</td>\n",
       "      <td>0.779711</td>\n",
       "      <td>0.724569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.460700</td>\n",
       "      <td>0.446364</td>\n",
       "      <td>0.793923</td>\n",
       "      <td>0.759393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.433600</td>\n",
       "      <td>0.450687</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.754867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.430900</td>\n",
       "      <td>0.455145</td>\n",
       "      <td>0.788777</td>\n",
       "      <td>0.761551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.424300</td>\n",
       "      <td>0.459581</td>\n",
       "      <td>0.789267</td>\n",
       "      <td>0.765914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.404900</td>\n",
       "      <td>0.444487</td>\n",
       "      <td>0.791963</td>\n",
       "      <td>0.766400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.407500</td>\n",
       "      <td>0.475878</td>\n",
       "      <td>0.796864</td>\n",
       "      <td>0.769328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.395400</td>\n",
       "      <td>0.471427</td>\n",
       "      <td>0.799069</td>\n",
       "      <td>0.769065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.388300</td>\n",
       "      <td>0.483512</td>\n",
       "      <td>0.791228</td>\n",
       "      <td>0.764052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.380900</td>\n",
       "      <td>0.507111</td>\n",
       "      <td>0.801029</td>\n",
       "      <td>0.763865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.382200</td>\n",
       "      <td>0.498332</td>\n",
       "      <td>0.797109</td>\n",
       "      <td>0.756825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.376200</td>\n",
       "      <td>0.477436</td>\n",
       "      <td>0.795393</td>\n",
       "      <td>0.773146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.357800</td>\n",
       "      <td>0.464428</td>\n",
       "      <td>0.798824</td>\n",
       "      <td>0.768073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.363500</td>\n",
       "      <td>0.464162</td>\n",
       "      <td>0.791228</td>\n",
       "      <td>0.770849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.357300</td>\n",
       "      <td>0.521688</td>\n",
       "      <td>0.780936</td>\n",
       "      <td>0.768245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.347400</td>\n",
       "      <td>0.466546</td>\n",
       "      <td>0.790247</td>\n",
       "      <td>0.771428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.345100</td>\n",
       "      <td>0.475805</td>\n",
       "      <td>0.804460</td>\n",
       "      <td>0.773585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.331100</td>\n",
       "      <td>0.482720</td>\n",
       "      <td>0.798334</td>\n",
       "      <td>0.772720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.323600</td>\n",
       "      <td>0.515780</td>\n",
       "      <td>0.791228</td>\n",
       "      <td>0.771215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.336400</td>\n",
       "      <td>0.503465</td>\n",
       "      <td>0.790493</td>\n",
       "      <td>0.770006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.314000</td>\n",
       "      <td>0.501701</td>\n",
       "      <td>0.799314</td>\n",
       "      <td>0.777870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.325400</td>\n",
       "      <td>0.500643</td>\n",
       "      <td>0.798579</td>\n",
       "      <td>0.778561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.302900</td>\n",
       "      <td>0.505562</td>\n",
       "      <td>0.802989</td>\n",
       "      <td>0.781232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.302400</td>\n",
       "      <td>0.499544</td>\n",
       "      <td>0.800784</td>\n",
       "      <td>0.777586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunis-ai/TunBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tunis-ai/TunBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "322b6e74012e439ab9bdd0f632f44530",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16321 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e000b2f3671b47f09800b858928f7662",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4081 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3072' max='3072' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3072/3072 04:44, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.582300</td>\n",
       "      <td>0.515445</td>\n",
       "      <td>0.765009</td>\n",
       "      <td>0.701705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.519500</td>\n",
       "      <td>0.500694</td>\n",
       "      <td>0.765009</td>\n",
       "      <td>0.700499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.509500</td>\n",
       "      <td>0.514866</td>\n",
       "      <td>0.772360</td>\n",
       "      <td>0.714593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.497400</td>\n",
       "      <td>0.483160</td>\n",
       "      <td>0.774810</td>\n",
       "      <td>0.716406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.486600</td>\n",
       "      <td>0.471885</td>\n",
       "      <td>0.771380</td>\n",
       "      <td>0.710948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.456520</td>\n",
       "      <td>0.788042</td>\n",
       "      <td>0.741869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.456400</td>\n",
       "      <td>0.461255</td>\n",
       "      <td>0.779711</td>\n",
       "      <td>0.724569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.460700</td>\n",
       "      <td>0.446364</td>\n",
       "      <td>0.793923</td>\n",
       "      <td>0.759393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.433600</td>\n",
       "      <td>0.450687</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.754867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.430900</td>\n",
       "      <td>0.455145</td>\n",
       "      <td>0.788777</td>\n",
       "      <td>0.761551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.424300</td>\n",
       "      <td>0.459581</td>\n",
       "      <td>0.789267</td>\n",
       "      <td>0.765914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.404900</td>\n",
       "      <td>0.444487</td>\n",
       "      <td>0.791963</td>\n",
       "      <td>0.766400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.407500</td>\n",
       "      <td>0.475878</td>\n",
       "      <td>0.796864</td>\n",
       "      <td>0.769328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.395400</td>\n",
       "      <td>0.471427</td>\n",
       "      <td>0.799069</td>\n",
       "      <td>0.769065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.388300</td>\n",
       "      <td>0.483512</td>\n",
       "      <td>0.791228</td>\n",
       "      <td>0.764052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.380900</td>\n",
       "      <td>0.507111</td>\n",
       "      <td>0.801029</td>\n",
       "      <td>0.763865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.382200</td>\n",
       "      <td>0.498332</td>\n",
       "      <td>0.797109</td>\n",
       "      <td>0.756825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.376200</td>\n",
       "      <td>0.477436</td>\n",
       "      <td>0.795393</td>\n",
       "      <td>0.773146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.357800</td>\n",
       "      <td>0.464428</td>\n",
       "      <td>0.798824</td>\n",
       "      <td>0.768073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.363500</td>\n",
       "      <td>0.464162</td>\n",
       "      <td>0.791228</td>\n",
       "      <td>0.770849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.357300</td>\n",
       "      <td>0.521688</td>\n",
       "      <td>0.780936</td>\n",
       "      <td>0.768245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.347400</td>\n",
       "      <td>0.466546</td>\n",
       "      <td>0.790247</td>\n",
       "      <td>0.771428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.345100</td>\n",
       "      <td>0.475805</td>\n",
       "      <td>0.804460</td>\n",
       "      <td>0.773585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.331100</td>\n",
       "      <td>0.482720</td>\n",
       "      <td>0.798334</td>\n",
       "      <td>0.772720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.323600</td>\n",
       "      <td>0.515780</td>\n",
       "      <td>0.791228</td>\n",
       "      <td>0.771215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.336400</td>\n",
       "      <td>0.503465</td>\n",
       "      <td>0.790493</td>\n",
       "      <td>0.770006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.314000</td>\n",
       "      <td>0.501701</td>\n",
       "      <td>0.799314</td>\n",
       "      <td>0.777870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.325400</td>\n",
       "      <td>0.500643</td>\n",
       "      <td>0.798579</td>\n",
       "      <td>0.778561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.302900</td>\n",
       "      <td>0.505562</td>\n",
       "      <td>0.802989</td>\n",
       "      <td>0.781232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.302400</td>\n",
       "      <td>0.499544</td>\n",
       "      <td>0.800784</td>\n",
       "      <td>0.777586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 16321\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 4081\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alger-ia/dziribert, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fe9bbfd6fb849abbaf68232efede396",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16321 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6782cdca16c1486b923593fa4e0a8e27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4081 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3072' max='3072' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3072/3072 04:50, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.364800</td>\n",
       "      <td>0.308227</td>\n",
       "      <td>0.861799</td>\n",
       "      <td>0.844447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.307200</td>\n",
       "      <td>0.265358</td>\n",
       "      <td>0.887528</td>\n",
       "      <td>0.877679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.230300</td>\n",
       "      <td>0.324013</td>\n",
       "      <td>0.873315</td>\n",
       "      <td>0.869008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.151100</td>\n",
       "      <td>0.327159</td>\n",
       "      <td>0.893654</td>\n",
       "      <td>0.886875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.147400</td>\n",
       "      <td>0.303827</td>\n",
       "      <td>0.897329</td>\n",
       "      <td>0.889961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.084300</td>\n",
       "      <td>0.314070</td>\n",
       "      <td>0.893408</td>\n",
       "      <td>0.886998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.088600</td>\n",
       "      <td>0.347446</td>\n",
       "      <td>0.893163</td>\n",
       "      <td>0.887164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.080800</td>\n",
       "      <td>0.539144</td>\n",
       "      <td>0.891203</td>\n",
       "      <td>0.883569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.064300</td>\n",
       "      <td>0.568337</td>\n",
       "      <td>0.888018</td>\n",
       "      <td>0.882712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.069600</td>\n",
       "      <td>0.473754</td>\n",
       "      <td>0.893408</td>\n",
       "      <td>0.886628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.050100</td>\n",
       "      <td>0.578022</td>\n",
       "      <td>0.892673</td>\n",
       "      <td>0.886400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.045400</td>\n",
       "      <td>0.436839</td>\n",
       "      <td>0.893654</td>\n",
       "      <td>0.887244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.049500</td>\n",
       "      <td>0.644012</td>\n",
       "      <td>0.891203</td>\n",
       "      <td>0.883412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.028800</td>\n",
       "      <td>0.625938</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.889368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.040300</td>\n",
       "      <td>0.493403</td>\n",
       "      <td>0.895614</td>\n",
       "      <td>0.888615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.028700</td>\n",
       "      <td>0.682000</td>\n",
       "      <td>0.895859</td>\n",
       "      <td>0.888832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.026200</td>\n",
       "      <td>0.669081</td>\n",
       "      <td>0.895859</td>\n",
       "      <td>0.888536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.031200</td>\n",
       "      <td>0.696611</td>\n",
       "      <td>0.895859</td>\n",
       "      <td>0.888715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.021800</td>\n",
       "      <td>0.770145</td>\n",
       "      <td>0.893654</td>\n",
       "      <td>0.887132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.028400</td>\n",
       "      <td>0.662120</td>\n",
       "      <td>0.897574</td>\n",
       "      <td>0.890446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.018000</td>\n",
       "      <td>0.748019</td>\n",
       "      <td>0.893899</td>\n",
       "      <td>0.887349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.028500</td>\n",
       "      <td>0.659004</td>\n",
       "      <td>0.896839</td>\n",
       "      <td>0.890416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>0.729819</td>\n",
       "      <td>0.895614</td>\n",
       "      <td>0.887799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.019800</td>\n",
       "      <td>0.793479</td>\n",
       "      <td>0.896349</td>\n",
       "      <td>0.888911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.024500</td>\n",
       "      <td>0.742797</td>\n",
       "      <td>0.894879</td>\n",
       "      <td>0.887962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.016200</td>\n",
       "      <td>0.792073</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.888843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.019800</td>\n",
       "      <td>0.789759</td>\n",
       "      <td>0.897574</td>\n",
       "      <td>0.890562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.021400</td>\n",
       "      <td>0.813935</td>\n",
       "      <td>0.897084</td>\n",
       "      <td>0.890126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.019800</td>\n",
       "      <td>0.825498</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.889253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.019000</td>\n",
       "      <td>0.825681</td>\n",
       "      <td>0.897084</td>\n",
       "      <td>0.890607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alger-ia/dziribert, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a7bee64d9fd46b49e1787cc8c26b508",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16321 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1087d27014442a99d4b240e08ef2494",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4081 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3072' max='3072' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3072/3072 04:50, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.364800</td>\n",
       "      <td>0.308227</td>\n",
       "      <td>0.861799</td>\n",
       "      <td>0.844447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.307200</td>\n",
       "      <td>0.265358</td>\n",
       "      <td>0.887528</td>\n",
       "      <td>0.877679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.230300</td>\n",
       "      <td>0.324013</td>\n",
       "      <td>0.873315</td>\n",
       "      <td>0.869008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.151100</td>\n",
       "      <td>0.327159</td>\n",
       "      <td>0.893654</td>\n",
       "      <td>0.886875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.147400</td>\n",
       "      <td>0.303827</td>\n",
       "      <td>0.897329</td>\n",
       "      <td>0.889961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.084300</td>\n",
       "      <td>0.314070</td>\n",
       "      <td>0.893408</td>\n",
       "      <td>0.886998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.088600</td>\n",
       "      <td>0.347446</td>\n",
       "      <td>0.893163</td>\n",
       "      <td>0.887164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.080800</td>\n",
       "      <td>0.539144</td>\n",
       "      <td>0.891203</td>\n",
       "      <td>0.883569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.064300</td>\n",
       "      <td>0.568337</td>\n",
       "      <td>0.888018</td>\n",
       "      <td>0.882712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.069600</td>\n",
       "      <td>0.473754</td>\n",
       "      <td>0.893408</td>\n",
       "      <td>0.886628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.050100</td>\n",
       "      <td>0.578022</td>\n",
       "      <td>0.892673</td>\n",
       "      <td>0.886400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.045400</td>\n",
       "      <td>0.436839</td>\n",
       "      <td>0.893654</td>\n",
       "      <td>0.887244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.049500</td>\n",
       "      <td>0.644012</td>\n",
       "      <td>0.891203</td>\n",
       "      <td>0.883412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.028800</td>\n",
       "      <td>0.625938</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.889368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.040300</td>\n",
       "      <td>0.493403</td>\n",
       "      <td>0.895614</td>\n",
       "      <td>0.888615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.028700</td>\n",
       "      <td>0.682000</td>\n",
       "      <td>0.895859</td>\n",
       "      <td>0.888832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.026200</td>\n",
       "      <td>0.669081</td>\n",
       "      <td>0.895859</td>\n",
       "      <td>0.888536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.031200</td>\n",
       "      <td>0.696611</td>\n",
       "      <td>0.895859</td>\n",
       "      <td>0.888715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.021800</td>\n",
       "      <td>0.770145</td>\n",
       "      <td>0.893654</td>\n",
       "      <td>0.887132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.028400</td>\n",
       "      <td>0.662120</td>\n",
       "      <td>0.897574</td>\n",
       "      <td>0.890446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.018000</td>\n",
       "      <td>0.748019</td>\n",
       "      <td>0.893899</td>\n",
       "      <td>0.887349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.028500</td>\n",
       "      <td>0.659004</td>\n",
       "      <td>0.896839</td>\n",
       "      <td>0.890416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>0.729819</td>\n",
       "      <td>0.895614</td>\n",
       "      <td>0.887799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.019800</td>\n",
       "      <td>0.793479</td>\n",
       "      <td>0.896349</td>\n",
       "      <td>0.888911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.024500</td>\n",
       "      <td>0.742797</td>\n",
       "      <td>0.894879</td>\n",
       "      <td>0.887962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.016200</td>\n",
       "      <td>0.792073</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.888843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.019800</td>\n",
       "      <td>0.789759</td>\n",
       "      <td>0.897574</td>\n",
       "      <td>0.890562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.021400</td>\n",
       "      <td>0.813935</td>\n",
       "      <td>0.897084</td>\n",
       "      <td>0.890126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.019800</td>\n",
       "      <td>0.825498</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.889253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.019000</td>\n",
       "      <td>0.825681</td>\n",
       "      <td>0.897084</td>\n",
       "      <td>0.890607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alger-ia/dziribert, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c221c88dc3b4ee7990908c532aa166b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16321 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b8835cbf7e74652bb2d6a8f60ab5876",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4081 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3072' max='3072' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3072/3072 04:49, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.364800</td>\n",
       "      <td>0.308227</td>\n",
       "      <td>0.861799</td>\n",
       "      <td>0.844447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.307200</td>\n",
       "      <td>0.265358</td>\n",
       "      <td>0.887528</td>\n",
       "      <td>0.877679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.230300</td>\n",
       "      <td>0.324013</td>\n",
       "      <td>0.873315</td>\n",
       "      <td>0.869008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.151100</td>\n",
       "      <td>0.327159</td>\n",
       "      <td>0.893654</td>\n",
       "      <td>0.886875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.147400</td>\n",
       "      <td>0.303827</td>\n",
       "      <td>0.897329</td>\n",
       "      <td>0.889961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.084300</td>\n",
       "      <td>0.314070</td>\n",
       "      <td>0.893408</td>\n",
       "      <td>0.886998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.088600</td>\n",
       "      <td>0.347446</td>\n",
       "      <td>0.893163</td>\n",
       "      <td>0.887164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.080800</td>\n",
       "      <td>0.539144</td>\n",
       "      <td>0.891203</td>\n",
       "      <td>0.883569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.064300</td>\n",
       "      <td>0.568337</td>\n",
       "      <td>0.888018</td>\n",
       "      <td>0.882712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.069600</td>\n",
       "      <td>0.473754</td>\n",
       "      <td>0.893408</td>\n",
       "      <td>0.886628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.050100</td>\n",
       "      <td>0.578022</td>\n",
       "      <td>0.892673</td>\n",
       "      <td>0.886400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.045400</td>\n",
       "      <td>0.436839</td>\n",
       "      <td>0.893654</td>\n",
       "      <td>0.887244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.049500</td>\n",
       "      <td>0.644012</td>\n",
       "      <td>0.891203</td>\n",
       "      <td>0.883412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.028800</td>\n",
       "      <td>0.625938</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.889368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.040300</td>\n",
       "      <td>0.493403</td>\n",
       "      <td>0.895614</td>\n",
       "      <td>0.888615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.028700</td>\n",
       "      <td>0.682000</td>\n",
       "      <td>0.895859</td>\n",
       "      <td>0.888832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.026200</td>\n",
       "      <td>0.669081</td>\n",
       "      <td>0.895859</td>\n",
       "      <td>0.888536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.031200</td>\n",
       "      <td>0.696611</td>\n",
       "      <td>0.895859</td>\n",
       "      <td>0.888715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.021800</td>\n",
       "      <td>0.770145</td>\n",
       "      <td>0.893654</td>\n",
       "      <td>0.887132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.028400</td>\n",
       "      <td>0.662120</td>\n",
       "      <td>0.897574</td>\n",
       "      <td>0.890446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.018000</td>\n",
       "      <td>0.748019</td>\n",
       "      <td>0.893899</td>\n",
       "      <td>0.887349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.028500</td>\n",
       "      <td>0.659004</td>\n",
       "      <td>0.896839</td>\n",
       "      <td>0.890416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>0.729819</td>\n",
       "      <td>0.895614</td>\n",
       "      <td>0.887799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.019800</td>\n",
       "      <td>0.793479</td>\n",
       "      <td>0.896349</td>\n",
       "      <td>0.888911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.024500</td>\n",
       "      <td>0.742797</td>\n",
       "      <td>0.894879</td>\n",
       "      <td>0.887962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.016200</td>\n",
       "      <td>0.792073</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.888843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.019800</td>\n",
       "      <td>0.789759</td>\n",
       "      <td>0.897574</td>\n",
       "      <td>0.890562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.021400</td>\n",
       "      <td>0.813935</td>\n",
       "      <td>0.897084</td>\n",
       "      <td>0.890126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.019800</td>\n",
       "      <td>0.825498</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.889253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.019000</td>\n",
       "      <td>0.825681</td>\n",
       "      <td>0.897084</td>\n",
       "      <td>0.890607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alger-ia/dziribert, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9c83c94273b41858fc8715a4045afca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16321 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4388cee78844dc2845c3c9c24ec1b0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4081 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3072' max='3072' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3072/3072 04:51, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.367800</td>\n",
       "      <td>0.307333</td>\n",
       "      <td>0.868905</td>\n",
       "      <td>0.861293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.293600</td>\n",
       "      <td>0.271078</td>\n",
       "      <td>0.889488</td>\n",
       "      <td>0.880063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.245300</td>\n",
       "      <td>0.282969</td>\n",
       "      <td>0.889733</td>\n",
       "      <td>0.879124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.149100</td>\n",
       "      <td>0.312378</td>\n",
       "      <td>0.891448</td>\n",
       "      <td>0.883878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.155400</td>\n",
       "      <td>0.290761</td>\n",
       "      <td>0.890958</td>\n",
       "      <td>0.885331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.090400</td>\n",
       "      <td>0.371106</td>\n",
       "      <td>0.895859</td>\n",
       "      <td>0.887985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.089400</td>\n",
       "      <td>0.402433</td>\n",
       "      <td>0.895614</td>\n",
       "      <td>0.887258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.112800</td>\n",
       "      <td>0.557872</td>\n",
       "      <td>0.894389</td>\n",
       "      <td>0.887926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.066900</td>\n",
       "      <td>0.443131</td>\n",
       "      <td>0.895124</td>\n",
       "      <td>0.885644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.070900</td>\n",
       "      <td>0.525065</td>\n",
       "      <td>0.899779</td>\n",
       "      <td>0.892292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.059500</td>\n",
       "      <td>0.530728</td>\n",
       "      <td>0.896349</td>\n",
       "      <td>0.887374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.050100</td>\n",
       "      <td>0.594769</td>\n",
       "      <td>0.897819</td>\n",
       "      <td>0.890001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.049000</td>\n",
       "      <td>0.628860</td>\n",
       "      <td>0.895614</td>\n",
       "      <td>0.886829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.038300</td>\n",
       "      <td>0.627635</td>\n",
       "      <td>0.892183</td>\n",
       "      <td>0.885398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.042500</td>\n",
       "      <td>0.608825</td>\n",
       "      <td>0.895124</td>\n",
       "      <td>0.888208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.037200</td>\n",
       "      <td>0.643363</td>\n",
       "      <td>0.897574</td>\n",
       "      <td>0.889343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.028500</td>\n",
       "      <td>0.695335</td>\n",
       "      <td>0.897574</td>\n",
       "      <td>0.889471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.028100</td>\n",
       "      <td>0.771604</td>\n",
       "      <td>0.896349</td>\n",
       "      <td>0.887971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.028000</td>\n",
       "      <td>0.695140</td>\n",
       "      <td>0.893408</td>\n",
       "      <td>0.887026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.029000</td>\n",
       "      <td>0.722891</td>\n",
       "      <td>0.897084</td>\n",
       "      <td>0.889410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.028900</td>\n",
       "      <td>0.743434</td>\n",
       "      <td>0.897574</td>\n",
       "      <td>0.888822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.026000</td>\n",
       "      <td>0.698335</td>\n",
       "      <td>0.897329</td>\n",
       "      <td>0.889504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.026400</td>\n",
       "      <td>0.659571</td>\n",
       "      <td>0.895859</td>\n",
       "      <td>0.888536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.026100</td>\n",
       "      <td>0.719615</td>\n",
       "      <td>0.900270</td>\n",
       "      <td>0.892608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.022100</td>\n",
       "      <td>0.755806</td>\n",
       "      <td>0.899044</td>\n",
       "      <td>0.891057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.023500</td>\n",
       "      <td>0.736969</td>\n",
       "      <td>0.899044</td>\n",
       "      <td>0.891517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.023400</td>\n",
       "      <td>0.741992</td>\n",
       "      <td>0.897574</td>\n",
       "      <td>0.890119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.020900</td>\n",
       "      <td>0.742270</td>\n",
       "      <td>0.897329</td>\n",
       "      <td>0.889750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.022700</td>\n",
       "      <td>0.756822</td>\n",
       "      <td>0.898799</td>\n",
       "      <td>0.891329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.756598</td>\n",
       "      <td>0.898064</td>\n",
       "      <td>0.890403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alger-ia/dziribert, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93879c71093f4eb4b4986eaa56ba150f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16321 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97f6dda96719473f8950ec1eab19fac0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4081 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3072' max='3072' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3072/3072 04:51, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.367800</td>\n",
       "      <td>0.307333</td>\n",
       "      <td>0.868905</td>\n",
       "      <td>0.861293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.293600</td>\n",
       "      <td>0.271078</td>\n",
       "      <td>0.889488</td>\n",
       "      <td>0.880063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.245300</td>\n",
       "      <td>0.282969</td>\n",
       "      <td>0.889733</td>\n",
       "      <td>0.879124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.149100</td>\n",
       "      <td>0.312378</td>\n",
       "      <td>0.891448</td>\n",
       "      <td>0.883878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.155400</td>\n",
       "      <td>0.290761</td>\n",
       "      <td>0.890958</td>\n",
       "      <td>0.885331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.090400</td>\n",
       "      <td>0.371106</td>\n",
       "      <td>0.895859</td>\n",
       "      <td>0.887985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.089400</td>\n",
       "      <td>0.402433</td>\n",
       "      <td>0.895614</td>\n",
       "      <td>0.887258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.112800</td>\n",
       "      <td>0.557872</td>\n",
       "      <td>0.894389</td>\n",
       "      <td>0.887926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.066900</td>\n",
       "      <td>0.443131</td>\n",
       "      <td>0.895124</td>\n",
       "      <td>0.885644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.070900</td>\n",
       "      <td>0.525065</td>\n",
       "      <td>0.899779</td>\n",
       "      <td>0.892292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.059500</td>\n",
       "      <td>0.530728</td>\n",
       "      <td>0.896349</td>\n",
       "      <td>0.887374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.050100</td>\n",
       "      <td>0.594769</td>\n",
       "      <td>0.897819</td>\n",
       "      <td>0.890001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.049000</td>\n",
       "      <td>0.628860</td>\n",
       "      <td>0.895614</td>\n",
       "      <td>0.886829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.038300</td>\n",
       "      <td>0.627635</td>\n",
       "      <td>0.892183</td>\n",
       "      <td>0.885398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.042500</td>\n",
       "      <td>0.608825</td>\n",
       "      <td>0.895124</td>\n",
       "      <td>0.888208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.037200</td>\n",
       "      <td>0.643363</td>\n",
       "      <td>0.897574</td>\n",
       "      <td>0.889343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.028500</td>\n",
       "      <td>0.695335</td>\n",
       "      <td>0.897574</td>\n",
       "      <td>0.889471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.028100</td>\n",
       "      <td>0.771604</td>\n",
       "      <td>0.896349</td>\n",
       "      <td>0.887971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.028000</td>\n",
       "      <td>0.695140</td>\n",
       "      <td>0.893408</td>\n",
       "      <td>0.887026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.029000</td>\n",
       "      <td>0.722891</td>\n",
       "      <td>0.897084</td>\n",
       "      <td>0.889410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.028900</td>\n",
       "      <td>0.743434</td>\n",
       "      <td>0.897574</td>\n",
       "      <td>0.888822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.026000</td>\n",
       "      <td>0.698335</td>\n",
       "      <td>0.897329</td>\n",
       "      <td>0.889504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.026400</td>\n",
       "      <td>0.659571</td>\n",
       "      <td>0.895859</td>\n",
       "      <td>0.888536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.026100</td>\n",
       "      <td>0.719615</td>\n",
       "      <td>0.900270</td>\n",
       "      <td>0.892608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.022100</td>\n",
       "      <td>0.755806</td>\n",
       "      <td>0.899044</td>\n",
       "      <td>0.891057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.023500</td>\n",
       "      <td>0.736969</td>\n",
       "      <td>0.899044</td>\n",
       "      <td>0.891517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.023400</td>\n",
       "      <td>0.741992</td>\n",
       "      <td>0.897574</td>\n",
       "      <td>0.890119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.020900</td>\n",
       "      <td>0.742270</td>\n",
       "      <td>0.897329</td>\n",
       "      <td>0.889750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.022700</td>\n",
       "      <td>0.756822</td>\n",
       "      <td>0.898799</td>\n",
       "      <td>0.891329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.756598</td>\n",
       "      <td>0.898064</td>\n",
       "      <td>0.890403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alger-ia/dziribert, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf940781dcdd4feaa7c41e0ad812c7ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16321 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d82dd956f5d94b7798bc3785804173ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4081 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3072' max='3072' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3072/3072 04:51, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.367800</td>\n",
       "      <td>0.307333</td>\n",
       "      <td>0.868905</td>\n",
       "      <td>0.861293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.293600</td>\n",
       "      <td>0.271078</td>\n",
       "      <td>0.889488</td>\n",
       "      <td>0.880063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.245300</td>\n",
       "      <td>0.282969</td>\n",
       "      <td>0.889733</td>\n",
       "      <td>0.879124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.149100</td>\n",
       "      <td>0.312378</td>\n",
       "      <td>0.891448</td>\n",
       "      <td>0.883878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.155400</td>\n",
       "      <td>0.290761</td>\n",
       "      <td>0.890958</td>\n",
       "      <td>0.885331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.090400</td>\n",
       "      <td>0.371106</td>\n",
       "      <td>0.895859</td>\n",
       "      <td>0.887985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.089400</td>\n",
       "      <td>0.402433</td>\n",
       "      <td>0.895614</td>\n",
       "      <td>0.887258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.112800</td>\n",
       "      <td>0.557872</td>\n",
       "      <td>0.894389</td>\n",
       "      <td>0.887926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.066900</td>\n",
       "      <td>0.443131</td>\n",
       "      <td>0.895124</td>\n",
       "      <td>0.885644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.070900</td>\n",
       "      <td>0.525065</td>\n",
       "      <td>0.899779</td>\n",
       "      <td>0.892292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.059500</td>\n",
       "      <td>0.530728</td>\n",
       "      <td>0.896349</td>\n",
       "      <td>0.887374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.050100</td>\n",
       "      <td>0.594769</td>\n",
       "      <td>0.897819</td>\n",
       "      <td>0.890001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.049000</td>\n",
       "      <td>0.628860</td>\n",
       "      <td>0.895614</td>\n",
       "      <td>0.886829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.038300</td>\n",
       "      <td>0.627635</td>\n",
       "      <td>0.892183</td>\n",
       "      <td>0.885398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.042500</td>\n",
       "      <td>0.608825</td>\n",
       "      <td>0.895124</td>\n",
       "      <td>0.888208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.037200</td>\n",
       "      <td>0.643363</td>\n",
       "      <td>0.897574</td>\n",
       "      <td>0.889343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.028500</td>\n",
       "      <td>0.695335</td>\n",
       "      <td>0.897574</td>\n",
       "      <td>0.889471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.028100</td>\n",
       "      <td>0.771604</td>\n",
       "      <td>0.896349</td>\n",
       "      <td>0.887971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.028000</td>\n",
       "      <td>0.695140</td>\n",
       "      <td>0.893408</td>\n",
       "      <td>0.887026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.029000</td>\n",
       "      <td>0.722891</td>\n",
       "      <td>0.897084</td>\n",
       "      <td>0.889410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.028900</td>\n",
       "      <td>0.743434</td>\n",
       "      <td>0.897574</td>\n",
       "      <td>0.888822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.026000</td>\n",
       "      <td>0.698335</td>\n",
       "      <td>0.897329</td>\n",
       "      <td>0.889504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.026400</td>\n",
       "      <td>0.659571</td>\n",
       "      <td>0.895859</td>\n",
       "      <td>0.888536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.026100</td>\n",
       "      <td>0.719615</td>\n",
       "      <td>0.900270</td>\n",
       "      <td>0.892608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.022100</td>\n",
       "      <td>0.755806</td>\n",
       "      <td>0.899044</td>\n",
       "      <td>0.891057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.023500</td>\n",
       "      <td>0.736969</td>\n",
       "      <td>0.899044</td>\n",
       "      <td>0.891517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.023400</td>\n",
       "      <td>0.741992</td>\n",
       "      <td>0.897574</td>\n",
       "      <td>0.890119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.020900</td>\n",
       "      <td>0.742270</td>\n",
       "      <td>0.897329</td>\n",
       "      <td>0.889750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.022700</td>\n",
       "      <td>0.756822</td>\n",
       "      <td>0.898799</td>\n",
       "      <td>0.891329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.756598</td>\n",
       "      <td>0.898064</td>\n",
       "      <td>0.890403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alger-ia/dziribert, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e62fb97a00404e19b65d4f657c6928f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16321 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "392434b8e8a04d22939c34315f558724",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4081 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3072' max='3072' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3072/3072 04:50, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.385700</td>\n",
       "      <td>0.295028</td>\n",
       "      <td>0.875031</td>\n",
       "      <td>0.868232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.303900</td>\n",
       "      <td>0.278812</td>\n",
       "      <td>0.882872</td>\n",
       "      <td>0.872557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.225300</td>\n",
       "      <td>0.315107</td>\n",
       "      <td>0.891203</td>\n",
       "      <td>0.883380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.308894</td>\n",
       "      <td>0.891203</td>\n",
       "      <td>0.884327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.151700</td>\n",
       "      <td>0.299050</td>\n",
       "      <td>0.893408</td>\n",
       "      <td>0.884860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.079700</td>\n",
       "      <td>0.431283</td>\n",
       "      <td>0.893654</td>\n",
       "      <td>0.885597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.093600</td>\n",
       "      <td>0.436809</td>\n",
       "      <td>0.899534</td>\n",
       "      <td>0.892542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.079100</td>\n",
       "      <td>0.585511</td>\n",
       "      <td>0.894634</td>\n",
       "      <td>0.888475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.059800</td>\n",
       "      <td>0.589352</td>\n",
       "      <td>0.893654</td>\n",
       "      <td>0.887815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.064900</td>\n",
       "      <td>0.479300</td>\n",
       "      <td>0.894389</td>\n",
       "      <td>0.886115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.049600</td>\n",
       "      <td>0.612758</td>\n",
       "      <td>0.897819</td>\n",
       "      <td>0.890516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.038900</td>\n",
       "      <td>0.559630</td>\n",
       "      <td>0.893408</td>\n",
       "      <td>0.887356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.053100</td>\n",
       "      <td>0.625068</td>\n",
       "      <td>0.894144</td>\n",
       "      <td>0.887708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.030900</td>\n",
       "      <td>0.660117</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.889196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.032500</td>\n",
       "      <td>0.798282</td>\n",
       "      <td>0.895124</td>\n",
       "      <td>0.887459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.035100</td>\n",
       "      <td>0.712650</td>\n",
       "      <td>0.893408</td>\n",
       "      <td>0.885413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.034400</td>\n",
       "      <td>0.609254</td>\n",
       "      <td>0.895124</td>\n",
       "      <td>0.888121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.027400</td>\n",
       "      <td>0.706809</td>\n",
       "      <td>0.892673</td>\n",
       "      <td>0.885567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.027700</td>\n",
       "      <td>0.700455</td>\n",
       "      <td>0.894389</td>\n",
       "      <td>0.887233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.025800</td>\n",
       "      <td>0.702445</td>\n",
       "      <td>0.895369</td>\n",
       "      <td>0.888599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.020400</td>\n",
       "      <td>0.733640</td>\n",
       "      <td>0.896839</td>\n",
       "      <td>0.889791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.022500</td>\n",
       "      <td>0.771096</td>\n",
       "      <td>0.895369</td>\n",
       "      <td>0.888571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.021900</td>\n",
       "      <td>0.768833</td>\n",
       "      <td>0.898064</td>\n",
       "      <td>0.890882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.016700</td>\n",
       "      <td>0.788956</td>\n",
       "      <td>0.897329</td>\n",
       "      <td>0.890228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.021100</td>\n",
       "      <td>0.781316</td>\n",
       "      <td>0.896349</td>\n",
       "      <td>0.889500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.022300</td>\n",
       "      <td>0.781002</td>\n",
       "      <td>0.897329</td>\n",
       "      <td>0.890517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.017100</td>\n",
       "      <td>0.803933</td>\n",
       "      <td>0.896349</td>\n",
       "      <td>0.889500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.020200</td>\n",
       "      <td>0.807550</td>\n",
       "      <td>0.897084</td>\n",
       "      <td>0.890097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.017300</td>\n",
       "      <td>0.814458</td>\n",
       "      <td>0.896594</td>\n",
       "      <td>0.889661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.021300</td>\n",
       "      <td>0.812975</td>\n",
       "      <td>0.896594</td>\n",
       "      <td>0.889946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alger-ia/dziribert, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92bd4b4122b7456aa134f39092c37bcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16321 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baebb44956714d07955c1bb9d8b1c768",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4081 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3072' max='3072' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3072/3072 04:50, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.385700</td>\n",
       "      <td>0.295028</td>\n",
       "      <td>0.875031</td>\n",
       "      <td>0.868232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.303900</td>\n",
       "      <td>0.278812</td>\n",
       "      <td>0.882872</td>\n",
       "      <td>0.872557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.225300</td>\n",
       "      <td>0.315107</td>\n",
       "      <td>0.891203</td>\n",
       "      <td>0.883380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.308894</td>\n",
       "      <td>0.891203</td>\n",
       "      <td>0.884327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.151700</td>\n",
       "      <td>0.299050</td>\n",
       "      <td>0.893408</td>\n",
       "      <td>0.884860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.079700</td>\n",
       "      <td>0.431283</td>\n",
       "      <td>0.893654</td>\n",
       "      <td>0.885597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.093600</td>\n",
       "      <td>0.436809</td>\n",
       "      <td>0.899534</td>\n",
       "      <td>0.892542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.079100</td>\n",
       "      <td>0.585511</td>\n",
       "      <td>0.894634</td>\n",
       "      <td>0.888475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.059800</td>\n",
       "      <td>0.589352</td>\n",
       "      <td>0.893654</td>\n",
       "      <td>0.887815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.064900</td>\n",
       "      <td>0.479300</td>\n",
       "      <td>0.894389</td>\n",
       "      <td>0.886115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.049600</td>\n",
       "      <td>0.612758</td>\n",
       "      <td>0.897819</td>\n",
       "      <td>0.890516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.038900</td>\n",
       "      <td>0.559630</td>\n",
       "      <td>0.893408</td>\n",
       "      <td>0.887356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.053100</td>\n",
       "      <td>0.625068</td>\n",
       "      <td>0.894144</td>\n",
       "      <td>0.887708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.030900</td>\n",
       "      <td>0.660117</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.889196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.032500</td>\n",
       "      <td>0.798282</td>\n",
       "      <td>0.895124</td>\n",
       "      <td>0.887459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.035100</td>\n",
       "      <td>0.712650</td>\n",
       "      <td>0.893408</td>\n",
       "      <td>0.885413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.034400</td>\n",
       "      <td>0.609254</td>\n",
       "      <td>0.895124</td>\n",
       "      <td>0.888121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.027400</td>\n",
       "      <td>0.706809</td>\n",
       "      <td>0.892673</td>\n",
       "      <td>0.885567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.027700</td>\n",
       "      <td>0.700455</td>\n",
       "      <td>0.894389</td>\n",
       "      <td>0.887233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.025800</td>\n",
       "      <td>0.702445</td>\n",
       "      <td>0.895369</td>\n",
       "      <td>0.888599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.020400</td>\n",
       "      <td>0.733640</td>\n",
       "      <td>0.896839</td>\n",
       "      <td>0.889791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.022500</td>\n",
       "      <td>0.771096</td>\n",
       "      <td>0.895369</td>\n",
       "      <td>0.888571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.021900</td>\n",
       "      <td>0.768833</td>\n",
       "      <td>0.898064</td>\n",
       "      <td>0.890882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.016700</td>\n",
       "      <td>0.788956</td>\n",
       "      <td>0.897329</td>\n",
       "      <td>0.890228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.021100</td>\n",
       "      <td>0.781316</td>\n",
       "      <td>0.896349</td>\n",
       "      <td>0.889500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.022300</td>\n",
       "      <td>0.781002</td>\n",
       "      <td>0.897329</td>\n",
       "      <td>0.890517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.017100</td>\n",
       "      <td>0.803933</td>\n",
       "      <td>0.896349</td>\n",
       "      <td>0.889500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.020200</td>\n",
       "      <td>0.807550</td>\n",
       "      <td>0.897084</td>\n",
       "      <td>0.890097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.017300</td>\n",
       "      <td>0.814458</td>\n",
       "      <td>0.896594</td>\n",
       "      <td>0.889661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.021300</td>\n",
       "      <td>0.812975</td>\n",
       "      <td>0.896594</td>\n",
       "      <td>0.889946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alger-ia/dziribert, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82837856b5864570947d0fcd41849122",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16321 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cfd2df033664bf7ac23056cdaa4b65c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4081 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3072' max='3072' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3072/3072 04:51, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.385700</td>\n",
       "      <td>0.295028</td>\n",
       "      <td>0.875031</td>\n",
       "      <td>0.868232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.303900</td>\n",
       "      <td>0.278812</td>\n",
       "      <td>0.882872</td>\n",
       "      <td>0.872557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.225300</td>\n",
       "      <td>0.315107</td>\n",
       "      <td>0.891203</td>\n",
       "      <td>0.883380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.308894</td>\n",
       "      <td>0.891203</td>\n",
       "      <td>0.884327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.151700</td>\n",
       "      <td>0.299050</td>\n",
       "      <td>0.893408</td>\n",
       "      <td>0.884860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.079700</td>\n",
       "      <td>0.431283</td>\n",
       "      <td>0.893654</td>\n",
       "      <td>0.885597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.093600</td>\n",
       "      <td>0.436809</td>\n",
       "      <td>0.899534</td>\n",
       "      <td>0.892542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.079100</td>\n",
       "      <td>0.585511</td>\n",
       "      <td>0.894634</td>\n",
       "      <td>0.888475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.059800</td>\n",
       "      <td>0.589352</td>\n",
       "      <td>0.893654</td>\n",
       "      <td>0.887815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.064900</td>\n",
       "      <td>0.479300</td>\n",
       "      <td>0.894389</td>\n",
       "      <td>0.886115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.049600</td>\n",
       "      <td>0.612758</td>\n",
       "      <td>0.897819</td>\n",
       "      <td>0.890516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.038900</td>\n",
       "      <td>0.559630</td>\n",
       "      <td>0.893408</td>\n",
       "      <td>0.887356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.053100</td>\n",
       "      <td>0.625068</td>\n",
       "      <td>0.894144</td>\n",
       "      <td>0.887708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.030900</td>\n",
       "      <td>0.660117</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.889196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.032500</td>\n",
       "      <td>0.798282</td>\n",
       "      <td>0.895124</td>\n",
       "      <td>0.887459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.035100</td>\n",
       "      <td>0.712650</td>\n",
       "      <td>0.893408</td>\n",
       "      <td>0.885413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.034400</td>\n",
       "      <td>0.609254</td>\n",
       "      <td>0.895124</td>\n",
       "      <td>0.888121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.027400</td>\n",
       "      <td>0.706809</td>\n",
       "      <td>0.892673</td>\n",
       "      <td>0.885567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.027700</td>\n",
       "      <td>0.700455</td>\n",
       "      <td>0.894389</td>\n",
       "      <td>0.887233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.025800</td>\n",
       "      <td>0.702445</td>\n",
       "      <td>0.895369</td>\n",
       "      <td>0.888599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.020400</td>\n",
       "      <td>0.733640</td>\n",
       "      <td>0.896839</td>\n",
       "      <td>0.889791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.022500</td>\n",
       "      <td>0.771096</td>\n",
       "      <td>0.895369</td>\n",
       "      <td>0.888571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.021900</td>\n",
       "      <td>0.768833</td>\n",
       "      <td>0.898064</td>\n",
       "      <td>0.890882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.016700</td>\n",
       "      <td>0.788956</td>\n",
       "      <td>0.897329</td>\n",
       "      <td>0.890228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.021100</td>\n",
       "      <td>0.781316</td>\n",
       "      <td>0.896349</td>\n",
       "      <td>0.889500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.022300</td>\n",
       "      <td>0.781002</td>\n",
       "      <td>0.897329</td>\n",
       "      <td>0.890517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.017100</td>\n",
       "      <td>0.803933</td>\n",
       "      <td>0.896349</td>\n",
       "      <td>0.889500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.020200</td>\n",
       "      <td>0.807550</td>\n",
       "      <td>0.897084</td>\n",
       "      <td>0.890097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.017300</td>\n",
       "      <td>0.814458</td>\n",
       "      <td>0.896594</td>\n",
       "      <td>0.889661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.021300</td>\n",
       "      <td>0.812975</td>\n",
       "      <td>0.896594</td>\n",
       "      <td>0.889946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 16321\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 4081\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SI2M-Lab/DarijaBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SI2M-Lab/DarijaBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cc42fb48f4b4ee0a8279f0cf9dbfeaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16321 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dfe660474f94b72a885f40c1a69b1c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4081 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3072' max='3072' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3072/3072 05:00, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.423300</td>\n",
       "      <td>0.342401</td>\n",
       "      <td>0.847096</td>\n",
       "      <td>0.824049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.332200</td>\n",
       "      <td>0.323897</td>\n",
       "      <td>0.871600</td>\n",
       "      <td>0.858470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.282400</td>\n",
       "      <td>0.380295</td>\n",
       "      <td>0.847096</td>\n",
       "      <td>0.842583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.224100</td>\n",
       "      <td>0.331496</td>\n",
       "      <td>0.880176</td>\n",
       "      <td>0.871613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.212200</td>\n",
       "      <td>0.331454</td>\n",
       "      <td>0.873315</td>\n",
       "      <td>0.866281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.134200</td>\n",
       "      <td>0.363227</td>\n",
       "      <td>0.883607</td>\n",
       "      <td>0.874272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.136600</td>\n",
       "      <td>0.357502</td>\n",
       "      <td>0.881647</td>\n",
       "      <td>0.875681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.117300</td>\n",
       "      <td>0.512637</td>\n",
       "      <td>0.878951</td>\n",
       "      <td>0.873367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.088600</td>\n",
       "      <td>0.478263</td>\n",
       "      <td>0.879196</td>\n",
       "      <td>0.872992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.097400</td>\n",
       "      <td>0.421605</td>\n",
       "      <td>0.884832</td>\n",
       "      <td>0.877302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.450955</td>\n",
       "      <td>0.878216</td>\n",
       "      <td>0.872334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>0.485781</td>\n",
       "      <td>0.882382</td>\n",
       "      <td>0.875718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.073500</td>\n",
       "      <td>0.558635</td>\n",
       "      <td>0.887037</td>\n",
       "      <td>0.881581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.052200</td>\n",
       "      <td>0.577788</td>\n",
       "      <td>0.887283</td>\n",
       "      <td>0.881178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.059600</td>\n",
       "      <td>0.472186</td>\n",
       "      <td>0.872825</td>\n",
       "      <td>0.867769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.047400</td>\n",
       "      <td>0.621845</td>\n",
       "      <td>0.883852</td>\n",
       "      <td>0.877789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.039900</td>\n",
       "      <td>0.585905</td>\n",
       "      <td>0.889243</td>\n",
       "      <td>0.882596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.049600</td>\n",
       "      <td>0.676070</td>\n",
       "      <td>0.889978</td>\n",
       "      <td>0.882708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.031300</td>\n",
       "      <td>0.630300</td>\n",
       "      <td>0.886057</td>\n",
       "      <td>0.880012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.034600</td>\n",
       "      <td>0.619565</td>\n",
       "      <td>0.890223</td>\n",
       "      <td>0.882677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.028500</td>\n",
       "      <td>0.730052</td>\n",
       "      <td>0.888508</td>\n",
       "      <td>0.881832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.036300</td>\n",
       "      <td>0.667093</td>\n",
       "      <td>0.889978</td>\n",
       "      <td>0.882890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.030500</td>\n",
       "      <td>0.640015</td>\n",
       "      <td>0.888998</td>\n",
       "      <td>0.882205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.027400</td>\n",
       "      <td>0.703943</td>\n",
       "      <td>0.890958</td>\n",
       "      <td>0.883354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.029500</td>\n",
       "      <td>0.683960</td>\n",
       "      <td>0.890713</td>\n",
       "      <td>0.883385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.026400</td>\n",
       "      <td>0.667618</td>\n",
       "      <td>0.893163</td>\n",
       "      <td>0.885261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.022700</td>\n",
       "      <td>0.743321</td>\n",
       "      <td>0.890958</td>\n",
       "      <td>0.883509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.027300</td>\n",
       "      <td>0.692755</td>\n",
       "      <td>0.890468</td>\n",
       "      <td>0.883231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.025400</td>\n",
       "      <td>0.691605</td>\n",
       "      <td>0.890713</td>\n",
       "      <td>0.883835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.022500</td>\n",
       "      <td>0.687356</td>\n",
       "      <td>0.889978</td>\n",
       "      <td>0.883390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SI2M-Lab/DarijaBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SI2M-Lab/DarijaBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faefa02db2f548f5b1bf9fef5dbe1fa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16321 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "439159fa495f4a12ab3404ef90037602",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4081 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3072' max='3072' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3072/3072 05:02, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.423300</td>\n",
       "      <td>0.342401</td>\n",
       "      <td>0.847096</td>\n",
       "      <td>0.824049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.332200</td>\n",
       "      <td>0.323897</td>\n",
       "      <td>0.871600</td>\n",
       "      <td>0.858470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.282400</td>\n",
       "      <td>0.380295</td>\n",
       "      <td>0.847096</td>\n",
       "      <td>0.842583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.224100</td>\n",
       "      <td>0.331496</td>\n",
       "      <td>0.880176</td>\n",
       "      <td>0.871613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.212200</td>\n",
       "      <td>0.331454</td>\n",
       "      <td>0.873315</td>\n",
       "      <td>0.866281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.134200</td>\n",
       "      <td>0.363227</td>\n",
       "      <td>0.883607</td>\n",
       "      <td>0.874272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.136600</td>\n",
       "      <td>0.357502</td>\n",
       "      <td>0.881647</td>\n",
       "      <td>0.875681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.117300</td>\n",
       "      <td>0.512637</td>\n",
       "      <td>0.878951</td>\n",
       "      <td>0.873367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.088600</td>\n",
       "      <td>0.478263</td>\n",
       "      <td>0.879196</td>\n",
       "      <td>0.872992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.097400</td>\n",
       "      <td>0.421605</td>\n",
       "      <td>0.884832</td>\n",
       "      <td>0.877302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.450955</td>\n",
       "      <td>0.878216</td>\n",
       "      <td>0.872334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>0.485781</td>\n",
       "      <td>0.882382</td>\n",
       "      <td>0.875718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.073500</td>\n",
       "      <td>0.558635</td>\n",
       "      <td>0.887037</td>\n",
       "      <td>0.881581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.052200</td>\n",
       "      <td>0.577788</td>\n",
       "      <td>0.887283</td>\n",
       "      <td>0.881178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.059600</td>\n",
       "      <td>0.472186</td>\n",
       "      <td>0.872825</td>\n",
       "      <td>0.867769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.047400</td>\n",
       "      <td>0.621845</td>\n",
       "      <td>0.883852</td>\n",
       "      <td>0.877789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.039900</td>\n",
       "      <td>0.585905</td>\n",
       "      <td>0.889243</td>\n",
       "      <td>0.882596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.049600</td>\n",
       "      <td>0.676070</td>\n",
       "      <td>0.889978</td>\n",
       "      <td>0.882708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.031300</td>\n",
       "      <td>0.630300</td>\n",
       "      <td>0.886057</td>\n",
       "      <td>0.880012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.034600</td>\n",
       "      <td>0.619565</td>\n",
       "      <td>0.890223</td>\n",
       "      <td>0.882677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.028500</td>\n",
       "      <td>0.730052</td>\n",
       "      <td>0.888508</td>\n",
       "      <td>0.881832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.036300</td>\n",
       "      <td>0.667093</td>\n",
       "      <td>0.889978</td>\n",
       "      <td>0.882890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.030500</td>\n",
       "      <td>0.640015</td>\n",
       "      <td>0.888998</td>\n",
       "      <td>0.882205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.027400</td>\n",
       "      <td>0.703943</td>\n",
       "      <td>0.890958</td>\n",
       "      <td>0.883354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.029500</td>\n",
       "      <td>0.683960</td>\n",
       "      <td>0.890713</td>\n",
       "      <td>0.883385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.026400</td>\n",
       "      <td>0.667618</td>\n",
       "      <td>0.893163</td>\n",
       "      <td>0.885261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.022700</td>\n",
       "      <td>0.743321</td>\n",
       "      <td>0.890958</td>\n",
       "      <td>0.883509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.027300</td>\n",
       "      <td>0.692755</td>\n",
       "      <td>0.890468</td>\n",
       "      <td>0.883231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.025400</td>\n",
       "      <td>0.691605</td>\n",
       "      <td>0.890713</td>\n",
       "      <td>0.883835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.022500</td>\n",
       "      <td>0.687356</td>\n",
       "      <td>0.889978</td>\n",
       "      <td>0.883390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SI2M-Lab/DarijaBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SI2M-Lab/DarijaBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "559c1b2c8550493ca444d1caf2eadb10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16321 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00b3efac70c24a18843e13d70294048e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4081 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3072' max='3072' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3072/3072 05:00, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.423300</td>\n",
       "      <td>0.342401</td>\n",
       "      <td>0.847096</td>\n",
       "      <td>0.824049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.332200</td>\n",
       "      <td>0.323897</td>\n",
       "      <td>0.871600</td>\n",
       "      <td>0.858470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.282400</td>\n",
       "      <td>0.380295</td>\n",
       "      <td>0.847096</td>\n",
       "      <td>0.842583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.224100</td>\n",
       "      <td>0.331496</td>\n",
       "      <td>0.880176</td>\n",
       "      <td>0.871613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.212200</td>\n",
       "      <td>0.331454</td>\n",
       "      <td>0.873315</td>\n",
       "      <td>0.866281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.134200</td>\n",
       "      <td>0.363227</td>\n",
       "      <td>0.883607</td>\n",
       "      <td>0.874272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.136600</td>\n",
       "      <td>0.357502</td>\n",
       "      <td>0.881647</td>\n",
       "      <td>0.875681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.117300</td>\n",
       "      <td>0.512637</td>\n",
       "      <td>0.878951</td>\n",
       "      <td>0.873367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.088600</td>\n",
       "      <td>0.478263</td>\n",
       "      <td>0.879196</td>\n",
       "      <td>0.872992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.097400</td>\n",
       "      <td>0.421605</td>\n",
       "      <td>0.884832</td>\n",
       "      <td>0.877302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.450955</td>\n",
       "      <td>0.878216</td>\n",
       "      <td>0.872334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>0.485781</td>\n",
       "      <td>0.882382</td>\n",
       "      <td>0.875718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.073500</td>\n",
       "      <td>0.558635</td>\n",
       "      <td>0.887037</td>\n",
       "      <td>0.881581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.052200</td>\n",
       "      <td>0.577788</td>\n",
       "      <td>0.887283</td>\n",
       "      <td>0.881178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.059600</td>\n",
       "      <td>0.472186</td>\n",
       "      <td>0.872825</td>\n",
       "      <td>0.867769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.047400</td>\n",
       "      <td>0.621845</td>\n",
       "      <td>0.883852</td>\n",
       "      <td>0.877789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.039900</td>\n",
       "      <td>0.585905</td>\n",
       "      <td>0.889243</td>\n",
       "      <td>0.882596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.049600</td>\n",
       "      <td>0.676070</td>\n",
       "      <td>0.889978</td>\n",
       "      <td>0.882708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.031300</td>\n",
       "      <td>0.630300</td>\n",
       "      <td>0.886057</td>\n",
       "      <td>0.880012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.034600</td>\n",
       "      <td>0.619565</td>\n",
       "      <td>0.890223</td>\n",
       "      <td>0.882677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.028500</td>\n",
       "      <td>0.730052</td>\n",
       "      <td>0.888508</td>\n",
       "      <td>0.881832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.036300</td>\n",
       "      <td>0.667093</td>\n",
       "      <td>0.889978</td>\n",
       "      <td>0.882890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.030500</td>\n",
       "      <td>0.640015</td>\n",
       "      <td>0.888998</td>\n",
       "      <td>0.882205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.027400</td>\n",
       "      <td>0.703943</td>\n",
       "      <td>0.890958</td>\n",
       "      <td>0.883354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.029500</td>\n",
       "      <td>0.683960</td>\n",
       "      <td>0.890713</td>\n",
       "      <td>0.883385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.026400</td>\n",
       "      <td>0.667618</td>\n",
       "      <td>0.893163</td>\n",
       "      <td>0.885261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.022700</td>\n",
       "      <td>0.743321</td>\n",
       "      <td>0.890958</td>\n",
       "      <td>0.883509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.027300</td>\n",
       "      <td>0.692755</td>\n",
       "      <td>0.890468</td>\n",
       "      <td>0.883231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.025400</td>\n",
       "      <td>0.691605</td>\n",
       "      <td>0.890713</td>\n",
       "      <td>0.883835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.022500</td>\n",
       "      <td>0.687356</td>\n",
       "      <td>0.889978</td>\n",
       "      <td>0.883390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SI2M-Lab/DarijaBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SI2M-Lab/DarijaBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "233cd39111764387beb29b1c99c9c7c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16321 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50d5c042911e4f41931e9bfb2261492b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4081 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3072' max='3072' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3072/3072 05:00, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.419400</td>\n",
       "      <td>0.323133</td>\n",
       "      <td>0.859838</td>\n",
       "      <td>0.849678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.325500</td>\n",
       "      <td>0.316781</td>\n",
       "      <td>0.871355</td>\n",
       "      <td>0.859488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.283700</td>\n",
       "      <td>0.328460</td>\n",
       "      <td>0.885077</td>\n",
       "      <td>0.873799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.209800</td>\n",
       "      <td>0.307214</td>\n",
       "      <td>0.884342</td>\n",
       "      <td>0.875958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.213000</td>\n",
       "      <td>0.286784</td>\n",
       "      <td>0.894144</td>\n",
       "      <td>0.885769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.134600</td>\n",
       "      <td>0.330354</td>\n",
       "      <td>0.888753</td>\n",
       "      <td>0.881137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.130200</td>\n",
       "      <td>0.303129</td>\n",
       "      <td>0.889978</td>\n",
       "      <td>0.882430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.123600</td>\n",
       "      <td>0.396839</td>\n",
       "      <td>0.889488</td>\n",
       "      <td>0.881264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.092300</td>\n",
       "      <td>0.384366</td>\n",
       "      <td>0.889978</td>\n",
       "      <td>0.881257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.093900</td>\n",
       "      <td>0.360093</td>\n",
       "      <td>0.891448</td>\n",
       "      <td>0.883909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.072800</td>\n",
       "      <td>0.478092</td>\n",
       "      <td>0.894144</td>\n",
       "      <td>0.886060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.068800</td>\n",
       "      <td>0.567457</td>\n",
       "      <td>0.892428</td>\n",
       "      <td>0.883834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.067900</td>\n",
       "      <td>0.668321</td>\n",
       "      <td>0.890468</td>\n",
       "      <td>0.880438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.049900</td>\n",
       "      <td>0.666865</td>\n",
       "      <td>0.882382</td>\n",
       "      <td>0.875836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.056200</td>\n",
       "      <td>0.573407</td>\n",
       "      <td>0.860573</td>\n",
       "      <td>0.855860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.052400</td>\n",
       "      <td>0.539216</td>\n",
       "      <td>0.893899</td>\n",
       "      <td>0.885651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.047900</td>\n",
       "      <td>0.585647</td>\n",
       "      <td>0.889488</td>\n",
       "      <td>0.879847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.031500</td>\n",
       "      <td>0.647053</td>\n",
       "      <td>0.897574</td>\n",
       "      <td>0.888822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.037000</td>\n",
       "      <td>0.613013</td>\n",
       "      <td>0.891938</td>\n",
       "      <td>0.883961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.040100</td>\n",
       "      <td>0.621520</td>\n",
       "      <td>0.890223</td>\n",
       "      <td>0.883432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.035400</td>\n",
       "      <td>0.662828</td>\n",
       "      <td>0.892428</td>\n",
       "      <td>0.884001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.034000</td>\n",
       "      <td>0.615997</td>\n",
       "      <td>0.896839</td>\n",
       "      <td>0.888630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.025800</td>\n",
       "      <td>0.666240</td>\n",
       "      <td>0.893163</td>\n",
       "      <td>0.885166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.032700</td>\n",
       "      <td>0.737624</td>\n",
       "      <td>0.892918</td>\n",
       "      <td>0.884595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.023400</td>\n",
       "      <td>0.697609</td>\n",
       "      <td>0.895369</td>\n",
       "      <td>0.887363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.027200</td>\n",
       "      <td>0.701018</td>\n",
       "      <td>0.894879</td>\n",
       "      <td>0.886867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.024400</td>\n",
       "      <td>0.731127</td>\n",
       "      <td>0.894879</td>\n",
       "      <td>0.886899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.026200</td>\n",
       "      <td>0.711138</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.887723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.027200</td>\n",
       "      <td>0.737001</td>\n",
       "      <td>0.893408</td>\n",
       "      <td>0.885188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.022000</td>\n",
       "      <td>0.740921</td>\n",
       "      <td>0.895369</td>\n",
       "      <td>0.887107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SI2M-Lab/DarijaBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SI2M-Lab/DarijaBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "165f703b514c41f3922e0fdba28a320c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16321 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03c2c180edd749ceafdebb840ce590dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4081 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3072' max='3072' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3072/3072 05:01, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.419400</td>\n",
       "      <td>0.323133</td>\n",
       "      <td>0.859838</td>\n",
       "      <td>0.849678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.325500</td>\n",
       "      <td>0.316781</td>\n",
       "      <td>0.871355</td>\n",
       "      <td>0.859488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.283700</td>\n",
       "      <td>0.328460</td>\n",
       "      <td>0.885077</td>\n",
       "      <td>0.873799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.209800</td>\n",
       "      <td>0.307214</td>\n",
       "      <td>0.884342</td>\n",
       "      <td>0.875958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.213000</td>\n",
       "      <td>0.286784</td>\n",
       "      <td>0.894144</td>\n",
       "      <td>0.885769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.134600</td>\n",
       "      <td>0.330354</td>\n",
       "      <td>0.888753</td>\n",
       "      <td>0.881137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.130200</td>\n",
       "      <td>0.303129</td>\n",
       "      <td>0.889978</td>\n",
       "      <td>0.882430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.123600</td>\n",
       "      <td>0.396839</td>\n",
       "      <td>0.889488</td>\n",
       "      <td>0.881264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.092300</td>\n",
       "      <td>0.384366</td>\n",
       "      <td>0.889978</td>\n",
       "      <td>0.881257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.093900</td>\n",
       "      <td>0.360093</td>\n",
       "      <td>0.891448</td>\n",
       "      <td>0.883909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.072800</td>\n",
       "      <td>0.478092</td>\n",
       "      <td>0.894144</td>\n",
       "      <td>0.886060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.068800</td>\n",
       "      <td>0.567457</td>\n",
       "      <td>0.892428</td>\n",
       "      <td>0.883834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.067900</td>\n",
       "      <td>0.668321</td>\n",
       "      <td>0.890468</td>\n",
       "      <td>0.880438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.049900</td>\n",
       "      <td>0.666865</td>\n",
       "      <td>0.882382</td>\n",
       "      <td>0.875836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.056200</td>\n",
       "      <td>0.573407</td>\n",
       "      <td>0.860573</td>\n",
       "      <td>0.855860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.052400</td>\n",
       "      <td>0.539216</td>\n",
       "      <td>0.893899</td>\n",
       "      <td>0.885651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.047900</td>\n",
       "      <td>0.585647</td>\n",
       "      <td>0.889488</td>\n",
       "      <td>0.879847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.031500</td>\n",
       "      <td>0.647053</td>\n",
       "      <td>0.897574</td>\n",
       "      <td>0.888822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.037000</td>\n",
       "      <td>0.613013</td>\n",
       "      <td>0.891938</td>\n",
       "      <td>0.883961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.040100</td>\n",
       "      <td>0.621520</td>\n",
       "      <td>0.890223</td>\n",
       "      <td>0.883432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.035400</td>\n",
       "      <td>0.662828</td>\n",
       "      <td>0.892428</td>\n",
       "      <td>0.884001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.034000</td>\n",
       "      <td>0.615997</td>\n",
       "      <td>0.896839</td>\n",
       "      <td>0.888630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.025800</td>\n",
       "      <td>0.666240</td>\n",
       "      <td>0.893163</td>\n",
       "      <td>0.885166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.032700</td>\n",
       "      <td>0.737624</td>\n",
       "      <td>0.892918</td>\n",
       "      <td>0.884595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.023400</td>\n",
       "      <td>0.697609</td>\n",
       "      <td>0.895369</td>\n",
       "      <td>0.887363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.027200</td>\n",
       "      <td>0.701018</td>\n",
       "      <td>0.894879</td>\n",
       "      <td>0.886867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.024400</td>\n",
       "      <td>0.731127</td>\n",
       "      <td>0.894879</td>\n",
       "      <td>0.886899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.026200</td>\n",
       "      <td>0.711138</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.887723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.027200</td>\n",
       "      <td>0.737001</td>\n",
       "      <td>0.893408</td>\n",
       "      <td>0.885188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.022000</td>\n",
       "      <td>0.740921</td>\n",
       "      <td>0.895369</td>\n",
       "      <td>0.887107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SI2M-Lab/DarijaBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SI2M-Lab/DarijaBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f112a0cf264d406ebf5444bb44db9d20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16321 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be2df6992eb447aca3a1712a3de22362",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4081 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3072' max='3072' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3072/3072 05:01, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.419400</td>\n",
       "      <td>0.323133</td>\n",
       "      <td>0.859838</td>\n",
       "      <td>0.849678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.325500</td>\n",
       "      <td>0.316781</td>\n",
       "      <td>0.871355</td>\n",
       "      <td>0.859488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.283700</td>\n",
       "      <td>0.328460</td>\n",
       "      <td>0.885077</td>\n",
       "      <td>0.873799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.209800</td>\n",
       "      <td>0.307214</td>\n",
       "      <td>0.884342</td>\n",
       "      <td>0.875958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.213000</td>\n",
       "      <td>0.286784</td>\n",
       "      <td>0.894144</td>\n",
       "      <td>0.885769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.134600</td>\n",
       "      <td>0.330354</td>\n",
       "      <td>0.888753</td>\n",
       "      <td>0.881137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.130200</td>\n",
       "      <td>0.303129</td>\n",
       "      <td>0.889978</td>\n",
       "      <td>0.882430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.123600</td>\n",
       "      <td>0.396839</td>\n",
       "      <td>0.889488</td>\n",
       "      <td>0.881264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.092300</td>\n",
       "      <td>0.384366</td>\n",
       "      <td>0.889978</td>\n",
       "      <td>0.881257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.093900</td>\n",
       "      <td>0.360093</td>\n",
       "      <td>0.891448</td>\n",
       "      <td>0.883909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.072800</td>\n",
       "      <td>0.478092</td>\n",
       "      <td>0.894144</td>\n",
       "      <td>0.886060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.068800</td>\n",
       "      <td>0.567457</td>\n",
       "      <td>0.892428</td>\n",
       "      <td>0.883834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.067900</td>\n",
       "      <td>0.668321</td>\n",
       "      <td>0.890468</td>\n",
       "      <td>0.880438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.049900</td>\n",
       "      <td>0.666865</td>\n",
       "      <td>0.882382</td>\n",
       "      <td>0.875836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.056200</td>\n",
       "      <td>0.573407</td>\n",
       "      <td>0.860573</td>\n",
       "      <td>0.855860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.052400</td>\n",
       "      <td>0.539216</td>\n",
       "      <td>0.893899</td>\n",
       "      <td>0.885651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.047900</td>\n",
       "      <td>0.585647</td>\n",
       "      <td>0.889488</td>\n",
       "      <td>0.879847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.031500</td>\n",
       "      <td>0.647053</td>\n",
       "      <td>0.897574</td>\n",
       "      <td>0.888822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.037000</td>\n",
       "      <td>0.613013</td>\n",
       "      <td>0.891938</td>\n",
       "      <td>0.883961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.040100</td>\n",
       "      <td>0.621520</td>\n",
       "      <td>0.890223</td>\n",
       "      <td>0.883432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.035400</td>\n",
       "      <td>0.662828</td>\n",
       "      <td>0.892428</td>\n",
       "      <td>0.884001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.034000</td>\n",
       "      <td>0.615997</td>\n",
       "      <td>0.896839</td>\n",
       "      <td>0.888630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.025800</td>\n",
       "      <td>0.666240</td>\n",
       "      <td>0.893163</td>\n",
       "      <td>0.885166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.032700</td>\n",
       "      <td>0.737624</td>\n",
       "      <td>0.892918</td>\n",
       "      <td>0.884595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.023400</td>\n",
       "      <td>0.697609</td>\n",
       "      <td>0.895369</td>\n",
       "      <td>0.887363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.027200</td>\n",
       "      <td>0.701018</td>\n",
       "      <td>0.894879</td>\n",
       "      <td>0.886867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.024400</td>\n",
       "      <td>0.731127</td>\n",
       "      <td>0.894879</td>\n",
       "      <td>0.886899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.026200</td>\n",
       "      <td>0.711138</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.887723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.027200</td>\n",
       "      <td>0.737001</td>\n",
       "      <td>0.893408</td>\n",
       "      <td>0.885188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.022000</td>\n",
       "      <td>0.740921</td>\n",
       "      <td>0.895369</td>\n",
       "      <td>0.887107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SI2M-Lab/DarijaBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SI2M-Lab/DarijaBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63b67e5eadd84357a542881c22564091",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16321 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddc22977e5c2484aad3b9b80fef7d2ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4081 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3072' max='3072' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3072/3072 05:01, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.422000</td>\n",
       "      <td>0.361549</td>\n",
       "      <td>0.852732</td>\n",
       "      <td>0.835232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.341800</td>\n",
       "      <td>0.298166</td>\n",
       "      <td>0.873805</td>\n",
       "      <td>0.864490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.273900</td>\n",
       "      <td>0.319191</td>\n",
       "      <td>0.878951</td>\n",
       "      <td>0.868010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.227600</td>\n",
       "      <td>0.324380</td>\n",
       "      <td>0.868660</td>\n",
       "      <td>0.863824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.217300</td>\n",
       "      <td>0.309953</td>\n",
       "      <td>0.888753</td>\n",
       "      <td>0.881692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.137000</td>\n",
       "      <td>0.326012</td>\n",
       "      <td>0.887528</td>\n",
       "      <td>0.880127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.136700</td>\n",
       "      <td>0.388993</td>\n",
       "      <td>0.889243</td>\n",
       "      <td>0.880583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.127800</td>\n",
       "      <td>0.439119</td>\n",
       "      <td>0.891448</td>\n",
       "      <td>0.883690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.090800</td>\n",
       "      <td>0.383065</td>\n",
       "      <td>0.890713</td>\n",
       "      <td>0.884549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.087000</td>\n",
       "      <td>0.427547</td>\n",
       "      <td>0.893408</td>\n",
       "      <td>0.886570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.075700</td>\n",
       "      <td>0.613035</td>\n",
       "      <td>0.887528</td>\n",
       "      <td>0.880939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.068000</td>\n",
       "      <td>0.470684</td>\n",
       "      <td>0.891203</td>\n",
       "      <td>0.883475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.069700</td>\n",
       "      <td>0.614304</td>\n",
       "      <td>0.877971</td>\n",
       "      <td>0.872532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.053100</td>\n",
       "      <td>0.524004</td>\n",
       "      <td>0.892918</td>\n",
       "      <td>0.885663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.054800</td>\n",
       "      <td>0.568736</td>\n",
       "      <td>0.889488</td>\n",
       "      <td>0.882900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.048900</td>\n",
       "      <td>0.634066</td>\n",
       "      <td>0.891448</td>\n",
       "      <td>0.884719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.041800</td>\n",
       "      <td>0.614225</td>\n",
       "      <td>0.888998</td>\n",
       "      <td>0.882351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.045400</td>\n",
       "      <td>0.609026</td>\n",
       "      <td>0.890958</td>\n",
       "      <td>0.884514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.033100</td>\n",
       "      <td>0.684157</td>\n",
       "      <td>0.894144</td>\n",
       "      <td>0.887134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.035600</td>\n",
       "      <td>0.686830</td>\n",
       "      <td>0.893654</td>\n",
       "      <td>0.886990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.024000</td>\n",
       "      <td>0.726568</td>\n",
       "      <td>0.892673</td>\n",
       "      <td>0.886510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.034000</td>\n",
       "      <td>0.683372</td>\n",
       "      <td>0.891448</td>\n",
       "      <td>0.884425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.031400</td>\n",
       "      <td>0.687678</td>\n",
       "      <td>0.889978</td>\n",
       "      <td>0.883702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.022300</td>\n",
       "      <td>0.739417</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.889196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.025900</td>\n",
       "      <td>0.705491</td>\n",
       "      <td>0.895614</td>\n",
       "      <td>0.888960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.031300</td>\n",
       "      <td>0.688733</td>\n",
       "      <td>0.893408</td>\n",
       "      <td>0.886886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.021300</td>\n",
       "      <td>0.731311</td>\n",
       "      <td>0.893899</td>\n",
       "      <td>0.886947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.023500</td>\n",
       "      <td>0.740306</td>\n",
       "      <td>0.895124</td>\n",
       "      <td>0.888524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.021600</td>\n",
       "      <td>0.730605</td>\n",
       "      <td>0.894879</td>\n",
       "      <td>0.887667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.021000</td>\n",
       "      <td>0.741358</td>\n",
       "      <td>0.893899</td>\n",
       "      <td>0.887121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SI2M-Lab/DarijaBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SI2M-Lab/DarijaBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfade3e41a7a48d69fc3f139df3c1531",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16321 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "959c124a98f34cb293d4503ef001c9b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4081 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3072' max='3072' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3072/3072 05:01, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.422000</td>\n",
       "      <td>0.361549</td>\n",
       "      <td>0.852732</td>\n",
       "      <td>0.835232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.341800</td>\n",
       "      <td>0.298166</td>\n",
       "      <td>0.873805</td>\n",
       "      <td>0.864490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.273900</td>\n",
       "      <td>0.319191</td>\n",
       "      <td>0.878951</td>\n",
       "      <td>0.868010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.227600</td>\n",
       "      <td>0.324380</td>\n",
       "      <td>0.868660</td>\n",
       "      <td>0.863824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.217300</td>\n",
       "      <td>0.309953</td>\n",
       "      <td>0.888753</td>\n",
       "      <td>0.881692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.137000</td>\n",
       "      <td>0.326012</td>\n",
       "      <td>0.887528</td>\n",
       "      <td>0.880127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.136700</td>\n",
       "      <td>0.388993</td>\n",
       "      <td>0.889243</td>\n",
       "      <td>0.880583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.127800</td>\n",
       "      <td>0.439119</td>\n",
       "      <td>0.891448</td>\n",
       "      <td>0.883690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.090800</td>\n",
       "      <td>0.383065</td>\n",
       "      <td>0.890713</td>\n",
       "      <td>0.884549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.087000</td>\n",
       "      <td>0.427547</td>\n",
       "      <td>0.893408</td>\n",
       "      <td>0.886570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.075700</td>\n",
       "      <td>0.613035</td>\n",
       "      <td>0.887528</td>\n",
       "      <td>0.880939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.068000</td>\n",
       "      <td>0.470684</td>\n",
       "      <td>0.891203</td>\n",
       "      <td>0.883475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.069700</td>\n",
       "      <td>0.614304</td>\n",
       "      <td>0.877971</td>\n",
       "      <td>0.872532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.053100</td>\n",
       "      <td>0.524004</td>\n",
       "      <td>0.892918</td>\n",
       "      <td>0.885663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.054800</td>\n",
       "      <td>0.568736</td>\n",
       "      <td>0.889488</td>\n",
       "      <td>0.882900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.048900</td>\n",
       "      <td>0.634066</td>\n",
       "      <td>0.891448</td>\n",
       "      <td>0.884719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.041800</td>\n",
       "      <td>0.614225</td>\n",
       "      <td>0.888998</td>\n",
       "      <td>0.882351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.045400</td>\n",
       "      <td>0.609026</td>\n",
       "      <td>0.890958</td>\n",
       "      <td>0.884514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.033100</td>\n",
       "      <td>0.684157</td>\n",
       "      <td>0.894144</td>\n",
       "      <td>0.887134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.035600</td>\n",
       "      <td>0.686830</td>\n",
       "      <td>0.893654</td>\n",
       "      <td>0.886990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.024000</td>\n",
       "      <td>0.726568</td>\n",
       "      <td>0.892673</td>\n",
       "      <td>0.886510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.034000</td>\n",
       "      <td>0.683372</td>\n",
       "      <td>0.891448</td>\n",
       "      <td>0.884425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.031400</td>\n",
       "      <td>0.687678</td>\n",
       "      <td>0.889978</td>\n",
       "      <td>0.883702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.022300</td>\n",
       "      <td>0.739417</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.889196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.025900</td>\n",
       "      <td>0.705491</td>\n",
       "      <td>0.895614</td>\n",
       "      <td>0.888960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.031300</td>\n",
       "      <td>0.688733</td>\n",
       "      <td>0.893408</td>\n",
       "      <td>0.886886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.021300</td>\n",
       "      <td>0.731311</td>\n",
       "      <td>0.893899</td>\n",
       "      <td>0.886947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.023500</td>\n",
       "      <td>0.740306</td>\n",
       "      <td>0.895124</td>\n",
       "      <td>0.888524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.021600</td>\n",
       "      <td>0.730605</td>\n",
       "      <td>0.894879</td>\n",
       "      <td>0.887667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.021000</td>\n",
       "      <td>0.741358</td>\n",
       "      <td>0.893899</td>\n",
       "      <td>0.887121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SI2M-Lab/DarijaBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SI2M-Lab/DarijaBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e998bcadb8d45d093bab2aa7a1f0496",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16321 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7394b7764b64983ac76a782fbd737a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4081 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3072' max='3072' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3072/3072 05:01, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.422000</td>\n",
       "      <td>0.361549</td>\n",
       "      <td>0.852732</td>\n",
       "      <td>0.835232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.341800</td>\n",
       "      <td>0.298166</td>\n",
       "      <td>0.873805</td>\n",
       "      <td>0.864490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.273900</td>\n",
       "      <td>0.319191</td>\n",
       "      <td>0.878951</td>\n",
       "      <td>0.868010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.227600</td>\n",
       "      <td>0.324380</td>\n",
       "      <td>0.868660</td>\n",
       "      <td>0.863824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.217300</td>\n",
       "      <td>0.309953</td>\n",
       "      <td>0.888753</td>\n",
       "      <td>0.881692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.137000</td>\n",
       "      <td>0.326012</td>\n",
       "      <td>0.887528</td>\n",
       "      <td>0.880127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.136700</td>\n",
       "      <td>0.388993</td>\n",
       "      <td>0.889243</td>\n",
       "      <td>0.880583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.127800</td>\n",
       "      <td>0.439119</td>\n",
       "      <td>0.891448</td>\n",
       "      <td>0.883690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.090800</td>\n",
       "      <td>0.383065</td>\n",
       "      <td>0.890713</td>\n",
       "      <td>0.884549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.087000</td>\n",
       "      <td>0.427547</td>\n",
       "      <td>0.893408</td>\n",
       "      <td>0.886570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.075700</td>\n",
       "      <td>0.613035</td>\n",
       "      <td>0.887528</td>\n",
       "      <td>0.880939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.068000</td>\n",
       "      <td>0.470684</td>\n",
       "      <td>0.891203</td>\n",
       "      <td>0.883475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.069700</td>\n",
       "      <td>0.614304</td>\n",
       "      <td>0.877971</td>\n",
       "      <td>0.872532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.053100</td>\n",
       "      <td>0.524004</td>\n",
       "      <td>0.892918</td>\n",
       "      <td>0.885663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.054800</td>\n",
       "      <td>0.568736</td>\n",
       "      <td>0.889488</td>\n",
       "      <td>0.882900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.048900</td>\n",
       "      <td>0.634066</td>\n",
       "      <td>0.891448</td>\n",
       "      <td>0.884719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.041800</td>\n",
       "      <td>0.614225</td>\n",
       "      <td>0.888998</td>\n",
       "      <td>0.882351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.045400</td>\n",
       "      <td>0.609026</td>\n",
       "      <td>0.890958</td>\n",
       "      <td>0.884514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.033100</td>\n",
       "      <td>0.684157</td>\n",
       "      <td>0.894144</td>\n",
       "      <td>0.887134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.035600</td>\n",
       "      <td>0.686830</td>\n",
       "      <td>0.893654</td>\n",
       "      <td>0.886990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.024000</td>\n",
       "      <td>0.726568</td>\n",
       "      <td>0.892673</td>\n",
       "      <td>0.886510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.034000</td>\n",
       "      <td>0.683372</td>\n",
       "      <td>0.891448</td>\n",
       "      <td>0.884425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.031400</td>\n",
       "      <td>0.687678</td>\n",
       "      <td>0.889978</td>\n",
       "      <td>0.883702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.022300</td>\n",
       "      <td>0.739417</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.889196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.025900</td>\n",
       "      <td>0.705491</td>\n",
       "      <td>0.895614</td>\n",
       "      <td>0.888960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.031300</td>\n",
       "      <td>0.688733</td>\n",
       "      <td>0.893408</td>\n",
       "      <td>0.886886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.021300</td>\n",
       "      <td>0.731311</td>\n",
       "      <td>0.893899</td>\n",
       "      <td>0.886947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.023500</td>\n",
       "      <td>0.740306</td>\n",
       "      <td>0.895124</td>\n",
       "      <td>0.888524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.021600</td>\n",
       "      <td>0.730605</td>\n",
       "      <td>0.894879</td>\n",
       "      <td>0.887667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.021000</td>\n",
       "      <td>0.741358</td>\n",
       "      <td>0.893899</td>\n",
       "      <td>0.887121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 16321\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 4081\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorRoBERTa, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at otmangi/MorRoBERTa and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8dceeb5d4ae4015a4674a642dfb9d46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16321 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3539c1c1e5714547ad56e272eb5944bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4081 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3072' max='3072' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3072/3072 02:42, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.392000</td>\n",
       "      <td>0.316881</td>\n",
       "      <td>0.859593</td>\n",
       "      <td>0.843188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.315900</td>\n",
       "      <td>0.292084</td>\n",
       "      <td>0.884097</td>\n",
       "      <td>0.873717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.241600</td>\n",
       "      <td>0.287246</td>\n",
       "      <td>0.895369</td>\n",
       "      <td>0.888368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.177600</td>\n",
       "      <td>0.335721</td>\n",
       "      <td>0.882382</td>\n",
       "      <td>0.871592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.180400</td>\n",
       "      <td>0.265926</td>\n",
       "      <td>0.893654</td>\n",
       "      <td>0.886553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.096800</td>\n",
       "      <td>0.381419</td>\n",
       "      <td>0.896594</td>\n",
       "      <td>0.889368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.101200</td>\n",
       "      <td>0.298212</td>\n",
       "      <td>0.897084</td>\n",
       "      <td>0.890718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.083300</td>\n",
       "      <td>0.485421</td>\n",
       "      <td>0.887037</td>\n",
       "      <td>0.881915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.068900</td>\n",
       "      <td>0.413802</td>\n",
       "      <td>0.895859</td>\n",
       "      <td>0.888920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.071500</td>\n",
       "      <td>0.454176</td>\n",
       "      <td>0.895614</td>\n",
       "      <td>0.888932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.053700</td>\n",
       "      <td>0.448033</td>\n",
       "      <td>0.899779</td>\n",
       "      <td>0.893240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.047500</td>\n",
       "      <td>0.514126</td>\n",
       "      <td>0.892673</td>\n",
       "      <td>0.886456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.048300</td>\n",
       "      <td>0.679117</td>\n",
       "      <td>0.892428</td>\n",
       "      <td>0.884740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.033800</td>\n",
       "      <td>0.678892</td>\n",
       "      <td>0.896839</td>\n",
       "      <td>0.890849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.045900</td>\n",
       "      <td>0.536042</td>\n",
       "      <td>0.889488</td>\n",
       "      <td>0.883128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.031200</td>\n",
       "      <td>0.628366</td>\n",
       "      <td>0.889733</td>\n",
       "      <td>0.883843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.032400</td>\n",
       "      <td>0.667659</td>\n",
       "      <td>0.893654</td>\n",
       "      <td>0.886553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.034200</td>\n",
       "      <td>0.682988</td>\n",
       "      <td>0.893408</td>\n",
       "      <td>0.885090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.027000</td>\n",
       "      <td>0.653234</td>\n",
       "      <td>0.892673</td>\n",
       "      <td>0.885597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.030500</td>\n",
       "      <td>0.692197</td>\n",
       "      <td>0.895859</td>\n",
       "      <td>0.889375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.024900</td>\n",
       "      <td>0.705196</td>\n",
       "      <td>0.890223</td>\n",
       "      <td>0.884196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.028500</td>\n",
       "      <td>0.740372</td>\n",
       "      <td>0.892428</td>\n",
       "      <td>0.884165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.025200</td>\n",
       "      <td>0.709914</td>\n",
       "      <td>0.893654</td>\n",
       "      <td>0.887410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.024400</td>\n",
       "      <td>0.749313</td>\n",
       "      <td>0.893408</td>\n",
       "      <td>0.886801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.024400</td>\n",
       "      <td>0.738426</td>\n",
       "      <td>0.895369</td>\n",
       "      <td>0.888426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.019400</td>\n",
       "      <td>0.773003</td>\n",
       "      <td>0.894634</td>\n",
       "      <td>0.887301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.022500</td>\n",
       "      <td>0.761826</td>\n",
       "      <td>0.894634</td>\n",
       "      <td>0.886871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.022800</td>\n",
       "      <td>0.784272</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.889509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>0.783402</td>\n",
       "      <td>0.894634</td>\n",
       "      <td>0.888003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.018900</td>\n",
       "      <td>0.776193</td>\n",
       "      <td>0.894389</td>\n",
       "      <td>0.887728</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorRoBERTa, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at otmangi/MorRoBERTa and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e531d755761149c1bf8023cd5b0e001e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16321 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e88c011fdd834503b018be0a4bb5cc54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4081 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3072' max='3072' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3072/3072 02:42, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.392000</td>\n",
       "      <td>0.316881</td>\n",
       "      <td>0.859593</td>\n",
       "      <td>0.843188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.315900</td>\n",
       "      <td>0.292084</td>\n",
       "      <td>0.884097</td>\n",
       "      <td>0.873717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.241600</td>\n",
       "      <td>0.287246</td>\n",
       "      <td>0.895369</td>\n",
       "      <td>0.888368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.177600</td>\n",
       "      <td>0.335721</td>\n",
       "      <td>0.882382</td>\n",
       "      <td>0.871592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.180400</td>\n",
       "      <td>0.265926</td>\n",
       "      <td>0.893654</td>\n",
       "      <td>0.886553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.096800</td>\n",
       "      <td>0.381419</td>\n",
       "      <td>0.896594</td>\n",
       "      <td>0.889368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.101200</td>\n",
       "      <td>0.298212</td>\n",
       "      <td>0.897084</td>\n",
       "      <td>0.890718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.083300</td>\n",
       "      <td>0.485421</td>\n",
       "      <td>0.887037</td>\n",
       "      <td>0.881915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.068900</td>\n",
       "      <td>0.413802</td>\n",
       "      <td>0.895859</td>\n",
       "      <td>0.888920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.071500</td>\n",
       "      <td>0.454176</td>\n",
       "      <td>0.895614</td>\n",
       "      <td>0.888932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.053700</td>\n",
       "      <td>0.448033</td>\n",
       "      <td>0.899779</td>\n",
       "      <td>0.893240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.047500</td>\n",
       "      <td>0.514126</td>\n",
       "      <td>0.892673</td>\n",
       "      <td>0.886456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.048300</td>\n",
       "      <td>0.679117</td>\n",
       "      <td>0.892428</td>\n",
       "      <td>0.884740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.033800</td>\n",
       "      <td>0.678892</td>\n",
       "      <td>0.896839</td>\n",
       "      <td>0.890849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.045900</td>\n",
       "      <td>0.536042</td>\n",
       "      <td>0.889488</td>\n",
       "      <td>0.883128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.031200</td>\n",
       "      <td>0.628366</td>\n",
       "      <td>0.889733</td>\n",
       "      <td>0.883843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.032400</td>\n",
       "      <td>0.667659</td>\n",
       "      <td>0.893654</td>\n",
       "      <td>0.886553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.034200</td>\n",
       "      <td>0.682988</td>\n",
       "      <td>0.893408</td>\n",
       "      <td>0.885090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.027000</td>\n",
       "      <td>0.653234</td>\n",
       "      <td>0.892673</td>\n",
       "      <td>0.885597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.030500</td>\n",
       "      <td>0.692197</td>\n",
       "      <td>0.895859</td>\n",
       "      <td>0.889375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.024900</td>\n",
       "      <td>0.705196</td>\n",
       "      <td>0.890223</td>\n",
       "      <td>0.884196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.028500</td>\n",
       "      <td>0.740372</td>\n",
       "      <td>0.892428</td>\n",
       "      <td>0.884165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.025200</td>\n",
       "      <td>0.709914</td>\n",
       "      <td>0.893654</td>\n",
       "      <td>0.887410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.024400</td>\n",
       "      <td>0.749313</td>\n",
       "      <td>0.893408</td>\n",
       "      <td>0.886801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.024400</td>\n",
       "      <td>0.738426</td>\n",
       "      <td>0.895369</td>\n",
       "      <td>0.888426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.019400</td>\n",
       "      <td>0.773003</td>\n",
       "      <td>0.894634</td>\n",
       "      <td>0.887301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.022500</td>\n",
       "      <td>0.761826</td>\n",
       "      <td>0.894634</td>\n",
       "      <td>0.886871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.022800</td>\n",
       "      <td>0.784272</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.889509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>0.783402</td>\n",
       "      <td>0.894634</td>\n",
       "      <td>0.888003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.018900</td>\n",
       "      <td>0.776193</td>\n",
       "      <td>0.894389</td>\n",
       "      <td>0.887728</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorRoBERTa, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at otmangi/MorRoBERTa and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f05dc2c0e5324f53a695e34704a906c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16321 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bbc13a338684b3fbff8d28168182c04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4081 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3072' max='3072' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3072/3072 02:42, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.392000</td>\n",
       "      <td>0.316881</td>\n",
       "      <td>0.859593</td>\n",
       "      <td>0.843188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.315900</td>\n",
       "      <td>0.292084</td>\n",
       "      <td>0.884097</td>\n",
       "      <td>0.873717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.241600</td>\n",
       "      <td>0.287246</td>\n",
       "      <td>0.895369</td>\n",
       "      <td>0.888368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.177600</td>\n",
       "      <td>0.335721</td>\n",
       "      <td>0.882382</td>\n",
       "      <td>0.871592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.180400</td>\n",
       "      <td>0.265926</td>\n",
       "      <td>0.893654</td>\n",
       "      <td>0.886553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.096800</td>\n",
       "      <td>0.381419</td>\n",
       "      <td>0.896594</td>\n",
       "      <td>0.889368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.101200</td>\n",
       "      <td>0.298212</td>\n",
       "      <td>0.897084</td>\n",
       "      <td>0.890718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.083300</td>\n",
       "      <td>0.485421</td>\n",
       "      <td>0.887037</td>\n",
       "      <td>0.881915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.068900</td>\n",
       "      <td>0.413802</td>\n",
       "      <td>0.895859</td>\n",
       "      <td>0.888920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.071500</td>\n",
       "      <td>0.454176</td>\n",
       "      <td>0.895614</td>\n",
       "      <td>0.888932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.053700</td>\n",
       "      <td>0.448033</td>\n",
       "      <td>0.899779</td>\n",
       "      <td>0.893240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.047500</td>\n",
       "      <td>0.514126</td>\n",
       "      <td>0.892673</td>\n",
       "      <td>0.886456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.048300</td>\n",
       "      <td>0.679117</td>\n",
       "      <td>0.892428</td>\n",
       "      <td>0.884740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.033800</td>\n",
       "      <td>0.678892</td>\n",
       "      <td>0.896839</td>\n",
       "      <td>0.890849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.045900</td>\n",
       "      <td>0.536042</td>\n",
       "      <td>0.889488</td>\n",
       "      <td>0.883128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.031200</td>\n",
       "      <td>0.628366</td>\n",
       "      <td>0.889733</td>\n",
       "      <td>0.883843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.032400</td>\n",
       "      <td>0.667659</td>\n",
       "      <td>0.893654</td>\n",
       "      <td>0.886553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.034200</td>\n",
       "      <td>0.682988</td>\n",
       "      <td>0.893408</td>\n",
       "      <td>0.885090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.027000</td>\n",
       "      <td>0.653234</td>\n",
       "      <td>0.892673</td>\n",
       "      <td>0.885597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.030500</td>\n",
       "      <td>0.692197</td>\n",
       "      <td>0.895859</td>\n",
       "      <td>0.889375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.024900</td>\n",
       "      <td>0.705196</td>\n",
       "      <td>0.890223</td>\n",
       "      <td>0.884196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.028500</td>\n",
       "      <td>0.740372</td>\n",
       "      <td>0.892428</td>\n",
       "      <td>0.884165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.025200</td>\n",
       "      <td>0.709914</td>\n",
       "      <td>0.893654</td>\n",
       "      <td>0.887410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.024400</td>\n",
       "      <td>0.749313</td>\n",
       "      <td>0.893408</td>\n",
       "      <td>0.886801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.024400</td>\n",
       "      <td>0.738426</td>\n",
       "      <td>0.895369</td>\n",
       "      <td>0.888426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.019400</td>\n",
       "      <td>0.773003</td>\n",
       "      <td>0.894634</td>\n",
       "      <td>0.887301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.022500</td>\n",
       "      <td>0.761826</td>\n",
       "      <td>0.894634</td>\n",
       "      <td>0.886871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.022800</td>\n",
       "      <td>0.784272</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.889509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>0.783402</td>\n",
       "      <td>0.894634</td>\n",
       "      <td>0.888003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.018900</td>\n",
       "      <td>0.776193</td>\n",
       "      <td>0.894389</td>\n",
       "      <td>0.887728</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorRoBERTa, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at otmangi/MorRoBERTa and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d712dc494734e9abc8cf0efeb6c0e2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16321 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fb92e1617404deab6b8bd4dbe4abba7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4081 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3072' max='3072' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3072/3072 02:42, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.391600</td>\n",
       "      <td>0.310670</td>\n",
       "      <td>0.867434</td>\n",
       "      <td>0.857921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.303600</td>\n",
       "      <td>0.273730</td>\n",
       "      <td>0.881892</td>\n",
       "      <td>0.873050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.255400</td>\n",
       "      <td>0.267761</td>\n",
       "      <td>0.892183</td>\n",
       "      <td>0.883885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.172800</td>\n",
       "      <td>0.267112</td>\n",
       "      <td>0.894879</td>\n",
       "      <td>0.888334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.179900</td>\n",
       "      <td>0.277910</td>\n",
       "      <td>0.892673</td>\n",
       "      <td>0.887402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.099100</td>\n",
       "      <td>0.327802</td>\n",
       "      <td>0.898554</td>\n",
       "      <td>0.891809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.096800</td>\n",
       "      <td>0.408092</td>\n",
       "      <td>0.892918</td>\n",
       "      <td>0.884095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.121000</td>\n",
       "      <td>0.460803</td>\n",
       "      <td>0.888018</td>\n",
       "      <td>0.881283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.069500</td>\n",
       "      <td>0.442196</td>\n",
       "      <td>0.886547</td>\n",
       "      <td>0.876273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.082300</td>\n",
       "      <td>0.411366</td>\n",
       "      <td>0.897574</td>\n",
       "      <td>0.889247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.058300</td>\n",
       "      <td>0.499409</td>\n",
       "      <td>0.892673</td>\n",
       "      <td>0.882754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.053900</td>\n",
       "      <td>0.632994</td>\n",
       "      <td>0.893899</td>\n",
       "      <td>0.886285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.059600</td>\n",
       "      <td>0.625340</td>\n",
       "      <td>0.894634</td>\n",
       "      <td>0.885215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.039100</td>\n",
       "      <td>0.615999</td>\n",
       "      <td>0.891693</td>\n",
       "      <td>0.884155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.041600</td>\n",
       "      <td>0.783731</td>\n",
       "      <td>0.878951</td>\n",
       "      <td>0.873421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.044000</td>\n",
       "      <td>0.669208</td>\n",
       "      <td>0.889733</td>\n",
       "      <td>0.881964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.034500</td>\n",
       "      <td>0.659904</td>\n",
       "      <td>0.889733</td>\n",
       "      <td>0.880872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.032600</td>\n",
       "      <td>0.682333</td>\n",
       "      <td>0.893408</td>\n",
       "      <td>0.884625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.031900</td>\n",
       "      <td>0.650633</td>\n",
       "      <td>0.890468</td>\n",
       "      <td>0.882186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.032500</td>\n",
       "      <td>0.736570</td>\n",
       "      <td>0.891693</td>\n",
       "      <td>0.884612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.034200</td>\n",
       "      <td>0.640242</td>\n",
       "      <td>0.890958</td>\n",
       "      <td>0.883813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.663591</td>\n",
       "      <td>0.889243</td>\n",
       "      <td>0.881940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.026900</td>\n",
       "      <td>0.700538</td>\n",
       "      <td>0.890713</td>\n",
       "      <td>0.882791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.027200</td>\n",
       "      <td>0.732330</td>\n",
       "      <td>0.890223</td>\n",
       "      <td>0.883075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.023900</td>\n",
       "      <td>0.729089</td>\n",
       "      <td>0.893408</td>\n",
       "      <td>0.886570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.024600</td>\n",
       "      <td>0.745772</td>\n",
       "      <td>0.892183</td>\n",
       "      <td>0.884894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.024100</td>\n",
       "      <td>0.749011</td>\n",
       "      <td>0.893654</td>\n",
       "      <td>0.885436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.023000</td>\n",
       "      <td>0.732132</td>\n",
       "      <td>0.892918</td>\n",
       "      <td>0.884886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.754582</td>\n",
       "      <td>0.891693</td>\n",
       "      <td>0.883810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.020600</td>\n",
       "      <td>0.762298</td>\n",
       "      <td>0.893899</td>\n",
       "      <td>0.886129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorRoBERTa, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at otmangi/MorRoBERTa and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f16e307e9ac8486493f55ba7aa2a84e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16321 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a6572d35e814f9792a09ab5b9deca89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4081 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3072' max='3072' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3072/3072 02:42, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.391600</td>\n",
       "      <td>0.310670</td>\n",
       "      <td>0.867434</td>\n",
       "      <td>0.857921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.303600</td>\n",
       "      <td>0.273730</td>\n",
       "      <td>0.881892</td>\n",
       "      <td>0.873050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.255400</td>\n",
       "      <td>0.267761</td>\n",
       "      <td>0.892183</td>\n",
       "      <td>0.883885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.172800</td>\n",
       "      <td>0.267112</td>\n",
       "      <td>0.894879</td>\n",
       "      <td>0.888334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.179900</td>\n",
       "      <td>0.277910</td>\n",
       "      <td>0.892673</td>\n",
       "      <td>0.887402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.099100</td>\n",
       "      <td>0.327802</td>\n",
       "      <td>0.898554</td>\n",
       "      <td>0.891809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.096800</td>\n",
       "      <td>0.408092</td>\n",
       "      <td>0.892918</td>\n",
       "      <td>0.884095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.121000</td>\n",
       "      <td>0.460803</td>\n",
       "      <td>0.888018</td>\n",
       "      <td>0.881283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.069500</td>\n",
       "      <td>0.442196</td>\n",
       "      <td>0.886547</td>\n",
       "      <td>0.876273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.082300</td>\n",
       "      <td>0.411366</td>\n",
       "      <td>0.897574</td>\n",
       "      <td>0.889247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.058300</td>\n",
       "      <td>0.499409</td>\n",
       "      <td>0.892673</td>\n",
       "      <td>0.882754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.053900</td>\n",
       "      <td>0.632994</td>\n",
       "      <td>0.893899</td>\n",
       "      <td>0.886285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.059600</td>\n",
       "      <td>0.625340</td>\n",
       "      <td>0.894634</td>\n",
       "      <td>0.885215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.039100</td>\n",
       "      <td>0.615999</td>\n",
       "      <td>0.891693</td>\n",
       "      <td>0.884155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.041600</td>\n",
       "      <td>0.783731</td>\n",
       "      <td>0.878951</td>\n",
       "      <td>0.873421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.044000</td>\n",
       "      <td>0.669208</td>\n",
       "      <td>0.889733</td>\n",
       "      <td>0.881964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.034500</td>\n",
       "      <td>0.659904</td>\n",
       "      <td>0.889733</td>\n",
       "      <td>0.880872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.032600</td>\n",
       "      <td>0.682333</td>\n",
       "      <td>0.893408</td>\n",
       "      <td>0.884625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.031900</td>\n",
       "      <td>0.650633</td>\n",
       "      <td>0.890468</td>\n",
       "      <td>0.882186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.032500</td>\n",
       "      <td>0.736570</td>\n",
       "      <td>0.891693</td>\n",
       "      <td>0.884612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.034200</td>\n",
       "      <td>0.640242</td>\n",
       "      <td>0.890958</td>\n",
       "      <td>0.883813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.663591</td>\n",
       "      <td>0.889243</td>\n",
       "      <td>0.881940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.026900</td>\n",
       "      <td>0.700538</td>\n",
       "      <td>0.890713</td>\n",
       "      <td>0.882791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.027200</td>\n",
       "      <td>0.732330</td>\n",
       "      <td>0.890223</td>\n",
       "      <td>0.883075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.023900</td>\n",
       "      <td>0.729089</td>\n",
       "      <td>0.893408</td>\n",
       "      <td>0.886570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.024600</td>\n",
       "      <td>0.745772</td>\n",
       "      <td>0.892183</td>\n",
       "      <td>0.884894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.024100</td>\n",
       "      <td>0.749011</td>\n",
       "      <td>0.893654</td>\n",
       "      <td>0.885436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.023000</td>\n",
       "      <td>0.732132</td>\n",
       "      <td>0.892918</td>\n",
       "      <td>0.884886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.754582</td>\n",
       "      <td>0.891693</td>\n",
       "      <td>0.883810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.020600</td>\n",
       "      <td>0.762298</td>\n",
       "      <td>0.893899</td>\n",
       "      <td>0.886129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorRoBERTa, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at otmangi/MorRoBERTa and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95a9c16a31184a7aa6daf692d5c5c46c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16321 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd26677805d54388a501b45d9d23fa55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4081 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3072' max='3072' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3072/3072 02:42, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.391600</td>\n",
       "      <td>0.310670</td>\n",
       "      <td>0.867434</td>\n",
       "      <td>0.857921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.303600</td>\n",
       "      <td>0.273730</td>\n",
       "      <td>0.881892</td>\n",
       "      <td>0.873050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.255400</td>\n",
       "      <td>0.267761</td>\n",
       "      <td>0.892183</td>\n",
       "      <td>0.883885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.172800</td>\n",
       "      <td>0.267112</td>\n",
       "      <td>0.894879</td>\n",
       "      <td>0.888334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.179900</td>\n",
       "      <td>0.277910</td>\n",
       "      <td>0.892673</td>\n",
       "      <td>0.887402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.099100</td>\n",
       "      <td>0.327802</td>\n",
       "      <td>0.898554</td>\n",
       "      <td>0.891809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.096800</td>\n",
       "      <td>0.408092</td>\n",
       "      <td>0.892918</td>\n",
       "      <td>0.884095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.121000</td>\n",
       "      <td>0.460803</td>\n",
       "      <td>0.888018</td>\n",
       "      <td>0.881283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.069500</td>\n",
       "      <td>0.442196</td>\n",
       "      <td>0.886547</td>\n",
       "      <td>0.876273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.082300</td>\n",
       "      <td>0.411366</td>\n",
       "      <td>0.897574</td>\n",
       "      <td>0.889247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.058300</td>\n",
       "      <td>0.499409</td>\n",
       "      <td>0.892673</td>\n",
       "      <td>0.882754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.053900</td>\n",
       "      <td>0.632994</td>\n",
       "      <td>0.893899</td>\n",
       "      <td>0.886285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.059600</td>\n",
       "      <td>0.625340</td>\n",
       "      <td>0.894634</td>\n",
       "      <td>0.885215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.039100</td>\n",
       "      <td>0.615999</td>\n",
       "      <td>0.891693</td>\n",
       "      <td>0.884155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.041600</td>\n",
       "      <td>0.783731</td>\n",
       "      <td>0.878951</td>\n",
       "      <td>0.873421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.044000</td>\n",
       "      <td>0.669208</td>\n",
       "      <td>0.889733</td>\n",
       "      <td>0.881964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.034500</td>\n",
       "      <td>0.659904</td>\n",
       "      <td>0.889733</td>\n",
       "      <td>0.880872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.032600</td>\n",
       "      <td>0.682333</td>\n",
       "      <td>0.893408</td>\n",
       "      <td>0.884625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.031900</td>\n",
       "      <td>0.650633</td>\n",
       "      <td>0.890468</td>\n",
       "      <td>0.882186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.032500</td>\n",
       "      <td>0.736570</td>\n",
       "      <td>0.891693</td>\n",
       "      <td>0.884612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.034200</td>\n",
       "      <td>0.640242</td>\n",
       "      <td>0.890958</td>\n",
       "      <td>0.883813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.663591</td>\n",
       "      <td>0.889243</td>\n",
       "      <td>0.881940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.026900</td>\n",
       "      <td>0.700538</td>\n",
       "      <td>0.890713</td>\n",
       "      <td>0.882791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.027200</td>\n",
       "      <td>0.732330</td>\n",
       "      <td>0.890223</td>\n",
       "      <td>0.883075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.023900</td>\n",
       "      <td>0.729089</td>\n",
       "      <td>0.893408</td>\n",
       "      <td>0.886570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.024600</td>\n",
       "      <td>0.745772</td>\n",
       "      <td>0.892183</td>\n",
       "      <td>0.884894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.024100</td>\n",
       "      <td>0.749011</td>\n",
       "      <td>0.893654</td>\n",
       "      <td>0.885436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.023000</td>\n",
       "      <td>0.732132</td>\n",
       "      <td>0.892918</td>\n",
       "      <td>0.884886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.754582</td>\n",
       "      <td>0.891693</td>\n",
       "      <td>0.883810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.020600</td>\n",
       "      <td>0.762298</td>\n",
       "      <td>0.893899</td>\n",
       "      <td>0.886129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorRoBERTa, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at otmangi/MorRoBERTa and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "092643e76d7d4338aa179b0c1f3dc2fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16321 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3d2b71d498a45c79e5b7858870f53c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4081 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3072' max='3072' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3072/3072 02:42, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.409900</td>\n",
       "      <td>0.324752</td>\n",
       "      <td>0.852732</td>\n",
       "      <td>0.845955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.320200</td>\n",
       "      <td>0.289490</td>\n",
       "      <td>0.882382</td>\n",
       "      <td>0.874095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.240700</td>\n",
       "      <td>0.307774</td>\n",
       "      <td>0.885567</td>\n",
       "      <td>0.875281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.180800</td>\n",
       "      <td>0.293333</td>\n",
       "      <td>0.887773</td>\n",
       "      <td>0.880920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.182700</td>\n",
       "      <td>0.278218</td>\n",
       "      <td>0.897819</td>\n",
       "      <td>0.890954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.104000</td>\n",
       "      <td>0.381885</td>\n",
       "      <td>0.881892</td>\n",
       "      <td>0.877060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.101100</td>\n",
       "      <td>0.451874</td>\n",
       "      <td>0.894389</td>\n",
       "      <td>0.886810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.102900</td>\n",
       "      <td>0.511619</td>\n",
       "      <td>0.894879</td>\n",
       "      <td>0.888020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.065200</td>\n",
       "      <td>0.452294</td>\n",
       "      <td>0.890713</td>\n",
       "      <td>0.885008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.070100</td>\n",
       "      <td>0.430841</td>\n",
       "      <td>0.895859</td>\n",
       "      <td>0.889375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.054700</td>\n",
       "      <td>0.520976</td>\n",
       "      <td>0.888998</td>\n",
       "      <td>0.882610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.043500</td>\n",
       "      <td>0.540091</td>\n",
       "      <td>0.894879</td>\n",
       "      <td>0.888135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.055900</td>\n",
       "      <td>0.617813</td>\n",
       "      <td>0.891448</td>\n",
       "      <td>0.885394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.035400</td>\n",
       "      <td>0.597147</td>\n",
       "      <td>0.892183</td>\n",
       "      <td>0.885134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.040500</td>\n",
       "      <td>0.643912</td>\n",
       "      <td>0.893899</td>\n",
       "      <td>0.887092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.032100</td>\n",
       "      <td>0.656513</td>\n",
       "      <td>0.890958</td>\n",
       "      <td>0.883903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.033900</td>\n",
       "      <td>0.672611</td>\n",
       "      <td>0.892183</td>\n",
       "      <td>0.884336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.032100</td>\n",
       "      <td>0.654650</td>\n",
       "      <td>0.888753</td>\n",
       "      <td>0.882478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.031300</td>\n",
       "      <td>0.654828</td>\n",
       "      <td>0.890223</td>\n",
       "      <td>0.883461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.028300</td>\n",
       "      <td>0.712148</td>\n",
       "      <td>0.891693</td>\n",
       "      <td>0.884993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.018800</td>\n",
       "      <td>0.799415</td>\n",
       "      <td>0.891448</td>\n",
       "      <td>0.884514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.025600</td>\n",
       "      <td>0.741203</td>\n",
       "      <td>0.891448</td>\n",
       "      <td>0.884155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.020900</td>\n",
       "      <td>0.759169</td>\n",
       "      <td>0.891448</td>\n",
       "      <td>0.884719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.020200</td>\n",
       "      <td>0.804136</td>\n",
       "      <td>0.893654</td>\n",
       "      <td>0.886343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.021300</td>\n",
       "      <td>0.771216</td>\n",
       "      <td>0.891448</td>\n",
       "      <td>0.884366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.024100</td>\n",
       "      <td>0.790990</td>\n",
       "      <td>0.894144</td>\n",
       "      <td>0.887482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.021200</td>\n",
       "      <td>0.796073</td>\n",
       "      <td>0.893654</td>\n",
       "      <td>0.887216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.020500</td>\n",
       "      <td>0.793980</td>\n",
       "      <td>0.894389</td>\n",
       "      <td>0.887556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.019100</td>\n",
       "      <td>0.795598</td>\n",
       "      <td>0.895124</td>\n",
       "      <td>0.888295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.019900</td>\n",
       "      <td>0.813920</td>\n",
       "      <td>0.895124</td>\n",
       "      <td>0.888410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorRoBERTa, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at otmangi/MorRoBERTa and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a6df3f6ff844a7585916c7ac3a51f25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16321 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c817e029416a47b6b867f8421f0f5644",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4081 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3072' max='3072' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3072/3072 02:42, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.409900</td>\n",
       "      <td>0.324752</td>\n",
       "      <td>0.852732</td>\n",
       "      <td>0.845955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.320200</td>\n",
       "      <td>0.289490</td>\n",
       "      <td>0.882382</td>\n",
       "      <td>0.874095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.240700</td>\n",
       "      <td>0.307774</td>\n",
       "      <td>0.885567</td>\n",
       "      <td>0.875281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.180800</td>\n",
       "      <td>0.293333</td>\n",
       "      <td>0.887773</td>\n",
       "      <td>0.880920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.182700</td>\n",
       "      <td>0.278218</td>\n",
       "      <td>0.897819</td>\n",
       "      <td>0.890954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.104000</td>\n",
       "      <td>0.381885</td>\n",
       "      <td>0.881892</td>\n",
       "      <td>0.877060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.101100</td>\n",
       "      <td>0.451874</td>\n",
       "      <td>0.894389</td>\n",
       "      <td>0.886810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.102900</td>\n",
       "      <td>0.511619</td>\n",
       "      <td>0.894879</td>\n",
       "      <td>0.888020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.065200</td>\n",
       "      <td>0.452294</td>\n",
       "      <td>0.890713</td>\n",
       "      <td>0.885008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.070100</td>\n",
       "      <td>0.430841</td>\n",
       "      <td>0.895859</td>\n",
       "      <td>0.889375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.054700</td>\n",
       "      <td>0.520976</td>\n",
       "      <td>0.888998</td>\n",
       "      <td>0.882610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.043500</td>\n",
       "      <td>0.540091</td>\n",
       "      <td>0.894879</td>\n",
       "      <td>0.888135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.055900</td>\n",
       "      <td>0.617813</td>\n",
       "      <td>0.891448</td>\n",
       "      <td>0.885394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.035400</td>\n",
       "      <td>0.597147</td>\n",
       "      <td>0.892183</td>\n",
       "      <td>0.885134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.040500</td>\n",
       "      <td>0.643912</td>\n",
       "      <td>0.893899</td>\n",
       "      <td>0.887092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.032100</td>\n",
       "      <td>0.656513</td>\n",
       "      <td>0.890958</td>\n",
       "      <td>0.883903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.033900</td>\n",
       "      <td>0.672611</td>\n",
       "      <td>0.892183</td>\n",
       "      <td>0.884336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.032100</td>\n",
       "      <td>0.654650</td>\n",
       "      <td>0.888753</td>\n",
       "      <td>0.882478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.031300</td>\n",
       "      <td>0.654828</td>\n",
       "      <td>0.890223</td>\n",
       "      <td>0.883461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.028300</td>\n",
       "      <td>0.712148</td>\n",
       "      <td>0.891693</td>\n",
       "      <td>0.884993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.018800</td>\n",
       "      <td>0.799415</td>\n",
       "      <td>0.891448</td>\n",
       "      <td>0.884514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.025600</td>\n",
       "      <td>0.741203</td>\n",
       "      <td>0.891448</td>\n",
       "      <td>0.884155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.020900</td>\n",
       "      <td>0.759169</td>\n",
       "      <td>0.891448</td>\n",
       "      <td>0.884719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.020200</td>\n",
       "      <td>0.804136</td>\n",
       "      <td>0.893654</td>\n",
       "      <td>0.886343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.021300</td>\n",
       "      <td>0.771216</td>\n",
       "      <td>0.891448</td>\n",
       "      <td>0.884366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.024100</td>\n",
       "      <td>0.790990</td>\n",
       "      <td>0.894144</td>\n",
       "      <td>0.887482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.021200</td>\n",
       "      <td>0.796073</td>\n",
       "      <td>0.893654</td>\n",
       "      <td>0.887216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.020500</td>\n",
       "      <td>0.793980</td>\n",
       "      <td>0.894389</td>\n",
       "      <td>0.887556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.019100</td>\n",
       "      <td>0.795598</td>\n",
       "      <td>0.895124</td>\n",
       "      <td>0.888295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.019900</td>\n",
       "      <td>0.813920</td>\n",
       "      <td>0.895124</td>\n",
       "      <td>0.888410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorRoBERTa, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at otmangi/MorRoBERTa and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8678a1e7e31d41ab9064d63f9557d4a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16321 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bda5eb80b0a84f4da7328a044d277b5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4081 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3072' max='3072' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3072/3072 02:42, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.409900</td>\n",
       "      <td>0.324752</td>\n",
       "      <td>0.852732</td>\n",
       "      <td>0.845955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.320200</td>\n",
       "      <td>0.289490</td>\n",
       "      <td>0.882382</td>\n",
       "      <td>0.874095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.240700</td>\n",
       "      <td>0.307774</td>\n",
       "      <td>0.885567</td>\n",
       "      <td>0.875281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.180800</td>\n",
       "      <td>0.293333</td>\n",
       "      <td>0.887773</td>\n",
       "      <td>0.880920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.182700</td>\n",
       "      <td>0.278218</td>\n",
       "      <td>0.897819</td>\n",
       "      <td>0.890954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.104000</td>\n",
       "      <td>0.381885</td>\n",
       "      <td>0.881892</td>\n",
       "      <td>0.877060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.101100</td>\n",
       "      <td>0.451874</td>\n",
       "      <td>0.894389</td>\n",
       "      <td>0.886810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.102900</td>\n",
       "      <td>0.511619</td>\n",
       "      <td>0.894879</td>\n",
       "      <td>0.888020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.065200</td>\n",
       "      <td>0.452294</td>\n",
       "      <td>0.890713</td>\n",
       "      <td>0.885008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.070100</td>\n",
       "      <td>0.430841</td>\n",
       "      <td>0.895859</td>\n",
       "      <td>0.889375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.054700</td>\n",
       "      <td>0.520976</td>\n",
       "      <td>0.888998</td>\n",
       "      <td>0.882610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.043500</td>\n",
       "      <td>0.540091</td>\n",
       "      <td>0.894879</td>\n",
       "      <td>0.888135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.055900</td>\n",
       "      <td>0.617813</td>\n",
       "      <td>0.891448</td>\n",
       "      <td>0.885394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.035400</td>\n",
       "      <td>0.597147</td>\n",
       "      <td>0.892183</td>\n",
       "      <td>0.885134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.040500</td>\n",
       "      <td>0.643912</td>\n",
       "      <td>0.893899</td>\n",
       "      <td>0.887092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.032100</td>\n",
       "      <td>0.656513</td>\n",
       "      <td>0.890958</td>\n",
       "      <td>0.883903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.033900</td>\n",
       "      <td>0.672611</td>\n",
       "      <td>0.892183</td>\n",
       "      <td>0.884336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.032100</td>\n",
       "      <td>0.654650</td>\n",
       "      <td>0.888753</td>\n",
       "      <td>0.882478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.031300</td>\n",
       "      <td>0.654828</td>\n",
       "      <td>0.890223</td>\n",
       "      <td>0.883461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.028300</td>\n",
       "      <td>0.712148</td>\n",
       "      <td>0.891693</td>\n",
       "      <td>0.884993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.018800</td>\n",
       "      <td>0.799415</td>\n",
       "      <td>0.891448</td>\n",
       "      <td>0.884514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.025600</td>\n",
       "      <td>0.741203</td>\n",
       "      <td>0.891448</td>\n",
       "      <td>0.884155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.020900</td>\n",
       "      <td>0.759169</td>\n",
       "      <td>0.891448</td>\n",
       "      <td>0.884719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.020200</td>\n",
       "      <td>0.804136</td>\n",
       "      <td>0.893654</td>\n",
       "      <td>0.886343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.021300</td>\n",
       "      <td>0.771216</td>\n",
       "      <td>0.891448</td>\n",
       "      <td>0.884366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.024100</td>\n",
       "      <td>0.790990</td>\n",
       "      <td>0.894144</td>\n",
       "      <td>0.887482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.021200</td>\n",
       "      <td>0.796073</td>\n",
       "      <td>0.893654</td>\n",
       "      <td>0.887216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.020500</td>\n",
       "      <td>0.793980</td>\n",
       "      <td>0.894389</td>\n",
       "      <td>0.887556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.019100</td>\n",
       "      <td>0.795598</td>\n",
       "      <td>0.895124</td>\n",
       "      <td>0.888295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.019900</td>\n",
       "      <td>0.813920</td>\n",
       "      <td>0.895124</td>\n",
       "      <td>0.888410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 16321\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 4081\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorrBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at otmangi/MorrBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4528f6c3d0ea46c28205091962cb61e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16321 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "126dcad0ac7a440b9d9fe1e5cd3ab207",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4081 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3072' max='3072' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3072/3072 04:53, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.334500</td>\n",
       "      <td>0.275559</td>\n",
       "      <td>0.879686</td>\n",
       "      <td>0.867751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.285300</td>\n",
       "      <td>0.257518</td>\n",
       "      <td>0.895369</td>\n",
       "      <td>0.886681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.216800</td>\n",
       "      <td>0.305379</td>\n",
       "      <td>0.889488</td>\n",
       "      <td>0.883917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.148900</td>\n",
       "      <td>0.316333</td>\n",
       "      <td>0.894879</td>\n",
       "      <td>0.888501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.161500</td>\n",
       "      <td>0.260229</td>\n",
       "      <td>0.901985</td>\n",
       "      <td>0.896555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.082200</td>\n",
       "      <td>0.337235</td>\n",
       "      <td>0.895614</td>\n",
       "      <td>0.890139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.093600</td>\n",
       "      <td>0.336214</td>\n",
       "      <td>0.899289</td>\n",
       "      <td>0.893723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>0.482541</td>\n",
       "      <td>0.897329</td>\n",
       "      <td>0.891019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.057700</td>\n",
       "      <td>0.457296</td>\n",
       "      <td>0.901740</td>\n",
       "      <td>0.895356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.072100</td>\n",
       "      <td>0.499220</td>\n",
       "      <td>0.898554</td>\n",
       "      <td>0.891230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.051900</td>\n",
       "      <td>0.519948</td>\n",
       "      <td>0.893163</td>\n",
       "      <td>0.887029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.042300</td>\n",
       "      <td>0.436441</td>\n",
       "      <td>0.899534</td>\n",
       "      <td>0.892714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.049500</td>\n",
       "      <td>0.531054</td>\n",
       "      <td>0.896594</td>\n",
       "      <td>0.889632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.035600</td>\n",
       "      <td>0.500347</td>\n",
       "      <td>0.893654</td>\n",
       "      <td>0.887244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.032900</td>\n",
       "      <td>0.572630</td>\n",
       "      <td>0.897084</td>\n",
       "      <td>0.890854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.026200</td>\n",
       "      <td>0.693110</td>\n",
       "      <td>0.897574</td>\n",
       "      <td>0.891265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.028500</td>\n",
       "      <td>0.640912</td>\n",
       "      <td>0.896839</td>\n",
       "      <td>0.891111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.034900</td>\n",
       "      <td>0.668277</td>\n",
       "      <td>0.896839</td>\n",
       "      <td>0.891137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.021800</td>\n",
       "      <td>0.695865</td>\n",
       "      <td>0.895614</td>\n",
       "      <td>0.888556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.028900</td>\n",
       "      <td>0.618086</td>\n",
       "      <td>0.898554</td>\n",
       "      <td>0.891609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.021800</td>\n",
       "      <td>0.659724</td>\n",
       "      <td>0.897084</td>\n",
       "      <td>0.890800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.028900</td>\n",
       "      <td>0.600265</td>\n",
       "      <td>0.898064</td>\n",
       "      <td>0.891201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.021200</td>\n",
       "      <td>0.685145</td>\n",
       "      <td>0.894389</td>\n",
       "      <td>0.888604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.021700</td>\n",
       "      <td>0.628969</td>\n",
       "      <td>0.901250</td>\n",
       "      <td>0.894447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.024500</td>\n",
       "      <td>0.696566</td>\n",
       "      <td>0.894389</td>\n",
       "      <td>0.888682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.017500</td>\n",
       "      <td>0.710230</td>\n",
       "      <td>0.898064</td>\n",
       "      <td>0.891840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.021200</td>\n",
       "      <td>0.703413</td>\n",
       "      <td>0.901005</td>\n",
       "      <td>0.894586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.021600</td>\n",
       "      <td>0.701657</td>\n",
       "      <td>0.897819</td>\n",
       "      <td>0.891566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.019300</td>\n",
       "      <td>0.718390</td>\n",
       "      <td>0.899289</td>\n",
       "      <td>0.892965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.019000</td>\n",
       "      <td>0.721282</td>\n",
       "      <td>0.898064</td>\n",
       "      <td>0.891813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorrBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at otmangi/MorrBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fef90e878444ec49700dfd1179916df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16321 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3b309650e9b4f4e8ff985edee0b6c6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4081 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3072' max='3072' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3072/3072 04:52, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.334500</td>\n",
       "      <td>0.275559</td>\n",
       "      <td>0.879686</td>\n",
       "      <td>0.867751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.285300</td>\n",
       "      <td>0.257518</td>\n",
       "      <td>0.895369</td>\n",
       "      <td>0.886681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.216800</td>\n",
       "      <td>0.305379</td>\n",
       "      <td>0.889488</td>\n",
       "      <td>0.883917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.148900</td>\n",
       "      <td>0.316333</td>\n",
       "      <td>0.894879</td>\n",
       "      <td>0.888501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.161500</td>\n",
       "      <td>0.260229</td>\n",
       "      <td>0.901985</td>\n",
       "      <td>0.896555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.082200</td>\n",
       "      <td>0.337235</td>\n",
       "      <td>0.895614</td>\n",
       "      <td>0.890139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.093600</td>\n",
       "      <td>0.336214</td>\n",
       "      <td>0.899289</td>\n",
       "      <td>0.893723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>0.482541</td>\n",
       "      <td>0.897329</td>\n",
       "      <td>0.891019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.057700</td>\n",
       "      <td>0.457296</td>\n",
       "      <td>0.901740</td>\n",
       "      <td>0.895356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.072100</td>\n",
       "      <td>0.499220</td>\n",
       "      <td>0.898554</td>\n",
       "      <td>0.891230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.051900</td>\n",
       "      <td>0.519948</td>\n",
       "      <td>0.893163</td>\n",
       "      <td>0.887029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.042300</td>\n",
       "      <td>0.436441</td>\n",
       "      <td>0.899534</td>\n",
       "      <td>0.892714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.049500</td>\n",
       "      <td>0.531054</td>\n",
       "      <td>0.896594</td>\n",
       "      <td>0.889632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.035600</td>\n",
       "      <td>0.500347</td>\n",
       "      <td>0.893654</td>\n",
       "      <td>0.887244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.032900</td>\n",
       "      <td>0.572630</td>\n",
       "      <td>0.897084</td>\n",
       "      <td>0.890854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.026200</td>\n",
       "      <td>0.693110</td>\n",
       "      <td>0.897574</td>\n",
       "      <td>0.891265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.028500</td>\n",
       "      <td>0.640912</td>\n",
       "      <td>0.896839</td>\n",
       "      <td>0.891111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.034900</td>\n",
       "      <td>0.668277</td>\n",
       "      <td>0.896839</td>\n",
       "      <td>0.891137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.021800</td>\n",
       "      <td>0.695865</td>\n",
       "      <td>0.895614</td>\n",
       "      <td>0.888556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.028900</td>\n",
       "      <td>0.618086</td>\n",
       "      <td>0.898554</td>\n",
       "      <td>0.891609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.021800</td>\n",
       "      <td>0.659724</td>\n",
       "      <td>0.897084</td>\n",
       "      <td>0.890800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.028900</td>\n",
       "      <td>0.600265</td>\n",
       "      <td>0.898064</td>\n",
       "      <td>0.891201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.021200</td>\n",
       "      <td>0.685145</td>\n",
       "      <td>0.894389</td>\n",
       "      <td>0.888604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.021700</td>\n",
       "      <td>0.628969</td>\n",
       "      <td>0.901250</td>\n",
       "      <td>0.894447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.024500</td>\n",
       "      <td>0.696566</td>\n",
       "      <td>0.894389</td>\n",
       "      <td>0.888682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.017500</td>\n",
       "      <td>0.710230</td>\n",
       "      <td>0.898064</td>\n",
       "      <td>0.891840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.021200</td>\n",
       "      <td>0.703413</td>\n",
       "      <td>0.901005</td>\n",
       "      <td>0.894586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.021600</td>\n",
       "      <td>0.701657</td>\n",
       "      <td>0.897819</td>\n",
       "      <td>0.891566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.019300</td>\n",
       "      <td>0.718390</td>\n",
       "      <td>0.899289</td>\n",
       "      <td>0.892965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.019000</td>\n",
       "      <td>0.721282</td>\n",
       "      <td>0.898064</td>\n",
       "      <td>0.891813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorrBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at otmangi/MorrBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8aacea3a4894e1e8871bfb89011ea9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16321 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4b5212ee40742c6bd302714b889648d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4081 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3072' max='3072' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3072/3072 04:52, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.334500</td>\n",
       "      <td>0.275559</td>\n",
       "      <td>0.879686</td>\n",
       "      <td>0.867751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.285300</td>\n",
       "      <td>0.257518</td>\n",
       "      <td>0.895369</td>\n",
       "      <td>0.886681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.216800</td>\n",
       "      <td>0.305379</td>\n",
       "      <td>0.889488</td>\n",
       "      <td>0.883917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.148900</td>\n",
       "      <td>0.316333</td>\n",
       "      <td>0.894879</td>\n",
       "      <td>0.888501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.161500</td>\n",
       "      <td>0.260229</td>\n",
       "      <td>0.901985</td>\n",
       "      <td>0.896555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.082200</td>\n",
       "      <td>0.337235</td>\n",
       "      <td>0.895614</td>\n",
       "      <td>0.890139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.093600</td>\n",
       "      <td>0.336214</td>\n",
       "      <td>0.899289</td>\n",
       "      <td>0.893723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>0.482541</td>\n",
       "      <td>0.897329</td>\n",
       "      <td>0.891019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.057700</td>\n",
       "      <td>0.457296</td>\n",
       "      <td>0.901740</td>\n",
       "      <td>0.895356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.072100</td>\n",
       "      <td>0.499220</td>\n",
       "      <td>0.898554</td>\n",
       "      <td>0.891230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.051900</td>\n",
       "      <td>0.519948</td>\n",
       "      <td>0.893163</td>\n",
       "      <td>0.887029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.042300</td>\n",
       "      <td>0.436441</td>\n",
       "      <td>0.899534</td>\n",
       "      <td>0.892714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.049500</td>\n",
       "      <td>0.531054</td>\n",
       "      <td>0.896594</td>\n",
       "      <td>0.889632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.035600</td>\n",
       "      <td>0.500347</td>\n",
       "      <td>0.893654</td>\n",
       "      <td>0.887244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.032900</td>\n",
       "      <td>0.572630</td>\n",
       "      <td>0.897084</td>\n",
       "      <td>0.890854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.026200</td>\n",
       "      <td>0.693110</td>\n",
       "      <td>0.897574</td>\n",
       "      <td>0.891265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.028500</td>\n",
       "      <td>0.640912</td>\n",
       "      <td>0.896839</td>\n",
       "      <td>0.891111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.034900</td>\n",
       "      <td>0.668277</td>\n",
       "      <td>0.896839</td>\n",
       "      <td>0.891137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.021800</td>\n",
       "      <td>0.695865</td>\n",
       "      <td>0.895614</td>\n",
       "      <td>0.888556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.028900</td>\n",
       "      <td>0.618086</td>\n",
       "      <td>0.898554</td>\n",
       "      <td>0.891609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.021800</td>\n",
       "      <td>0.659724</td>\n",
       "      <td>0.897084</td>\n",
       "      <td>0.890800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.028900</td>\n",
       "      <td>0.600265</td>\n",
       "      <td>0.898064</td>\n",
       "      <td>0.891201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.021200</td>\n",
       "      <td>0.685145</td>\n",
       "      <td>0.894389</td>\n",
       "      <td>0.888604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.021700</td>\n",
       "      <td>0.628969</td>\n",
       "      <td>0.901250</td>\n",
       "      <td>0.894447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.024500</td>\n",
       "      <td>0.696566</td>\n",
       "      <td>0.894389</td>\n",
       "      <td>0.888682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.017500</td>\n",
       "      <td>0.710230</td>\n",
       "      <td>0.898064</td>\n",
       "      <td>0.891840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.021200</td>\n",
       "      <td>0.703413</td>\n",
       "      <td>0.901005</td>\n",
       "      <td>0.894586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.021600</td>\n",
       "      <td>0.701657</td>\n",
       "      <td>0.897819</td>\n",
       "      <td>0.891566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.019300</td>\n",
       "      <td>0.718390</td>\n",
       "      <td>0.899289</td>\n",
       "      <td>0.892965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.019000</td>\n",
       "      <td>0.721282</td>\n",
       "      <td>0.898064</td>\n",
       "      <td>0.891813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorrBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at otmangi/MorrBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac304358c9fb44d6a0c6708c0fcd4554",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16321 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d230973293e4c18bc759f49a9c68330",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4081 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3072' max='3072' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3072/3072 04:53, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.326000</td>\n",
       "      <td>0.291866</td>\n",
       "      <td>0.872580</td>\n",
       "      <td>0.865034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.279100</td>\n",
       "      <td>0.251395</td>\n",
       "      <td>0.891693</td>\n",
       "      <td>0.883874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.231200</td>\n",
       "      <td>0.265044</td>\n",
       "      <td>0.902230</td>\n",
       "      <td>0.893409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.144300</td>\n",
       "      <td>0.267153</td>\n",
       "      <td>0.904925</td>\n",
       "      <td>0.898550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.152000</td>\n",
       "      <td>0.255104</td>\n",
       "      <td>0.902720</td>\n",
       "      <td>0.896611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.091000</td>\n",
       "      <td>0.342193</td>\n",
       "      <td>0.905415</td>\n",
       "      <td>0.898447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.087600</td>\n",
       "      <td>0.360282</td>\n",
       "      <td>0.900760</td>\n",
       "      <td>0.893256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.121600</td>\n",
       "      <td>0.436092</td>\n",
       "      <td>0.900270</td>\n",
       "      <td>0.892819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.067300</td>\n",
       "      <td>0.399853</td>\n",
       "      <td>0.899779</td>\n",
       "      <td>0.891167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.072200</td>\n",
       "      <td>0.351520</td>\n",
       "      <td>0.907621</td>\n",
       "      <td>0.900154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.052600</td>\n",
       "      <td>0.548984</td>\n",
       "      <td>0.902965</td>\n",
       "      <td>0.894830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.049500</td>\n",
       "      <td>0.578825</td>\n",
       "      <td>0.898799</td>\n",
       "      <td>0.890746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.051400</td>\n",
       "      <td>0.603485</td>\n",
       "      <td>0.898554</td>\n",
       "      <td>0.890082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.041400</td>\n",
       "      <td>0.540927</td>\n",
       "      <td>0.898309</td>\n",
       "      <td>0.890803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.043800</td>\n",
       "      <td>0.532979</td>\n",
       "      <td>0.899289</td>\n",
       "      <td>0.893285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.039500</td>\n",
       "      <td>0.554933</td>\n",
       "      <td>0.899289</td>\n",
       "      <td>0.892523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.578539</td>\n",
       "      <td>0.905415</td>\n",
       "      <td>0.898221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.036900</td>\n",
       "      <td>0.618843</td>\n",
       "      <td>0.901740</td>\n",
       "      <td>0.894515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.026100</td>\n",
       "      <td>0.640074</td>\n",
       "      <td>0.900025</td>\n",
       "      <td>0.893515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.666724</td>\n",
       "      <td>0.900270</td>\n",
       "      <td>0.891925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.026600</td>\n",
       "      <td>0.664162</td>\n",
       "      <td>0.901250</td>\n",
       "      <td>0.893361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.025500</td>\n",
       "      <td>0.700354</td>\n",
       "      <td>0.898064</td>\n",
       "      <td>0.890734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.020900</td>\n",
       "      <td>0.678100</td>\n",
       "      <td>0.899534</td>\n",
       "      <td>0.892073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.023600</td>\n",
       "      <td>0.747825</td>\n",
       "      <td>0.899534</td>\n",
       "      <td>0.891984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.022900</td>\n",
       "      <td>0.732650</td>\n",
       "      <td>0.897084</td>\n",
       "      <td>0.889803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.020800</td>\n",
       "      <td>0.743748</td>\n",
       "      <td>0.898064</td>\n",
       "      <td>0.891343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.023400</td>\n",
       "      <td>0.737288</td>\n",
       "      <td>0.899044</td>\n",
       "      <td>0.891960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.020800</td>\n",
       "      <td>0.729431</td>\n",
       "      <td>0.900760</td>\n",
       "      <td>0.893810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.023200</td>\n",
       "      <td>0.747861</td>\n",
       "      <td>0.898309</td>\n",
       "      <td>0.891391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.019300</td>\n",
       "      <td>0.744082</td>\n",
       "      <td>0.899044</td>\n",
       "      <td>0.891902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorrBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at otmangi/MorrBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97c8f080b06c451fa463d53054bedcd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16321 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40b28ed1ebc74b94b971e657a144c58f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4081 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3072' max='3072' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3072/3072 04:53, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.326000</td>\n",
       "      <td>0.291866</td>\n",
       "      <td>0.872580</td>\n",
       "      <td>0.865034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.279100</td>\n",
       "      <td>0.251395</td>\n",
       "      <td>0.891693</td>\n",
       "      <td>0.883874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.231200</td>\n",
       "      <td>0.265044</td>\n",
       "      <td>0.902230</td>\n",
       "      <td>0.893409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.144300</td>\n",
       "      <td>0.267153</td>\n",
       "      <td>0.904925</td>\n",
       "      <td>0.898550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.152000</td>\n",
       "      <td>0.255104</td>\n",
       "      <td>0.902720</td>\n",
       "      <td>0.896611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.091000</td>\n",
       "      <td>0.342193</td>\n",
       "      <td>0.905415</td>\n",
       "      <td>0.898447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.087600</td>\n",
       "      <td>0.360282</td>\n",
       "      <td>0.900760</td>\n",
       "      <td>0.893256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.121600</td>\n",
       "      <td>0.436092</td>\n",
       "      <td>0.900270</td>\n",
       "      <td>0.892819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.067300</td>\n",
       "      <td>0.399853</td>\n",
       "      <td>0.899779</td>\n",
       "      <td>0.891167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.072200</td>\n",
       "      <td>0.351520</td>\n",
       "      <td>0.907621</td>\n",
       "      <td>0.900154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.052600</td>\n",
       "      <td>0.548984</td>\n",
       "      <td>0.902965</td>\n",
       "      <td>0.894830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.049500</td>\n",
       "      <td>0.578825</td>\n",
       "      <td>0.898799</td>\n",
       "      <td>0.890746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.051400</td>\n",
       "      <td>0.603485</td>\n",
       "      <td>0.898554</td>\n",
       "      <td>0.890082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.041400</td>\n",
       "      <td>0.540927</td>\n",
       "      <td>0.898309</td>\n",
       "      <td>0.890803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.043800</td>\n",
       "      <td>0.532979</td>\n",
       "      <td>0.899289</td>\n",
       "      <td>0.893285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.039500</td>\n",
       "      <td>0.554933</td>\n",
       "      <td>0.899289</td>\n",
       "      <td>0.892523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.578539</td>\n",
       "      <td>0.905415</td>\n",
       "      <td>0.898221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.036900</td>\n",
       "      <td>0.618843</td>\n",
       "      <td>0.901740</td>\n",
       "      <td>0.894515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.026100</td>\n",
       "      <td>0.640074</td>\n",
       "      <td>0.900025</td>\n",
       "      <td>0.893515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.666724</td>\n",
       "      <td>0.900270</td>\n",
       "      <td>0.891925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.026600</td>\n",
       "      <td>0.664162</td>\n",
       "      <td>0.901250</td>\n",
       "      <td>0.893361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.025500</td>\n",
       "      <td>0.700354</td>\n",
       "      <td>0.898064</td>\n",
       "      <td>0.890734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.020900</td>\n",
       "      <td>0.678100</td>\n",
       "      <td>0.899534</td>\n",
       "      <td>0.892073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.023600</td>\n",
       "      <td>0.747825</td>\n",
       "      <td>0.899534</td>\n",
       "      <td>0.891984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.022900</td>\n",
       "      <td>0.732650</td>\n",
       "      <td>0.897084</td>\n",
       "      <td>0.889803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.020800</td>\n",
       "      <td>0.743748</td>\n",
       "      <td>0.898064</td>\n",
       "      <td>0.891343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.023400</td>\n",
       "      <td>0.737288</td>\n",
       "      <td>0.899044</td>\n",
       "      <td>0.891960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.020800</td>\n",
       "      <td>0.729431</td>\n",
       "      <td>0.900760</td>\n",
       "      <td>0.893810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.023200</td>\n",
       "      <td>0.747861</td>\n",
       "      <td>0.898309</td>\n",
       "      <td>0.891391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.019300</td>\n",
       "      <td>0.744082</td>\n",
       "      <td>0.899044</td>\n",
       "      <td>0.891902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorrBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at otmangi/MorrBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "183d425f98a84d359ace0e91e6745b11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16321 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9609137858724ae79e02d62269cec38c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4081 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3072' max='3072' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3072/3072 04:52, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.326000</td>\n",
       "      <td>0.291866</td>\n",
       "      <td>0.872580</td>\n",
       "      <td>0.865034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.279100</td>\n",
       "      <td>0.251395</td>\n",
       "      <td>0.891693</td>\n",
       "      <td>0.883874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.231200</td>\n",
       "      <td>0.265044</td>\n",
       "      <td>0.902230</td>\n",
       "      <td>0.893409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.144300</td>\n",
       "      <td>0.267153</td>\n",
       "      <td>0.904925</td>\n",
       "      <td>0.898550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.152000</td>\n",
       "      <td>0.255104</td>\n",
       "      <td>0.902720</td>\n",
       "      <td>0.896611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.091000</td>\n",
       "      <td>0.342193</td>\n",
       "      <td>0.905415</td>\n",
       "      <td>0.898447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.087600</td>\n",
       "      <td>0.360282</td>\n",
       "      <td>0.900760</td>\n",
       "      <td>0.893256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.121600</td>\n",
       "      <td>0.436092</td>\n",
       "      <td>0.900270</td>\n",
       "      <td>0.892819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.067300</td>\n",
       "      <td>0.399853</td>\n",
       "      <td>0.899779</td>\n",
       "      <td>0.891167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.072200</td>\n",
       "      <td>0.351520</td>\n",
       "      <td>0.907621</td>\n",
       "      <td>0.900154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.052600</td>\n",
       "      <td>0.548984</td>\n",
       "      <td>0.902965</td>\n",
       "      <td>0.894830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.049500</td>\n",
       "      <td>0.578825</td>\n",
       "      <td>0.898799</td>\n",
       "      <td>0.890746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.051400</td>\n",
       "      <td>0.603485</td>\n",
       "      <td>0.898554</td>\n",
       "      <td>0.890082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.041400</td>\n",
       "      <td>0.540927</td>\n",
       "      <td>0.898309</td>\n",
       "      <td>0.890803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.043800</td>\n",
       "      <td>0.532979</td>\n",
       "      <td>0.899289</td>\n",
       "      <td>0.893285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.039500</td>\n",
       "      <td>0.554933</td>\n",
       "      <td>0.899289</td>\n",
       "      <td>0.892523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.578539</td>\n",
       "      <td>0.905415</td>\n",
       "      <td>0.898221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.036900</td>\n",
       "      <td>0.618843</td>\n",
       "      <td>0.901740</td>\n",
       "      <td>0.894515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.026100</td>\n",
       "      <td>0.640074</td>\n",
       "      <td>0.900025</td>\n",
       "      <td>0.893515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.666724</td>\n",
       "      <td>0.900270</td>\n",
       "      <td>0.891925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.026600</td>\n",
       "      <td>0.664162</td>\n",
       "      <td>0.901250</td>\n",
       "      <td>0.893361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.025500</td>\n",
       "      <td>0.700354</td>\n",
       "      <td>0.898064</td>\n",
       "      <td>0.890734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.020900</td>\n",
       "      <td>0.678100</td>\n",
       "      <td>0.899534</td>\n",
       "      <td>0.892073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.023600</td>\n",
       "      <td>0.747825</td>\n",
       "      <td>0.899534</td>\n",
       "      <td>0.891984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.022900</td>\n",
       "      <td>0.732650</td>\n",
       "      <td>0.897084</td>\n",
       "      <td>0.889803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.020800</td>\n",
       "      <td>0.743748</td>\n",
       "      <td>0.898064</td>\n",
       "      <td>0.891343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.023400</td>\n",
       "      <td>0.737288</td>\n",
       "      <td>0.899044</td>\n",
       "      <td>0.891960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.020800</td>\n",
       "      <td>0.729431</td>\n",
       "      <td>0.900760</td>\n",
       "      <td>0.893810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.023200</td>\n",
       "      <td>0.747861</td>\n",
       "      <td>0.898309</td>\n",
       "      <td>0.891391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.019300</td>\n",
       "      <td>0.744082</td>\n",
       "      <td>0.899044</td>\n",
       "      <td>0.891902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorrBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at otmangi/MorrBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0238d8fb269b416db378cfe5c5d6ca64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16321 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c64edc5439534b7f9c786a3fc6eacac5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4081 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3072' max='3072' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3072/3072 04:52, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.351500</td>\n",
       "      <td>0.289318</td>\n",
       "      <td>0.866699</td>\n",
       "      <td>0.861923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.281700</td>\n",
       "      <td>0.271015</td>\n",
       "      <td>0.893654</td>\n",
       "      <td>0.885207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.214600</td>\n",
       "      <td>0.302248</td>\n",
       "      <td>0.899779</td>\n",
       "      <td>0.892733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.153400</td>\n",
       "      <td>0.294887</td>\n",
       "      <td>0.902230</td>\n",
       "      <td>0.895715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.148700</td>\n",
       "      <td>0.278163</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.898945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.079000</td>\n",
       "      <td>0.345093</td>\n",
       "      <td>0.900760</td>\n",
       "      <td>0.894713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.091400</td>\n",
       "      <td>0.374306</td>\n",
       "      <td>0.901985</td>\n",
       "      <td>0.895974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.080100</td>\n",
       "      <td>0.462016</td>\n",
       "      <td>0.902965</td>\n",
       "      <td>0.895902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.058200</td>\n",
       "      <td>0.398301</td>\n",
       "      <td>0.902720</td>\n",
       "      <td>0.896637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.059300</td>\n",
       "      <td>0.497955</td>\n",
       "      <td>0.902720</td>\n",
       "      <td>0.895335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.049000</td>\n",
       "      <td>0.550737</td>\n",
       "      <td>0.903945</td>\n",
       "      <td>0.898256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.043200</td>\n",
       "      <td>0.513833</td>\n",
       "      <td>0.898309</td>\n",
       "      <td>0.891702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.045800</td>\n",
       "      <td>0.601682</td>\n",
       "      <td>0.901005</td>\n",
       "      <td>0.894934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.035800</td>\n",
       "      <td>0.476530</td>\n",
       "      <td>0.904190</td>\n",
       "      <td>0.897453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.037800</td>\n",
       "      <td>0.587503</td>\n",
       "      <td>0.904190</td>\n",
       "      <td>0.898251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.025700</td>\n",
       "      <td>0.647318</td>\n",
       "      <td>0.901985</td>\n",
       "      <td>0.894994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.027600</td>\n",
       "      <td>0.667708</td>\n",
       "      <td>0.903210</td>\n",
       "      <td>0.896815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.023600</td>\n",
       "      <td>0.677796</td>\n",
       "      <td>0.903700</td>\n",
       "      <td>0.897934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.023200</td>\n",
       "      <td>0.723847</td>\n",
       "      <td>0.902475</td>\n",
       "      <td>0.895376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.025700</td>\n",
       "      <td>0.676298</td>\n",
       "      <td>0.903455</td>\n",
       "      <td>0.897036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.020400</td>\n",
       "      <td>0.681838</td>\n",
       "      <td>0.905415</td>\n",
       "      <td>0.899463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.022600</td>\n",
       "      <td>0.737127</td>\n",
       "      <td>0.902230</td>\n",
       "      <td>0.895467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.020700</td>\n",
       "      <td>0.713678</td>\n",
       "      <td>0.900760</td>\n",
       "      <td>0.894064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.016400</td>\n",
       "      <td>0.764993</td>\n",
       "      <td>0.902230</td>\n",
       "      <td>0.896011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.020800</td>\n",
       "      <td>0.737535</td>\n",
       "      <td>0.901985</td>\n",
       "      <td>0.895764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.022300</td>\n",
       "      <td>0.779993</td>\n",
       "      <td>0.901740</td>\n",
       "      <td>0.894831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.017300</td>\n",
       "      <td>0.774873</td>\n",
       "      <td>0.902230</td>\n",
       "      <td>0.895931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.018500</td>\n",
       "      <td>0.778298</td>\n",
       "      <td>0.901740</td>\n",
       "      <td>0.895463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.017200</td>\n",
       "      <td>0.789998</td>\n",
       "      <td>0.901740</td>\n",
       "      <td>0.895543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.019100</td>\n",
       "      <td>0.795040</td>\n",
       "      <td>0.901985</td>\n",
       "      <td>0.895790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorrBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at otmangi/MorrBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f0f0f38bc4c438c8a139111d8f24de6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16321 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53f9ca4dccdd49a88263ddd6041b7239",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4081 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3072' max='3072' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3072/3072 04:52, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.351500</td>\n",
       "      <td>0.289318</td>\n",
       "      <td>0.866699</td>\n",
       "      <td>0.861923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.281700</td>\n",
       "      <td>0.271015</td>\n",
       "      <td>0.893654</td>\n",
       "      <td>0.885207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.214600</td>\n",
       "      <td>0.302248</td>\n",
       "      <td>0.899779</td>\n",
       "      <td>0.892733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.153400</td>\n",
       "      <td>0.294887</td>\n",
       "      <td>0.902230</td>\n",
       "      <td>0.895715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.148700</td>\n",
       "      <td>0.278163</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.898945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.079000</td>\n",
       "      <td>0.345093</td>\n",
       "      <td>0.900760</td>\n",
       "      <td>0.894713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.091400</td>\n",
       "      <td>0.374306</td>\n",
       "      <td>0.901985</td>\n",
       "      <td>0.895974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.080100</td>\n",
       "      <td>0.462016</td>\n",
       "      <td>0.902965</td>\n",
       "      <td>0.895902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.058200</td>\n",
       "      <td>0.398301</td>\n",
       "      <td>0.902720</td>\n",
       "      <td>0.896637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.059300</td>\n",
       "      <td>0.497955</td>\n",
       "      <td>0.902720</td>\n",
       "      <td>0.895335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.049000</td>\n",
       "      <td>0.550737</td>\n",
       "      <td>0.903945</td>\n",
       "      <td>0.898256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.043200</td>\n",
       "      <td>0.513833</td>\n",
       "      <td>0.898309</td>\n",
       "      <td>0.891702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.045800</td>\n",
       "      <td>0.601682</td>\n",
       "      <td>0.901005</td>\n",
       "      <td>0.894934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.035800</td>\n",
       "      <td>0.476530</td>\n",
       "      <td>0.904190</td>\n",
       "      <td>0.897453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.037800</td>\n",
       "      <td>0.587503</td>\n",
       "      <td>0.904190</td>\n",
       "      <td>0.898251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.025700</td>\n",
       "      <td>0.647318</td>\n",
       "      <td>0.901985</td>\n",
       "      <td>0.894994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.027600</td>\n",
       "      <td>0.667708</td>\n",
       "      <td>0.903210</td>\n",
       "      <td>0.896815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.023600</td>\n",
       "      <td>0.677796</td>\n",
       "      <td>0.903700</td>\n",
       "      <td>0.897934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.023200</td>\n",
       "      <td>0.723847</td>\n",
       "      <td>0.902475</td>\n",
       "      <td>0.895376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.025700</td>\n",
       "      <td>0.676298</td>\n",
       "      <td>0.903455</td>\n",
       "      <td>0.897036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.020400</td>\n",
       "      <td>0.681838</td>\n",
       "      <td>0.905415</td>\n",
       "      <td>0.899463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.022600</td>\n",
       "      <td>0.737127</td>\n",
       "      <td>0.902230</td>\n",
       "      <td>0.895467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.020700</td>\n",
       "      <td>0.713678</td>\n",
       "      <td>0.900760</td>\n",
       "      <td>0.894064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.016400</td>\n",
       "      <td>0.764993</td>\n",
       "      <td>0.902230</td>\n",
       "      <td>0.896011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.020800</td>\n",
       "      <td>0.737535</td>\n",
       "      <td>0.901985</td>\n",
       "      <td>0.895764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.022300</td>\n",
       "      <td>0.779993</td>\n",
       "      <td>0.901740</td>\n",
       "      <td>0.894831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.017300</td>\n",
       "      <td>0.774873</td>\n",
       "      <td>0.902230</td>\n",
       "      <td>0.895931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.018500</td>\n",
       "      <td>0.778298</td>\n",
       "      <td>0.901740</td>\n",
       "      <td>0.895463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.017200</td>\n",
       "      <td>0.789998</td>\n",
       "      <td>0.901740</td>\n",
       "      <td>0.895543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.019100</td>\n",
       "      <td>0.795040</td>\n",
       "      <td>0.901985</td>\n",
       "      <td>0.895790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorrBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at otmangi/MorrBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c0b4c6b05154ae5b1cf4aaa401215f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16321 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76d4398c95004556bc6d9472478f54f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4081 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3072' max='3072' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3072/3072 04:53, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.351500</td>\n",
       "      <td>0.289318</td>\n",
       "      <td>0.866699</td>\n",
       "      <td>0.861923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.281700</td>\n",
       "      <td>0.271015</td>\n",
       "      <td>0.893654</td>\n",
       "      <td>0.885207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.214600</td>\n",
       "      <td>0.302248</td>\n",
       "      <td>0.899779</td>\n",
       "      <td>0.892733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.153400</td>\n",
       "      <td>0.294887</td>\n",
       "      <td>0.902230</td>\n",
       "      <td>0.895715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.148700</td>\n",
       "      <td>0.278163</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.898945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.079000</td>\n",
       "      <td>0.345093</td>\n",
       "      <td>0.900760</td>\n",
       "      <td>0.894713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.091400</td>\n",
       "      <td>0.374306</td>\n",
       "      <td>0.901985</td>\n",
       "      <td>0.895974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.080100</td>\n",
       "      <td>0.462016</td>\n",
       "      <td>0.902965</td>\n",
       "      <td>0.895902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.058200</td>\n",
       "      <td>0.398301</td>\n",
       "      <td>0.902720</td>\n",
       "      <td>0.896637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.059300</td>\n",
       "      <td>0.497955</td>\n",
       "      <td>0.902720</td>\n",
       "      <td>0.895335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.049000</td>\n",
       "      <td>0.550737</td>\n",
       "      <td>0.903945</td>\n",
       "      <td>0.898256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.043200</td>\n",
       "      <td>0.513833</td>\n",
       "      <td>0.898309</td>\n",
       "      <td>0.891702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.045800</td>\n",
       "      <td>0.601682</td>\n",
       "      <td>0.901005</td>\n",
       "      <td>0.894934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.035800</td>\n",
       "      <td>0.476530</td>\n",
       "      <td>0.904190</td>\n",
       "      <td>0.897453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.037800</td>\n",
       "      <td>0.587503</td>\n",
       "      <td>0.904190</td>\n",
       "      <td>0.898251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.025700</td>\n",
       "      <td>0.647318</td>\n",
       "      <td>0.901985</td>\n",
       "      <td>0.894994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.027600</td>\n",
       "      <td>0.667708</td>\n",
       "      <td>0.903210</td>\n",
       "      <td>0.896815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.023600</td>\n",
       "      <td>0.677796</td>\n",
       "      <td>0.903700</td>\n",
       "      <td>0.897934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.023200</td>\n",
       "      <td>0.723847</td>\n",
       "      <td>0.902475</td>\n",
       "      <td>0.895376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.025700</td>\n",
       "      <td>0.676298</td>\n",
       "      <td>0.903455</td>\n",
       "      <td>0.897036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.020400</td>\n",
       "      <td>0.681838</td>\n",
       "      <td>0.905415</td>\n",
       "      <td>0.899463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.022600</td>\n",
       "      <td>0.737127</td>\n",
       "      <td>0.902230</td>\n",
       "      <td>0.895467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.020700</td>\n",
       "      <td>0.713678</td>\n",
       "      <td>0.900760</td>\n",
       "      <td>0.894064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.016400</td>\n",
       "      <td>0.764993</td>\n",
       "      <td>0.902230</td>\n",
       "      <td>0.896011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.020800</td>\n",
       "      <td>0.737535</td>\n",
       "      <td>0.901985</td>\n",
       "      <td>0.895764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.022300</td>\n",
       "      <td>0.779993</td>\n",
       "      <td>0.901740</td>\n",
       "      <td>0.894831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.017300</td>\n",
       "      <td>0.774873</td>\n",
       "      <td>0.902230</td>\n",
       "      <td>0.895931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.018500</td>\n",
       "      <td>0.778298</td>\n",
       "      <td>0.901740</td>\n",
       "      <td>0.895463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.017200</td>\n",
       "      <td>0.789998</td>\n",
       "      <td>0.901740</td>\n",
       "      <td>0.895543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.019100</td>\n",
       "      <td>0.795040</td>\n",
       "      <td>0.901985</td>\n",
       "      <td>0.895790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SI2M-Lab/DarijaBERT</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.889196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alger-ia/dziribert</td>\n",
       "      <td>0.900270</td>\n",
       "      <td>0.892608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>faisalq/EgyBERT</td>\n",
       "      <td>0.895369</td>\n",
       "      <td>0.887830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>faisalq/SaudiBERT</td>\n",
       "      <td>0.900515</td>\n",
       "      <td>0.894413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>otmangi/MorRoBERTa</td>\n",
       "      <td>0.899779</td>\n",
       "      <td>0.893240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>otmangi/MorrBERT</td>\n",
       "      <td>0.907621</td>\n",
       "      <td>0.900154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>tunis-ai/TunBERT</td>\n",
       "      <td>0.802989</td>\n",
       "      <td>0.781232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model  Accuracy        F1\n",
       "0   SI2M-Lab/DarijaBERT  0.896104  0.889196\n",
       "3    alger-ia/dziribert  0.900270  0.892608\n",
       "6       faisalq/EgyBERT  0.895369  0.887830\n",
       "9     faisalq/SaudiBERT  0.900515  0.894413\n",
       "12   otmangi/MorRoBERTa  0.899779  0.893240\n",
       "15     otmangi/MorrBERT  0.907621  0.900154\n",
       "18     tunis-ai/TunBERT  0.802989  0.781232"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" \n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import pyarabic.araby as araby\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.initializers import TruncatedNormal\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from datasets import load_dataset, Dataset, concatenate_datasets\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', 1000)\n",
    "\n",
    "\n",
    "fname = 'MDOD_2'\n",
    "log_file = fname + '.txt'\n",
    "\n",
    "with open(log_file, 'w') as f:\n",
    "    f.write('Model,Accuracy,F1\\n')\n",
    "\n",
    "\n",
    "df = pd.read_csv('datasets/Moroccan_Darija_Offensive_Language_Detection_Dataset.csv', encoding='utf-8', engine='python') #, quotechar=\"'\"  , quoting=3\n",
    "\n",
    "\n",
    "      \n",
    "display(df.columns)\n",
    "display(len(df))\n",
    "display(df[:4])\n",
    "\n",
    "\n",
    "\n",
    "classes = set(df['label'].values)\n",
    "display(classes)\n",
    "\n",
    "c = df['label'].value_counts()\n",
    "display(c)\n",
    "\n",
    "df['label'] = df['label'].astype('category')\n",
    "df['label'] = df['label'].cat.codes\n",
    "\n",
    "df = df[['text', 'label']]\n",
    "classes_num = len(classes)\n",
    "display(classes_num)\n",
    "display(len(df))\n",
    "\n",
    "\n",
    "ds = Dataset.from_pandas(df)\n",
    "ds = ds.train_test_split(test_size=0.2)\n",
    "\n",
    "display(ds)\n",
    "\n",
    "max_sequence_length = 128\n",
    "\n",
    "\n",
    "models = [ \n",
    "        'faisalq/EgyBERT',            \n",
    "    'faisalq/SaudiBERT',            \n",
    "    'tunis-ai/TunBERT',\n",
    "    'alger-ia/dziribert',\n",
    "    'SI2M-Lab/DarijaBERT',\n",
    "    'otmangi/MorRoBERTa',\n",
    "    'otmangi/MorrBERT'\n",
    "            \n",
    "]\n",
    "\n",
    "seeds = [0, 1, 42]\n",
    "\n",
    "for model_name in models:\n",
    "    for seed in seeds:\n",
    "        ds = Dataset.from_pandas(df)\n",
    "        ds = ds.train_test_split(test_size=0.2, seed = seed)\n",
    "        if seed==0:\n",
    "            display(ds)\n",
    "        for i in range(3):\n",
    "            print(f'{model_name}, try:{i}')\n",
    "                  \n",
    "            tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "            model = AutoModelForSequenceClassification.from_pretrained(model_name,\n",
    "                                                                  num_labels=classes_num).to('cuda')                                                 \n",
    "            dataset_train = ds['train']\n",
    "            dataset_validation = ds['test']                                                    \n",
    "            \n",
    "          \n",
    "    \n",
    "            def preprocess_function(examples):\n",
    "                return tokenizer(examples['text'], truncation=True, padding=\"max_length\",\n",
    "                                max_length=max_sequence_length)\n",
    "            \n",
    "            \n",
    "            dataset_train = dataset_train.map(preprocess_function, batched=True) # , batched=True\n",
    "            dataset_validation = dataset_validation.map(preprocess_function, batched=True)  # , batched=True\n",
    "            \n",
    "           \n",
    "            \n",
    "            def compute_metrics(eval_pred):\n",
    "                logits, labels = eval_pred\n",
    "                predictions = np.argmax(logits, axis=-1)    \n",
    "                acc = accuracy_score(labels, predictions)        \n",
    "                f1 = f1_score(labels, predictions, average='macro')   \n",
    "                with open(log_file, 'a') as f:\n",
    "                    f.write(f'{model_name},{acc},{f1}\\n')\n",
    "                return {'accuracy': acc, 'f1_score': f1}\n",
    "    \n",
    "    \n",
    "            \n",
    "            \n",
    "            epochs = 12\n",
    "            save_steps = 10000 #save checkpoint every 10000 steps\n",
    "            batch_size = 64\n",
    "            \n",
    "            training_args = TrainingArguments(\n",
    "                output_dir = 'bert/',\n",
    "                overwrite_output_dir=True,\n",
    "                num_train_epochs = epochs,\n",
    "                per_device_train_batch_size = batch_size,\n",
    "                per_device_eval_batch_size = batch_size,\n",
    "                save_steps = save_steps,\n",
    "                save_total_limit = 1, #only save the last 5 checkpoints\n",
    "                fp16=True,\n",
    "                learning_rate = 5e-5,  # 5e-5 is the default\n",
    "                logging_steps = 100, #50_000\n",
    "                evaluation_strategy = 'steps',\n",
    "                # evaluate_during_training = True,\n",
    "                eval_steps = 100\n",
    "                \n",
    "            )\n",
    "            \n",
    "            trainer = Trainer(\n",
    "                model = model,\n",
    "                args = training_args,\n",
    "                # data_collator=data_collator,\n",
    "                train_dataset=dataset_train,\n",
    "                eval_dataset=dataset_validation,\n",
    "                compute_metrics = compute_metrics\n",
    "            )\n",
    "            \n",
    "            \n",
    "            trainer.train()\n",
    "\n",
    "\n",
    "results = pd.read_csv(log_file)\n",
    "\n",
    "best_results = results.groupby('Model', as_index=False)['F1'].max()\n",
    "\n",
    "best_results = pd.merge(best_results, results, on=['Model', 'F1'])\n",
    "best_results = best_results[['Model', 'Accuracy', 'F1']]\n",
    "best_results = best_results.drop_duplicates()\n",
    "best_results.to_csv(f'{fname}.csv')\n",
    "display(best_results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a213ac86-934f-4e82-a949-0bcdcae2188d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220784d6-b06d-4429-adb8-0026654f9d49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8647cf08-3aa6-44eb-846f-4bed97554042",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8794b705-31a1-45d7-8e88-4017a9c282aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
