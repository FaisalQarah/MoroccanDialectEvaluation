{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d804ae66-9435-44be-8aad-beacbdeec0f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-19 08:14:33.348378: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-19 08:14:33.374453: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-19 08:14:34.032472: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Found cached dataset parquet (/home/ffq/.cache/huggingface/datasets/ohidaoui___parquet/ohidaoui--darija-reviews-34030453886e5230/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b829eba9a7d4654a5b18100617db46c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "851"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['review', 'label', 'topic', 'writing_style'], dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>topic</th>\n",
       "      <th>writing_style</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>داسيا فقدت أهم ميزة كانت تميزها وهي السعر للأسف !</td>\n",
       "      <td>negative</td>\n",
       "      <td>automotive</td>\n",
       "      <td>Arabic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>لاأظنها ستنجح كالنسخ الأولى</td>\n",
       "      <td>negative</td>\n",
       "      <td>automotive</td>\n",
       "      <td>Arabic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Khas ykon tghyir mbanch li lfar9 rir fa dizayn lkrasa mikanik tablo fih dak lblstik lmryat 3lach mdyrinch lhm daw volm mzl kif mahwa jwant kifma howa fin kyn lfr9 fdizyn ama ljiti tchof mkynch fra9 fra9 howa y9riban 40% mli kt9ol l3mrya hdi bnsba li ana nas 3morya ama l3morya kolchi daw mzl khsha whd 10 ans wnchofo ana knfdl dacia l9dima</td>\n",
       "      <td>negative</td>\n",
       "      <td>automotive</td>\n",
       "      <td>Arabizi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>هناك اختيارات أحسن وماركات عالميه أجود من داصيا.</td>\n",
       "      <td>negative</td>\n",
       "      <td>automotive</td>\n",
       "      <td>Arabic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                review   \n",
       "0                                                                                                                                                                                                                                                                                                    داسيا فقدت أهم ميزة كانت تميزها وهي السعر للأسف !  \\\n",
       "1                                                                                                                                                                                                                                                                                                                          لاأظنها ستنجح كالنسخ الأولى   \n",
       "2  Khas ykon tghyir mbanch li lfar9 rir fa dizayn lkrasa mikanik tablo fih dak lblstik lmryat 3lach mdyrinch lhm daw volm mzl kif mahwa jwant kifma howa fin kyn lfr9 fdizyn ama ljiti tchof mkynch fra9 fra9 howa y9riban 40% mli kt9ol l3mrya hdi bnsba li ana nas 3morya ama l3morya kolchi daw mzl khsha whd 10 ans wnchofo ana knfdl dacia l9dima   \n",
       "3                                                                                                                                                                                                                                                                                                     هناك اختيارات أحسن وماركات عالميه أجود من داصيا.   \n",
       "\n",
       "      label       topic writing_style  \n",
       "0  negative  automotive        Arabic  \n",
       "1  negative  automotive        Arabic  \n",
       "2  negative  automotive       Arabizi  \n",
       "3  negative  automotive        Arabic  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "topic\n",
       "it                      287\n",
       "cosmetics               172\n",
       "entertainment           121\n",
       "clothing                 93\n",
       "cleaning                 57\n",
       "hospitality              37\n",
       "household appliances     33\n",
       "automotive               20\n",
       "restaurants              19\n",
       "jewelry                   8\n",
       "other                     4\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'automotive',\n",
       " 'cleaning',\n",
       " 'clothing',\n",
       " 'cosmetics',\n",
       " 'entertainment',\n",
       " 'hospitality',\n",
       " 'household appliances',\n",
       " 'it',\n",
       " 'jewelry',\n",
       " 'other',\n",
       " 'restaurants'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "851"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['review', 'label'],\n",
       "        num_rows: 680\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['review', 'label'],\n",
       "        num_rows: 171\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/EgyBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/EgyBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:28, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.386500</td>\n",
       "      <td>2.356839</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.053333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.329900</td>\n",
       "      <td>2.302597</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.053333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.273500</td>\n",
       "      <td>2.247339</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.053333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.212900</td>\n",
       "      <td>2.190681</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.053333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.141800</td>\n",
       "      <td>2.129957</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.053333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2.093100</td>\n",
       "      <td>2.062466</td>\n",
       "      <td>0.339181</td>\n",
       "      <td>0.080938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.970200</td>\n",
       "      <td>1.997801</td>\n",
       "      <td>0.345029</td>\n",
       "      <td>0.085586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.955000</td>\n",
       "      <td>1.939727</td>\n",
       "      <td>0.438596</td>\n",
       "      <td>0.134863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.849100</td>\n",
       "      <td>1.878672</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.137375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.763600</td>\n",
       "      <td>1.823985</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.134867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.706700</td>\n",
       "      <td>1.772746</td>\n",
       "      <td>0.438596</td>\n",
       "      <td>0.133067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.627200</td>\n",
       "      <td>1.728207</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.142185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1.559900</td>\n",
       "      <td>1.674371</td>\n",
       "      <td>0.479532</td>\n",
       "      <td>0.175493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.458300</td>\n",
       "      <td>1.643735</td>\n",
       "      <td>0.508772</td>\n",
       "      <td>0.287978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.462000</td>\n",
       "      <td>1.614298</td>\n",
       "      <td>0.502924</td>\n",
       "      <td>0.279665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.371300</td>\n",
       "      <td>1.587561</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.248804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.372800</td>\n",
       "      <td>1.572551</td>\n",
       "      <td>0.584795</td>\n",
       "      <td>0.250059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.254100</td>\n",
       "      <td>1.539542</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.326975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.238300</td>\n",
       "      <td>1.537112</td>\n",
       "      <td>0.643275</td>\n",
       "      <td>0.370686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.208400</td>\n",
       "      <td>1.500959</td>\n",
       "      <td>0.637427</td>\n",
       "      <td>0.365850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1.164900</td>\n",
       "      <td>1.477586</td>\n",
       "      <td>0.660819</td>\n",
       "      <td>0.382243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1.141400</td>\n",
       "      <td>1.472129</td>\n",
       "      <td>0.654971</td>\n",
       "      <td>0.380383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1.106100</td>\n",
       "      <td>1.468799</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.404774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1.067100</td>\n",
       "      <td>1.466630</td>\n",
       "      <td>0.660819</td>\n",
       "      <td>0.384817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.105200</td>\n",
       "      <td>1.450186</td>\n",
       "      <td>0.690058</td>\n",
       "      <td>0.422197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1.006000</td>\n",
       "      <td>1.444015</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.426857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1.055900</td>\n",
       "      <td>1.460938</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.433558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1.019200</td>\n",
       "      <td>1.442568</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.390051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.982800</td>\n",
       "      <td>1.425009</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.409107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.013800</td>\n",
       "      <td>1.435676</td>\n",
       "      <td>0.690058</td>\n",
       "      <td>0.399045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.986700</td>\n",
       "      <td>1.437212</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.405789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.940400</td>\n",
       "      <td>1.434005</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.405789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1.002300</td>\n",
       "      <td>1.432724</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.405789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/EgyBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/EgyBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:28, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.378500</td>\n",
       "      <td>2.349153</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.053333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.319800</td>\n",
       "      <td>2.293323</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.053333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.260200</td>\n",
       "      <td>2.238293</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.053333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.199000</td>\n",
       "      <td>2.180835</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.053333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.127300</td>\n",
       "      <td>2.123355</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.053333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2.086200</td>\n",
       "      <td>2.071563</td>\n",
       "      <td>0.385965</td>\n",
       "      <td>0.112683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.962500</td>\n",
       "      <td>2.004363</td>\n",
       "      <td>0.415205</td>\n",
       "      <td>0.125480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.943900</td>\n",
       "      <td>1.934142</td>\n",
       "      <td>0.426901</td>\n",
       "      <td>0.130435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.838700</td>\n",
       "      <td>1.871642</td>\n",
       "      <td>0.438596</td>\n",
       "      <td>0.133625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.749000</td>\n",
       "      <td>1.827388</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.136030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.707700</td>\n",
       "      <td>1.783917</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.127859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.632700</td>\n",
       "      <td>1.736891</td>\n",
       "      <td>0.438596</td>\n",
       "      <td>0.134206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1.571600</td>\n",
       "      <td>1.700064</td>\n",
       "      <td>0.426901</td>\n",
       "      <td>0.130026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.472200</td>\n",
       "      <td>1.656438</td>\n",
       "      <td>0.456140</td>\n",
       "      <td>0.205883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.474900</td>\n",
       "      <td>1.614141</td>\n",
       "      <td>0.461988</td>\n",
       "      <td>0.207775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.370200</td>\n",
       "      <td>1.585749</td>\n",
       "      <td>0.461988</td>\n",
       "      <td>0.243836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.377200</td>\n",
       "      <td>1.552108</td>\n",
       "      <td>0.520468</td>\n",
       "      <td>0.299429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.249800</td>\n",
       "      <td>1.547609</td>\n",
       "      <td>0.520468</td>\n",
       "      <td>0.269490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.233300</td>\n",
       "      <td>1.515047</td>\n",
       "      <td>0.567251</td>\n",
       "      <td>0.305856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.203600</td>\n",
       "      <td>1.488838</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.286301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1.155600</td>\n",
       "      <td>1.459416</td>\n",
       "      <td>0.602339</td>\n",
       "      <td>0.319292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1.134600</td>\n",
       "      <td>1.444394</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.349050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1.091200</td>\n",
       "      <td>1.423712</td>\n",
       "      <td>0.596491</td>\n",
       "      <td>0.314320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1.059100</td>\n",
       "      <td>1.401898</td>\n",
       "      <td>0.608187</td>\n",
       "      <td>0.331789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.081000</td>\n",
       "      <td>1.388756</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.348382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.997300</td>\n",
       "      <td>1.389085</td>\n",
       "      <td>0.637427</td>\n",
       "      <td>0.388996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1.017500</td>\n",
       "      <td>1.378097</td>\n",
       "      <td>0.654971</td>\n",
       "      <td>0.404226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1.003300</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.459321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.955900</td>\n",
       "      <td>1.368834</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.384809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.993600</td>\n",
       "      <td>1.368702</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.389482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.959900</td>\n",
       "      <td>1.357838</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.389141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.919900</td>\n",
       "      <td>1.358520</td>\n",
       "      <td>0.672515</td>\n",
       "      <td>0.391564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.979800</td>\n",
       "      <td>1.359856</td>\n",
       "      <td>0.672515</td>\n",
       "      <td>0.391564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/EgyBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/EgyBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:28, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.378500</td>\n",
       "      <td>2.349153</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.053333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.319800</td>\n",
       "      <td>2.293323</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.053333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.260200</td>\n",
       "      <td>2.238293</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.053333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.199000</td>\n",
       "      <td>2.180835</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.053333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.127300</td>\n",
       "      <td>2.123355</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.053333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2.086200</td>\n",
       "      <td>2.071563</td>\n",
       "      <td>0.385965</td>\n",
       "      <td>0.112683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.962500</td>\n",
       "      <td>2.004363</td>\n",
       "      <td>0.415205</td>\n",
       "      <td>0.125480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.943900</td>\n",
       "      <td>1.934142</td>\n",
       "      <td>0.426901</td>\n",
       "      <td>0.130435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.838700</td>\n",
       "      <td>1.871642</td>\n",
       "      <td>0.438596</td>\n",
       "      <td>0.133625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.749000</td>\n",
       "      <td>1.827388</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.136030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.707700</td>\n",
       "      <td>1.783917</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.127859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.632700</td>\n",
       "      <td>1.736891</td>\n",
       "      <td>0.438596</td>\n",
       "      <td>0.134206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1.571600</td>\n",
       "      <td>1.700064</td>\n",
       "      <td>0.426901</td>\n",
       "      <td>0.130026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.472200</td>\n",
       "      <td>1.656438</td>\n",
       "      <td>0.456140</td>\n",
       "      <td>0.205883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.474900</td>\n",
       "      <td>1.614141</td>\n",
       "      <td>0.461988</td>\n",
       "      <td>0.207775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.370200</td>\n",
       "      <td>1.585749</td>\n",
       "      <td>0.461988</td>\n",
       "      <td>0.243836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.377200</td>\n",
       "      <td>1.552108</td>\n",
       "      <td>0.520468</td>\n",
       "      <td>0.299429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.249800</td>\n",
       "      <td>1.547609</td>\n",
       "      <td>0.520468</td>\n",
       "      <td>0.269490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.233300</td>\n",
       "      <td>1.515047</td>\n",
       "      <td>0.567251</td>\n",
       "      <td>0.305856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.203600</td>\n",
       "      <td>1.488838</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.286301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1.155600</td>\n",
       "      <td>1.459416</td>\n",
       "      <td>0.602339</td>\n",
       "      <td>0.319292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1.134600</td>\n",
       "      <td>1.444394</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.349050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1.091200</td>\n",
       "      <td>1.423712</td>\n",
       "      <td>0.596491</td>\n",
       "      <td>0.314320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1.059100</td>\n",
       "      <td>1.401898</td>\n",
       "      <td>0.608187</td>\n",
       "      <td>0.331789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.081000</td>\n",
       "      <td>1.388756</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.348382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.997300</td>\n",
       "      <td>1.389085</td>\n",
       "      <td>0.637427</td>\n",
       "      <td>0.388996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1.017500</td>\n",
       "      <td>1.378097</td>\n",
       "      <td>0.654971</td>\n",
       "      <td>0.404226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1.003300</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.459321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.955900</td>\n",
       "      <td>1.368834</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.384809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.993600</td>\n",
       "      <td>1.368702</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.389482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.959900</td>\n",
       "      <td>1.357838</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.389141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.919900</td>\n",
       "      <td>1.358520</td>\n",
       "      <td>0.672515</td>\n",
       "      <td>0.391564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.979800</td>\n",
       "      <td>1.359856</td>\n",
       "      <td>0.672515</td>\n",
       "      <td>0.391564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/EgyBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/EgyBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:28, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.380000</td>\n",
       "      <td>2.342060</td>\n",
       "      <td>0.397661</td>\n",
       "      <td>0.051731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.326900</td>\n",
       "      <td>2.278989</td>\n",
       "      <td>0.397661</td>\n",
       "      <td>0.051731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.264300</td>\n",
       "      <td>2.214650</td>\n",
       "      <td>0.397661</td>\n",
       "      <td>0.051731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.218500</td>\n",
       "      <td>2.152698</td>\n",
       "      <td>0.397661</td>\n",
       "      <td>0.051731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.134800</td>\n",
       "      <td>2.086971</td>\n",
       "      <td>0.397661</td>\n",
       "      <td>0.051731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2.075400</td>\n",
       "      <td>2.019508</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.104692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>2.009600</td>\n",
       "      <td>1.948830</td>\n",
       "      <td>0.508772</td>\n",
       "      <td>0.116689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.929200</td>\n",
       "      <td>1.872670</td>\n",
       "      <td>0.514620</td>\n",
       "      <td>0.117252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.831900</td>\n",
       "      <td>1.811706</td>\n",
       "      <td>0.502924</td>\n",
       "      <td>0.113625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.776500</td>\n",
       "      <td>1.740714</td>\n",
       "      <td>0.514620</td>\n",
       "      <td>0.116780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.677300</td>\n",
       "      <td>1.679550</td>\n",
       "      <td>0.538012</td>\n",
       "      <td>0.139008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.603900</td>\n",
       "      <td>1.632815</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.215523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1.534300</td>\n",
       "      <td>1.593773</td>\n",
       "      <td>0.602339</td>\n",
       "      <td>0.241283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.460700</td>\n",
       "      <td>1.556258</td>\n",
       "      <td>0.596491</td>\n",
       "      <td>0.240437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.424300</td>\n",
       "      <td>1.497470</td>\n",
       "      <td>0.602339</td>\n",
       "      <td>0.232573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.353400</td>\n",
       "      <td>1.462011</td>\n",
       "      <td>0.625731</td>\n",
       "      <td>0.268638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.340800</td>\n",
       "      <td>1.450772</td>\n",
       "      <td>0.619883</td>\n",
       "      <td>0.263822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.226600</td>\n",
       "      <td>1.430788</td>\n",
       "      <td>0.643275</td>\n",
       "      <td>0.304763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.241500</td>\n",
       "      <td>1.403372</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>0.293668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.187600</td>\n",
       "      <td>1.394855</td>\n",
       "      <td>0.660819</td>\n",
       "      <td>0.298444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1.177500</td>\n",
       "      <td>1.384744</td>\n",
       "      <td>0.660819</td>\n",
       "      <td>0.299857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1.130300</td>\n",
       "      <td>1.379186</td>\n",
       "      <td>0.654971</td>\n",
       "      <td>0.298788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1.132200</td>\n",
       "      <td>1.353369</td>\n",
       "      <td>0.654971</td>\n",
       "      <td>0.300159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1.070400</td>\n",
       "      <td>1.355487</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.307189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.074300</td>\n",
       "      <td>1.355496</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.306772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1.065600</td>\n",
       "      <td>1.342489</td>\n",
       "      <td>0.660819</td>\n",
       "      <td>0.305985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1.012500</td>\n",
       "      <td>1.340152</td>\n",
       "      <td>0.660819</td>\n",
       "      <td>0.306106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1.033500</td>\n",
       "      <td>1.328746</td>\n",
       "      <td>0.660819</td>\n",
       "      <td>0.306700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.991000</td>\n",
       "      <td>1.328209</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.308724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.003600</td>\n",
       "      <td>1.317373</td>\n",
       "      <td>0.660819</td>\n",
       "      <td>0.306700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.993800</td>\n",
       "      <td>1.320615</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.308724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.968300</td>\n",
       "      <td>1.317972</td>\n",
       "      <td>0.660819</td>\n",
       "      <td>0.306700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.978400</td>\n",
       "      <td>1.319060</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.308649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/EgyBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/EgyBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:28, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.380000</td>\n",
       "      <td>2.342060</td>\n",
       "      <td>0.397661</td>\n",
       "      <td>0.051731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.326900</td>\n",
       "      <td>2.278989</td>\n",
       "      <td>0.397661</td>\n",
       "      <td>0.051731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.264300</td>\n",
       "      <td>2.214650</td>\n",
       "      <td>0.397661</td>\n",
       "      <td>0.051731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.218500</td>\n",
       "      <td>2.152698</td>\n",
       "      <td>0.397661</td>\n",
       "      <td>0.051731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.134800</td>\n",
       "      <td>2.086971</td>\n",
       "      <td>0.397661</td>\n",
       "      <td>0.051731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2.075400</td>\n",
       "      <td>2.019508</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.104692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>2.009600</td>\n",
       "      <td>1.948830</td>\n",
       "      <td>0.508772</td>\n",
       "      <td>0.116689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.929200</td>\n",
       "      <td>1.872670</td>\n",
       "      <td>0.514620</td>\n",
       "      <td>0.117252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.831900</td>\n",
       "      <td>1.811706</td>\n",
       "      <td>0.502924</td>\n",
       "      <td>0.113625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.776500</td>\n",
       "      <td>1.740714</td>\n",
       "      <td>0.514620</td>\n",
       "      <td>0.116780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.677300</td>\n",
       "      <td>1.679550</td>\n",
       "      <td>0.538012</td>\n",
       "      <td>0.139008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.603900</td>\n",
       "      <td>1.632815</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.215523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1.534300</td>\n",
       "      <td>1.593773</td>\n",
       "      <td>0.602339</td>\n",
       "      <td>0.241283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.460700</td>\n",
       "      <td>1.556258</td>\n",
       "      <td>0.596491</td>\n",
       "      <td>0.240437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.424300</td>\n",
       "      <td>1.497470</td>\n",
       "      <td>0.602339</td>\n",
       "      <td>0.232573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.353400</td>\n",
       "      <td>1.462011</td>\n",
       "      <td>0.625731</td>\n",
       "      <td>0.268638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.340800</td>\n",
       "      <td>1.450772</td>\n",
       "      <td>0.619883</td>\n",
       "      <td>0.263822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.226600</td>\n",
       "      <td>1.430788</td>\n",
       "      <td>0.643275</td>\n",
       "      <td>0.304763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.241500</td>\n",
       "      <td>1.403372</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>0.293668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.187600</td>\n",
       "      <td>1.394855</td>\n",
       "      <td>0.660819</td>\n",
       "      <td>0.298444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1.177500</td>\n",
       "      <td>1.384744</td>\n",
       "      <td>0.660819</td>\n",
       "      <td>0.299857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1.130300</td>\n",
       "      <td>1.379186</td>\n",
       "      <td>0.654971</td>\n",
       "      <td>0.298788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1.132200</td>\n",
       "      <td>1.353369</td>\n",
       "      <td>0.654971</td>\n",
       "      <td>0.300159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1.070400</td>\n",
       "      <td>1.355487</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.307189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.074300</td>\n",
       "      <td>1.355496</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.306772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1.065600</td>\n",
       "      <td>1.342489</td>\n",
       "      <td>0.660819</td>\n",
       "      <td>0.305985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1.012500</td>\n",
       "      <td>1.340152</td>\n",
       "      <td>0.660819</td>\n",
       "      <td>0.306106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1.033500</td>\n",
       "      <td>1.328746</td>\n",
       "      <td>0.660819</td>\n",
       "      <td>0.306700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.991000</td>\n",
       "      <td>1.328209</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.308724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.003600</td>\n",
       "      <td>1.317373</td>\n",
       "      <td>0.660819</td>\n",
       "      <td>0.306700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.993800</td>\n",
       "      <td>1.320615</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.308724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.968300</td>\n",
       "      <td>1.317972</td>\n",
       "      <td>0.660819</td>\n",
       "      <td>0.306700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.978400</td>\n",
       "      <td>1.319060</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.308649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/EgyBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/EgyBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:28, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.380000</td>\n",
       "      <td>2.342060</td>\n",
       "      <td>0.397661</td>\n",
       "      <td>0.051731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.326900</td>\n",
       "      <td>2.278989</td>\n",
       "      <td>0.397661</td>\n",
       "      <td>0.051731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.264300</td>\n",
       "      <td>2.214650</td>\n",
       "      <td>0.397661</td>\n",
       "      <td>0.051731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.218500</td>\n",
       "      <td>2.152698</td>\n",
       "      <td>0.397661</td>\n",
       "      <td>0.051731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.134800</td>\n",
       "      <td>2.086971</td>\n",
       "      <td>0.397661</td>\n",
       "      <td>0.051731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2.075400</td>\n",
       "      <td>2.019508</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.104692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>2.009600</td>\n",
       "      <td>1.948830</td>\n",
       "      <td>0.508772</td>\n",
       "      <td>0.116689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.929200</td>\n",
       "      <td>1.872670</td>\n",
       "      <td>0.514620</td>\n",
       "      <td>0.117252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.831900</td>\n",
       "      <td>1.811706</td>\n",
       "      <td>0.502924</td>\n",
       "      <td>0.113625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.776500</td>\n",
       "      <td>1.740714</td>\n",
       "      <td>0.514620</td>\n",
       "      <td>0.116780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.677300</td>\n",
       "      <td>1.679550</td>\n",
       "      <td>0.538012</td>\n",
       "      <td>0.139008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.603900</td>\n",
       "      <td>1.632815</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.215523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1.534300</td>\n",
       "      <td>1.593773</td>\n",
       "      <td>0.602339</td>\n",
       "      <td>0.241283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.460700</td>\n",
       "      <td>1.556258</td>\n",
       "      <td>0.596491</td>\n",
       "      <td>0.240437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.424300</td>\n",
       "      <td>1.497470</td>\n",
       "      <td>0.602339</td>\n",
       "      <td>0.232573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.353400</td>\n",
       "      <td>1.462011</td>\n",
       "      <td>0.625731</td>\n",
       "      <td>0.268638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.340800</td>\n",
       "      <td>1.450772</td>\n",
       "      <td>0.619883</td>\n",
       "      <td>0.263822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.226600</td>\n",
       "      <td>1.430788</td>\n",
       "      <td>0.643275</td>\n",
       "      <td>0.304763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.241500</td>\n",
       "      <td>1.403372</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>0.293668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.187600</td>\n",
       "      <td>1.394855</td>\n",
       "      <td>0.660819</td>\n",
       "      <td>0.298444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1.177500</td>\n",
       "      <td>1.384744</td>\n",
       "      <td>0.660819</td>\n",
       "      <td>0.299857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1.130300</td>\n",
       "      <td>1.379186</td>\n",
       "      <td>0.654971</td>\n",
       "      <td>0.298788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1.132200</td>\n",
       "      <td>1.353369</td>\n",
       "      <td>0.654971</td>\n",
       "      <td>0.300159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1.070400</td>\n",
       "      <td>1.355487</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.307189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.074300</td>\n",
       "      <td>1.355496</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.306772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1.065600</td>\n",
       "      <td>1.342489</td>\n",
       "      <td>0.660819</td>\n",
       "      <td>0.305985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1.012500</td>\n",
       "      <td>1.340152</td>\n",
       "      <td>0.660819</td>\n",
       "      <td>0.306106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1.033500</td>\n",
       "      <td>1.328746</td>\n",
       "      <td>0.660819</td>\n",
       "      <td>0.306700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.991000</td>\n",
       "      <td>1.328209</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.308724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.003600</td>\n",
       "      <td>1.317373</td>\n",
       "      <td>0.660819</td>\n",
       "      <td>0.306700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.993800</td>\n",
       "      <td>1.320615</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.308724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.968300</td>\n",
       "      <td>1.317972</td>\n",
       "      <td>0.660819</td>\n",
       "      <td>0.306700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.978400</td>\n",
       "      <td>1.319060</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.308649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/EgyBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/EgyBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:28, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.379300</td>\n",
       "      <td>2.349633</td>\n",
       "      <td>0.339181</td>\n",
       "      <td>0.073574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.322000</td>\n",
       "      <td>2.292717</td>\n",
       "      <td>0.321637</td>\n",
       "      <td>0.054081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.266500</td>\n",
       "      <td>2.235117</td>\n",
       "      <td>0.321637</td>\n",
       "      <td>0.054081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.215600</td>\n",
       "      <td>2.178677</td>\n",
       "      <td>0.321637</td>\n",
       "      <td>0.054081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.124700</td>\n",
       "      <td>2.119032</td>\n",
       "      <td>0.321637</td>\n",
       "      <td>0.054081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2.089200</td>\n",
       "      <td>2.058411</td>\n",
       "      <td>0.350877</td>\n",
       "      <td>0.084555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.983800</td>\n",
       "      <td>1.995854</td>\n",
       "      <td>0.374269</td>\n",
       "      <td>0.099577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.958400</td>\n",
       "      <td>1.922143</td>\n",
       "      <td>0.438596</td>\n",
       "      <td>0.129898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.846600</td>\n",
       "      <td>1.871305</td>\n",
       "      <td>0.426901</td>\n",
       "      <td>0.125392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.784800</td>\n",
       "      <td>1.814859</td>\n",
       "      <td>0.438596</td>\n",
       "      <td>0.130244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.708700</td>\n",
       "      <td>1.755754</td>\n",
       "      <td>0.432749</td>\n",
       "      <td>0.128170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.650700</td>\n",
       "      <td>1.724207</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.124038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1.558700</td>\n",
       "      <td>1.654914</td>\n",
       "      <td>0.461988</td>\n",
       "      <td>0.213343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.457300</td>\n",
       "      <td>1.605934</td>\n",
       "      <td>0.461988</td>\n",
       "      <td>0.211503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.463100</td>\n",
       "      <td>1.580187</td>\n",
       "      <td>0.520468</td>\n",
       "      <td>0.278312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.342000</td>\n",
       "      <td>1.550030</td>\n",
       "      <td>0.538012</td>\n",
       "      <td>0.294075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.320800</td>\n",
       "      <td>1.518605</td>\n",
       "      <td>0.590643</td>\n",
       "      <td>0.337068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.293600</td>\n",
       "      <td>1.496558</td>\n",
       "      <td>0.567251</td>\n",
       "      <td>0.317818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.167800</td>\n",
       "      <td>1.484614</td>\n",
       "      <td>0.584795</td>\n",
       "      <td>0.338756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.193700</td>\n",
       "      <td>1.460823</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.363963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1.159200</td>\n",
       "      <td>1.454310</td>\n",
       "      <td>0.573099</td>\n",
       "      <td>0.317693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1.107700</td>\n",
       "      <td>1.464028</td>\n",
       "      <td>0.608187</td>\n",
       "      <td>0.360035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1.085100</td>\n",
       "      <td>1.402779</td>\n",
       "      <td>0.625731</td>\n",
       "      <td>0.363283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1.083300</td>\n",
       "      <td>1.399675</td>\n",
       "      <td>0.619883</td>\n",
       "      <td>0.367933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.075500</td>\n",
       "      <td>1.409460</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.358029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1.017400</td>\n",
       "      <td>1.384055</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.357255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1.009000</td>\n",
       "      <td>1.369275</td>\n",
       "      <td>0.619883</td>\n",
       "      <td>0.372122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.993000</td>\n",
       "      <td>1.386843</td>\n",
       "      <td>0.643275</td>\n",
       "      <td>0.402531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.971000</td>\n",
       "      <td>1.377109</td>\n",
       "      <td>0.643275</td>\n",
       "      <td>0.404092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.002300</td>\n",
       "      <td>1.376661</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.386431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.944500</td>\n",
       "      <td>1.369500</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.387365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.969900</td>\n",
       "      <td>1.373624</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.388346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.957800</td>\n",
       "      <td>1.373597</td>\n",
       "      <td>0.637427</td>\n",
       "      <td>0.395389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/EgyBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/EgyBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:30, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.379300</td>\n",
       "      <td>2.349633</td>\n",
       "      <td>0.339181</td>\n",
       "      <td>0.073574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.322000</td>\n",
       "      <td>2.292717</td>\n",
       "      <td>0.321637</td>\n",
       "      <td>0.054081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.266500</td>\n",
       "      <td>2.235117</td>\n",
       "      <td>0.321637</td>\n",
       "      <td>0.054081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.215600</td>\n",
       "      <td>2.178677</td>\n",
       "      <td>0.321637</td>\n",
       "      <td>0.054081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.124700</td>\n",
       "      <td>2.119032</td>\n",
       "      <td>0.321637</td>\n",
       "      <td>0.054081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2.089200</td>\n",
       "      <td>2.058411</td>\n",
       "      <td>0.350877</td>\n",
       "      <td>0.084555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.983800</td>\n",
       "      <td>1.995854</td>\n",
       "      <td>0.374269</td>\n",
       "      <td>0.099577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.958400</td>\n",
       "      <td>1.922143</td>\n",
       "      <td>0.438596</td>\n",
       "      <td>0.129898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.846600</td>\n",
       "      <td>1.871305</td>\n",
       "      <td>0.426901</td>\n",
       "      <td>0.125392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.784800</td>\n",
       "      <td>1.814859</td>\n",
       "      <td>0.438596</td>\n",
       "      <td>0.130244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.708700</td>\n",
       "      <td>1.755754</td>\n",
       "      <td>0.432749</td>\n",
       "      <td>0.128170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.650700</td>\n",
       "      <td>1.724207</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.124038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1.558700</td>\n",
       "      <td>1.654914</td>\n",
       "      <td>0.461988</td>\n",
       "      <td>0.213343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.457300</td>\n",
       "      <td>1.605934</td>\n",
       "      <td>0.461988</td>\n",
       "      <td>0.211503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.463100</td>\n",
       "      <td>1.580187</td>\n",
       "      <td>0.520468</td>\n",
       "      <td>0.278312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.342000</td>\n",
       "      <td>1.550030</td>\n",
       "      <td>0.538012</td>\n",
       "      <td>0.294075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.320800</td>\n",
       "      <td>1.518605</td>\n",
       "      <td>0.590643</td>\n",
       "      <td>0.337068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.293600</td>\n",
       "      <td>1.496558</td>\n",
       "      <td>0.567251</td>\n",
       "      <td>0.317818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.167800</td>\n",
       "      <td>1.484614</td>\n",
       "      <td>0.584795</td>\n",
       "      <td>0.338756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.193700</td>\n",
       "      <td>1.460823</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.363963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1.159200</td>\n",
       "      <td>1.454310</td>\n",
       "      <td>0.573099</td>\n",
       "      <td>0.317693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1.107700</td>\n",
       "      <td>1.464028</td>\n",
       "      <td>0.608187</td>\n",
       "      <td>0.360035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1.085100</td>\n",
       "      <td>1.402779</td>\n",
       "      <td>0.625731</td>\n",
       "      <td>0.363283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1.083300</td>\n",
       "      <td>1.399675</td>\n",
       "      <td>0.619883</td>\n",
       "      <td>0.367933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.075500</td>\n",
       "      <td>1.409460</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.358029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1.017400</td>\n",
       "      <td>1.384055</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.357255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1.009000</td>\n",
       "      <td>1.369275</td>\n",
       "      <td>0.619883</td>\n",
       "      <td>0.372122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.993000</td>\n",
       "      <td>1.386843</td>\n",
       "      <td>0.643275</td>\n",
       "      <td>0.402531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.971000</td>\n",
       "      <td>1.377109</td>\n",
       "      <td>0.643275</td>\n",
       "      <td>0.404092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.002300</td>\n",
       "      <td>1.376661</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.386431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.944500</td>\n",
       "      <td>1.369500</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.387365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.969900</td>\n",
       "      <td>1.373624</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.388346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.957800</td>\n",
       "      <td>1.373597</td>\n",
       "      <td>0.637427</td>\n",
       "      <td>0.395389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/EgyBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/EgyBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1485fd1ab1eb42aeaa8e09b69d2d995d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a67da780faf404ebaedc7a02be9a403",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:28, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.379300</td>\n",
       "      <td>2.349633</td>\n",
       "      <td>0.339181</td>\n",
       "      <td>0.073574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.322000</td>\n",
       "      <td>2.292717</td>\n",
       "      <td>0.321637</td>\n",
       "      <td>0.054081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.266500</td>\n",
       "      <td>2.235117</td>\n",
       "      <td>0.321637</td>\n",
       "      <td>0.054081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.215600</td>\n",
       "      <td>2.178677</td>\n",
       "      <td>0.321637</td>\n",
       "      <td>0.054081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.124700</td>\n",
       "      <td>2.119032</td>\n",
       "      <td>0.321637</td>\n",
       "      <td>0.054081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2.089200</td>\n",
       "      <td>2.058411</td>\n",
       "      <td>0.350877</td>\n",
       "      <td>0.084555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.983800</td>\n",
       "      <td>1.995854</td>\n",
       "      <td>0.374269</td>\n",
       "      <td>0.099577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.958400</td>\n",
       "      <td>1.922143</td>\n",
       "      <td>0.438596</td>\n",
       "      <td>0.129898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.846600</td>\n",
       "      <td>1.871305</td>\n",
       "      <td>0.426901</td>\n",
       "      <td>0.125392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.784800</td>\n",
       "      <td>1.814859</td>\n",
       "      <td>0.438596</td>\n",
       "      <td>0.130244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.708700</td>\n",
       "      <td>1.755754</td>\n",
       "      <td>0.432749</td>\n",
       "      <td>0.128170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.650700</td>\n",
       "      <td>1.724207</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.124038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1.558700</td>\n",
       "      <td>1.654914</td>\n",
       "      <td>0.461988</td>\n",
       "      <td>0.213343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.457300</td>\n",
       "      <td>1.605934</td>\n",
       "      <td>0.461988</td>\n",
       "      <td>0.211503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.463100</td>\n",
       "      <td>1.580187</td>\n",
       "      <td>0.520468</td>\n",
       "      <td>0.278312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.342000</td>\n",
       "      <td>1.550030</td>\n",
       "      <td>0.538012</td>\n",
       "      <td>0.294075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.320800</td>\n",
       "      <td>1.518605</td>\n",
       "      <td>0.590643</td>\n",
       "      <td>0.337068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.293600</td>\n",
       "      <td>1.496558</td>\n",
       "      <td>0.567251</td>\n",
       "      <td>0.317818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.167800</td>\n",
       "      <td>1.484614</td>\n",
       "      <td>0.584795</td>\n",
       "      <td>0.338756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.193700</td>\n",
       "      <td>1.460823</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.363963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1.159200</td>\n",
       "      <td>1.454310</td>\n",
       "      <td>0.573099</td>\n",
       "      <td>0.317693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1.107700</td>\n",
       "      <td>1.464028</td>\n",
       "      <td>0.608187</td>\n",
       "      <td>0.360035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1.085100</td>\n",
       "      <td>1.402779</td>\n",
       "      <td>0.625731</td>\n",
       "      <td>0.363283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1.083300</td>\n",
       "      <td>1.399675</td>\n",
       "      <td>0.619883</td>\n",
       "      <td>0.367933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.075500</td>\n",
       "      <td>1.409460</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.358029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1.017400</td>\n",
       "      <td>1.384055</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.357255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1.009000</td>\n",
       "      <td>1.369275</td>\n",
       "      <td>0.619883</td>\n",
       "      <td>0.372122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.993000</td>\n",
       "      <td>1.386843</td>\n",
       "      <td>0.643275</td>\n",
       "      <td>0.402531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.971000</td>\n",
       "      <td>1.377109</td>\n",
       "      <td>0.643275</td>\n",
       "      <td>0.404092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.002300</td>\n",
       "      <td>1.376661</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.386431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.944500</td>\n",
       "      <td>1.369500</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.387365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.969900</td>\n",
       "      <td>1.373624</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.388346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.957800</td>\n",
       "      <td>1.373597</td>\n",
       "      <td>0.637427</td>\n",
       "      <td>0.395389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['review', 'label'],\n",
       "        num_rows: 680\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['review', 'label'],\n",
       "        num_rows: 171\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fac110d43bef4dc3831d238fa5794fe6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d527677604d14c7393fd078fe29fbb55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:28, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.797000</td>\n",
       "      <td>1.456134</td>\n",
       "      <td>0.532164</td>\n",
       "      <td>0.232643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.170200</td>\n",
       "      <td>1.115634</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>0.367058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.866900</td>\n",
       "      <td>1.027802</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.409400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.585400</td>\n",
       "      <td>1.012543</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.527515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.449000</td>\n",
       "      <td>1.027242</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.497865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.294000</td>\n",
       "      <td>0.986448</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.609284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.201900</td>\n",
       "      <td>1.156547</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.546200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.157000</td>\n",
       "      <td>1.249398</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.574853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.096200</td>\n",
       "      <td>1.227833</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.548201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.057100</td>\n",
       "      <td>1.322394</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.561942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.041700</td>\n",
       "      <td>1.317189</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.601591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.025200</td>\n",
       "      <td>1.398157</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.611152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.015200</td>\n",
       "      <td>1.441887</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.518025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.010800</td>\n",
       "      <td>1.592280</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.552392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>1.577692</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.536088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.007200</td>\n",
       "      <td>1.605709</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.529017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.006300</td>\n",
       "      <td>1.630615</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.528241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.005200</td>\n",
       "      <td>1.650149</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.534801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>1.662509</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.530123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.004800</td>\n",
       "      <td>1.674744</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.530123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>1.688400</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.530123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>1.701716</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.530123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>1.715202</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.534801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>1.728447</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.530123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>1.737270</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.530123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>1.760799</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.541570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>1.787915</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.537795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.791085</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.528606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.790891</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.526505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.789943</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.530104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.789330</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.530104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>1.789982</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.530104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.790181</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.530104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9de9bdaf6f2d400a8101079973c3ccb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92ad69d4335e4b3fa35690a5e604b36e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:28, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.797000</td>\n",
       "      <td>1.456134</td>\n",
       "      <td>0.532164</td>\n",
       "      <td>0.232643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.170200</td>\n",
       "      <td>1.115634</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>0.367058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.866900</td>\n",
       "      <td>1.027802</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.409400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.585400</td>\n",
       "      <td>1.012543</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.527515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.449000</td>\n",
       "      <td>1.027242</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.497865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.294000</td>\n",
       "      <td>0.986448</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.609284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.201900</td>\n",
       "      <td>1.156547</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.546200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.157000</td>\n",
       "      <td>1.249398</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.574853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.096200</td>\n",
       "      <td>1.227833</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.548201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.057100</td>\n",
       "      <td>1.322394</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.561942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.041700</td>\n",
       "      <td>1.317189</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.601591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.025200</td>\n",
       "      <td>1.398157</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.611152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.015200</td>\n",
       "      <td>1.441887</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.518025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.010800</td>\n",
       "      <td>1.592280</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.552392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>1.577692</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.536088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.007200</td>\n",
       "      <td>1.605709</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.529017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.006300</td>\n",
       "      <td>1.630615</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.528241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.005200</td>\n",
       "      <td>1.650149</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.534801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>1.662509</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.530123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.004800</td>\n",
       "      <td>1.674744</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.530123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>1.688400</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.530123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>1.701716</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.530123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>1.715202</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.534801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>1.728447</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.530123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>1.737270</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.530123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>1.760799</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.541570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>1.787915</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.537795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.791085</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.528606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.790891</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.526505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.789943</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.530104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.789330</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.530104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>1.789982</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.530104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.790181</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.530104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b66f0068ed0e45d3809c547450fc4646",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcfd57ad8f194723a461fc4ea91d0c5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:28, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.797000</td>\n",
       "      <td>1.456134</td>\n",
       "      <td>0.532164</td>\n",
       "      <td>0.232643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.170200</td>\n",
       "      <td>1.115634</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>0.367058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.866900</td>\n",
       "      <td>1.027802</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.409400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.585400</td>\n",
       "      <td>1.012543</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.527515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.449000</td>\n",
       "      <td>1.027242</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.497865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.294000</td>\n",
       "      <td>0.986448</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.609284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.201900</td>\n",
       "      <td>1.156547</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.546200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.157000</td>\n",
       "      <td>1.249398</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.574853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.096200</td>\n",
       "      <td>1.227833</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.548201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.057100</td>\n",
       "      <td>1.322394</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.561942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.041700</td>\n",
       "      <td>1.317189</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.601591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.025200</td>\n",
       "      <td>1.398157</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.611152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.015200</td>\n",
       "      <td>1.441887</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.518025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.010800</td>\n",
       "      <td>1.592280</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.552392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>1.577692</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.536088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.007200</td>\n",
       "      <td>1.605709</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.529017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.006300</td>\n",
       "      <td>1.630615</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.528241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.005200</td>\n",
       "      <td>1.650149</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.534801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>1.662509</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.530123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.004800</td>\n",
       "      <td>1.674744</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.530123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>1.688400</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.530123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>1.701716</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.530123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>1.715202</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.534801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>1.728447</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.530123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>1.737270</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.530123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>1.760799</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.541570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>1.787915</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.537795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.791085</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.528606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.790891</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.526505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.789943</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.530104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.789330</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.530104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>1.789982</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.530104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.790181</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.530104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5cc10b6ba2940369778688ffa0524fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83f07ea7715740f4a1ed762c2488e64e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:28, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.843000</td>\n",
       "      <td>1.444382</td>\n",
       "      <td>0.561404</td>\n",
       "      <td>0.179920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.234000</td>\n",
       "      <td>1.106577</td>\n",
       "      <td>0.660819</td>\n",
       "      <td>0.297915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.782400</td>\n",
       "      <td>1.079086</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.321344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.572900</td>\n",
       "      <td>1.133410</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.469510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.419000</td>\n",
       "      <td>1.068544</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.440886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.252800</td>\n",
       "      <td>1.113602</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.505927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.221800</td>\n",
       "      <td>1.358237</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.515861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.130600</td>\n",
       "      <td>1.174455</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.491740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.099800</td>\n",
       "      <td>1.365094</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.433919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.135300</td>\n",
       "      <td>1.343320</td>\n",
       "      <td>0.690058</td>\n",
       "      <td>0.502609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.055900</td>\n",
       "      <td>1.275754</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.457105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.042700</td>\n",
       "      <td>1.464214</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.516005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.028700</td>\n",
       "      <td>1.401765</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.521617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.015100</td>\n",
       "      <td>1.446553</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.532875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.011600</td>\n",
       "      <td>1.408891</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.534793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.009100</td>\n",
       "      <td>1.414109</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.513523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.007400</td>\n",
       "      <td>1.443663</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.523981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.006300</td>\n",
       "      <td>1.413169</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.531731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>1.407403</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.516352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>1.409147</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.554263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>1.422938</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.549637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>1.483585</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.515648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>1.568365</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.491710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>1.567603</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.496030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>1.552292</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.506033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>1.541685</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.527048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>1.539674</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.527048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.539592</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.527048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>1.539519</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.527048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.543172</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.522780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>1.544690</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.522780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.545203</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.522780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.545766</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.522780</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29392a3ea984403a8b429414599b245e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62787d4884884452adfae81b65eb0405",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:28, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.843000</td>\n",
       "      <td>1.444382</td>\n",
       "      <td>0.561404</td>\n",
       "      <td>0.179920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.234000</td>\n",
       "      <td>1.106577</td>\n",
       "      <td>0.660819</td>\n",
       "      <td>0.297915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.782400</td>\n",
       "      <td>1.079086</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.321344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.572900</td>\n",
       "      <td>1.133410</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.469510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.419000</td>\n",
       "      <td>1.068544</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.440886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.252800</td>\n",
       "      <td>1.113602</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.505927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.221800</td>\n",
       "      <td>1.358237</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.515861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.130600</td>\n",
       "      <td>1.174455</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.491740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.099800</td>\n",
       "      <td>1.365094</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.433919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.135300</td>\n",
       "      <td>1.343320</td>\n",
       "      <td>0.690058</td>\n",
       "      <td>0.502609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.055900</td>\n",
       "      <td>1.275754</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.457105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.042700</td>\n",
       "      <td>1.464214</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.516005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.028700</td>\n",
       "      <td>1.401765</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.521617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.015100</td>\n",
       "      <td>1.446553</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.532875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.011600</td>\n",
       "      <td>1.408891</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.534793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.009100</td>\n",
       "      <td>1.414109</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.513523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.007400</td>\n",
       "      <td>1.443663</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.523981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.006300</td>\n",
       "      <td>1.413169</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.531731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>1.407403</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.516352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>1.409147</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.554263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>1.422938</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.549637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>1.483585</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.515648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>1.568365</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.491710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>1.567603</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.496030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>1.552292</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.506033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>1.541685</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.527048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>1.539674</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.527048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.539592</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.527048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>1.539519</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.527048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.543172</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.522780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>1.544690</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.522780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.545203</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.522780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.545766</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.522780</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee0eb76a2fde444eae32c72e1b09befe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79f41eff41b847c299a756c66536e581",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:28, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.843000</td>\n",
       "      <td>1.444382</td>\n",
       "      <td>0.561404</td>\n",
       "      <td>0.179920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.234000</td>\n",
       "      <td>1.106577</td>\n",
       "      <td>0.660819</td>\n",
       "      <td>0.297915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.782400</td>\n",
       "      <td>1.079086</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.321344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.572900</td>\n",
       "      <td>1.133410</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.469510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.419000</td>\n",
       "      <td>1.068544</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.440886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.252800</td>\n",
       "      <td>1.113602</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.505927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.221800</td>\n",
       "      <td>1.358237</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.515861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.130600</td>\n",
       "      <td>1.174455</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.491740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.099800</td>\n",
       "      <td>1.365094</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.433919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.135300</td>\n",
       "      <td>1.343320</td>\n",
       "      <td>0.690058</td>\n",
       "      <td>0.502609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.055900</td>\n",
       "      <td>1.275754</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.457105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.042700</td>\n",
       "      <td>1.464214</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.516005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.028700</td>\n",
       "      <td>1.401765</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.521617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.015100</td>\n",
       "      <td>1.446553</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.532875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.011600</td>\n",
       "      <td>1.408891</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.534793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.009100</td>\n",
       "      <td>1.414109</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.513523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.007400</td>\n",
       "      <td>1.443663</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.523981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.006300</td>\n",
       "      <td>1.413169</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.531731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>1.407403</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.516352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>1.409147</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.554263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>1.422938</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.549637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>1.483585</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.515648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>1.568365</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.491710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>1.567603</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.496030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>1.552292</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.506033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>1.541685</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.527048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>1.539674</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.527048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.539592</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.527048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>1.539519</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.527048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.543172</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.522780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>1.544690</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.522780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.545203</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.522780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.545766</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.522780</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25d113008ee34544af8fafb8dd2c4b21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "016b2f3fa6ce46df9bcd3b68424bca1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:28, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.818400</td>\n",
       "      <td>1.482680</td>\n",
       "      <td>0.538012</td>\n",
       "      <td>0.222719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.188400</td>\n",
       "      <td>1.095231</td>\n",
       "      <td>0.643275</td>\n",
       "      <td>0.360395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.874500</td>\n",
       "      <td>0.979592</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.411921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.666600</td>\n",
       "      <td>0.907999</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.466387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.434400</td>\n",
       "      <td>0.922148</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.540680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.323900</td>\n",
       "      <td>0.983034</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.597642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.242500</td>\n",
       "      <td>1.020890</td>\n",
       "      <td>0.690058</td>\n",
       "      <td>0.523589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.178600</td>\n",
       "      <td>1.003332</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.612866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.108000</td>\n",
       "      <td>1.105792</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.619761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.095400</td>\n",
       "      <td>1.050525</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.559111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.067900</td>\n",
       "      <td>1.106283</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.613037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.033300</td>\n",
       "      <td>1.254904</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.591175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>1.255896</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.546111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.013300</td>\n",
       "      <td>1.289832</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.548219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.013100</td>\n",
       "      <td>1.287759</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.572828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.008300</td>\n",
       "      <td>1.345497</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.565958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.006600</td>\n",
       "      <td>1.359290</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.554912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.006200</td>\n",
       "      <td>1.359630</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.565993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.005200</td>\n",
       "      <td>1.362121</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.559689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>1.370499</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.570735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>1.380609</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.569943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>1.393160</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.575089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>1.407056</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.575089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>1.417861</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.575089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>1.426649</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.571436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>1.431479</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.571436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>1.436351</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.571436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.439854</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.571436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>1.442263</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.571436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.444054</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.571436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.445346</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.575089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.446614</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.575089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>1.447270</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.575089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c79bb015378049ceba0841a09e6b5c6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b823bef1bc84a1a8ea8d8d90e70b947",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:28, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.818400</td>\n",
       "      <td>1.482680</td>\n",
       "      <td>0.538012</td>\n",
       "      <td>0.222719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.188400</td>\n",
       "      <td>1.095231</td>\n",
       "      <td>0.643275</td>\n",
       "      <td>0.360395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.874500</td>\n",
       "      <td>0.979592</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.411921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.666600</td>\n",
       "      <td>0.907999</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.466387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.434400</td>\n",
       "      <td>0.922148</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.540680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.323900</td>\n",
       "      <td>0.983034</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.597642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.242500</td>\n",
       "      <td>1.020890</td>\n",
       "      <td>0.690058</td>\n",
       "      <td>0.523589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.178600</td>\n",
       "      <td>1.003332</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.612866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.108000</td>\n",
       "      <td>1.105792</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.619761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.095400</td>\n",
       "      <td>1.050525</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.559111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.067900</td>\n",
       "      <td>1.106283</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.613037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.033300</td>\n",
       "      <td>1.254904</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.591175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>1.255896</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.546111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.013300</td>\n",
       "      <td>1.289832</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.548219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.013100</td>\n",
       "      <td>1.287759</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.572828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.008300</td>\n",
       "      <td>1.345497</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.565958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.006600</td>\n",
       "      <td>1.359290</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.554912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.006200</td>\n",
       "      <td>1.359630</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.565993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.005200</td>\n",
       "      <td>1.362121</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.559689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>1.370499</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.570735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>1.380609</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.569943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>1.393160</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.575089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>1.407056</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.575089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>1.417861</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.575089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>1.426649</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.571436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>1.431479</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.571436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>1.436351</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.571436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.439854</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.571436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>1.442263</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.571436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.444054</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.571436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.445346</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.575089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.446614</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.575089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>1.447270</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.575089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e44094b1ac854849bffa62ba676fb04c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd3f12bb01134dc08cd45fd8185e212d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:30, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.818400</td>\n",
       "      <td>1.482680</td>\n",
       "      <td>0.538012</td>\n",
       "      <td>0.222719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.188400</td>\n",
       "      <td>1.095231</td>\n",
       "      <td>0.643275</td>\n",
       "      <td>0.360395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.874500</td>\n",
       "      <td>0.979592</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.411921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.666600</td>\n",
       "      <td>0.907999</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.466387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.434400</td>\n",
       "      <td>0.922148</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.540680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.323900</td>\n",
       "      <td>0.983034</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.597642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.242500</td>\n",
       "      <td>1.020890</td>\n",
       "      <td>0.690058</td>\n",
       "      <td>0.523589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.178600</td>\n",
       "      <td>1.003332</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.612866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.108000</td>\n",
       "      <td>1.105792</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.619761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.095400</td>\n",
       "      <td>1.050525</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.559111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.067900</td>\n",
       "      <td>1.106283</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.613037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.033300</td>\n",
       "      <td>1.254904</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.591175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>1.255896</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.546111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.013300</td>\n",
       "      <td>1.289832</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.548219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.013100</td>\n",
       "      <td>1.287759</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.572828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.008300</td>\n",
       "      <td>1.345497</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.565958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.006600</td>\n",
       "      <td>1.359290</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.554912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.006200</td>\n",
       "      <td>1.359630</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.565993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.005200</td>\n",
       "      <td>1.362121</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.559689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>1.370499</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.570735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>1.380609</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.569943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>1.393160</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.575089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>1.407056</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.575089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>1.417861</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.575089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>1.426649</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.571436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>1.431479</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.571436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>1.436351</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.571436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.439854</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.571436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>1.442263</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.571436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.444054</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.571436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.445346</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.575089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.446614</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.575089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>1.447270</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.575089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['review', 'label'],\n",
       "        num_rows: 680\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['review', 'label'],\n",
       "        num_rows: 171\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunis-ai/TunBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tunis-ai/TunBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "816ae01d7b5549c6a700f6cceb46c215",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89f2bc17328c432fad63ea57e95ace01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:27, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.010000</td>\n",
       "      <td>1.942543</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.053333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.906000</td>\n",
       "      <td>1.994689</td>\n",
       "      <td>0.339181</td>\n",
       "      <td>0.100965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.903700</td>\n",
       "      <td>1.906270</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.053333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.879200</td>\n",
       "      <td>1.911094</td>\n",
       "      <td>0.362573</td>\n",
       "      <td>0.105870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.755100</td>\n",
       "      <td>1.843125</td>\n",
       "      <td>0.391813</td>\n",
       "      <td>0.118242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.736800</td>\n",
       "      <td>1.831976</td>\n",
       "      <td>0.380117</td>\n",
       "      <td>0.143042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.528200</td>\n",
       "      <td>1.840458</td>\n",
       "      <td>0.380117</td>\n",
       "      <td>0.130693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.619600</td>\n",
       "      <td>1.876808</td>\n",
       "      <td>0.391813</td>\n",
       "      <td>0.138046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.597100</td>\n",
       "      <td>1.879591</td>\n",
       "      <td>0.385965</td>\n",
       "      <td>0.147849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.481200</td>\n",
       "      <td>1.859062</td>\n",
       "      <td>0.403509</td>\n",
       "      <td>0.141549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.461900</td>\n",
       "      <td>1.791179</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.169541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.367100</td>\n",
       "      <td>1.733219</td>\n",
       "      <td>0.450292</td>\n",
       "      <td>0.244796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1.368200</td>\n",
       "      <td>1.718228</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.192998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.213200</td>\n",
       "      <td>1.868042</td>\n",
       "      <td>0.456140</td>\n",
       "      <td>0.209351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.290500</td>\n",
       "      <td>1.807057</td>\n",
       "      <td>0.450292</td>\n",
       "      <td>0.228410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.179900</td>\n",
       "      <td>1.752081</td>\n",
       "      <td>0.432749</td>\n",
       "      <td>0.233319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.223900</td>\n",
       "      <td>1.735280</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.196913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.028400</td>\n",
       "      <td>1.762736</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.225010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.061900</td>\n",
       "      <td>1.790892</td>\n",
       "      <td>0.456140</td>\n",
       "      <td>0.228201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.066100</td>\n",
       "      <td>1.815081</td>\n",
       "      <td>0.438596</td>\n",
       "      <td>0.261468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1.012200</td>\n",
       "      <td>2.065642</td>\n",
       "      <td>0.467836</td>\n",
       "      <td>0.232215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1.058400</td>\n",
       "      <td>1.866495</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.238253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.941800</td>\n",
       "      <td>1.834153</td>\n",
       "      <td>0.461988</td>\n",
       "      <td>0.235378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.877700</td>\n",
       "      <td>1.817767</td>\n",
       "      <td>0.467836</td>\n",
       "      <td>0.260398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.873100</td>\n",
       "      <td>1.841781</td>\n",
       "      <td>0.456140</td>\n",
       "      <td>0.224929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.860900</td>\n",
       "      <td>1.883861</td>\n",
       "      <td>0.491228</td>\n",
       "      <td>0.272593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.826900</td>\n",
       "      <td>1.947473</td>\n",
       "      <td>0.497076</td>\n",
       "      <td>0.263610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.720900</td>\n",
       "      <td>1.864867</td>\n",
       "      <td>0.456140</td>\n",
       "      <td>0.253126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.754800</td>\n",
       "      <td>1.867862</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.262601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.732900</td>\n",
       "      <td>1.900854</td>\n",
       "      <td>0.456140</td>\n",
       "      <td>0.275208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.673600</td>\n",
       "      <td>1.852449</td>\n",
       "      <td>0.461988</td>\n",
       "      <td>0.266296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.652700</td>\n",
       "      <td>1.878052</td>\n",
       "      <td>0.461988</td>\n",
       "      <td>0.261378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.690300</td>\n",
       "      <td>1.851304</td>\n",
       "      <td>0.461988</td>\n",
       "      <td>0.257278</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunis-ai/TunBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tunis-ai/TunBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "099d6d953c524a3d9ba344649de8727a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c167c589eca4daba3bfd3ccd1389896",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:26, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.010000</td>\n",
       "      <td>1.942543</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.053333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.906000</td>\n",
       "      <td>1.994689</td>\n",
       "      <td>0.339181</td>\n",
       "      <td>0.100965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.903700</td>\n",
       "      <td>1.906270</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.053333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.879200</td>\n",
       "      <td>1.911094</td>\n",
       "      <td>0.362573</td>\n",
       "      <td>0.105870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.755100</td>\n",
       "      <td>1.843125</td>\n",
       "      <td>0.391813</td>\n",
       "      <td>0.118242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.736800</td>\n",
       "      <td>1.831976</td>\n",
       "      <td>0.380117</td>\n",
       "      <td>0.143042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.528200</td>\n",
       "      <td>1.840458</td>\n",
       "      <td>0.380117</td>\n",
       "      <td>0.130693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.619600</td>\n",
       "      <td>1.876808</td>\n",
       "      <td>0.391813</td>\n",
       "      <td>0.138046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.597100</td>\n",
       "      <td>1.879591</td>\n",
       "      <td>0.385965</td>\n",
       "      <td>0.147849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.481200</td>\n",
       "      <td>1.859062</td>\n",
       "      <td>0.403509</td>\n",
       "      <td>0.141549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.461900</td>\n",
       "      <td>1.791179</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.169541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.367100</td>\n",
       "      <td>1.733219</td>\n",
       "      <td>0.450292</td>\n",
       "      <td>0.244796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1.368200</td>\n",
       "      <td>1.718228</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.192998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.213200</td>\n",
       "      <td>1.868042</td>\n",
       "      <td>0.456140</td>\n",
       "      <td>0.209351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.290500</td>\n",
       "      <td>1.807057</td>\n",
       "      <td>0.450292</td>\n",
       "      <td>0.228410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.179900</td>\n",
       "      <td>1.752081</td>\n",
       "      <td>0.432749</td>\n",
       "      <td>0.233319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.223900</td>\n",
       "      <td>1.735280</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.196913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.028400</td>\n",
       "      <td>1.762736</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.225010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.061900</td>\n",
       "      <td>1.790892</td>\n",
       "      <td>0.456140</td>\n",
       "      <td>0.228201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.066100</td>\n",
       "      <td>1.815081</td>\n",
       "      <td>0.438596</td>\n",
       "      <td>0.261468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1.012200</td>\n",
       "      <td>2.065642</td>\n",
       "      <td>0.467836</td>\n",
       "      <td>0.232215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1.058400</td>\n",
       "      <td>1.866495</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.238253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.941800</td>\n",
       "      <td>1.834153</td>\n",
       "      <td>0.461988</td>\n",
       "      <td>0.235378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.877700</td>\n",
       "      <td>1.817767</td>\n",
       "      <td>0.467836</td>\n",
       "      <td>0.260398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.873100</td>\n",
       "      <td>1.841781</td>\n",
       "      <td>0.456140</td>\n",
       "      <td>0.224929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.860900</td>\n",
       "      <td>1.883861</td>\n",
       "      <td>0.491228</td>\n",
       "      <td>0.272593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.826900</td>\n",
       "      <td>1.947473</td>\n",
       "      <td>0.497076</td>\n",
       "      <td>0.263610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.720900</td>\n",
       "      <td>1.864867</td>\n",
       "      <td>0.456140</td>\n",
       "      <td>0.253126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.754800</td>\n",
       "      <td>1.867862</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.262601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.732900</td>\n",
       "      <td>1.900854</td>\n",
       "      <td>0.456140</td>\n",
       "      <td>0.275208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.673600</td>\n",
       "      <td>1.852449</td>\n",
       "      <td>0.461988</td>\n",
       "      <td>0.266296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.652700</td>\n",
       "      <td>1.878052</td>\n",
       "      <td>0.461988</td>\n",
       "      <td>0.261378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.690300</td>\n",
       "      <td>1.851304</td>\n",
       "      <td>0.461988</td>\n",
       "      <td>0.257278</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunis-ai/TunBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tunis-ai/TunBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0691165601864d89bfd06c8c8f555d84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b06e6e503db84db899b30be45fdd0b0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:27, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.010000</td>\n",
       "      <td>1.942543</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.053333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.906000</td>\n",
       "      <td>1.994689</td>\n",
       "      <td>0.339181</td>\n",
       "      <td>0.100965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.903700</td>\n",
       "      <td>1.906270</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.053333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.879200</td>\n",
       "      <td>1.911094</td>\n",
       "      <td>0.362573</td>\n",
       "      <td>0.105870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.755100</td>\n",
       "      <td>1.843125</td>\n",
       "      <td>0.391813</td>\n",
       "      <td>0.118242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.736800</td>\n",
       "      <td>1.831976</td>\n",
       "      <td>0.380117</td>\n",
       "      <td>0.143042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.528200</td>\n",
       "      <td>1.840458</td>\n",
       "      <td>0.380117</td>\n",
       "      <td>0.130693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.619600</td>\n",
       "      <td>1.876808</td>\n",
       "      <td>0.391813</td>\n",
       "      <td>0.138046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.597100</td>\n",
       "      <td>1.879591</td>\n",
       "      <td>0.385965</td>\n",
       "      <td>0.147849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.481200</td>\n",
       "      <td>1.859062</td>\n",
       "      <td>0.403509</td>\n",
       "      <td>0.141549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.461900</td>\n",
       "      <td>1.791179</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.169541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.367100</td>\n",
       "      <td>1.733219</td>\n",
       "      <td>0.450292</td>\n",
       "      <td>0.244796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1.368200</td>\n",
       "      <td>1.718228</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.192998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.213200</td>\n",
       "      <td>1.868042</td>\n",
       "      <td>0.456140</td>\n",
       "      <td>0.209351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.290500</td>\n",
       "      <td>1.807057</td>\n",
       "      <td>0.450292</td>\n",
       "      <td>0.228410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.179900</td>\n",
       "      <td>1.752081</td>\n",
       "      <td>0.432749</td>\n",
       "      <td>0.233319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.223900</td>\n",
       "      <td>1.735280</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.196913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.028400</td>\n",
       "      <td>1.762736</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.225010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.061900</td>\n",
       "      <td>1.790892</td>\n",
       "      <td>0.456140</td>\n",
       "      <td>0.228201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.066100</td>\n",
       "      <td>1.815081</td>\n",
       "      <td>0.438596</td>\n",
       "      <td>0.261468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1.012200</td>\n",
       "      <td>2.065642</td>\n",
       "      <td>0.467836</td>\n",
       "      <td>0.232215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1.058400</td>\n",
       "      <td>1.866495</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.238253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.941800</td>\n",
       "      <td>1.834153</td>\n",
       "      <td>0.461988</td>\n",
       "      <td>0.235378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.877700</td>\n",
       "      <td>1.817767</td>\n",
       "      <td>0.467836</td>\n",
       "      <td>0.260398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.873100</td>\n",
       "      <td>1.841781</td>\n",
       "      <td>0.456140</td>\n",
       "      <td>0.224929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.860900</td>\n",
       "      <td>1.883861</td>\n",
       "      <td>0.491228</td>\n",
       "      <td>0.272593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.826900</td>\n",
       "      <td>1.947473</td>\n",
       "      <td>0.497076</td>\n",
       "      <td>0.263610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.720900</td>\n",
       "      <td>1.864867</td>\n",
       "      <td>0.456140</td>\n",
       "      <td>0.253126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.754800</td>\n",
       "      <td>1.867862</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.262601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.732900</td>\n",
       "      <td>1.900854</td>\n",
       "      <td>0.456140</td>\n",
       "      <td>0.275208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.673600</td>\n",
       "      <td>1.852449</td>\n",
       "      <td>0.461988</td>\n",
       "      <td>0.266296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.652700</td>\n",
       "      <td>1.878052</td>\n",
       "      <td>0.461988</td>\n",
       "      <td>0.261378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.690300</td>\n",
       "      <td>1.851304</td>\n",
       "      <td>0.461988</td>\n",
       "      <td>0.257278</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunis-ai/TunBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tunis-ai/TunBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c13a90fe40f24dcb8867628f70fc2380",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a40c42754c6142a1bd5ad8861f8c10c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:26, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.003600</td>\n",
       "      <td>1.940887</td>\n",
       "      <td>0.175439</td>\n",
       "      <td>0.029131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.992400</td>\n",
       "      <td>1.910545</td>\n",
       "      <td>0.397661</td>\n",
       "      <td>0.051731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.905200</td>\n",
       "      <td>1.845663</td>\n",
       "      <td>0.397661</td>\n",
       "      <td>0.051731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.906400</td>\n",
       "      <td>1.795005</td>\n",
       "      <td>0.461988</td>\n",
       "      <td>0.106383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.770700</td>\n",
       "      <td>2.054930</td>\n",
       "      <td>0.239766</td>\n",
       "      <td>0.054308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.817700</td>\n",
       "      <td>1.711020</td>\n",
       "      <td>0.467836</td>\n",
       "      <td>0.106768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.643800</td>\n",
       "      <td>1.717408</td>\n",
       "      <td>0.461988</td>\n",
       "      <td>0.112958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.677800</td>\n",
       "      <td>1.656147</td>\n",
       "      <td>0.467836</td>\n",
       "      <td>0.143658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.549200</td>\n",
       "      <td>1.748919</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.142462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.518700</td>\n",
       "      <td>1.636704</td>\n",
       "      <td>0.491228</td>\n",
       "      <td>0.158074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.481700</td>\n",
       "      <td>1.618297</td>\n",
       "      <td>0.467836</td>\n",
       "      <td>0.150089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.465500</td>\n",
       "      <td>1.647331</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.159722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1.424000</td>\n",
       "      <td>1.722753</td>\n",
       "      <td>0.385965</td>\n",
       "      <td>0.151826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.327400</td>\n",
       "      <td>1.737771</td>\n",
       "      <td>0.514620</td>\n",
       "      <td>0.186611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.325900</td>\n",
       "      <td>1.709401</td>\n",
       "      <td>0.491228</td>\n",
       "      <td>0.185455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.242500</td>\n",
       "      <td>1.837766</td>\n",
       "      <td>0.409357</td>\n",
       "      <td>0.182624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.208200</td>\n",
       "      <td>1.815922</td>\n",
       "      <td>0.391813</td>\n",
       "      <td>0.167470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.192700</td>\n",
       "      <td>1.675084</td>\n",
       "      <td>0.497076</td>\n",
       "      <td>0.163993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.092600</td>\n",
       "      <td>1.692086</td>\n",
       "      <td>0.514620</td>\n",
       "      <td>0.176041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.115300</td>\n",
       "      <td>1.813822</td>\n",
       "      <td>0.485380</td>\n",
       "      <td>0.166482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1.024700</td>\n",
       "      <td>1.766224</td>\n",
       "      <td>0.508772</td>\n",
       "      <td>0.173162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.897200</td>\n",
       "      <td>1.759947</td>\n",
       "      <td>0.491228</td>\n",
       "      <td>0.192642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.904700</td>\n",
       "      <td>1.777463</td>\n",
       "      <td>0.491228</td>\n",
       "      <td>0.205349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.830200</td>\n",
       "      <td>1.781878</td>\n",
       "      <td>0.502924</td>\n",
       "      <td>0.174616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.796800</td>\n",
       "      <td>1.812893</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.217340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.764800</td>\n",
       "      <td>1.807136</td>\n",
       "      <td>0.514620</td>\n",
       "      <td>0.202891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.752600</td>\n",
       "      <td>1.877840</td>\n",
       "      <td>0.491228</td>\n",
       "      <td>0.174175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.755400</td>\n",
       "      <td>1.858487</td>\n",
       "      <td>0.502924</td>\n",
       "      <td>0.208511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.677700</td>\n",
       "      <td>1.858212</td>\n",
       "      <td>0.514620</td>\n",
       "      <td>0.193199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.711100</td>\n",
       "      <td>1.878514</td>\n",
       "      <td>0.491228</td>\n",
       "      <td>0.199565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.638600</td>\n",
       "      <td>1.877069</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.205716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.648200</td>\n",
       "      <td>1.859291</td>\n",
       "      <td>0.508772</td>\n",
       "      <td>0.218645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.621300</td>\n",
       "      <td>1.884903</td>\n",
       "      <td>0.497076</td>\n",
       "      <td>0.227861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunis-ai/TunBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tunis-ai/TunBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "026beeafa5cb4ec09d287583bbb13a75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fce3ca7a1cc44f1b5967b05b761d374",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:26, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.003600</td>\n",
       "      <td>1.940887</td>\n",
       "      <td>0.175439</td>\n",
       "      <td>0.029131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.992400</td>\n",
       "      <td>1.910545</td>\n",
       "      <td>0.397661</td>\n",
       "      <td>0.051731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.905200</td>\n",
       "      <td>1.845663</td>\n",
       "      <td>0.397661</td>\n",
       "      <td>0.051731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.906400</td>\n",
       "      <td>1.795005</td>\n",
       "      <td>0.461988</td>\n",
       "      <td>0.106383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.770700</td>\n",
       "      <td>2.054930</td>\n",
       "      <td>0.239766</td>\n",
       "      <td>0.054308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.817700</td>\n",
       "      <td>1.711020</td>\n",
       "      <td>0.467836</td>\n",
       "      <td>0.106768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.643800</td>\n",
       "      <td>1.717408</td>\n",
       "      <td>0.461988</td>\n",
       "      <td>0.112958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.677800</td>\n",
       "      <td>1.656147</td>\n",
       "      <td>0.467836</td>\n",
       "      <td>0.143658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.549200</td>\n",
       "      <td>1.748919</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.142462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.518700</td>\n",
       "      <td>1.636704</td>\n",
       "      <td>0.491228</td>\n",
       "      <td>0.158074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.481700</td>\n",
       "      <td>1.618297</td>\n",
       "      <td>0.467836</td>\n",
       "      <td>0.150089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.465500</td>\n",
       "      <td>1.647331</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.159722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1.424000</td>\n",
       "      <td>1.722753</td>\n",
       "      <td>0.385965</td>\n",
       "      <td>0.151826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.327400</td>\n",
       "      <td>1.737771</td>\n",
       "      <td>0.514620</td>\n",
       "      <td>0.186611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.325900</td>\n",
       "      <td>1.709401</td>\n",
       "      <td>0.491228</td>\n",
       "      <td>0.185455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.242500</td>\n",
       "      <td>1.837766</td>\n",
       "      <td>0.409357</td>\n",
       "      <td>0.182624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.208200</td>\n",
       "      <td>1.815922</td>\n",
       "      <td>0.391813</td>\n",
       "      <td>0.167470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.192700</td>\n",
       "      <td>1.675084</td>\n",
       "      <td>0.497076</td>\n",
       "      <td>0.163993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.092600</td>\n",
       "      <td>1.692086</td>\n",
       "      <td>0.514620</td>\n",
       "      <td>0.176041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.115300</td>\n",
       "      <td>1.813822</td>\n",
       "      <td>0.485380</td>\n",
       "      <td>0.166482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1.024700</td>\n",
       "      <td>1.766224</td>\n",
       "      <td>0.508772</td>\n",
       "      <td>0.173162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.897200</td>\n",
       "      <td>1.759947</td>\n",
       "      <td>0.491228</td>\n",
       "      <td>0.192642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.904700</td>\n",
       "      <td>1.777463</td>\n",
       "      <td>0.491228</td>\n",
       "      <td>0.205349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.830200</td>\n",
       "      <td>1.781878</td>\n",
       "      <td>0.502924</td>\n",
       "      <td>0.174616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.796800</td>\n",
       "      <td>1.812893</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.217340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.764800</td>\n",
       "      <td>1.807136</td>\n",
       "      <td>0.514620</td>\n",
       "      <td>0.202891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.752600</td>\n",
       "      <td>1.877840</td>\n",
       "      <td>0.491228</td>\n",
       "      <td>0.174175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.755400</td>\n",
       "      <td>1.858487</td>\n",
       "      <td>0.502924</td>\n",
       "      <td>0.208511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.677700</td>\n",
       "      <td>1.858212</td>\n",
       "      <td>0.514620</td>\n",
       "      <td>0.193199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.711100</td>\n",
       "      <td>1.878514</td>\n",
       "      <td>0.491228</td>\n",
       "      <td>0.199565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.638600</td>\n",
       "      <td>1.877069</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.205716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.648200</td>\n",
       "      <td>1.859291</td>\n",
       "      <td>0.508772</td>\n",
       "      <td>0.218645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.621300</td>\n",
       "      <td>1.884903</td>\n",
       "      <td>0.497076</td>\n",
       "      <td>0.227861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunis-ai/TunBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tunis-ai/TunBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff88937007c944e1bd5b9c0695a970e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3cffa382a3146ca9e2fc93012bd032a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:27, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.003600</td>\n",
       "      <td>1.940887</td>\n",
       "      <td>0.175439</td>\n",
       "      <td>0.029131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.992400</td>\n",
       "      <td>1.910545</td>\n",
       "      <td>0.397661</td>\n",
       "      <td>0.051731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.905200</td>\n",
       "      <td>1.845663</td>\n",
       "      <td>0.397661</td>\n",
       "      <td>0.051731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.906400</td>\n",
       "      <td>1.795005</td>\n",
       "      <td>0.461988</td>\n",
       "      <td>0.106383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.770700</td>\n",
       "      <td>2.054930</td>\n",
       "      <td>0.239766</td>\n",
       "      <td>0.054308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.817700</td>\n",
       "      <td>1.711020</td>\n",
       "      <td>0.467836</td>\n",
       "      <td>0.106768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.643800</td>\n",
       "      <td>1.717408</td>\n",
       "      <td>0.461988</td>\n",
       "      <td>0.112958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.677800</td>\n",
       "      <td>1.656147</td>\n",
       "      <td>0.467836</td>\n",
       "      <td>0.143658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.549200</td>\n",
       "      <td>1.748919</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.142462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.518700</td>\n",
       "      <td>1.636704</td>\n",
       "      <td>0.491228</td>\n",
       "      <td>0.158074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.481700</td>\n",
       "      <td>1.618297</td>\n",
       "      <td>0.467836</td>\n",
       "      <td>0.150089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.465500</td>\n",
       "      <td>1.647331</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.159722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1.424000</td>\n",
       "      <td>1.722753</td>\n",
       "      <td>0.385965</td>\n",
       "      <td>0.151826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.327400</td>\n",
       "      <td>1.737771</td>\n",
       "      <td>0.514620</td>\n",
       "      <td>0.186611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.325900</td>\n",
       "      <td>1.709401</td>\n",
       "      <td>0.491228</td>\n",
       "      <td>0.185455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.242500</td>\n",
       "      <td>1.837766</td>\n",
       "      <td>0.409357</td>\n",
       "      <td>0.182624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.208200</td>\n",
       "      <td>1.815922</td>\n",
       "      <td>0.391813</td>\n",
       "      <td>0.167470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.192700</td>\n",
       "      <td>1.675084</td>\n",
       "      <td>0.497076</td>\n",
       "      <td>0.163993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.092600</td>\n",
       "      <td>1.692086</td>\n",
       "      <td>0.514620</td>\n",
       "      <td>0.176041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.115300</td>\n",
       "      <td>1.813822</td>\n",
       "      <td>0.485380</td>\n",
       "      <td>0.166482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1.024700</td>\n",
       "      <td>1.766224</td>\n",
       "      <td>0.508772</td>\n",
       "      <td>0.173162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.897200</td>\n",
       "      <td>1.759947</td>\n",
       "      <td>0.491228</td>\n",
       "      <td>0.192642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.904700</td>\n",
       "      <td>1.777463</td>\n",
       "      <td>0.491228</td>\n",
       "      <td>0.205349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.830200</td>\n",
       "      <td>1.781878</td>\n",
       "      <td>0.502924</td>\n",
       "      <td>0.174616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.796800</td>\n",
       "      <td>1.812893</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.217340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.764800</td>\n",
       "      <td>1.807136</td>\n",
       "      <td>0.514620</td>\n",
       "      <td>0.202891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.752600</td>\n",
       "      <td>1.877840</td>\n",
       "      <td>0.491228</td>\n",
       "      <td>0.174175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.755400</td>\n",
       "      <td>1.858487</td>\n",
       "      <td>0.502924</td>\n",
       "      <td>0.208511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.677700</td>\n",
       "      <td>1.858212</td>\n",
       "      <td>0.514620</td>\n",
       "      <td>0.193199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.711100</td>\n",
       "      <td>1.878514</td>\n",
       "      <td>0.491228</td>\n",
       "      <td>0.199565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.638600</td>\n",
       "      <td>1.877069</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.205716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.648200</td>\n",
       "      <td>1.859291</td>\n",
       "      <td>0.508772</td>\n",
       "      <td>0.218645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.621300</td>\n",
       "      <td>1.884903</td>\n",
       "      <td>0.497076</td>\n",
       "      <td>0.227861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunis-ai/TunBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tunis-ai/TunBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caf3a602e07a441395cb0b748d75c95b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94770c3a9bc442d6875c6893c01c2ca9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:26, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.039000</td>\n",
       "      <td>1.989886</td>\n",
       "      <td>0.321637</td>\n",
       "      <td>0.054081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.908200</td>\n",
       "      <td>1.949076</td>\n",
       "      <td>0.181287</td>\n",
       "      <td>0.034103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.987300</td>\n",
       "      <td>1.916587</td>\n",
       "      <td>0.321637</td>\n",
       "      <td>0.054081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.954900</td>\n",
       "      <td>1.890534</td>\n",
       "      <td>0.321637</td>\n",
       "      <td>0.054081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.829800</td>\n",
       "      <td>1.909469</td>\n",
       "      <td>0.339181</td>\n",
       "      <td>0.096947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.815300</td>\n",
       "      <td>1.874115</td>\n",
       "      <td>0.327485</td>\n",
       "      <td>0.096948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.735300</td>\n",
       "      <td>1.831937</td>\n",
       "      <td>0.350877</td>\n",
       "      <td>0.103376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.786000</td>\n",
       "      <td>1.776119</td>\n",
       "      <td>0.356725</td>\n",
       "      <td>0.105391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.632100</td>\n",
       "      <td>1.756086</td>\n",
       "      <td>0.385965</td>\n",
       "      <td>0.113686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.518900</td>\n",
       "      <td>1.746596</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.140506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.504100</td>\n",
       "      <td>1.695490</td>\n",
       "      <td>0.432749</td>\n",
       "      <td>0.174113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.427000</td>\n",
       "      <td>1.679501</td>\n",
       "      <td>0.438596</td>\n",
       "      <td>0.197788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1.313800</td>\n",
       "      <td>1.733110</td>\n",
       "      <td>0.461988</td>\n",
       "      <td>0.182859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.237800</td>\n",
       "      <td>1.715503</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.186547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.227600</td>\n",
       "      <td>1.698633</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.218301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.159400</td>\n",
       "      <td>1.608234</td>\n",
       "      <td>0.479532</td>\n",
       "      <td>0.209094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.085500</td>\n",
       "      <td>1.632521</td>\n",
       "      <td>0.461988</td>\n",
       "      <td>0.232865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.024700</td>\n",
       "      <td>1.709702</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.256804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.019800</td>\n",
       "      <td>1.673177</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.218683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.933900</td>\n",
       "      <td>1.818254</td>\n",
       "      <td>0.502924</td>\n",
       "      <td>0.223955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.932300</td>\n",
       "      <td>1.660829</td>\n",
       "      <td>0.456140</td>\n",
       "      <td>0.258118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.813600</td>\n",
       "      <td>1.717820</td>\n",
       "      <td>0.467836</td>\n",
       "      <td>0.266621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.798300</td>\n",
       "      <td>1.667205</td>\n",
       "      <td>0.485380</td>\n",
       "      <td>0.268524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.754400</td>\n",
       "      <td>1.634522</td>\n",
       "      <td>0.497076</td>\n",
       "      <td>0.257530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.735600</td>\n",
       "      <td>1.664300</td>\n",
       "      <td>0.491228</td>\n",
       "      <td>0.266856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.639300</td>\n",
       "      <td>1.731139</td>\n",
       "      <td>0.485380</td>\n",
       "      <td>0.295023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.696500</td>\n",
       "      <td>1.727478</td>\n",
       "      <td>0.491228</td>\n",
       "      <td>0.255630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.637100</td>\n",
       "      <td>1.797147</td>\n",
       "      <td>0.491228</td>\n",
       "      <td>0.288282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.604200</td>\n",
       "      <td>1.709779</td>\n",
       "      <td>0.485380</td>\n",
       "      <td>0.261338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.611200</td>\n",
       "      <td>1.744420</td>\n",
       "      <td>0.508772</td>\n",
       "      <td>0.277394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.552000</td>\n",
       "      <td>1.787630</td>\n",
       "      <td>0.497076</td>\n",
       "      <td>0.302101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.570100</td>\n",
       "      <td>1.750459</td>\n",
       "      <td>0.514620</td>\n",
       "      <td>0.304322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.546200</td>\n",
       "      <td>1.759437</td>\n",
       "      <td>0.514620</td>\n",
       "      <td>0.302052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunis-ai/TunBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tunis-ai/TunBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "753b8ddf87f9490c9a31ba3087388709",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83f21920909840ec97a70ce4460e8a81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:26, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.039000</td>\n",
       "      <td>1.989886</td>\n",
       "      <td>0.321637</td>\n",
       "      <td>0.054081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.908200</td>\n",
       "      <td>1.949076</td>\n",
       "      <td>0.181287</td>\n",
       "      <td>0.034103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.987300</td>\n",
       "      <td>1.916587</td>\n",
       "      <td>0.321637</td>\n",
       "      <td>0.054081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.954900</td>\n",
       "      <td>1.890534</td>\n",
       "      <td>0.321637</td>\n",
       "      <td>0.054081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.829800</td>\n",
       "      <td>1.909469</td>\n",
       "      <td>0.339181</td>\n",
       "      <td>0.096947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.815300</td>\n",
       "      <td>1.874115</td>\n",
       "      <td>0.327485</td>\n",
       "      <td>0.096948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.735300</td>\n",
       "      <td>1.831937</td>\n",
       "      <td>0.350877</td>\n",
       "      <td>0.103376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.786000</td>\n",
       "      <td>1.776119</td>\n",
       "      <td>0.356725</td>\n",
       "      <td>0.105391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.632100</td>\n",
       "      <td>1.756086</td>\n",
       "      <td>0.385965</td>\n",
       "      <td>0.113686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.518900</td>\n",
       "      <td>1.746596</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.140506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.504100</td>\n",
       "      <td>1.695490</td>\n",
       "      <td>0.432749</td>\n",
       "      <td>0.174113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.427000</td>\n",
       "      <td>1.679501</td>\n",
       "      <td>0.438596</td>\n",
       "      <td>0.197788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1.313800</td>\n",
       "      <td>1.733110</td>\n",
       "      <td>0.461988</td>\n",
       "      <td>0.182859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.237800</td>\n",
       "      <td>1.715503</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.186547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.227600</td>\n",
       "      <td>1.698633</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.218301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.159400</td>\n",
       "      <td>1.608234</td>\n",
       "      <td>0.479532</td>\n",
       "      <td>0.209094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.085500</td>\n",
       "      <td>1.632521</td>\n",
       "      <td>0.461988</td>\n",
       "      <td>0.232865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.024700</td>\n",
       "      <td>1.709702</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.256804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.019800</td>\n",
       "      <td>1.673177</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.218683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.933900</td>\n",
       "      <td>1.818254</td>\n",
       "      <td>0.502924</td>\n",
       "      <td>0.223955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.932300</td>\n",
       "      <td>1.660829</td>\n",
       "      <td>0.456140</td>\n",
       "      <td>0.258118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.813600</td>\n",
       "      <td>1.717820</td>\n",
       "      <td>0.467836</td>\n",
       "      <td>0.266621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.798300</td>\n",
       "      <td>1.667205</td>\n",
       "      <td>0.485380</td>\n",
       "      <td>0.268524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.754400</td>\n",
       "      <td>1.634522</td>\n",
       "      <td>0.497076</td>\n",
       "      <td>0.257530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.735600</td>\n",
       "      <td>1.664300</td>\n",
       "      <td>0.491228</td>\n",
       "      <td>0.266856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.639300</td>\n",
       "      <td>1.731139</td>\n",
       "      <td>0.485380</td>\n",
       "      <td>0.295023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.696500</td>\n",
       "      <td>1.727478</td>\n",
       "      <td>0.491228</td>\n",
       "      <td>0.255630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.637100</td>\n",
       "      <td>1.797147</td>\n",
       "      <td>0.491228</td>\n",
       "      <td>0.288282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.604200</td>\n",
       "      <td>1.709779</td>\n",
       "      <td>0.485380</td>\n",
       "      <td>0.261338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.611200</td>\n",
       "      <td>1.744420</td>\n",
       "      <td>0.508772</td>\n",
       "      <td>0.277394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.552000</td>\n",
       "      <td>1.787630</td>\n",
       "      <td>0.497076</td>\n",
       "      <td>0.302101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.570100</td>\n",
       "      <td>1.750459</td>\n",
       "      <td>0.514620</td>\n",
       "      <td>0.304322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.546200</td>\n",
       "      <td>1.759437</td>\n",
       "      <td>0.514620</td>\n",
       "      <td>0.302052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunis-ai/TunBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tunis-ai/TunBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "604b584ecc0b40dfbea30fee24768b40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a46c1185e464fef8a4eb4038e7b2ffb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:26, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.039000</td>\n",
       "      <td>1.989886</td>\n",
       "      <td>0.321637</td>\n",
       "      <td>0.054081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.908200</td>\n",
       "      <td>1.949076</td>\n",
       "      <td>0.181287</td>\n",
       "      <td>0.034103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.987300</td>\n",
       "      <td>1.916587</td>\n",
       "      <td>0.321637</td>\n",
       "      <td>0.054081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.954900</td>\n",
       "      <td>1.890534</td>\n",
       "      <td>0.321637</td>\n",
       "      <td>0.054081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.829800</td>\n",
       "      <td>1.909469</td>\n",
       "      <td>0.339181</td>\n",
       "      <td>0.096947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.815300</td>\n",
       "      <td>1.874115</td>\n",
       "      <td>0.327485</td>\n",
       "      <td>0.096948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.735300</td>\n",
       "      <td>1.831937</td>\n",
       "      <td>0.350877</td>\n",
       "      <td>0.103376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.786000</td>\n",
       "      <td>1.776119</td>\n",
       "      <td>0.356725</td>\n",
       "      <td>0.105391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.632100</td>\n",
       "      <td>1.756086</td>\n",
       "      <td>0.385965</td>\n",
       "      <td>0.113686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.518900</td>\n",
       "      <td>1.746596</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.140506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.504100</td>\n",
       "      <td>1.695490</td>\n",
       "      <td>0.432749</td>\n",
       "      <td>0.174113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.427000</td>\n",
       "      <td>1.679501</td>\n",
       "      <td>0.438596</td>\n",
       "      <td>0.197788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1.313800</td>\n",
       "      <td>1.733110</td>\n",
       "      <td>0.461988</td>\n",
       "      <td>0.182859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.237800</td>\n",
       "      <td>1.715503</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.186547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.227600</td>\n",
       "      <td>1.698633</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.218301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.159400</td>\n",
       "      <td>1.608234</td>\n",
       "      <td>0.479532</td>\n",
       "      <td>0.209094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.085500</td>\n",
       "      <td>1.632521</td>\n",
       "      <td>0.461988</td>\n",
       "      <td>0.232865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.024700</td>\n",
       "      <td>1.709702</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.256804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.019800</td>\n",
       "      <td>1.673177</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.218683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.933900</td>\n",
       "      <td>1.818254</td>\n",
       "      <td>0.502924</td>\n",
       "      <td>0.223955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.932300</td>\n",
       "      <td>1.660829</td>\n",
       "      <td>0.456140</td>\n",
       "      <td>0.258118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.813600</td>\n",
       "      <td>1.717820</td>\n",
       "      <td>0.467836</td>\n",
       "      <td>0.266621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.798300</td>\n",
       "      <td>1.667205</td>\n",
       "      <td>0.485380</td>\n",
       "      <td>0.268524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.754400</td>\n",
       "      <td>1.634522</td>\n",
       "      <td>0.497076</td>\n",
       "      <td>0.257530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.735600</td>\n",
       "      <td>1.664300</td>\n",
       "      <td>0.491228</td>\n",
       "      <td>0.266856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.639300</td>\n",
       "      <td>1.731139</td>\n",
       "      <td>0.485380</td>\n",
       "      <td>0.295023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.696500</td>\n",
       "      <td>1.727478</td>\n",
       "      <td>0.491228</td>\n",
       "      <td>0.255630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.637100</td>\n",
       "      <td>1.797147</td>\n",
       "      <td>0.491228</td>\n",
       "      <td>0.288282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.604200</td>\n",
       "      <td>1.709779</td>\n",
       "      <td>0.485380</td>\n",
       "      <td>0.261338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.611200</td>\n",
       "      <td>1.744420</td>\n",
       "      <td>0.508772</td>\n",
       "      <td>0.277394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.552000</td>\n",
       "      <td>1.787630</td>\n",
       "      <td>0.497076</td>\n",
       "      <td>0.302101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.570100</td>\n",
       "      <td>1.750459</td>\n",
       "      <td>0.514620</td>\n",
       "      <td>0.304322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.546200</td>\n",
       "      <td>1.759437</td>\n",
       "      <td>0.514620</td>\n",
       "      <td>0.302052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['review', 'label'],\n",
       "        num_rows: 680\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['review', 'label'],\n",
       "        num_rows: 171\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alger-ia/dziribert, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0ff41da5c0e4841a195b286f89adb94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e897a3ed560d4500ad44e721d9756366",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:27, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.967300</td>\n",
       "      <td>1.727422</td>\n",
       "      <td>0.409357</td>\n",
       "      <td>0.147056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.393800</td>\n",
       "      <td>1.277377</td>\n",
       "      <td>0.619883</td>\n",
       "      <td>0.308668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.973800</td>\n",
       "      <td>1.038326</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.428257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.643700</td>\n",
       "      <td>0.927825</td>\n",
       "      <td>0.672515</td>\n",
       "      <td>0.402663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.391800</td>\n",
       "      <td>0.914712</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.477630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.206500</td>\n",
       "      <td>0.948899</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.482537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.111300</td>\n",
       "      <td>1.059221</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.554994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.067600</td>\n",
       "      <td>1.071494</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.512804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.034100</td>\n",
       "      <td>1.121985</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.483551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.018600</td>\n",
       "      <td>1.129223</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.502758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.013400</td>\n",
       "      <td>1.223249</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.511823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.009600</td>\n",
       "      <td>1.203287</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.510130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.008300</td>\n",
       "      <td>1.198793</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.502567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>1.235926</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.504907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.006200</td>\n",
       "      <td>1.272553</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.521192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>1.287257</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.519008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.005200</td>\n",
       "      <td>1.292835</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.510130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>1.302466</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.510130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>1.310733</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.510130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>1.323173</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.510130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>1.327796</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.510130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>1.334133</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.510130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>1.338634</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.505487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.345440</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.502331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>1.349006</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.502331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.354317</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.513903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.358717</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.518546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>1.361592</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.518546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>1.364377</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.518546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.366249</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.518546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>1.368776</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.518546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>1.369996</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.518546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.370204</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.518546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alger-ia/dziribert, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb74923323de4378ba438bcfd4a5847a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7473248ffb342f18c992b7298a07a77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:27, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.967300</td>\n",
       "      <td>1.727422</td>\n",
       "      <td>0.409357</td>\n",
       "      <td>0.147056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.393800</td>\n",
       "      <td>1.277377</td>\n",
       "      <td>0.619883</td>\n",
       "      <td>0.308668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.973800</td>\n",
       "      <td>1.038326</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.428257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.643700</td>\n",
       "      <td>0.927825</td>\n",
       "      <td>0.672515</td>\n",
       "      <td>0.402663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.391800</td>\n",
       "      <td>0.914712</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.477630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.206500</td>\n",
       "      <td>0.948899</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.482537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.111300</td>\n",
       "      <td>1.059221</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.554994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.067600</td>\n",
       "      <td>1.071494</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.512804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.034100</td>\n",
       "      <td>1.121985</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.483551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.018600</td>\n",
       "      <td>1.129223</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.502758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.013400</td>\n",
       "      <td>1.223249</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.511823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.009600</td>\n",
       "      <td>1.203287</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.510130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.008300</td>\n",
       "      <td>1.198793</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.502567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>1.235926</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.504907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.006200</td>\n",
       "      <td>1.272553</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.521192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>1.287257</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.519008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.005200</td>\n",
       "      <td>1.292835</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.510130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>1.302466</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.510130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>1.310733</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.510130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>1.323173</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.510130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>1.327796</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.510130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>1.334133</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.510130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>1.338634</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.505487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.345440</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.502331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>1.349006</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.502331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.354317</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.513903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.358717</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.518546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>1.361592</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.518546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>1.364377</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.518546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.366249</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.518546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>1.368776</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.518546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>1.369996</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.518546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.370204</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.518546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alger-ia/dziribert, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c590df51a7d471badeb224a09662ac5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "259af493423d4a219ed2705a76ab594d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:27, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.967300</td>\n",
       "      <td>1.727422</td>\n",
       "      <td>0.409357</td>\n",
       "      <td>0.147056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.393800</td>\n",
       "      <td>1.277377</td>\n",
       "      <td>0.619883</td>\n",
       "      <td>0.308668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.973800</td>\n",
       "      <td>1.038326</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.428257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.643700</td>\n",
       "      <td>0.927825</td>\n",
       "      <td>0.672515</td>\n",
       "      <td>0.402663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.391800</td>\n",
       "      <td>0.914712</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.477630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.206500</td>\n",
       "      <td>0.948899</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.482537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.111300</td>\n",
       "      <td>1.059221</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.554994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.067600</td>\n",
       "      <td>1.071494</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.512804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.034100</td>\n",
       "      <td>1.121985</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.483551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.018600</td>\n",
       "      <td>1.129223</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.502758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.013400</td>\n",
       "      <td>1.223249</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.511823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.009600</td>\n",
       "      <td>1.203287</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.510130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.008300</td>\n",
       "      <td>1.198793</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.502567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>1.235926</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.504907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.006200</td>\n",
       "      <td>1.272553</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.521192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>1.287257</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.519008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.005200</td>\n",
       "      <td>1.292835</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.510130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>1.302466</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.510130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>1.310733</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.510130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>1.323173</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.510130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>1.327796</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.510130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>1.334133</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.510130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>1.338634</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.505487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.345440</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.502331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>1.349006</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.502331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.354317</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.513903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.358717</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.518546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>1.361592</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.518546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>1.364377</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.518546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.366249</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.518546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>1.368776</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.518546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>1.369996</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.518546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.370204</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.518546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alger-ia/dziribert, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2be9a4a6dc645c0999ce5a0e8e37356",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0b5fad3214249d785a2732ab09665ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:27, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.982600</td>\n",
       "      <td>1.691244</td>\n",
       "      <td>0.479532</td>\n",
       "      <td>0.157566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.495100</td>\n",
       "      <td>1.323888</td>\n",
       "      <td>0.584795</td>\n",
       "      <td>0.201089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.989900</td>\n",
       "      <td>1.102030</td>\n",
       "      <td>0.637427</td>\n",
       "      <td>0.254917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.729500</td>\n",
       "      <td>1.078532</td>\n",
       "      <td>0.654971</td>\n",
       "      <td>0.334017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.411700</td>\n",
       "      <td>0.998032</td>\n",
       "      <td>0.660819</td>\n",
       "      <td>0.315112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.271500</td>\n",
       "      <td>1.013209</td>\n",
       "      <td>0.690058</td>\n",
       "      <td>0.375387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.191100</td>\n",
       "      <td>0.972562</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.490047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.080900</td>\n",
       "      <td>1.019220</td>\n",
       "      <td>0.672515</td>\n",
       "      <td>0.427218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.045500</td>\n",
       "      <td>1.064055</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.531230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.032000</td>\n",
       "      <td>1.209596</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>0.395575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.018600</td>\n",
       "      <td>1.114084</td>\n",
       "      <td>0.690058</td>\n",
       "      <td>0.494207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>1.112819</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.507322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.009200</td>\n",
       "      <td>1.150985</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.508911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.007100</td>\n",
       "      <td>1.201864</td>\n",
       "      <td>0.690058</td>\n",
       "      <td>0.483021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>1.224560</td>\n",
       "      <td>0.690058</td>\n",
       "      <td>0.480362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.005700</td>\n",
       "      <td>1.230016</td>\n",
       "      <td>0.690058</td>\n",
       "      <td>0.477349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>1.243386</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.490999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>1.266760</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.511329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>1.285302</td>\n",
       "      <td>0.690058</td>\n",
       "      <td>0.477349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>1.297154</td>\n",
       "      <td>0.690058</td>\n",
       "      <td>0.477349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>1.304597</td>\n",
       "      <td>0.690058</td>\n",
       "      <td>0.477349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>1.313476</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.481941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>1.326526</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.483502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.340546</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.483502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.349215</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.481941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>1.362040</td>\n",
       "      <td>0.690058</td>\n",
       "      <td>0.478910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.382661</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.495195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.386766</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.495195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>1.382091</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.495195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>1.380128</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.495195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.379364</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.495195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>1.378924</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.495195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>1.381128</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.495195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alger-ia/dziribert, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "962d4d73c12f4af5bf68a7763735bead",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "663bb68bf5a64ea4bb34d109a72bb882",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:27, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.982600</td>\n",
       "      <td>1.691244</td>\n",
       "      <td>0.479532</td>\n",
       "      <td>0.157566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.495100</td>\n",
       "      <td>1.323888</td>\n",
       "      <td>0.584795</td>\n",
       "      <td>0.201089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.989900</td>\n",
       "      <td>1.102030</td>\n",
       "      <td>0.637427</td>\n",
       "      <td>0.254917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.729500</td>\n",
       "      <td>1.078532</td>\n",
       "      <td>0.654971</td>\n",
       "      <td>0.334017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.411700</td>\n",
       "      <td>0.998032</td>\n",
       "      <td>0.660819</td>\n",
       "      <td>0.315112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.271500</td>\n",
       "      <td>1.013209</td>\n",
       "      <td>0.690058</td>\n",
       "      <td>0.375387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.191100</td>\n",
       "      <td>0.972562</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.490047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.080900</td>\n",
       "      <td>1.019220</td>\n",
       "      <td>0.672515</td>\n",
       "      <td>0.427218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.045500</td>\n",
       "      <td>1.064055</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.531230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.032000</td>\n",
       "      <td>1.209596</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>0.395575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.018600</td>\n",
       "      <td>1.114084</td>\n",
       "      <td>0.690058</td>\n",
       "      <td>0.494207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>1.112819</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.507322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.009200</td>\n",
       "      <td>1.150985</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.508911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.007100</td>\n",
       "      <td>1.201864</td>\n",
       "      <td>0.690058</td>\n",
       "      <td>0.483021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>1.224560</td>\n",
       "      <td>0.690058</td>\n",
       "      <td>0.480362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.005700</td>\n",
       "      <td>1.230016</td>\n",
       "      <td>0.690058</td>\n",
       "      <td>0.477349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>1.243386</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.490999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>1.266760</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.511329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>1.285302</td>\n",
       "      <td>0.690058</td>\n",
       "      <td>0.477349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>1.297154</td>\n",
       "      <td>0.690058</td>\n",
       "      <td>0.477349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>1.304597</td>\n",
       "      <td>0.690058</td>\n",
       "      <td>0.477349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>1.313476</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.481941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>1.326526</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.483502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.340546</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.483502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.349215</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.481941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>1.362040</td>\n",
       "      <td>0.690058</td>\n",
       "      <td>0.478910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.382661</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.495195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.386766</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.495195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>1.382091</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.495195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>1.380128</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.495195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.379364</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.495195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>1.378924</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.495195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>1.381128</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.495195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alger-ia/dziribert, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f19a1b5c54c24c8abb881832807acaf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4871e7da34114745a11fffa94458e812",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:27, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.982600</td>\n",
       "      <td>1.691244</td>\n",
       "      <td>0.479532</td>\n",
       "      <td>0.157566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.495100</td>\n",
       "      <td>1.323888</td>\n",
       "      <td>0.584795</td>\n",
       "      <td>0.201089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.989900</td>\n",
       "      <td>1.102030</td>\n",
       "      <td>0.637427</td>\n",
       "      <td>0.254917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.729500</td>\n",
       "      <td>1.078532</td>\n",
       "      <td>0.654971</td>\n",
       "      <td>0.334017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.411700</td>\n",
       "      <td>0.998032</td>\n",
       "      <td>0.660819</td>\n",
       "      <td>0.315112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.271500</td>\n",
       "      <td>1.013209</td>\n",
       "      <td>0.690058</td>\n",
       "      <td>0.375387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.191100</td>\n",
       "      <td>0.972562</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.490047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.080900</td>\n",
       "      <td>1.019220</td>\n",
       "      <td>0.672515</td>\n",
       "      <td>0.427218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.045500</td>\n",
       "      <td>1.064055</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.531230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.032000</td>\n",
       "      <td>1.209596</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>0.395575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.018600</td>\n",
       "      <td>1.114084</td>\n",
       "      <td>0.690058</td>\n",
       "      <td>0.494207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>1.112819</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.507322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.009200</td>\n",
       "      <td>1.150985</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.508911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.007100</td>\n",
       "      <td>1.201864</td>\n",
       "      <td>0.690058</td>\n",
       "      <td>0.483021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>1.224560</td>\n",
       "      <td>0.690058</td>\n",
       "      <td>0.480362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.005700</td>\n",
       "      <td>1.230016</td>\n",
       "      <td>0.690058</td>\n",
       "      <td>0.477349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>1.243386</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.490999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>1.266760</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.511329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>1.285302</td>\n",
       "      <td>0.690058</td>\n",
       "      <td>0.477349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>1.297154</td>\n",
       "      <td>0.690058</td>\n",
       "      <td>0.477349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>1.304597</td>\n",
       "      <td>0.690058</td>\n",
       "      <td>0.477349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>1.313476</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.481941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>1.326526</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.483502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.340546</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.483502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.349215</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.481941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>1.362040</td>\n",
       "      <td>0.690058</td>\n",
       "      <td>0.478910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.382661</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.495195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.386766</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.495195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>1.382091</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.495195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>1.380128</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.495195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.379364</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.495195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>1.378924</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.495195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>1.381128</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.495195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alger-ia/dziribert, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbc5d6f998404d72b15380bae0e0d448",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "033c50e7604247928aa72dd7b213c449",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:27, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.954400</td>\n",
       "      <td>1.681055</td>\n",
       "      <td>0.438596</td>\n",
       "      <td>0.168420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.388100</td>\n",
       "      <td>1.288269</td>\n",
       "      <td>0.567251</td>\n",
       "      <td>0.268914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.005000</td>\n",
       "      <td>1.055454</td>\n",
       "      <td>0.625731</td>\n",
       "      <td>0.350185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.704600</td>\n",
       "      <td>1.002396</td>\n",
       "      <td>0.672515</td>\n",
       "      <td>0.400247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.433300</td>\n",
       "      <td>0.967133</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.463737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.264800</td>\n",
       "      <td>0.980180</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.466419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.151300</td>\n",
       "      <td>1.079972</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.466835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.091700</td>\n",
       "      <td>1.039557</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.570141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.039500</td>\n",
       "      <td>1.169161</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.563895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.023500</td>\n",
       "      <td>1.230832</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.508117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.014000</td>\n",
       "      <td>1.237633</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.588746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.010300</td>\n",
       "      <td>1.275172</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.592533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.008200</td>\n",
       "      <td>1.281613</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.606202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>1.326958</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.602414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>1.343529</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.584597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>1.349609</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.588746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.005200</td>\n",
       "      <td>1.369104</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.532506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>1.390918</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.532303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>1.406907</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.527177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>1.424239</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.504708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>1.438495</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.504708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>1.442154</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.526943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.443743</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.539245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>1.446720</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.539245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>1.452984</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.539245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>1.459648</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.504443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.463292</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.504443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.467821</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.504443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.471051</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.504443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.474764</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.516744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>1.477193</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.516744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.477822</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.516744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.477503</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.516744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alger-ia/dziribert, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e9853308ea0484aaedd54c11885d157",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a76a120535e48818a7f65733c919737",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:27, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.954400</td>\n",
       "      <td>1.681055</td>\n",
       "      <td>0.438596</td>\n",
       "      <td>0.168420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.388100</td>\n",
       "      <td>1.288269</td>\n",
       "      <td>0.567251</td>\n",
       "      <td>0.268914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.005000</td>\n",
       "      <td>1.055454</td>\n",
       "      <td>0.625731</td>\n",
       "      <td>0.350185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.704600</td>\n",
       "      <td>1.002396</td>\n",
       "      <td>0.672515</td>\n",
       "      <td>0.400247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.433300</td>\n",
       "      <td>0.967133</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.463737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.264800</td>\n",
       "      <td>0.980180</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.466419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.151300</td>\n",
       "      <td>1.079972</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.466835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.091700</td>\n",
       "      <td>1.039557</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.570141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.039500</td>\n",
       "      <td>1.169161</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.563895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.023500</td>\n",
       "      <td>1.230832</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.508117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.014000</td>\n",
       "      <td>1.237633</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.588746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.010300</td>\n",
       "      <td>1.275172</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.592533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.008200</td>\n",
       "      <td>1.281613</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.606202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>1.326958</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.602414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>1.343529</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.584597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>1.349609</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.588746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.005200</td>\n",
       "      <td>1.369104</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.532506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>1.390918</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.532303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>1.406907</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.527177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>1.424239</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.504708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>1.438495</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.504708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>1.442154</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.526943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.443743</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.539245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>1.446720</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.539245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>1.452984</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.539245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>1.459648</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.504443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.463292</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.504443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.467821</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.504443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.471051</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.504443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.474764</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.516744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>1.477193</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.516744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.477822</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.516744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.477503</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.516744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alger-ia/dziribert, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48450098c7814de5831213e7cbe7d9a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "864efc52aaf5459dbe2784f2b164be96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:27, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.954400</td>\n",
       "      <td>1.681055</td>\n",
       "      <td>0.438596</td>\n",
       "      <td>0.168420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.388100</td>\n",
       "      <td>1.288269</td>\n",
       "      <td>0.567251</td>\n",
       "      <td>0.268914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.005000</td>\n",
       "      <td>1.055454</td>\n",
       "      <td>0.625731</td>\n",
       "      <td>0.350185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.704600</td>\n",
       "      <td>1.002396</td>\n",
       "      <td>0.672515</td>\n",
       "      <td>0.400247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.433300</td>\n",
       "      <td>0.967133</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.463737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.264800</td>\n",
       "      <td>0.980180</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.466419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.151300</td>\n",
       "      <td>1.079972</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.466835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.091700</td>\n",
       "      <td>1.039557</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.570141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.039500</td>\n",
       "      <td>1.169161</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.563895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.023500</td>\n",
       "      <td>1.230832</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.508117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.014000</td>\n",
       "      <td>1.237633</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.588746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.010300</td>\n",
       "      <td>1.275172</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.592533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.008200</td>\n",
       "      <td>1.281613</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.606202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>1.326958</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.602414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>1.343529</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.584597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>1.349609</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.588746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.005200</td>\n",
       "      <td>1.369104</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.532506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>1.390918</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.532303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>1.406907</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.527177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>1.424239</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.504708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>1.438495</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.504708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>1.442154</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.526943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.443743</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.539245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>1.446720</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.539245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>1.452984</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.539245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>1.459648</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.504443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.463292</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.504443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.467821</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.504443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.471051</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.504443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.474764</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.516744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>1.477193</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.516744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.477822</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.516744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.477503</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.516744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['review', 'label'],\n",
       "        num_rows: 680\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['review', 'label'],\n",
       "        num_rows: 171\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SI2M-Lab/DarijaBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SI2M-Lab/DarijaBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4da7407989924b248957611b599d3649",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a97a664cb564f5fbc5c2bf28faac35e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:28, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.904800</td>\n",
       "      <td>1.671892</td>\n",
       "      <td>0.385965</td>\n",
       "      <td>0.132576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.365800</td>\n",
       "      <td>1.344011</td>\n",
       "      <td>0.573099</td>\n",
       "      <td>0.267395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.032000</td>\n",
       "      <td>1.094569</td>\n",
       "      <td>0.643275</td>\n",
       "      <td>0.346088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.725800</td>\n",
       "      <td>0.974752</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.448748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.501300</td>\n",
       "      <td>0.969496</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.489264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.348700</td>\n",
       "      <td>1.006144</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.503916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.214000</td>\n",
       "      <td>1.039534</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.572930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.187600</td>\n",
       "      <td>1.152060</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.499464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.122300</td>\n",
       "      <td>1.094475</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.577485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.064400</td>\n",
       "      <td>1.251686</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.502422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.044800</td>\n",
       "      <td>1.089113</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.575290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.025700</td>\n",
       "      <td>1.319362</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.590950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.021200</td>\n",
       "      <td>1.231274</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.605649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.011400</td>\n",
       "      <td>1.248045</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.596402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>1.261242</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.592755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.007100</td>\n",
       "      <td>1.267222</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.608031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>1.260609</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.605676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.005200</td>\n",
       "      <td>1.272637</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.542360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.004900</td>\n",
       "      <td>1.288878</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.542360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.004900</td>\n",
       "      <td>1.292106</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.616002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>1.290831</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.604515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>1.298999</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.601370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>1.307883</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.615476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>1.316011</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.615476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>1.350285</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.611831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.357660</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.611831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.334290</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.620471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>1.327458</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.622234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.332631</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.611833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>1.342908</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.610493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>1.345990</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.610493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>1.345922</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.610493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>1.346354</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.610493</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SI2M-Lab/DarijaBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SI2M-Lab/DarijaBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aa12853fd4047b99e94e0297504046e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "582b6d7113cb4b6280c2fdba2faad9b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:28, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.904800</td>\n",
       "      <td>1.671892</td>\n",
       "      <td>0.385965</td>\n",
       "      <td>0.132576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.365800</td>\n",
       "      <td>1.344011</td>\n",
       "      <td>0.573099</td>\n",
       "      <td>0.267395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.032000</td>\n",
       "      <td>1.094569</td>\n",
       "      <td>0.643275</td>\n",
       "      <td>0.346088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.725800</td>\n",
       "      <td>0.974752</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.448748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.501300</td>\n",
       "      <td>0.969496</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.489264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.348700</td>\n",
       "      <td>1.006144</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.503916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.214000</td>\n",
       "      <td>1.039534</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.572930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.187600</td>\n",
       "      <td>1.152060</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.499464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.122300</td>\n",
       "      <td>1.094475</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.577485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.064400</td>\n",
       "      <td>1.251686</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.502422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.044800</td>\n",
       "      <td>1.089113</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.575290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.025700</td>\n",
       "      <td>1.319362</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.590950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.021200</td>\n",
       "      <td>1.231274</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.605649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.011400</td>\n",
       "      <td>1.248045</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.596402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>1.261242</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.592755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.007100</td>\n",
       "      <td>1.267222</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.608031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>1.260609</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.605676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.005200</td>\n",
       "      <td>1.272637</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.542360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.004900</td>\n",
       "      <td>1.288878</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.542360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.004900</td>\n",
       "      <td>1.292106</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.616002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>1.290831</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.604515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>1.298999</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.601370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>1.307883</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.615476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>1.316011</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.615476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>1.350285</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.611831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.357660</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.611831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.334290</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.620471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>1.327458</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.622234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.332631</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.611833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>1.342908</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.610493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>1.345990</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.610493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>1.345922</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.610493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>1.346354</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.610493</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SI2M-Lab/DarijaBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SI2M-Lab/DarijaBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "412ba94b983e46f9a2c313e6168f296d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d9f532e2ee24f71b59c65f69e809a16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:28, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.904800</td>\n",
       "      <td>1.671892</td>\n",
       "      <td>0.385965</td>\n",
       "      <td>0.132576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.365800</td>\n",
       "      <td>1.344011</td>\n",
       "      <td>0.573099</td>\n",
       "      <td>0.267395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.032000</td>\n",
       "      <td>1.094569</td>\n",
       "      <td>0.643275</td>\n",
       "      <td>0.346088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.725800</td>\n",
       "      <td>0.974752</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.448748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.501300</td>\n",
       "      <td>0.969496</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.489264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.348700</td>\n",
       "      <td>1.006144</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.503916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.214000</td>\n",
       "      <td>1.039534</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.572930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.187600</td>\n",
       "      <td>1.152060</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.499464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.122300</td>\n",
       "      <td>1.094475</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.577485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.064400</td>\n",
       "      <td>1.251686</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.502422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.044800</td>\n",
       "      <td>1.089113</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.575290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.025700</td>\n",
       "      <td>1.319362</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.590950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.021200</td>\n",
       "      <td>1.231274</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.605649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.011400</td>\n",
       "      <td>1.248045</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.596402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>1.261242</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.592755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.007100</td>\n",
       "      <td>1.267222</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.608031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>1.260609</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.605676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.005200</td>\n",
       "      <td>1.272637</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.542360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.004900</td>\n",
       "      <td>1.288878</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.542360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.004900</td>\n",
       "      <td>1.292106</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.616002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>1.290831</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.604515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>1.298999</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.601370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>1.307883</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.615476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>1.316011</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.615476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>1.350285</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.611831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.357660</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.611831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.334290</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.620471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>1.327458</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.622234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.332631</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.611833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>1.342908</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.610493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>1.345990</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.610493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>1.345922</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.610493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>1.346354</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.610493</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SI2M-Lab/DarijaBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SI2M-Lab/DarijaBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "087af357b58f466891c25802d539547a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab60b11e7ce64a62a43efb871cd55836",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:28, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.941200</td>\n",
       "      <td>1.673671</td>\n",
       "      <td>0.491228</td>\n",
       "      <td>0.144843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.469100</td>\n",
       "      <td>1.458500</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.223787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.991100</td>\n",
       "      <td>1.250955</td>\n",
       "      <td>0.619883</td>\n",
       "      <td>0.274118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.781200</td>\n",
       "      <td>1.171206</td>\n",
       "      <td>0.643275</td>\n",
       "      <td>0.318910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.481000</td>\n",
       "      <td>1.307557</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.280987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.375700</td>\n",
       "      <td>1.365985</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>0.338890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.298700</td>\n",
       "      <td>1.260936</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.395660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.168500</td>\n",
       "      <td>1.290772</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>0.385515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.115000</td>\n",
       "      <td>1.311715</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.441368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.086000</td>\n",
       "      <td>1.452834</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>0.339144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.057600</td>\n",
       "      <td>1.349792</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.440232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.054400</td>\n",
       "      <td>1.567488</td>\n",
       "      <td>0.602339</td>\n",
       "      <td>0.399976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.031900</td>\n",
       "      <td>1.558044</td>\n",
       "      <td>0.672515</td>\n",
       "      <td>0.473554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.019200</td>\n",
       "      <td>1.559384</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.484272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.014600</td>\n",
       "      <td>1.520023</td>\n",
       "      <td>0.660819</td>\n",
       "      <td>0.432087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.011100</td>\n",
       "      <td>1.635312</td>\n",
       "      <td>0.643275</td>\n",
       "      <td>0.447501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.008200</td>\n",
       "      <td>1.661821</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.482555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>1.627391</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.497883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>1.641703</td>\n",
       "      <td>0.690058</td>\n",
       "      <td>0.480268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>1.665389</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.476455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.004800</td>\n",
       "      <td>1.707191</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.466842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>1.726047</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.470200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>1.722306</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.471757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>1.726045</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.471757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>1.731659</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.471265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.724242</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.467543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.726630</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.467543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.738129</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.472358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.746805</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.467543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.750752</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.467543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.750527</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.471966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>1.750200</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.471966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>1.750469</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.471966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SI2M-Lab/DarijaBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SI2M-Lab/DarijaBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6e21f0c0db34eeaa266cc518add1875",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "480f459e82054b91a31d2bed9451b454",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:28, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.941200</td>\n",
       "      <td>1.673671</td>\n",
       "      <td>0.491228</td>\n",
       "      <td>0.144843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.469100</td>\n",
       "      <td>1.458500</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.223787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.991100</td>\n",
       "      <td>1.250955</td>\n",
       "      <td>0.619883</td>\n",
       "      <td>0.274118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.781200</td>\n",
       "      <td>1.171206</td>\n",
       "      <td>0.643275</td>\n",
       "      <td>0.318910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.481000</td>\n",
       "      <td>1.307557</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.280987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.375700</td>\n",
       "      <td>1.365985</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>0.338890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.298700</td>\n",
       "      <td>1.260936</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.395660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.168500</td>\n",
       "      <td>1.290772</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>0.385515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.115000</td>\n",
       "      <td>1.311715</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.441368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.086000</td>\n",
       "      <td>1.452834</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>0.339144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.057600</td>\n",
       "      <td>1.349792</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.440232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.054400</td>\n",
       "      <td>1.567488</td>\n",
       "      <td>0.602339</td>\n",
       "      <td>0.399976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.031900</td>\n",
       "      <td>1.558044</td>\n",
       "      <td>0.672515</td>\n",
       "      <td>0.473554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.019200</td>\n",
       "      <td>1.559384</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.484272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.014600</td>\n",
       "      <td>1.520023</td>\n",
       "      <td>0.660819</td>\n",
       "      <td>0.432087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.011100</td>\n",
       "      <td>1.635312</td>\n",
       "      <td>0.643275</td>\n",
       "      <td>0.447501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.008200</td>\n",
       "      <td>1.661821</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.482555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>1.627391</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.497883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>1.641703</td>\n",
       "      <td>0.690058</td>\n",
       "      <td>0.480268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>1.665389</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.476455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.004800</td>\n",
       "      <td>1.707191</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.466842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>1.726047</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.470200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>1.722306</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.471757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>1.726045</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.471757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>1.731659</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.471265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.724242</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.467543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.726630</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.467543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.738129</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.472358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.746805</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.467543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.750752</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.467543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.750527</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.471966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>1.750200</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.471966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>1.750469</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.471966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SI2M-Lab/DarijaBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SI2M-Lab/DarijaBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "343b179fc7244e55b3f6431a1b9de574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71d7dd666f1d4aa8a15157bb52698410",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:28, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.941200</td>\n",
       "      <td>1.673671</td>\n",
       "      <td>0.491228</td>\n",
       "      <td>0.144843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.469100</td>\n",
       "      <td>1.458500</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.223787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.991100</td>\n",
       "      <td>1.250955</td>\n",
       "      <td>0.619883</td>\n",
       "      <td>0.274118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.781200</td>\n",
       "      <td>1.171206</td>\n",
       "      <td>0.643275</td>\n",
       "      <td>0.318910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.481000</td>\n",
       "      <td>1.307557</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.280987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.375700</td>\n",
       "      <td>1.365985</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>0.338890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.298700</td>\n",
       "      <td>1.260936</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.395660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.168500</td>\n",
       "      <td>1.290772</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>0.385515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.115000</td>\n",
       "      <td>1.311715</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.441368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.086000</td>\n",
       "      <td>1.452834</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>0.339144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.057600</td>\n",
       "      <td>1.349792</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.440232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.054400</td>\n",
       "      <td>1.567488</td>\n",
       "      <td>0.602339</td>\n",
       "      <td>0.399976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.031900</td>\n",
       "      <td>1.558044</td>\n",
       "      <td>0.672515</td>\n",
       "      <td>0.473554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.019200</td>\n",
       "      <td>1.559384</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.484272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.014600</td>\n",
       "      <td>1.520023</td>\n",
       "      <td>0.660819</td>\n",
       "      <td>0.432087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.011100</td>\n",
       "      <td>1.635312</td>\n",
       "      <td>0.643275</td>\n",
       "      <td>0.447501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.008200</td>\n",
       "      <td>1.661821</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.482555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>1.627391</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.497883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>1.641703</td>\n",
       "      <td>0.690058</td>\n",
       "      <td>0.480268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>1.665389</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.476455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.004800</td>\n",
       "      <td>1.707191</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.466842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>1.726047</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.470200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>1.722306</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.471757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>1.726045</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.471757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>1.731659</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.471265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.724242</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.467543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.726630</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.467543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.738129</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.472358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.746805</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.467543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.750752</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.467543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.750527</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.471966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>1.750200</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.471966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>1.750469</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.471966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SI2M-Lab/DarijaBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SI2M-Lab/DarijaBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14889b586b1e48ebba347d3436253008",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee8b5cf11a4a48028307ce4a28a03be1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:28, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.934100</td>\n",
       "      <td>1.750564</td>\n",
       "      <td>0.374269</td>\n",
       "      <td>0.123551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.495400</td>\n",
       "      <td>1.373624</td>\n",
       "      <td>0.584795</td>\n",
       "      <td>0.291070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.122500</td>\n",
       "      <td>1.136954</td>\n",
       "      <td>0.660819</td>\n",
       "      <td>0.407164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.824900</td>\n",
       "      <td>1.075731</td>\n",
       "      <td>0.654971</td>\n",
       "      <td>0.442195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.546800</td>\n",
       "      <td>1.055672</td>\n",
       "      <td>0.672515</td>\n",
       "      <td>0.428174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.369900</td>\n",
       "      <td>1.060412</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.565986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.254000</td>\n",
       "      <td>1.107995</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.508286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.214100</td>\n",
       "      <td>1.161860</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.522565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.126800</td>\n",
       "      <td>1.208541</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.499255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.096700</td>\n",
       "      <td>1.144718</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.533485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.051200</td>\n",
       "      <td>1.206847</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.545631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.033200</td>\n",
       "      <td>1.301831</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.544424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.028700</td>\n",
       "      <td>1.258872</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.573580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.013700</td>\n",
       "      <td>1.372364</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.520679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.014600</td>\n",
       "      <td>1.471857</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.559082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.015500</td>\n",
       "      <td>1.438507</td>\n",
       "      <td>0.690058</td>\n",
       "      <td>0.526203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.007200</td>\n",
       "      <td>1.499062</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.553341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>1.473716</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.552297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>1.480993</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.575294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.004900</td>\n",
       "      <td>1.503788</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.566557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>1.510295</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.565159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>1.509485</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.528504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>1.521041</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.532499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>1.529684</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.532499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.538370</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.532499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>1.547123</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.532499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>1.555838</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.532499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.560757</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.532499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.565020</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.532499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.567239</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.532499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.568778</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.532499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.569689</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.532499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>1.570069</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.532499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SI2M-Lab/DarijaBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SI2M-Lab/DarijaBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e3baa77e4584e7a852d4a138574484f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0babd3ff3b3b416d8b464a411149310b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:28, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.934100</td>\n",
       "      <td>1.750564</td>\n",
       "      <td>0.374269</td>\n",
       "      <td>0.123551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.495400</td>\n",
       "      <td>1.373624</td>\n",
       "      <td>0.584795</td>\n",
       "      <td>0.291070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.122500</td>\n",
       "      <td>1.136954</td>\n",
       "      <td>0.660819</td>\n",
       "      <td>0.407164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.824900</td>\n",
       "      <td>1.075731</td>\n",
       "      <td>0.654971</td>\n",
       "      <td>0.442195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.546800</td>\n",
       "      <td>1.055672</td>\n",
       "      <td>0.672515</td>\n",
       "      <td>0.428174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.369900</td>\n",
       "      <td>1.060412</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.565986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.254000</td>\n",
       "      <td>1.107995</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.508286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.214100</td>\n",
       "      <td>1.161860</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.522565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.126800</td>\n",
       "      <td>1.208541</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.499255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.096700</td>\n",
       "      <td>1.144718</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.533485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.051200</td>\n",
       "      <td>1.206847</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.545631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.033200</td>\n",
       "      <td>1.301831</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.544424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.028700</td>\n",
       "      <td>1.258872</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.573580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.013700</td>\n",
       "      <td>1.372364</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.520679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.014600</td>\n",
       "      <td>1.471857</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.559082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.015500</td>\n",
       "      <td>1.438507</td>\n",
       "      <td>0.690058</td>\n",
       "      <td>0.526203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.007200</td>\n",
       "      <td>1.499062</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.553341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>1.473716</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.552297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>1.480993</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.575294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.004900</td>\n",
       "      <td>1.503788</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.566557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>1.510295</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.565159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>1.509485</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.528504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>1.521041</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.532499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>1.529684</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.532499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.538370</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.532499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>1.547123</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.532499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>1.555838</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.532499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.560757</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.532499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.565020</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.532499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.567239</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.532499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.568778</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.532499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.569689</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.532499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>1.570069</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.532499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SI2M-Lab/DarijaBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SI2M-Lab/DarijaBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4d8a5c2c09d476b88dbb2912242d3dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24ed7777db8b4f458b88fbb389b0886c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:28, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.934100</td>\n",
       "      <td>1.750564</td>\n",
       "      <td>0.374269</td>\n",
       "      <td>0.123551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.495400</td>\n",
       "      <td>1.373624</td>\n",
       "      <td>0.584795</td>\n",
       "      <td>0.291070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.122500</td>\n",
       "      <td>1.136954</td>\n",
       "      <td>0.660819</td>\n",
       "      <td>0.407164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.824900</td>\n",
       "      <td>1.075731</td>\n",
       "      <td>0.654971</td>\n",
       "      <td>0.442195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.546800</td>\n",
       "      <td>1.055672</td>\n",
       "      <td>0.672515</td>\n",
       "      <td>0.428174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.369900</td>\n",
       "      <td>1.060412</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.565986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.254000</td>\n",
       "      <td>1.107995</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.508286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.214100</td>\n",
       "      <td>1.161860</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.522565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.126800</td>\n",
       "      <td>1.208541</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.499255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.096700</td>\n",
       "      <td>1.144718</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.533485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.051200</td>\n",
       "      <td>1.206847</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.545631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.033200</td>\n",
       "      <td>1.301831</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.544424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.028700</td>\n",
       "      <td>1.258872</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.573580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.013700</td>\n",
       "      <td>1.372364</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.520679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.014600</td>\n",
       "      <td>1.471857</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.559082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.015500</td>\n",
       "      <td>1.438507</td>\n",
       "      <td>0.690058</td>\n",
       "      <td>0.526203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.007200</td>\n",
       "      <td>1.499062</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.553341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>1.473716</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.552297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>1.480993</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.575294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.004900</td>\n",
       "      <td>1.503788</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.566557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>1.510295</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.565159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>1.509485</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.528504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>1.521041</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.532499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>1.529684</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.532499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.538370</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.532499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>1.547123</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.532499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>1.555838</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.532499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.560757</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.532499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.565020</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.532499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.567239</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.532499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.568778</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.532499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.569689</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.532499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>1.570069</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.532499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['review', 'label'],\n",
       "        num_rows: 680\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['review', 'label'],\n",
       "        num_rows: 171\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorRoBERTa, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at otmangi/MorRoBERTa and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0974b8e4fc44fca9990a59d7cf198f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd17b29346f14412a932f40f5d1c2cb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:15, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.925800</td>\n",
       "      <td>1.750220</td>\n",
       "      <td>0.426901</td>\n",
       "      <td>0.183400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.477800</td>\n",
       "      <td>1.425571</td>\n",
       "      <td>0.549708</td>\n",
       "      <td>0.270164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.112300</td>\n",
       "      <td>1.247542</td>\n",
       "      <td>0.608187</td>\n",
       "      <td>0.361305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.831100</td>\n",
       "      <td>1.104753</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.398379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.558300</td>\n",
       "      <td>1.107980</td>\n",
       "      <td>0.643275</td>\n",
       "      <td>0.426358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.380900</td>\n",
       "      <td>1.116383</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>0.441899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.266300</td>\n",
       "      <td>1.243193</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>0.449181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.189200</td>\n",
       "      <td>1.262129</td>\n",
       "      <td>0.625731</td>\n",
       "      <td>0.417048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.114400</td>\n",
       "      <td>1.295828</td>\n",
       "      <td>0.660819</td>\n",
       "      <td>0.491646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.065200</td>\n",
       "      <td>1.418666</td>\n",
       "      <td>0.637427</td>\n",
       "      <td>0.440647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.043500</td>\n",
       "      <td>1.425719</td>\n",
       "      <td>0.654971</td>\n",
       "      <td>0.494712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.024400</td>\n",
       "      <td>1.431075</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.487977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.018800</td>\n",
       "      <td>1.479843</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>0.424112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.012200</td>\n",
       "      <td>1.531973</td>\n",
       "      <td>0.672515</td>\n",
       "      <td>0.508673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.009900</td>\n",
       "      <td>1.538725</td>\n",
       "      <td>0.672515</td>\n",
       "      <td>0.513093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.008100</td>\n",
       "      <td>1.535553</td>\n",
       "      <td>0.654971</td>\n",
       "      <td>0.495980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>1.564612</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.532268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>1.581018</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.534131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>1.600410</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.534131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>1.628821</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.531097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.004900</td>\n",
       "      <td>1.625074</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.534748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>1.620709</td>\n",
       "      <td>0.672515</td>\n",
       "      <td>0.515657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>1.634056</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.525900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>1.651397</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.534748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>1.661937</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.529312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>1.668468</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.531097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>1.669912</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.531097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.668850</td>\n",
       "      <td>0.672515</td>\n",
       "      <td>0.534418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>1.670836</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.537395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.671088</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.536667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>1.671210</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.536667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.671447</td>\n",
       "      <td>0.672515</td>\n",
       "      <td>0.534418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.671645</td>\n",
       "      <td>0.672515</td>\n",
       "      <td>0.534418</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorRoBERTa, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at otmangi/MorRoBERTa and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0af97de4d88241e5b4ca906379dc133a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7371c29166784f5a946b76322520d85d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:15, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.925800</td>\n",
       "      <td>1.750220</td>\n",
       "      <td>0.426901</td>\n",
       "      <td>0.183400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.477800</td>\n",
       "      <td>1.425571</td>\n",
       "      <td>0.549708</td>\n",
       "      <td>0.270164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.112300</td>\n",
       "      <td>1.247542</td>\n",
       "      <td>0.608187</td>\n",
       "      <td>0.361305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.831100</td>\n",
       "      <td>1.104753</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.398379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.558300</td>\n",
       "      <td>1.107980</td>\n",
       "      <td>0.643275</td>\n",
       "      <td>0.426358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.380900</td>\n",
       "      <td>1.116383</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>0.441899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.266300</td>\n",
       "      <td>1.243193</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>0.449181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.189200</td>\n",
       "      <td>1.262129</td>\n",
       "      <td>0.625731</td>\n",
       "      <td>0.417048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.114400</td>\n",
       "      <td>1.295828</td>\n",
       "      <td>0.660819</td>\n",
       "      <td>0.491646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.065200</td>\n",
       "      <td>1.418666</td>\n",
       "      <td>0.637427</td>\n",
       "      <td>0.440647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.043500</td>\n",
       "      <td>1.425719</td>\n",
       "      <td>0.654971</td>\n",
       "      <td>0.494712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.024400</td>\n",
       "      <td>1.431075</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.487977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.018800</td>\n",
       "      <td>1.479843</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>0.424112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.012200</td>\n",
       "      <td>1.531973</td>\n",
       "      <td>0.672515</td>\n",
       "      <td>0.508673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.009900</td>\n",
       "      <td>1.538725</td>\n",
       "      <td>0.672515</td>\n",
       "      <td>0.513093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.008100</td>\n",
       "      <td>1.535553</td>\n",
       "      <td>0.654971</td>\n",
       "      <td>0.495980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>1.564612</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.532268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>1.581018</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.534131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>1.600410</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.534131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>1.628821</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.531097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.004900</td>\n",
       "      <td>1.625074</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.534748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>1.620709</td>\n",
       "      <td>0.672515</td>\n",
       "      <td>0.515657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>1.634056</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.525900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>1.651397</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.534748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>1.661937</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.529312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>1.668468</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.531097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>1.669912</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.531097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.668850</td>\n",
       "      <td>0.672515</td>\n",
       "      <td>0.534418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>1.670836</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.537395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.671088</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.536667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>1.671210</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.536667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.671447</td>\n",
       "      <td>0.672515</td>\n",
       "      <td>0.534418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.671645</td>\n",
       "      <td>0.672515</td>\n",
       "      <td>0.534418</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorRoBERTa, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at otmangi/MorRoBERTa and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cef8f4ad5dc64869bdde2f2e40632b1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fa19f67098147a098c354529bb642c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:15, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.925800</td>\n",
       "      <td>1.750220</td>\n",
       "      <td>0.426901</td>\n",
       "      <td>0.183400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.477800</td>\n",
       "      <td>1.425571</td>\n",
       "      <td>0.549708</td>\n",
       "      <td>0.270164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.112300</td>\n",
       "      <td>1.247542</td>\n",
       "      <td>0.608187</td>\n",
       "      <td>0.361305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.831100</td>\n",
       "      <td>1.104753</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.398379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.558300</td>\n",
       "      <td>1.107980</td>\n",
       "      <td>0.643275</td>\n",
       "      <td>0.426358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.380900</td>\n",
       "      <td>1.116383</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>0.441899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.266300</td>\n",
       "      <td>1.243193</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>0.449181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.189200</td>\n",
       "      <td>1.262129</td>\n",
       "      <td>0.625731</td>\n",
       "      <td>0.417048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.114400</td>\n",
       "      <td>1.295828</td>\n",
       "      <td>0.660819</td>\n",
       "      <td>0.491646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.065200</td>\n",
       "      <td>1.418666</td>\n",
       "      <td>0.637427</td>\n",
       "      <td>0.440647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.043500</td>\n",
       "      <td>1.425719</td>\n",
       "      <td>0.654971</td>\n",
       "      <td>0.494712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.024400</td>\n",
       "      <td>1.431075</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.487977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.018800</td>\n",
       "      <td>1.479843</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>0.424112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.012200</td>\n",
       "      <td>1.531973</td>\n",
       "      <td>0.672515</td>\n",
       "      <td>0.508673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.009900</td>\n",
       "      <td>1.538725</td>\n",
       "      <td>0.672515</td>\n",
       "      <td>0.513093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.008100</td>\n",
       "      <td>1.535553</td>\n",
       "      <td>0.654971</td>\n",
       "      <td>0.495980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>1.564612</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.532268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>1.581018</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.534131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>1.600410</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.534131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>1.628821</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.531097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.004900</td>\n",
       "      <td>1.625074</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.534748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>1.620709</td>\n",
       "      <td>0.672515</td>\n",
       "      <td>0.515657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>1.634056</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.525900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>1.651397</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.534748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>1.661937</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.529312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>1.668468</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.531097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>1.669912</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.531097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.668850</td>\n",
       "      <td>0.672515</td>\n",
       "      <td>0.534418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>1.670836</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.537395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.671088</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.536667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>1.671210</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.536667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.671447</td>\n",
       "      <td>0.672515</td>\n",
       "      <td>0.534418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.671645</td>\n",
       "      <td>0.672515</td>\n",
       "      <td>0.534418</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorRoBERTa, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at otmangi/MorRoBERTa and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a02135e4441247ae9c3dfe560b7c89ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cf4f69724a044efb423427dcc133362",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:15, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.960700</td>\n",
       "      <td>1.708425</td>\n",
       "      <td>0.426901</td>\n",
       "      <td>0.146707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.509100</td>\n",
       "      <td>1.396394</td>\n",
       "      <td>0.584795</td>\n",
       "      <td>0.238747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.086900</td>\n",
       "      <td>1.248222</td>\n",
       "      <td>0.596491</td>\n",
       "      <td>0.247428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.851500</td>\n",
       "      <td>1.241084</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.299943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.527000</td>\n",
       "      <td>1.238433</td>\n",
       "      <td>0.625731</td>\n",
       "      <td>0.315012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.376900</td>\n",
       "      <td>1.197382</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.378030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.283400</td>\n",
       "      <td>1.393095</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>0.357373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.170600</td>\n",
       "      <td>1.283134</td>\n",
       "      <td>0.672515</td>\n",
       "      <td>0.398453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.108000</td>\n",
       "      <td>1.422924</td>\n",
       "      <td>0.654971</td>\n",
       "      <td>0.389442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.084500</td>\n",
       "      <td>1.428200</td>\n",
       "      <td>0.654971</td>\n",
       "      <td>0.373165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.049000</td>\n",
       "      <td>1.511813</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>0.408527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.028900</td>\n",
       "      <td>1.525721</td>\n",
       "      <td>0.660819</td>\n",
       "      <td>0.415758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.018200</td>\n",
       "      <td>1.523869</td>\n",
       "      <td>0.660819</td>\n",
       "      <td>0.415685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.012700</td>\n",
       "      <td>1.572509</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>0.382087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.012700</td>\n",
       "      <td>1.574674</td>\n",
       "      <td>0.654971</td>\n",
       "      <td>0.414651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.009100</td>\n",
       "      <td>1.603601</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.421084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.007300</td>\n",
       "      <td>1.613298</td>\n",
       "      <td>0.672515</td>\n",
       "      <td>0.423133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>1.609843</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.427303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>1.616959</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.427303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>1.638560</td>\n",
       "      <td>0.672515</td>\n",
       "      <td>0.424888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>1.662765</td>\n",
       "      <td>0.672515</td>\n",
       "      <td>0.423297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>1.676681</td>\n",
       "      <td>0.672515</td>\n",
       "      <td>0.425152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>1.680568</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.422950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>1.679278</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.429169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>1.680970</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.429169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>1.686216</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.429169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>1.696519</td>\n",
       "      <td>0.672515</td>\n",
       "      <td>0.425378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>1.699594</td>\n",
       "      <td>0.672515</td>\n",
       "      <td>0.425378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>1.702537</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.429169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.709839</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.429169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>1.712273</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.429169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>1.713359</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.429169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>1.713850</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.429169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorRoBERTa, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at otmangi/MorRoBERTa and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73308823af5f4c74bb536c5d995c39e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6967c8cc63504dd3a627157966d0c9ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:15, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.960700</td>\n",
       "      <td>1.708425</td>\n",
       "      <td>0.426901</td>\n",
       "      <td>0.146707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.509100</td>\n",
       "      <td>1.396394</td>\n",
       "      <td>0.584795</td>\n",
       "      <td>0.238747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.086900</td>\n",
       "      <td>1.248222</td>\n",
       "      <td>0.596491</td>\n",
       "      <td>0.247428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.851500</td>\n",
       "      <td>1.241084</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.299943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.527000</td>\n",
       "      <td>1.238433</td>\n",
       "      <td>0.625731</td>\n",
       "      <td>0.315012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.376900</td>\n",
       "      <td>1.197382</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.378030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.283400</td>\n",
       "      <td>1.393095</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>0.357373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.170600</td>\n",
       "      <td>1.283134</td>\n",
       "      <td>0.672515</td>\n",
       "      <td>0.398453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.108000</td>\n",
       "      <td>1.422924</td>\n",
       "      <td>0.654971</td>\n",
       "      <td>0.389442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.084500</td>\n",
       "      <td>1.428200</td>\n",
       "      <td>0.654971</td>\n",
       "      <td>0.373165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.049000</td>\n",
       "      <td>1.511813</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>0.408527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.028900</td>\n",
       "      <td>1.525721</td>\n",
       "      <td>0.660819</td>\n",
       "      <td>0.415758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.018200</td>\n",
       "      <td>1.523869</td>\n",
       "      <td>0.660819</td>\n",
       "      <td>0.415685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.012700</td>\n",
       "      <td>1.572509</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>0.382087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.012700</td>\n",
       "      <td>1.574674</td>\n",
       "      <td>0.654971</td>\n",
       "      <td>0.414651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.009100</td>\n",
       "      <td>1.603601</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.421084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.007300</td>\n",
       "      <td>1.613298</td>\n",
       "      <td>0.672515</td>\n",
       "      <td>0.423133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>1.609843</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.427303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>1.616959</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.427303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>1.638560</td>\n",
       "      <td>0.672515</td>\n",
       "      <td>0.424888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>1.662765</td>\n",
       "      <td>0.672515</td>\n",
       "      <td>0.423297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>1.676681</td>\n",
       "      <td>0.672515</td>\n",
       "      <td>0.425152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>1.680568</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.422950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>1.679278</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.429169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>1.680970</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.429169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>1.686216</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.429169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>1.696519</td>\n",
       "      <td>0.672515</td>\n",
       "      <td>0.425378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>1.699594</td>\n",
       "      <td>0.672515</td>\n",
       "      <td>0.425378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>1.702537</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.429169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.709839</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.429169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>1.712273</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.429169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>1.713359</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.429169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>1.713850</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.429169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorRoBERTa, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at otmangi/MorRoBERTa and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "654df44f2fc64491bbed5a5b7a775a65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dba4552e05584a5fb1b1104a6c44a141",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:15, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.960700</td>\n",
       "      <td>1.708425</td>\n",
       "      <td>0.426901</td>\n",
       "      <td>0.146707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.509100</td>\n",
       "      <td>1.396394</td>\n",
       "      <td>0.584795</td>\n",
       "      <td>0.238747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.086900</td>\n",
       "      <td>1.248222</td>\n",
       "      <td>0.596491</td>\n",
       "      <td>0.247428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.851500</td>\n",
       "      <td>1.241084</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.299943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.527000</td>\n",
       "      <td>1.238433</td>\n",
       "      <td>0.625731</td>\n",
       "      <td>0.315012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.376900</td>\n",
       "      <td>1.197382</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.378030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.283400</td>\n",
       "      <td>1.393095</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>0.357373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.170600</td>\n",
       "      <td>1.283134</td>\n",
       "      <td>0.672515</td>\n",
       "      <td>0.398453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.108000</td>\n",
       "      <td>1.422924</td>\n",
       "      <td>0.654971</td>\n",
       "      <td>0.389442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.084500</td>\n",
       "      <td>1.428200</td>\n",
       "      <td>0.654971</td>\n",
       "      <td>0.373165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.049000</td>\n",
       "      <td>1.511813</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>0.408527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.028900</td>\n",
       "      <td>1.525721</td>\n",
       "      <td>0.660819</td>\n",
       "      <td>0.415758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.018200</td>\n",
       "      <td>1.523869</td>\n",
       "      <td>0.660819</td>\n",
       "      <td>0.415685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.012700</td>\n",
       "      <td>1.572509</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>0.382087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.012700</td>\n",
       "      <td>1.574674</td>\n",
       "      <td>0.654971</td>\n",
       "      <td>0.414651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.009100</td>\n",
       "      <td>1.603601</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.421084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.007300</td>\n",
       "      <td>1.613298</td>\n",
       "      <td>0.672515</td>\n",
       "      <td>0.423133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>1.609843</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.427303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>1.616959</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.427303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>1.638560</td>\n",
       "      <td>0.672515</td>\n",
       "      <td>0.424888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>1.662765</td>\n",
       "      <td>0.672515</td>\n",
       "      <td>0.423297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>1.676681</td>\n",
       "      <td>0.672515</td>\n",
       "      <td>0.425152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>1.680568</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.422950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>1.679278</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.429169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>1.680970</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.429169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>1.686216</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.429169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>1.696519</td>\n",
       "      <td>0.672515</td>\n",
       "      <td>0.425378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>1.699594</td>\n",
       "      <td>0.672515</td>\n",
       "      <td>0.425378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>1.702537</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.429169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.709839</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.429169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>1.712273</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.429169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>1.713359</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.429169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>1.713850</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.429169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorRoBERTa, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at otmangi/MorRoBERTa and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "695dd71cb5f147ea9f53d8fedfdadd51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cf5c6f801f648b38b973d4367684983",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:15, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.933400</td>\n",
       "      <td>1.669819</td>\n",
       "      <td>0.438596</td>\n",
       "      <td>0.164791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.458000</td>\n",
       "      <td>1.393062</td>\n",
       "      <td>0.508772</td>\n",
       "      <td>0.244949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.140000</td>\n",
       "      <td>1.164517</td>\n",
       "      <td>0.619883</td>\n",
       "      <td>0.340355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.851200</td>\n",
       "      <td>1.094415</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>0.388572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.607100</td>\n",
       "      <td>1.012347</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.448373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.413600</td>\n",
       "      <td>1.024966</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.506056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.275000</td>\n",
       "      <td>1.009048</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.576027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.199300</td>\n",
       "      <td>1.053709</td>\n",
       "      <td>0.690058</td>\n",
       "      <td>0.520571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.112600</td>\n",
       "      <td>1.133862</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.557730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.071300</td>\n",
       "      <td>1.217952</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.539689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.046800</td>\n",
       "      <td>1.244998</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.579550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.028600</td>\n",
       "      <td>1.318707</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.589720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.024500</td>\n",
       "      <td>1.333959</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.614669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.015100</td>\n",
       "      <td>1.391457</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.605390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.011000</td>\n",
       "      <td>1.369987</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.579414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.008700</td>\n",
       "      <td>1.400009</td>\n",
       "      <td>0.690058</td>\n",
       "      <td>0.579325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.007100</td>\n",
       "      <td>1.415524</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.581631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>1.403911</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.581631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>1.409697</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.581631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.005900</td>\n",
       "      <td>1.417428</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.584504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>1.429666</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.607063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.004800</td>\n",
       "      <td>1.446203</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.607063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>1.454778</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.610734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>1.463340</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.613949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>1.463742</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.613949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>1.465563</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.610734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>1.463382</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.607472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>1.466189</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.607472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.469285</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.607472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>1.470962</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.587687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.472803</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.587687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>1.473714</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.587687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>1.473940</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.587687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorRoBERTa, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at otmangi/MorRoBERTa and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cccbd51283714c09bf4c867dbe2634cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53c060ae30244efdbbc8a0b2a4a1c047",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:15, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.933400</td>\n",
       "      <td>1.669819</td>\n",
       "      <td>0.438596</td>\n",
       "      <td>0.164791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.458000</td>\n",
       "      <td>1.393062</td>\n",
       "      <td>0.508772</td>\n",
       "      <td>0.244949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.140000</td>\n",
       "      <td>1.164517</td>\n",
       "      <td>0.619883</td>\n",
       "      <td>0.340355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.851200</td>\n",
       "      <td>1.094415</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>0.388572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.607100</td>\n",
       "      <td>1.012347</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.448373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.413600</td>\n",
       "      <td>1.024966</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.506056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.275000</td>\n",
       "      <td>1.009048</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.576027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.199300</td>\n",
       "      <td>1.053709</td>\n",
       "      <td>0.690058</td>\n",
       "      <td>0.520571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.112600</td>\n",
       "      <td>1.133862</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.557730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.071300</td>\n",
       "      <td>1.217952</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.539689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.046800</td>\n",
       "      <td>1.244998</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.579550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.028600</td>\n",
       "      <td>1.318707</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.589720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.024500</td>\n",
       "      <td>1.333959</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.614669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.015100</td>\n",
       "      <td>1.391457</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.605390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.011000</td>\n",
       "      <td>1.369987</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.579414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.008700</td>\n",
       "      <td>1.400009</td>\n",
       "      <td>0.690058</td>\n",
       "      <td>0.579325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.007100</td>\n",
       "      <td>1.415524</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.581631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>1.403911</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.581631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>1.409697</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.581631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.005900</td>\n",
       "      <td>1.417428</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.584504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>1.429666</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.607063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.004800</td>\n",
       "      <td>1.446203</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.607063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>1.454778</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.610734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>1.463340</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.613949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>1.463742</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.613949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>1.465563</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.610734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>1.463382</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.607472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>1.466189</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.607472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.469285</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.607472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>1.470962</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.587687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.472803</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.587687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>1.473714</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.587687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>1.473940</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.587687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorRoBERTa, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at otmangi/MorRoBERTa and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6a9ae5518f346808b6230c2afe35c57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73eae36085ed4747b56d279c2e43e3fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:15, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.933400</td>\n",
       "      <td>1.669819</td>\n",
       "      <td>0.438596</td>\n",
       "      <td>0.164791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.458000</td>\n",
       "      <td>1.393062</td>\n",
       "      <td>0.508772</td>\n",
       "      <td>0.244949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.140000</td>\n",
       "      <td>1.164517</td>\n",
       "      <td>0.619883</td>\n",
       "      <td>0.340355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.851200</td>\n",
       "      <td>1.094415</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>0.388572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.607100</td>\n",
       "      <td>1.012347</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.448373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.413600</td>\n",
       "      <td>1.024966</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.506056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.275000</td>\n",
       "      <td>1.009048</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.576027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.199300</td>\n",
       "      <td>1.053709</td>\n",
       "      <td>0.690058</td>\n",
       "      <td>0.520571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.112600</td>\n",
       "      <td>1.133862</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.557730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.071300</td>\n",
       "      <td>1.217952</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.539689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.046800</td>\n",
       "      <td>1.244998</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.579550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.028600</td>\n",
       "      <td>1.318707</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.589720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.024500</td>\n",
       "      <td>1.333959</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.614669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.015100</td>\n",
       "      <td>1.391457</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.605390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.011000</td>\n",
       "      <td>1.369987</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.579414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.008700</td>\n",
       "      <td>1.400009</td>\n",
       "      <td>0.690058</td>\n",
       "      <td>0.579325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.007100</td>\n",
       "      <td>1.415524</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.581631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>1.403911</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.581631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>1.409697</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.581631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.005900</td>\n",
       "      <td>1.417428</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.584504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>1.429666</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.607063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.004800</td>\n",
       "      <td>1.446203</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.607063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>1.454778</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.610734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>1.463340</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.613949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>1.463742</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.613949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>1.465563</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.610734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>1.463382</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.607472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>1.466189</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.607472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.469285</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.607472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>1.470962</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.587687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.472803</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.587687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>1.473714</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.587687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>1.473940</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.587687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['review', 'label'],\n",
       "        num_rows: 680\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['review', 'label'],\n",
       "        num_rows: 171\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorrBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at otmangi/MorrBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0dc1c8dd18444efb144e4fb642a9b40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eaaf5b3cb42415eb40e6765f43344e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:27, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.832700</td>\n",
       "      <td>1.497510</td>\n",
       "      <td>0.573099</td>\n",
       "      <td>0.288035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.188200</td>\n",
       "      <td>1.178828</td>\n",
       "      <td>0.608187</td>\n",
       "      <td>0.317424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.880400</td>\n",
       "      <td>1.049534</td>\n",
       "      <td>0.672515</td>\n",
       "      <td>0.394176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.601200</td>\n",
       "      <td>0.946682</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.520331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.395100</td>\n",
       "      <td>0.996129</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.563791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.207500</td>\n",
       "      <td>0.979982</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.588092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.182600</td>\n",
       "      <td>1.085568</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.504411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.137800</td>\n",
       "      <td>1.023577</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.611751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.090300</td>\n",
       "      <td>1.229767</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.524919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.070800</td>\n",
       "      <td>1.253977</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.562675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.056400</td>\n",
       "      <td>1.153859</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.517902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.043100</td>\n",
       "      <td>1.224657</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.557663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.034400</td>\n",
       "      <td>1.255494</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.550524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.020400</td>\n",
       "      <td>1.296028</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.549748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.037200</td>\n",
       "      <td>1.309421</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.515253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.024100</td>\n",
       "      <td>1.333126</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.525497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.034300</td>\n",
       "      <td>1.362712</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.516583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.020400</td>\n",
       "      <td>1.332285</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.519187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.028000</td>\n",
       "      <td>1.324451</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.536774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.023800</td>\n",
       "      <td>1.332950</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.549945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.019700</td>\n",
       "      <td>1.361990</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.549791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.025600</td>\n",
       "      <td>1.388566</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.553465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.022700</td>\n",
       "      <td>1.387561</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.551861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.025700</td>\n",
       "      <td>1.382452</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.555546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.024200</td>\n",
       "      <td>1.404666</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.549791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.020400</td>\n",
       "      <td>1.414943</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.555333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.015800</td>\n",
       "      <td>1.402186</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.533089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.024600</td>\n",
       "      <td>1.409547</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.533089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.024800</td>\n",
       "      <td>1.418478</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.533089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.021100</td>\n",
       "      <td>1.420103</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.533089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.013500</td>\n",
       "      <td>1.419725</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.533089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.025300</td>\n",
       "      <td>1.421014</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.533089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.017300</td>\n",
       "      <td>1.421254</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.533089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorrBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at otmangi/MorrBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd0a64bc923a483fbcd59bb695e5c056",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bed7bafd9c914d53a8a8312135adb210",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:27, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.832700</td>\n",
       "      <td>1.497510</td>\n",
       "      <td>0.573099</td>\n",
       "      <td>0.288035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.188200</td>\n",
       "      <td>1.178828</td>\n",
       "      <td>0.608187</td>\n",
       "      <td>0.317424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.880400</td>\n",
       "      <td>1.049534</td>\n",
       "      <td>0.672515</td>\n",
       "      <td>0.394176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.601200</td>\n",
       "      <td>0.946682</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.520331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.395100</td>\n",
       "      <td>0.996129</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.563791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.207500</td>\n",
       "      <td>0.979982</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.588092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.182600</td>\n",
       "      <td>1.085568</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.504411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.137800</td>\n",
       "      <td>1.023577</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.611751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.090300</td>\n",
       "      <td>1.229767</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.524919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.070800</td>\n",
       "      <td>1.253977</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.562675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.056400</td>\n",
       "      <td>1.153859</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.517902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.043100</td>\n",
       "      <td>1.224657</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.557663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.034400</td>\n",
       "      <td>1.255494</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.550524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.020400</td>\n",
       "      <td>1.296028</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.549748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.037200</td>\n",
       "      <td>1.309421</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.515253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.024100</td>\n",
       "      <td>1.333126</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.525497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.034300</td>\n",
       "      <td>1.362712</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.516583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.020400</td>\n",
       "      <td>1.332285</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.519187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.028000</td>\n",
       "      <td>1.324451</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.536774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.023800</td>\n",
       "      <td>1.332950</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.549945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.019700</td>\n",
       "      <td>1.361990</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.549791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.025600</td>\n",
       "      <td>1.388566</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.553465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.022700</td>\n",
       "      <td>1.387561</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.551861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.025700</td>\n",
       "      <td>1.382452</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.555546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.024200</td>\n",
       "      <td>1.404666</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.549791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.020400</td>\n",
       "      <td>1.414943</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.555333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.015800</td>\n",
       "      <td>1.402186</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.533089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.024600</td>\n",
       "      <td>1.409547</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.533089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.024800</td>\n",
       "      <td>1.418478</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.533089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.021100</td>\n",
       "      <td>1.420103</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.533089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.013500</td>\n",
       "      <td>1.419725</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.533089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.025300</td>\n",
       "      <td>1.421014</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.533089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.017300</td>\n",
       "      <td>1.421254</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.533089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorrBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at otmangi/MorrBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28994511ddd94ef38030e53ea5d0145e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1222f8079b84e1eb1b1769ca619202f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:27, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.832700</td>\n",
       "      <td>1.497510</td>\n",
       "      <td>0.573099</td>\n",
       "      <td>0.288035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.188200</td>\n",
       "      <td>1.178828</td>\n",
       "      <td>0.608187</td>\n",
       "      <td>0.317424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.880400</td>\n",
       "      <td>1.049534</td>\n",
       "      <td>0.672515</td>\n",
       "      <td>0.394176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.601200</td>\n",
       "      <td>0.946682</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.520331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.395100</td>\n",
       "      <td>0.996129</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.563791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.207500</td>\n",
       "      <td>0.979982</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.588092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.182600</td>\n",
       "      <td>1.085568</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.504411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.137800</td>\n",
       "      <td>1.023577</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.611751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.090300</td>\n",
       "      <td>1.229767</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.524919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.070800</td>\n",
       "      <td>1.253977</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.562675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.056400</td>\n",
       "      <td>1.153859</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.517902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.043100</td>\n",
       "      <td>1.224657</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.557663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.034400</td>\n",
       "      <td>1.255494</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.550524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.020400</td>\n",
       "      <td>1.296028</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.549748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.037200</td>\n",
       "      <td>1.309421</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.515253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.024100</td>\n",
       "      <td>1.333126</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.525497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.034300</td>\n",
       "      <td>1.362712</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.516583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.020400</td>\n",
       "      <td>1.332285</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.519187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.028000</td>\n",
       "      <td>1.324451</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.536774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.023800</td>\n",
       "      <td>1.332950</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.549945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.019700</td>\n",
       "      <td>1.361990</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.549791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.025600</td>\n",
       "      <td>1.388566</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.553465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.022700</td>\n",
       "      <td>1.387561</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.551861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.025700</td>\n",
       "      <td>1.382452</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.555546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.024200</td>\n",
       "      <td>1.404666</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.549791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.020400</td>\n",
       "      <td>1.414943</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.555333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.015800</td>\n",
       "      <td>1.402186</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.533089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.024600</td>\n",
       "      <td>1.409547</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.533089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.024800</td>\n",
       "      <td>1.418478</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.533089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.021100</td>\n",
       "      <td>1.420103</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.533089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.013500</td>\n",
       "      <td>1.419725</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.533089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.025300</td>\n",
       "      <td>1.421014</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.533089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.017300</td>\n",
       "      <td>1.421254</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.533089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorrBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at otmangi/MorrBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34d54309c4fa4708b901d1cb74938f93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b898cd5b92944f0b30c45a65e05964e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:27, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.888000</td>\n",
       "      <td>1.520045</td>\n",
       "      <td>0.538012</td>\n",
       "      <td>0.213114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.254600</td>\n",
       "      <td>1.212645</td>\n",
       "      <td>0.637427</td>\n",
       "      <td>0.266647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.835100</td>\n",
       "      <td>1.061955</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.299934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.636400</td>\n",
       "      <td>1.036336</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.416537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.351800</td>\n",
       "      <td>0.999189</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.481741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.226200</td>\n",
       "      <td>1.070827</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.446974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.185000</td>\n",
       "      <td>1.097269</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.450566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.096500</td>\n",
       "      <td>1.231263</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.435338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.075400</td>\n",
       "      <td>1.155699</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.447234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.065100</td>\n",
       "      <td>1.215822</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.442872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.042400</td>\n",
       "      <td>1.190771</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.466614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.039200</td>\n",
       "      <td>1.234463</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.474409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.027100</td>\n",
       "      <td>1.299995</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.460565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.028800</td>\n",
       "      <td>1.316073</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.461399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.026700</td>\n",
       "      <td>1.306208</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.483774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.014500</td>\n",
       "      <td>1.340969</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.458495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.031500</td>\n",
       "      <td>1.359336</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.478051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.023000</td>\n",
       "      <td>1.380483</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.482156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>1.387997</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.470760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.025200</td>\n",
       "      <td>1.406731</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.469716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.014600</td>\n",
       "      <td>1.414730</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.470760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.016000</td>\n",
       "      <td>1.433211</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.468813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.019400</td>\n",
       "      <td>1.441147</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.469716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.020400</td>\n",
       "      <td>1.452614</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.469716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.018000</td>\n",
       "      <td>1.454601</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.469716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.017700</td>\n",
       "      <td>1.463258</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.468813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.014500</td>\n",
       "      <td>1.466476</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.466650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.014200</td>\n",
       "      <td>1.472886</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.466650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.014600</td>\n",
       "      <td>1.479476</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.468813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.016800</td>\n",
       "      <td>1.486202</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.469716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.020900</td>\n",
       "      <td>1.485473</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.468813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.013600</td>\n",
       "      <td>1.485289</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.468813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.016000</td>\n",
       "      <td>1.485718</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.468813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorrBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at otmangi/MorrBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64d7da7f63374a38b1a666173f814154",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "462842c955214164bab7f841389dae57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:27, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.888000</td>\n",
       "      <td>1.520045</td>\n",
       "      <td>0.538012</td>\n",
       "      <td>0.213114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.254600</td>\n",
       "      <td>1.212645</td>\n",
       "      <td>0.637427</td>\n",
       "      <td>0.266647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.835100</td>\n",
       "      <td>1.061955</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.299934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.636400</td>\n",
       "      <td>1.036336</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.416537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.351800</td>\n",
       "      <td>0.999189</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.481741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.226200</td>\n",
       "      <td>1.070827</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.446974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.185000</td>\n",
       "      <td>1.097269</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.450566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.096500</td>\n",
       "      <td>1.231263</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.435338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.075400</td>\n",
       "      <td>1.155699</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.447234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.065100</td>\n",
       "      <td>1.215822</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.442872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.042400</td>\n",
       "      <td>1.190771</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.466614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.039200</td>\n",
       "      <td>1.234463</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.474409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.027100</td>\n",
       "      <td>1.299995</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.460565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.028800</td>\n",
       "      <td>1.316073</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.461399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.026700</td>\n",
       "      <td>1.306208</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.483774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.014500</td>\n",
       "      <td>1.340969</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.458495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.031500</td>\n",
       "      <td>1.359336</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.478051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.023000</td>\n",
       "      <td>1.380483</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.482156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>1.387997</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.470760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.025200</td>\n",
       "      <td>1.406731</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.469716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.014600</td>\n",
       "      <td>1.414730</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.470760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.016000</td>\n",
       "      <td>1.433211</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.468813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.019400</td>\n",
       "      <td>1.441147</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.469716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.020400</td>\n",
       "      <td>1.452614</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.469716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.018000</td>\n",
       "      <td>1.454601</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.469716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.017700</td>\n",
       "      <td>1.463258</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.468813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.014500</td>\n",
       "      <td>1.466476</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.466650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.014200</td>\n",
       "      <td>1.472886</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.466650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.014600</td>\n",
       "      <td>1.479476</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.468813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.016800</td>\n",
       "      <td>1.486202</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.469716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.020900</td>\n",
       "      <td>1.485473</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.468813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.013600</td>\n",
       "      <td>1.485289</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.468813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.016000</td>\n",
       "      <td>1.485718</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.468813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorrBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at otmangi/MorrBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3360c74bb8f244f1852a95f56700d7cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7fea7bcb59d4a85836e091d0d43ad0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:27, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.888000</td>\n",
       "      <td>1.520045</td>\n",
       "      <td>0.538012</td>\n",
       "      <td>0.213114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.254600</td>\n",
       "      <td>1.212645</td>\n",
       "      <td>0.637427</td>\n",
       "      <td>0.266647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.835100</td>\n",
       "      <td>1.061955</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.299934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.636400</td>\n",
       "      <td>1.036336</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.416537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.351800</td>\n",
       "      <td>0.999189</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.481741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.226200</td>\n",
       "      <td>1.070827</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.446974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.185000</td>\n",
       "      <td>1.097269</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.450566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.096500</td>\n",
       "      <td>1.231263</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.435338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.075400</td>\n",
       "      <td>1.155699</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.447234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.065100</td>\n",
       "      <td>1.215822</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.442872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.042400</td>\n",
       "      <td>1.190771</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.466614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.039200</td>\n",
       "      <td>1.234463</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.474409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.027100</td>\n",
       "      <td>1.299995</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.460565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.028800</td>\n",
       "      <td>1.316073</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.461399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.026700</td>\n",
       "      <td>1.306208</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.483774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.014500</td>\n",
       "      <td>1.340969</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.458495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.031500</td>\n",
       "      <td>1.359336</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.478051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.023000</td>\n",
       "      <td>1.380483</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.482156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>1.387997</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.470760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.025200</td>\n",
       "      <td>1.406731</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.469716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.014600</td>\n",
       "      <td>1.414730</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.470760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.016000</td>\n",
       "      <td>1.433211</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.468813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.019400</td>\n",
       "      <td>1.441147</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.469716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.020400</td>\n",
       "      <td>1.452614</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.469716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.018000</td>\n",
       "      <td>1.454601</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.469716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.017700</td>\n",
       "      <td>1.463258</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.468813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.014500</td>\n",
       "      <td>1.466476</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.466650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.014200</td>\n",
       "      <td>1.472886</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.466650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.014600</td>\n",
       "      <td>1.479476</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.468813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.016800</td>\n",
       "      <td>1.486202</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.469716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.020900</td>\n",
       "      <td>1.485473</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.468813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.013600</td>\n",
       "      <td>1.485289</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.468813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.016000</td>\n",
       "      <td>1.485718</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.468813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorrBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at otmangi/MorrBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c527cf04b2634978863fffdca730f730",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c261711cada41598db59a5ed0eb9e15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:27, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.844500</td>\n",
       "      <td>1.538296</td>\n",
       "      <td>0.520468</td>\n",
       "      <td>0.256481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.226400</td>\n",
       "      <td>1.139264</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.339390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.891500</td>\n",
       "      <td>0.980184</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.428125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.623300</td>\n",
       "      <td>0.866787</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.503114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.385600</td>\n",
       "      <td>0.895401</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.515022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.219500</td>\n",
       "      <td>0.965935</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.473700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.145400</td>\n",
       "      <td>1.079721</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.566565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.099600</td>\n",
       "      <td>1.059929</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.557290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.062200</td>\n",
       "      <td>1.165489</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.549524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.041800</td>\n",
       "      <td>1.109924</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.587428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.048100</td>\n",
       "      <td>1.230534</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.501148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.036800</td>\n",
       "      <td>1.201815</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.574232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.031100</td>\n",
       "      <td>1.186742</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.588398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.018500</td>\n",
       "      <td>1.173431</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.559116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.027000</td>\n",
       "      <td>1.155915</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.536193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.019100</td>\n",
       "      <td>1.311685</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.525887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.032900</td>\n",
       "      <td>1.272613</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.527197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.021400</td>\n",
       "      <td>1.182135</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.524405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.015300</td>\n",
       "      <td>1.214003</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.524522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.022800</td>\n",
       "      <td>1.290234</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.589425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.014600</td>\n",
       "      <td>1.299653</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.590571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.017900</td>\n",
       "      <td>1.278663</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.556644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.018100</td>\n",
       "      <td>1.263853</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.550443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.018600</td>\n",
       "      <td>1.287487</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.556644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.016600</td>\n",
       "      <td>1.288655</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.550443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.015300</td>\n",
       "      <td>1.275414</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.545078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1.279569</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.524394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.018100</td>\n",
       "      <td>1.297872</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.528954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.012300</td>\n",
       "      <td>1.307672</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.550571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>1.309299</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.550571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.024700</td>\n",
       "      <td>1.311514</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.550571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.009800</td>\n",
       "      <td>1.313272</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.610986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.017100</td>\n",
       "      <td>1.313912</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.610986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorrBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at otmangi/MorrBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69bdc9afc2a64639af4ff78ae977a75a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "870e28e3211648ada02aaa959dbf676e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:27, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.844500</td>\n",
       "      <td>1.538296</td>\n",
       "      <td>0.520468</td>\n",
       "      <td>0.256481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.226400</td>\n",
       "      <td>1.139264</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.339390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.891500</td>\n",
       "      <td>0.980184</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.428125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.623300</td>\n",
       "      <td>0.866787</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.503114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.385600</td>\n",
       "      <td>0.895401</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.515022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.219500</td>\n",
       "      <td>0.965935</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.473700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.145400</td>\n",
       "      <td>1.079721</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.566565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.099600</td>\n",
       "      <td>1.059929</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.557290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.062200</td>\n",
       "      <td>1.165489</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.549524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.041800</td>\n",
       "      <td>1.109924</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.587428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.048100</td>\n",
       "      <td>1.230534</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.501148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.036800</td>\n",
       "      <td>1.201815</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.574232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.031100</td>\n",
       "      <td>1.186742</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.588398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.018500</td>\n",
       "      <td>1.173431</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.559116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.027000</td>\n",
       "      <td>1.155915</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.536193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.019100</td>\n",
       "      <td>1.311685</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.525887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.032900</td>\n",
       "      <td>1.272613</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.527197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.021400</td>\n",
       "      <td>1.182135</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.524405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.015300</td>\n",
       "      <td>1.214003</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.524522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.022800</td>\n",
       "      <td>1.290234</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.589425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.014600</td>\n",
       "      <td>1.299653</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.590571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.017900</td>\n",
       "      <td>1.278663</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.556644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.018100</td>\n",
       "      <td>1.263853</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.550443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.018600</td>\n",
       "      <td>1.287487</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.556644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.016600</td>\n",
       "      <td>1.288655</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.550443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.015300</td>\n",
       "      <td>1.275414</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.545078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1.279569</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.524394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.018100</td>\n",
       "      <td>1.297872</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.528954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.012300</td>\n",
       "      <td>1.307672</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.550571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>1.309299</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.550571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.024700</td>\n",
       "      <td>1.311514</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.550571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.009800</td>\n",
       "      <td>1.313272</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.610986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.017100</td>\n",
       "      <td>1.313912</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.610986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otmangi/MorrBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at otmangi/MorrBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5497c876dfa3464da7a70c0a84ec1662",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc45242e84c7433d95af3c38f006a121",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 00:27, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.844500</td>\n",
       "      <td>1.538296</td>\n",
       "      <td>0.520468</td>\n",
       "      <td>0.256481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.226400</td>\n",
       "      <td>1.139264</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.339390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.891500</td>\n",
       "      <td>0.980184</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.428125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.623300</td>\n",
       "      <td>0.866787</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.503114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.385600</td>\n",
       "      <td>0.895401</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.515022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.219500</td>\n",
       "      <td>0.965935</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.473700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.145400</td>\n",
       "      <td>1.079721</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.566565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.099600</td>\n",
       "      <td>1.059929</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.557290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.062200</td>\n",
       "      <td>1.165489</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.549524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.041800</td>\n",
       "      <td>1.109924</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.587428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.048100</td>\n",
       "      <td>1.230534</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.501148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.036800</td>\n",
       "      <td>1.201815</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.574232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.031100</td>\n",
       "      <td>1.186742</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.588398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.018500</td>\n",
       "      <td>1.173431</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.559116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.027000</td>\n",
       "      <td>1.155915</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.536193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.019100</td>\n",
       "      <td>1.311685</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.525887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.032900</td>\n",
       "      <td>1.272613</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>0.527197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.021400</td>\n",
       "      <td>1.182135</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.524405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.015300</td>\n",
       "      <td>1.214003</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.524522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.022800</td>\n",
       "      <td>1.290234</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.589425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.014600</td>\n",
       "      <td>1.299653</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.590571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.017900</td>\n",
       "      <td>1.278663</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.556644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.018100</td>\n",
       "      <td>1.263853</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.550443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.018600</td>\n",
       "      <td>1.287487</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.556644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.016600</td>\n",
       "      <td>1.288655</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.550443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.015300</td>\n",
       "      <td>1.275414</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.545078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1.279569</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.524394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.018100</td>\n",
       "      <td>1.297872</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.528954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.012300</td>\n",
       "      <td>1.307672</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.550571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>1.309299</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.550571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.024700</td>\n",
       "      <td>1.311514</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.550571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.009800</td>\n",
       "      <td>1.313272</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.610986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.017100</td>\n",
       "      <td>1.313912</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.610986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SI2M-Lab/DarijaBERT</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.622234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alger-ia/dziribert</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.606202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>faisalq/EgyBERT</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.459321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>faisalq/SaudiBERT</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.619761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>otmangi/MorRoBERTa</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.614669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>otmangi/MorrBERT</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.611751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>tunis-ai/TunBERT</td>\n",
       "      <td>0.514620</td>\n",
       "      <td>0.304322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model  Accuracy        F1\n",
       "0   SI2M-Lab/DarijaBERT  0.771930  0.622234\n",
       "3    alger-ia/dziribert  0.730994  0.606202\n",
       "6       faisalq/EgyBERT  0.666667  0.459321\n",
       "8     faisalq/SaudiBERT  0.742690  0.619761\n",
       "11   otmangi/MorRoBERTa  0.719298  0.614669\n",
       "14     otmangi/MorrBERT  0.730994  0.611751\n",
       "17     tunis-ai/TunBERT  0.514620  0.304322"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\" \n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import pyarabic.araby as araby\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.initializers import TruncatedNormal\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from datasets import load_dataset, Dataset, concatenate_datasets\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', 1000)\n",
    "\n",
    "\n",
    "fname = 'dreviews_tc_2'\n",
    "log_file = fname + '.txt'\n",
    "\n",
    "with open(log_file, 'w') as f:\n",
    "    f.write('Model,Accuracy,F1\\n')\n",
    "\n",
    "\n",
    "dataset = load_dataset('ohidaoui/darija-reviews')\n",
    "\n",
    "\n",
    "df = pd.DataFrame(dataset['test'])\n",
    "\n",
    "display(len(df))\n",
    "      \n",
    "display(df.columns)\n",
    "display(df[:4])\n",
    "\n",
    "df['label'] = df['label'].replace('negative ', 'negative')\n",
    "\n",
    "c = df['topic'].value_counts()\n",
    "display(c)\n",
    "\n",
    "classes = set(df['topic'].values)\n",
    "display(classes)\n",
    "\n",
    "df['topic'] = df['topic'].astype('category')\n",
    "df['label'] = df['topic'].cat.codes\n",
    "\n",
    "df = df[['review', 'label']]\n",
    "classes_num = len(classes)\n",
    "display(classes_num)\n",
    "display(len(df))\n",
    "\n",
    "\n",
    "\n",
    "max_sequence_length = 128\n",
    "\n",
    "models = [ \n",
    "        'faisalq/EgyBERT',            \n",
    "    'faisalq/SaudiBERT',            \n",
    "    'tunis-ai/TunBERT',\n",
    "    'alger-ia/dziribert',\n",
    "    'SI2M-Lab/DarijaBERT',\n",
    "    'otmangi/MorRoBERTa',\n",
    "    'otmangi/MorrBERT'\n",
    "            \n",
    "]\n",
    "\n",
    "\n",
    "seeds = [0, 1, 42]\n",
    "\n",
    "for model_name in models:\n",
    "    for seed in seeds:\n",
    "        ds = Dataset.from_pandas(df)\n",
    "        ds = ds.train_test_split(test_size=0.2, seed = seed)\n",
    "        if seed==0:\n",
    "            display(ds)\n",
    "            \n",
    "        for i in range(3):\n",
    "            print(f'{model_name}, try:{i}')\n",
    "                  \n",
    "            tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "            model = AutoModelForSequenceClassification.from_pretrained(model_name,\n",
    "                                                                  num_labels=classes_num).to('cuda')                                                 \n",
    "            dataset_train = ds['train']\n",
    "            dataset_validation = ds['test']                                                    \n",
    "            \n",
    "          \n",
    "    \n",
    "            def preprocess_function(examples):\n",
    "                return tokenizer(examples['review'], truncation=True, padding=\"max_length\",\n",
    "                                max_length=max_sequence_length)\n",
    "            \n",
    "            \n",
    "            dataset_train = dataset_train.map(preprocess_function, batched=True)\n",
    "            dataset_validation = dataset_validation.map(preprocess_function, batched=True)\n",
    "            \n",
    "           \n",
    "            \n",
    "            def compute_metrics(eval_pred):\n",
    "                logits, labels = eval_pred\n",
    "                predictions = np.argmax(logits, axis=-1)    \n",
    "                acc = accuracy_score(labels, predictions)        \n",
    "                f1 = f1_score(labels, predictions, average='macro')   \n",
    "                with open(log_file, 'a') as f:\n",
    "                    f.write(f'{model_name},{acc},{f1}\\n')\n",
    "                return {'accuracy': acc, 'f1_score': f1}\n",
    "    \n",
    "    \n",
    "            \n",
    "            \n",
    "            epochs = 30\n",
    "            save_steps = 10000 #save checkpoint every 10000 steps\n",
    "            batch_size = 64\n",
    "            \n",
    "            training_args = TrainingArguments(\n",
    "                output_dir = 'bert/',\n",
    "                overwrite_output_dir=True,\n",
    "                num_train_epochs = epochs,\n",
    "                per_device_train_batch_size = batch_size,\n",
    "                per_device_eval_batch_size = batch_size,\n",
    "                save_steps = save_steps,\n",
    "                save_total_limit = 1, #only save the last 5 checkpoints\n",
    "                fp16=True,\n",
    "                learning_rate = 5e-5,  # 5e-5 is the default\n",
    "                logging_steps = 10, #50_000\n",
    "                evaluation_strategy = 'steps',\n",
    "                # evaluate_during_training = True,\n",
    "                eval_steps = 10\n",
    "                \n",
    "            )\n",
    "            \n",
    "            trainer = Trainer(\n",
    "                model = model,\n",
    "                args = training_args,\n",
    "                # data_collator=data_collator,\n",
    "                train_dataset=dataset_train,\n",
    "                eval_dataset=dataset_validation,\n",
    "                compute_metrics = compute_metrics\n",
    "            )\n",
    "            \n",
    "            \n",
    "            trainer.train()\n",
    "\n",
    "\n",
    "results = pd.read_csv(log_file)\n",
    "\n",
    "best_results = results.groupby('Model', as_index=False)['F1'].max()\n",
    "\n",
    "best_results = pd.merge(best_results, results, on=['Model', 'F1'])\n",
    "best_results = best_results[['Model', 'Accuracy', 'F1']]\n",
    "best_results = best_results.drop_duplicates()\n",
    "best_results.to_csv(f'{fname}.csv')\n",
    "display(best_results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a213ac86-934f-4e82-a949-0bcdcae2188d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220784d6-b06d-4429-adb8-0026654f9d49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8647cf08-3aa6-44eb-846f-4bed97554042",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e203fa6b-c9d7-44a4-b501-a67bfd3e4ce4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8794b705-31a1-45d7-8e88-4017a9c282aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
